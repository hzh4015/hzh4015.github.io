<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Notes</title>
  
  <subtitle>little notes</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-07-25T14:51:14.530Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>秋水一色</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka代码</title>
    <link href="http://example.com/2022/07/25/kafka%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/25/kafka%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-25T14:44:58.432Z</published>
    <updated>2022-07-25T14:51:14.530Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、kafkaProducer"><a href="#1、kafkaProducer" class="headerlink" title="1、kafkaProducer"></a>1、kafkaProducer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1kafkaProducer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、向kafka中生产数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;test_topic2&quot;</span>, <span class="string">&quot;java&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//发送数据到kafka中</span></span><br><span class="line">    producer.send(record)</span><br><span class="line">    producer.flush()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、KafkaConsumer"><a href="#2、KafkaConsumer" class="headerlink" title="2、KafkaConsumer"></a>2、KafkaConsumer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerRecord</span>, <span class="type">ConsumerRecords</span>, <span class="type">KafkaConsumer</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"><span class="keyword">import</span> java.&#123;lang, util&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3KafkaConsumer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建消费者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key 和value 反序列化的类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * earliest</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费</span></span><br><span class="line"><span class="comment">     * latest  默认</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产认值生的该分区下的数据</span></span><br><span class="line"><span class="comment">     * none</span></span><br><span class="line"><span class="comment">     * topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;auto.offset.reset&quot;</span>, <span class="string">&quot;earliest&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者组</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;asdasd&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> consumer = <span class="keyword">new</span> <span class="type">KafkaConsumer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、订阅一个topic,可以一次订阅多个topic</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    topics.add(<span class="string">&quot;student&quot;</span>)</span><br><span class="line">    consumer.subscribe(topics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      println(<span class="string">&quot;正在消费&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 消费数据, 需要这一个超时时间</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">val</span> consumerRecords: <span class="type">ConsumerRecords</span>[<span class="type">String</span>, <span class="type">String</span>] = consumer</span><br><span class="line">        .poll(<span class="type">Duration</span>.ofSeconds(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//解析数据</span></span><br><span class="line">      <span class="keyword">val</span> records: lang.<span class="type">Iterable</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = consumerRecords</span><br><span class="line">        .records(<span class="string">&quot;student&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> iterRecord: util.<span class="type">Iterator</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = records.iterator()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (iterRecord.hasNext) &#123;</span><br><span class="line">        <span class="comment">//获取一行数据</span></span><br><span class="line">        <span class="keyword">val</span> record: <span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>] = iterRecord.next()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> topic: <span class="type">String</span> = record.topic() <span class="comment">//topic</span></span><br><span class="line">        <span class="keyword">val</span> offset: <span class="type">Long</span> = record.offset() <span class="comment">//数据偏移量</span></span><br><span class="line">        <span class="keyword">val</span> key: <span class="type">String</span> = record.key() <span class="comment">//数据的key ,默认没有指定的情况下时null</span></span><br><span class="line">        <span class="keyword">val</span> value: <span class="type">String</span> = record.value() <span class="comment">//保存的数据</span></span><br><span class="line">        <span class="keyword">val</span> ts: <span class="type">Long</span> = record.timestamp() <span class="comment">//时间戳，默认时存入的时间</span></span><br><span class="line"></span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$topic</span>\t<span class="subst">$offset</span>\t<span class="subst">$key</span>\t<span class="subst">$value</span>\t<span class="subst">$ts</span>&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    consumer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、StudnetToKafka"><a href="#3、StudnetToKafka" class="headerlink" title="3、StudnetToKafka"></a>3、StudnetToKafka</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2StudnetToKafka</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取学生表将数据批量写入kafka中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (student &lt;- studentList) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;student&quot;</span>, student)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//发送数据到kafka中</span></span><br><span class="line">      producer.send(record)</span><br><span class="line">      producer.flush()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、统计车流量-练习"><a href="#4、统计车流量-练习" class="headerlink" title="4、统计车流量-练习"></a>4、统计车流量-练习</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.&#123;<span class="type">SerializableTimestampAssigner</span>, <span class="type">WatermarkStrategy</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.<span class="type">KafkaSource</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.<span class="type">OffsetsInitializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.&#123;<span class="type">RichSinkFunction</span>, <span class="type">SinkFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingEventTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Cars</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、从kafka中读取卡口过车数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">KafkaSource</span>[<span class="type">String</span>] = <span class="type">KafkaSource</span></span><br><span class="line">      .builder[<span class="type">String</span>]</span><br><span class="line">      .setBootstrapServers(<span class="string">&quot;master:9092,node1:9092,node2:9092&quot;</span>) <span class="comment">//kafka集群broker列表</span></span><br><span class="line">      .setTopics(<span class="string">&quot;cars&quot;</span>) <span class="comment">//指定topic</span></span><br><span class="line">      .setGroupId(<span class="string">&quot;asdasdasd&quot;</span>) <span class="comment">//指定消费者组，一条数据在一个组内只被消费一次</span></span><br><span class="line">      .setStartingOffsets(<span class="type">OffsetsInitializer</span>.latest()) <span class="comment">//读取数据的位置，earliest：读取所有的数据，latest：读取最新的数据</span></span><br><span class="line">      .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()) <span class="comment">//反序列的类</span></span><br><span class="line">      .build</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用kafka source</span></span><br><span class="line">    <span class="keyword">val</span> carsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.fromSource(source, <span class="type">WatermarkStrategy</span>.noWatermarks(), <span class="string">&quot;Kafka Source&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式数据，将卡口编号和时间字段取出来</span></span><br><span class="line"><span class="comment">     * fastJson</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> cardAndTimeDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = carsDS.map(line =&gt; &#123;</span><br><span class="line">      <span class="comment">//将字符串转换成json对象</span></span><br><span class="line">      <span class="keyword">val</span> jsonObj: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="comment">//使用字段名获取字段值</span></span><br><span class="line">      <span class="comment">//卡口编号</span></span><br><span class="line">      <span class="keyword">val</span> card: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;card&quot;</span>)</span><br><span class="line">      <span class="comment">//事件时间，事件时间要求时毫秒级别</span></span><br><span class="line">      <span class="keyword">val</span> time: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;time&quot;</span>) * <span class="number">1000</span></span><br><span class="line">      (card, time)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 设置时间字段和水位线</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> assDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = cardAndTimeDS.assignTimestampsAndWatermarks(</span><br><span class="line">      <span class="type">WatermarkStrategy</span></span><br><span class="line">        <span class="comment">//设置水位线的生成策略，前移5秒</span></span><br><span class="line">        .forBoundedOutOfOrderness(<span class="type">Duration</span>.ofSeconds(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">//设置时间字段</span></span><br><span class="line">        .withTimestampAssigner(<span class="keyword">new</span> <span class="type">SerializableTimestampAssigner</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: (<span class="type">Long</span>, <span class="type">Long</span>), recordTimestamp: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            <span class="comment">//时间字段</span></span><br><span class="line">            element._2</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计车流量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = assDS.map(kv =&gt; (kv._1, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照卡口分组</span></span><br><span class="line">    <span class="keyword">val</span> keyBYDS: <span class="type">KeyedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>] = kvDS.keyBy(_._1)</span><br><span class="line">    <span class="comment">//开窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>, <span class="type">TimeWindow</span>] = keyBYDS</span><br><span class="line">      .window(<span class="type">SlidingEventTimeWindows</span>.of(<span class="type">Time</span>.minutes(<span class="number">15</span>), <span class="type">Time</span>.minutes(<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计车流量</span></span><br><span class="line">    <span class="keyword">val</span> flowDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将统计的结果保存到mysql中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    flowDS.addSink(<span class="keyword">new</span> <span class="type">RichSinkFunction</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">//插入数据</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: (<span class="type">Long</span>, <span class="type">Int</span>), context: <span class="type">SinkFunction</span>.<span class="type">Context</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;数据写入mysql&quot;</span>)</span><br><span class="line">        stat.setLong(<span class="number">1</span>, value._1)</span><br><span class="line">        stat.setInt(<span class="number">2</span>, value._2)</span><br><span class="line"></span><br><span class="line">        stat.execute()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> con: <span class="type">Connection</span> = _</span><br><span class="line">      <span class="keyword">var</span> stat: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//创建链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//1、加载驱动</span></span><br><span class="line">        <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">        <span class="comment">//创建链接</span></span><br><span class="line">        con = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master:3306/bigdata&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">        <span class="comment">//编写插入数据的sql</span></span><br><span class="line">        <span class="comment">//replace :如果不存在插入，如果存在就替换，需要在表中设置主键</span></span><br><span class="line">        stat = con.prepareStatement(<span class="string">&quot;replace into card_flow(card,flow) values(?,?)&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//关闭链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        stat.close()</span><br><span class="line">        con.close()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka搭建</title>
    <link href="http://example.com/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-25T14:24:58.265Z</published>
    <updated>2022-07-25T14:51:32.281Z</updated>
    
    <content type="html"><![CDATA[<h2 id="搭建Kafka"><a href="#搭建Kafka" class="headerlink" title="搭建Kafka"></a>搭建Kafka</h2><h3 id="1、上传解压修改环境变量"><a href="#1、上传解压修改环境变量" class="headerlink" title="1、上传解压修改环境变量"></a>1、上传解压修改环境变量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压</span></span><br><span class="line">tar -xvf kafka_2.11-1.0.0.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export KAFKA_HOME=/usr/local/soft/kafka_2.11-1.0.0</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、修改配置文件"><a href="#2、修改配置文件" class="headerlink" title="2、修改配置文件"></a>2、修改配置文件</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">broker.id</span>=<span class="string">0 每一个节点broker.id 要不一样</span></span><br><span class="line"><span class="attr">zookeeper.connect</span>=<span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/usr/local/soft/kafka_2.11-1.0.0/data   数据存放的位置</span></span><br></pre></td></tr></table></figure><h3 id="3、将kafka文件同步到node1-node2"><a href="#3、将kafka文件同步到node1-node2" class="headerlink" title="3、将kafka文件同步到node1,node2"></a>3、将kafka文件同步到node1,node2</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步kafka文件</span></span><br><span class="line">scp -r kafka_2.11-1.0.0/ node1:`pwd`</span><br><span class="line">scp -r kafka_2.11-1.0.0/ node2:`pwd`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将master中的而环境变量同步到node1和node2中</span></span><br><span class="line">scp /etc/profile node1:/etc/</span><br><span class="line">scp /etc/profile node2:/etc/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 在ndoe1和node2中执行<span class="built_in">source</span></span></span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4、修改node1和node2中的broker-id"><a href="#4、修改node1和node2中的broker-id" class="headerlink" title="4、修改node1和node2中的broker.id"></a>4、修改node1和node2中的broker.id</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># node1</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># node2</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">2</span></span><br></pre></td></tr></table></figure><h3 id="5、启动kafka"><a href="#5、启动kafka" class="headerlink" title="5、启动kafka"></a>5、启动kafka</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、需要先启动zookeeper,  kafka使用zk保存元数据</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要在每隔节点中执行启动的命令</span></span><br><span class="line">zkServer.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动的状态</span></span><br><span class="line">zkServer.sh status</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、启动kafka，每个节点中都要启动（去中心化的架构）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-daemon后台启动</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/soft/kafka_2.11-1.0.0/config/server.properties</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用kafka"><a href="#使用kafka" class="headerlink" title="使用kafka"></a>使用kafka</h3><h3 id="1、创建topic"><a href="#1、创建topic" class="headerlink" title="1、创建topic"></a>1、创建topic</h3><blockquote><p>在生产和消费数据时，如果topic不存在会自动创建一个分区为1，副本为1的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--replication-factor  ---每一个分区的副本数量, 同一个分区的副本不能放在同一个节点，副本的数量不能大于kafak集群节点的数量</span><br><span class="line">--partition   --分区数，  根据数据量设置</span><br><span class="line">--zookeeper zk的地址，将topic的元数据保存在zookeeper中</span><br><span class="line"></span><br><span class="line">kafka-topics.sh --create --zookeeper master:2181,node1:2181,node2:2181 --replication-factor 3 --partitions 3 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="2、查看topic描述信息"><a href="#2、查看topic描述信息" class="headerlink" title="2、查看topic描述信息"></a>2、查看topic描述信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --describe  --zookeeper master:2181,node1:2181,node2:2181 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="3、获取所有topic"><a href="#3、获取所有topic" class="headerlink" title="3、获取所有topic"></a>3、获取所有topic</h3><blockquote><p>__consumer_offsetsL kafka用于保存消费偏移量的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br></pre></td></tr></table></figure><h3 id="4、创建控制台生产者"><a href="#4、创建控制台生产者" class="headerlink" title="4、创建控制台生产者"></a>4、创建控制台生产者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list master:9092,node1:9092,node2:9092 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="5、创建控制台消费者"><a href="#5、创建控制台消费者" class="headerlink" title="5、创建控制台消费者"></a>5、创建控制台消费者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> --from-beginning   从头消费，如果不在执行消费的新的数据</span><br><span class="line">kafka-console-consumer.sh --bootstrap-server  master:9092,node1:9092,node2:9092 --from-beginning --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="kafka数据保存的方式"><a href="#kafka数据保存的方式" class="headerlink" title="kafka数据保存的方式"></a>kafka数据保存的方式</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、保存的文件</span></span><br><span class="line">/usr/local/soft/kafka_2.11-1.0.0/data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、每一个分区每一个副本对应一个目录</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3、每一个分区目录中可以有多个文件， 文件时滚动生成的</span></span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000000001.log</span><br><span class="line">00000000000000000002.log</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4、滚动生成文件的策略</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5、文件删除的策略，默认时7天，以文件为单位删除</span></span><br><span class="line">log.retention.hours=168</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Canal搭建</title>
    <link href="http://example.com/2022/07/21/canal%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/21/canal%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-20T16:00:00.000Z</published>
    <updated>2022-07-25T14:44:33.158Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开启mysql-binlog"><a href="#开启mysql-binlog" class="headerlink" title="开启mysql binlog"></a>开启mysql binlog</h2><blockquote><p>默认没有开启</p><p>开启binlog之后mysql的性能会手动影响</p></blockquote><h3 id="1、修改mysql配置文件-x2F-etc-x2F-my-cnf"><a href="#1、修改mysql配置文件-x2F-etc-x2F-my-cnf" class="headerlink" title="1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf"></a>1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果配置文件不存在，复制一个过来</span></span><br><span class="line">cp /usr/share/mysql/my-medium.cnf /etc/my.cnf</span><br><span class="line"></span><br><span class="line">vim /etc/my.cnf </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在配置文件中增加二配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要将配置放在[mysqld]后面</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开binlog</span></span><br><span class="line">log-bin=mysql-bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择ROW(行)模式</span></span><br><span class="line">binlog-format=ROW</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置MySQL replaction需要定义，不要和canal的slaveId重复</span></span><br><span class="line">server_id=1</span><br></pre></td></tr></table></figure><h3 id="2、重启mysql"><a href="#2、重启mysql" class="headerlink" title="2、重启mysql"></a>2、重启mysql</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service mysqld restart</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看mysql binlog文件</span></span><br><span class="line">cd /var/lib/mysql</span><br><span class="line">mysql-bin.000001</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">改了配置文件之后，重启MySQL，使用命令查看是否打开binlog模式：</span></span><br><span class="line">mysql -uroot -p123456</span><br><span class="line">show variables like &#x27;log_bin&#x27;;</span><br></pre></td></tr></table></figure><h2 id="搭建Canal"><a href="#搭建Canal" class="headerlink" title="搭建Canal"></a>搭建Canal</h2><h3 id="2、上传解压，上传到soft目录"><a href="#2、上传解压，上传到soft目录" class="headerlink" title="2、上传解压，上传到soft目录"></a>2、上传解压，上传到soft目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建解压目录</span></span><br><span class="line">mkdir canal</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压到指定目录</span></span><br><span class="line">tar -xvf canal.deployer-1.1.4.tar.gz -C canal</span><br></pre></td></tr></table></figure><h3 id="3、修改配置文件conf-x2F-example-x2F-instance-properties"><a href="#3、修改配置文件conf-x2F-example-x2F-instance-properties" class="headerlink" title="3、修改配置文件conf&#x2F;example&#x2F;instance.properties"></a>3、修改配置文件conf&#x2F;example&#x2F;instance.properties</h3><p>vim conf&#x2F;example&#x2F;instance.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql 地址</span></span><br><span class="line"><span class="attr">canal.instance.master.address</span>=<span class="string">master:3306</span></span><br><span class="line"><span class="comment"># mysql用户名</span></span><br><span class="line"><span class="attr">canal.instance.dbUsername</span>=<span class="string">root</span></span><br><span class="line"><span class="comment"># mysql密码</span></span><br><span class="line"><span class="attr">canal.instance.dbPassword</span>=<span class="string">123456</span></span><br><span class="line"><span class="comment"># 数据写入kafka 的topic名称, 所有的数据写入同一个topic</span></span><br><span class="line"><span class="attr">canal.mq.topic</span>=<span class="string">example</span></span><br><span class="line"><span class="comment"># 为每一个表自动创建一个topic</span></span><br><span class="line"><span class="comment"># 监控bigdata数据库，不同的表发送到表名的topic上, topic命令方式bigdata.student</span></span><br><span class="line"><span class="attr">canal.mq.dynamicTopic</span>=<span class="string">bigdata\\..*</span></span><br></pre></td></tr></table></figure><h3 id="4、修改配置文件conf-x2F-canal-properties"><a href="#4、修改配置文件conf-x2F-canal-properties" class="headerlink" title="4、修改配置文件conf&#x2F;canal.properties"></a>4、修改配置文件conf&#x2F;canal.properties</h3><p>vim conf&#x2F;canal.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># zk地址 </span></span><br><span class="line"><span class="attr">canal.zkServers</span> = <span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="comment"># 数据保存到kafka</span></span><br><span class="line"><span class="attr">canal.serverMode</span> = <span class="string">kafka</span></span><br><span class="line"><span class="comment"># kafka集群地址</span></span><br><span class="line"><span class="attr">canal.mq.servers</span> = <span class="string">master:9092,node1:9092,node2:9092</span></span><br></pre></td></tr></table></figure><h3 id="5、启动canal"><a href="#5、启动canal" class="headerlink" title="5、启动canal"></a>5、启动canal</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/canal/bin/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动canal</span></span><br><span class="line">./startup.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动日志</span></span><br><span class="line">cd /usr/local/soft/canal/logs</span><br><span class="line">cat canal/*</span><br><span class="line">cat example/*</span><br></pre></td></tr></table></figure><h3 id="5、测试"><a href="#5、测试" class="headerlink" title="5、测试"></a>5、测试</h3><p>在test数据库创建一个订单表，并且执行几个简单的DML：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 登录mysql</span></span><br><span class="line">mysql <span class="operator">-</span>uroot <span class="operator">-</span>p123456</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 切换数据库</span></span><br><span class="line">use `bigdata`;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `<span class="keyword">order</span>`</span><br><span class="line">(</span><br><span class="line">    id          <span class="type">BIGINT</span> <span class="keyword">UNIQUE</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT COMMENT <span class="string">&#x27;主键&#x27;</span>,</span><br><span class="line">    order_id    <span class="type">VARCHAR</span>(<span class="number">64</span>)   COMMENT <span class="string">&#x27;订单ID&#x27;</span>,</span><br><span class="line">    amount      <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;订单金额&#x27;</span>,</span><br><span class="line">    create_time DATETIME       COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">    <span class="keyword">UNIQUE</span> uniq_order_id (`order_id`)</span><br><span class="line">) COMMENT <span class="string">&#x27;订单表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">order</span>`(order_id, amount) <span class="keyword">VALUES</span> (<span class="string">&#x27;10087&#x27;</span>, <span class="number">999</span>);</span><br><span class="line"><span class="keyword">UPDATE</span> `<span class="keyword">order</span>` <span class="keyword">SET</span> amount <span class="operator">=</span> <span class="number">99</span> <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"><span class="keyword">DELETE</span>  <span class="keyword">FROM</span> `<span class="keyword">order</span>` <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="6、可以利用Kafka的kafka-console-consumer消费数据"><a href="#6、可以利用Kafka的kafka-console-consumer消费数据" class="headerlink" title="6、可以利用Kafka的kafka-console-consumer消费数据"></a>6、可以利用Kafka的kafka-console-consumer消费数据</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否自动创建topic</span></span><br><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">消费数据</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server master:9092,node1:9092,node2:9092 --from-beginning --topic bigdata.order</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>spark优化</title>
    <link href="http://example.com/2022/07/20/spark%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/07/20/spark%E4%BC%98%E5%8C%96/</id>
    <published>2022-07-19T16:00:00.000Z</published>
    <updated>2022-07-21T11:36:59.635Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spark优化"><a href="#spark优化" class="headerlink" title="spark优化"></a>spark优化</h1><h2 id="一、代码优化"><a href="#一、代码优化" class="headerlink" title="一、代码优化"></a>一、代码优化</h2><h3 id="1、多次使用的rdd-df-table进行缓存"><a href="#1、多次使用的rdd-df-table进行缓存" class="headerlink" title="**1、多次使用的rdd df table进行缓存 ***"></a>**1、多次使用的rdd df table进行缓存 ***</h3><ul><li><p>缓存级别</p><ul><li>数据量不大时可以使用MEMORY_ONLY</li><li>数据量超过了内存的限制 MEMORy_AND_DISK_SER</li></ul></li></ul><h3 id="2、使用高性能的算子"><a href="#2、使用高性能的算子" class="headerlink" title="**2、使用高性能的算子 ***"></a>**2、使用高性能的算子 ***</h3><ul><li><p>reduceByKey</p><ul><li>会再map端做预聚合</li></ul></li><li><p>aggregateByKey</p></li><li><p>mapPartition</p></li><li><p>foreachPartition</p><ul><li>主要用于将数据保存到外部数据库时</li><li>只需要为每一个分区创建一个网络链接</li></ul></li><li><p>coalesce</p><ul><li>如果代码产生了很多的小文件，可以再保存数据的时候合并小文件</li></ul></li></ul><h3 id="3、map-join"><a href="#3、map-join" class="headerlink" title="**3、map join ***"></a>**3、map join ***</h3><ul><li>当一个大表join小表的时候，可以将小表广播，在map端进行关联</li><li>小表不能超过1G</li></ul><h3 id="4、Kryo"><a href="#4、Kryo" class="headerlink" title="4、Kryo"></a>4、Kryo</h3><h3 id="5、优化数据结构"><a href="#5、优化数据结构" class="headerlink" title="5、优化数据结构"></a>5、优化数据结构</h3><ul><li>1、尽量使用字符串代替对象</li><li>2、尽量使用基本数据类型代替字符串</li><li>3、尽量使用数组代替集合</li></ul><h3 id="6、使用高性能的fastUtil库"><a href="#6、使用高性能的fastUtil库" class="headerlink" title="6、使用高性能的fastUtil库"></a>6、使用高性能的fastUtil库</h3><h2 id="二、参数优化"><a href="#二、参数优化" class="headerlink" title="二、参数优化"></a>二、参数优化</h2><h3 id="–num-executors-executor的数量"><a href="#–num-executors-executor的数量" class="headerlink" title="–num-executors executor的数量"></a><strong>–num-executors executor的数量</strong></h3><h3 id="–executor-memory-每一个executor的内存"><a href="#–executor-memory-每一个executor的内存" class="headerlink" title="–executor-memory 每一个executor的内存"></a><strong>–executor-memory 每一个executor的内存</strong></h3><h3 id="–executor-cores-每一个executor的核心数"><a href="#–executor-cores-每一个executor的核心数" class="headerlink" title="–executor-cores  每一个executor的核心数"></a><strong>–executor-cores  每一个executor的核心数</strong></h3><h3 id="–driver-memory-Driver的内存1G-2G-保存广播变量"><a href="#–driver-memory-Driver的内存1G-2G-保存广播变量" class="headerlink" title="–driver-memory  Driver的内存1G-2G(保存广播变量)"></a>–driver-memory  Driver的内存1G-2G(保存广播变量)</h3><h3 id="–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle"><a href="#–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle" class="headerlink" title="–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle"></a>–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle</h3><h3 id="–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2"><a href="#–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2" class="headerlink" title="–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2"></a>–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2</h3><h3 id="–spark-locality-wait-数据本地化等待时间"><a href="#–spark-locality-wait-数据本地化等待时间" class="headerlink" title="–spark.locality.wait 数据本地化等待时间"></a>–spark.locality.wait 数据本地化等待时间</h3><h3 id="–spark-yarn-executor-memoryOverhead堆外内存"><a href="#–spark-yarn-executor-memoryOverhead堆外内存" class="headerlink" title="–spark.yarn.executor.memoryOverhead堆外内存"></a>–spark.yarn.executor.memoryOverhead堆外内存</h3><h3 id="–spark-network-timeout-网络链接的超时时间"><a href="#–spark-network-timeout-网络链接的超时时间" class="headerlink" title="–spark.network.timeout 网络链接的超时时间"></a>–spark.network.timeout 网络链接的超时时间</h3><h2 id="三、数据倾斜"><a href="#三、数据倾斜" class="headerlink" title="三、数据倾斜"></a>三、数据倾斜</h2><h3 id="1、将数据倾斜提前带hive"><a href="#1、将数据倾斜提前带hive" class="headerlink" title="1、将数据倾斜提前带hive"></a><strong>1、将数据倾斜提前带hive</strong></h3><ul><li>hive比spark稳定</li></ul><h3 id="2、过滤少量导致倾斜的key"><a href="#2、过滤少量导致倾斜的key" class="headerlink" title="2、过滤少量导致倾斜的key"></a><strong>2、过滤少量导致倾斜的key</strong></h3><ul><li>key对业务不重要</li></ul><h3 id="3、提高shuffle的并行度"><a href="#3、提高shuffle的并行度" class="headerlink" title="3、提高shuffle的并行度"></a><strong>3、提高shuffle的并行度</strong></h3><ul><li>可以减少每一个reduce中分到的数据量，可以缓解数据倾斜</li></ul><h3 id="4、双重聚合"><a href="#4、双重聚合" class="headerlink" title="4、双重聚合"></a><strong>4、双重聚合</strong></h3><ul><li>先增加随机前缀聚合一次，再去掉前缀聚合一次</li></ul><h3 id="5、map-join"><a href="#5、map-join" class="headerlink" title="**5、map join **"></a>**5、map join **</h3><ul><li>适合大表关联小表，大表部分数据分布不均</li><li>mapjoin 不会产生shuffle,就不会导致数据倾斜</li></ul><h3 id="6、采样倾斜的key并拆分jon"><a href="#6、采样倾斜的key并拆分jon" class="headerlink" title="6、采样倾斜的key并拆分jon"></a><strong>6、采样倾斜的key并拆分jon</strong></h3><ul><li>当大表关联大表，有一个表部分key数据分布不均</li><li>把倾斜的数据单独拿出来使用mapjoin进行关联，避免了数据倾斜</li></ul>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>FLink代码</title>
    <link href="http://example.com/2022/07/19/FLink%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/19/FLink%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-25T14:43:16.297Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、flink编写WordCount"><a href="#1、flink编写WordCount" class="headerlink" title="1、flink编写WordCount"></a>1、flink编写WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建flink环境</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置flink任务的并行度</span></span><br><span class="line">    <span class="comment">//默认和电脑的核数有关</span></span><br><span class="line">    env.setParallelism(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据从上游发送到下游的超时时间</span></span><br><span class="line">    <span class="comment">//默认是200毫秒</span></span><br><span class="line">    env.setBufferTimeout(<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计单词的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//将一行转换成多行</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//转换成kv格式</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照单词进行分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//d对value进行汇总</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = groupByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、查看结果</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动flink程序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、map"><a href="#2、map" class="headerlink" title="2、map"></a>2、map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * map方法，每一条数据执行一次，传进来一条返回一条</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ： 一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">String</span>): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">4</span>)</span><br><span class="line">        (clazz, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    kvDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、Java-API"><a href="#3、Java-API" class="headerlink" title="3、Java API"></a>3、Java API</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.<span class="type">Tuple2</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">DataStreamSource</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">SingleOutputStreamOperator</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.<span class="type">StreamExecutionEnvironment</span>;</span><br><span class="line"></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Demo2JavaApi</span> </span>&#123;</span><br><span class="line">    public static void main(<span class="type">String</span>[] args) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">        <span class="comment">//创建flink环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="type">DataStreamSource</span>&lt;<span class="type">String</span>&gt; studentDS = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//java 代码</span></span><br><span class="line">        <span class="type">SingleOutputStreamOperator</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt; kvDS = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>&lt;<span class="type">String</span>, <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            public <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt; map(<span class="type">String</span> value) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">                <span class="type">String</span> clazz = value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">4</span>];</span><br><span class="line">                <span class="keyword">return</span> <span class="type">Tuple2</span>.of(clazz, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        kvDS.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、FlatMapFuncation"><a href="#4、FlatMapFuncation" class="headerlink" title="4、FlatMapFuncation"></a>4、FlatMapFuncation</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FlatMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3FlatMapFuncation</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(<span class="keyword">new</span> <span class="type">FlatMapFunction</span>[<span class="type">String</span>, <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * flatMap： 一条数据执行一次，传入一条数据可以返回多条数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @param out   ：用于将数据发送到下游</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: <span class="type">String</span>, out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = value.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">          <span class="comment">//将数据发送到下游</span></span><br><span class="line">          out.collect(word)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    wordsDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Filter"><a href="#5、Filter" class="headerlink" title="5、Filter"></a>5、Filter</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FilterFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.&#123;<span class="type">DataStream</span>, <span class="type">StreamExecutionEnvironment</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4Filter</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> filterDS: <span class="type">DataStream</span>[<span class="type">String</span>] = studentDS.filter(<span class="keyword">new</span> <span class="type">FilterFunction</span>[<span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 传如一条数据返回一个布尔值，返回true保留数据，返回false过滤数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> gender: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">3</span>)</span><br><span class="line">        <span class="string">&quot;女&quot;</span>.equals(gender)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    filterDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、KeyBy"><a href="#6、KeyBy" class="headerlink" title="6、KeyBy"></a>6、KeyBy</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.<span class="type">KeySelector</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5KeyBy</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(<span class="keyword">new</span> <span class="type">KeySelector</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKey</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>)): <span class="type">String</span> = &#123;</span><br><span class="line">        value._1</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key之后进行聚合计算</span></span><br><span class="line">    <span class="keyword">val</span> sumDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    sumDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Reduce"><a href="#7、Reduce" class="headerlink" title="7、Reduce"></a>7、Reduce</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">ReduceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Reduce</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再分组之后进行聚合计算</span></span><br><span class="line">    <span class="comment">//val reduceDS: DataStream[(String, Int)] = keyByDS.reduce((kv1, kv2) =&gt; (kv1._1, kv1._2 + kv2._2))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> reduceDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.reduce(<span class="keyword">new</span> <span class="type">ReduceFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(kv1: (<span class="type">String</span>, <span class="type">Int</span>), kv2: (<span class="type">String</span>, <span class="type">Int</span>)): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        (kv1._1, kv1._2 + kv2._2)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    reduceDS.print()</span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Window"><a href="#8、Window" class="headerlink" title="8、Window"></a>8、Window</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingProcessingTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计最近10秒单词的数量，每个5秒统计一次</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//滑动窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] = keyByDS</span><br><span class="line">      .window(<span class="type">SlidingProcessingTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">10</span>), <span class="type">Time</span>.seconds(<span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再开窗之后进行集合计算</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、Union"><a href="#9、Union" class="headerlink" title="9、Union"></a>9、Union</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Union</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ds1: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">    <span class="keyword">val</span> ds2: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//两个ds的类型要一致</span></span><br><span class="line">    <span class="keyword">val</span> unionDS: <span class="type">DataStream</span>[<span class="type">Int</span>] = ds1.union(ds2)</span><br><span class="line"></span><br><span class="line">    unionDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>Flink状态和checkPoint</title>
    <link href="http://example.com/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/"/>
    <id>http://example.com/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-27T02:18:40.568Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、实时计算每一个班级的平均年龄"><a href="#1、实时计算每一个班级的平均年龄" class="headerlink" title="1、实时计算每一个班级的平均年龄"></a>1、实时计算每一个班级的平均年龄</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">RuntimeContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo14AvgAge</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取socket的数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> clazzAndAge: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = lines.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> splits: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = splits(<span class="number">4</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Int</span> = splits(<span class="number">2</span>).toInt</span><br><span class="line">      (clazz, age)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照班级分组</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = clazzAndAge.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 计算平均年龄</span></span><br><span class="line"><span class="comment">     * flink的状态可以在任务算子中使用，map，filter，process都可以（Rich）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> resultDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = keyByDS.process(<span class="keyword">new</span> <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 定义两个状态来保存总人数和总年龄</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">val</span> context: <span class="type">RuntimeContext</span> = getRuntimeContext</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总人数的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumNumDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumNum&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总年龄的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumAgeDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumAge&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        sumNumState = context.getState(sumNumDesc)</span><br><span class="line"></span><br><span class="line">        sumAgeState = context.getState(sumAgeDesc)</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总人数的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumNumState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总年龄的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumAgeState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>),</span><br><span class="line">                                  ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                  out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value._1</span><br><span class="line">        <span class="keyword">val</span> age: <span class="type">Int</span> = value._2</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1、获取之前的总人数和总的年龄</span></span><br><span class="line">        <span class="keyword">var</span> sumNum: <span class="type">Int</span> = sumNumState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumNum += <span class="number">1</span></span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumNumState.update(sumNum)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> sumAge: <span class="type">Int</span> = sumAgeState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumAge += age</span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumAgeState.update(sumAge)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算平均年龄</span></span><br><span class="line">        <span class="keyword">val</span> avgAge: <span class="type">Double</span> = sumAge / sumNum.toDouble</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将数据发送到下游</span></span><br><span class="line"></span><br><span class="line">        out.collect((clazz, avgAge))</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    resultDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、状态"><a href="#2、状态" class="headerlink" title="2、状态"></a>2、状态</h4><ol><li><p>flink用于保存之前计算结果的机制</p></li><li><p>flink会为每一个key保存一个状态</p></li><li><p>常用的sum（需要保存之前的计算结果）  window（需要保存一段时间内的数据）内部都是有状态的</p></li><li><p>flink也提供了几种查用的状态类</p><ol><li><strong>valueState: 单值状态</strong>，为每一个key保存一个值，可以是任何类型，必须可以序列化</li><li><strong>mapState: kv格式的状态</strong>，为每一个key保存一个kv格式的状态</li><li><strong>listState: 集合状态</strong>，为每一个key保存一个集合状态，集合中可以保存多个元素</li><li><strong>reducingState&#x2F;AggregatingState:聚合状态</strong>，为每一个key保存一个值，再定义状态时需要一个聚合函数</li></ol></li><li><p>flink的状态和普通变量的区别</p><ol><li>普通变量是保存再flink的内存中的，如果flink任务执行失败，变量的数据会丢失</li><li>flink的状态是一个特殊的变量，状态中的数据会被checkpoint持久化到hdfs中, 如果任务执行失败，重启任务，可以恢复状态</li></ol></li><li><p>状态后端，用于保存状态的位置</p><ol><li><p>HashMapStateBackend： </p><ol><li><p>将flink的状态先保存TaskManager的内存中，在触发checkpoint的时候将taskmanager中的状态再持久化到hdfs中</p></li><li><p>可以直接使用</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">HashMapStateBackend</span>())</span><br></pre></td></tr></table></figure></li></ol></li><li><p>EmbeddedRocksDBStateBackend：</p><ol><li><p>RocksDS是一个本地的轻量级的数据库，数据在磁盘上</p></li><li><p>再启动lfink任务的时候会在每一个taskManager所在的节点启动一个rocksDB进程</p></li><li><p>flink的状态会先保存在rocksDb数据库中，当触发checkpoint的时候将数据库中的状态持久化到hdfs中</p></li><li><p>可以支持增量快照</p></li><li><p>使用rocksDb状态后端需要带入依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-statebackend-rocksdb<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>使用方式</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br></pre></td></tr></table></figure></li></ol></li></ol></li></ol><h4 id="3、checkpoint"><a href="#3、checkpoint" class="headerlink" title="3、checkpoint"></a>3、checkpoint</h4><ol><li><p>checkpoint是flink用于持久化flink状态的机制</p></li><li><p>flink会定时将flink计算的状态持久化到hdfs中</p></li><li><p>开启checkpint的方法</p><ol><li><p>在代码中开启- 每一个代码单独开启，优先级最高</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 每 1000ms 开始一次 checkpoint</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>)</span><br><span class="line"><span class="comment">// 高级选项：</span></span><br><span class="line"><span class="comment">// 设置模式为精确一次 (这是默认值)</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)</span><br><span class="line"><span class="comment">// 确认 checkpoints 之间的时间会进行 500 ms</span></span><br><span class="line">env.getCheckpointConfig.setMinPauseBetweenCheckpoints(<span class="number">500</span>)</span><br><span class="line"><span class="comment">// Checkpoint 必须在一分钟内完成，否则就会被抛弃</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointTimeout(<span class="number">60000</span>)</span><br><span class="line"><span class="comment">// 允许两个连续的 checkpoint 错误</span></span><br><span class="line">env.getCheckpointConfig.setTolerableCheckpointFailureNumber(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// 同一时间只允许一个 checkpoint 进行</span></span><br><span class="line">env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// 使用 externalized checkpoints，这样 checkpoint 在作业取消后仍就会被保留</span></span><br><span class="line"><span class="comment">//RETAIN_ON_CANCELLATION: 当任务取消时保留checkpoint</span></span><br><span class="line">env.getCheckpointConfig.setExternalizedCheckpointCleanup(</span><br><span class="line">ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)</span><br><span class="line"><span class="comment">//指定状态后端</span></span><br><span class="line"><span class="comment">//EmbeddedRocksDBStateBackend eocksDb状态后端</span></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br><span class="line"><span class="comment">//将状态保存到hdfs中，在触发checkpoint的时候将状态持久化到hdfs中</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointStorage(<span class="string">&quot;hdfs://master:9000/flink/checkpoint&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>在flink的集群的配置文件中同意开启– flink新版才有</p><p>vim  flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">execution.checkpointing.interval:</span> <span class="string">3min</span></span><br><span class="line"><span class="attr">execution.checkpointing.externalized-checkpoint-retention:</span> <span class="string">RETAIN_ON_CANCELLATION</span></span><br><span class="line"><span class="attr">execution.checkpointing.max-concurrent-checkpoints:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">execution.checkpointing.min-pause:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">execution.checkpointing.mode:</span> <span class="string">EXACTLY_ONCE</span></span><br><span class="line"><span class="attr">execution.checkpointing.timeout:</span> <span class="string">10min</span></span><br><span class="line"><span class="attr">execution.checkpointing.tolerable-failed-checkpoints:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://master:9000/flink/checkpoint</span></span><br></pre></td></tr></table></figure></li><li><p>从checkpoint恢复任务</p></li><li><p>可以在网页中指定checkpint的路径恢复,路径需要带上前缀hdfs:&#x2F;&#x2F;master:9000</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35</span><br></pre></td></tr></table></figure></li><li><p>也可以在命令行中重新提交任务，指定恢复任务的位置, 需要先上传jar包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-s 恢复任务的位置</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0005  -c com.hzh.flink.core.Demo15RocksDB -s hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35 flink-1.0.jar</span><br></pre></td></tr></table></figure></li></ol></li></ol>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>flink SQL</title>
    <link href="http://example.com/2022/07/19/flink%20SQL/"/>
    <id>http://example.com/2022/07/19/flink%20SQL/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-30T00:55:23.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="1、连接器"><a href="#1、连接器" class="headerlink" title="1、连接器"></a>1、连接器</h3><h4 id="1、DataGen"><a href="#1、DataGen" class="headerlink" title="1、DataGen"></a>1、DataGen</h4><blockquote><p>用于生成随机数据的工具</p><p>只能用于source表</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line"> id STRING,</span><br><span class="line"> name STRING,</span><br><span class="line"> age <span class="type">INT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ts AS localtimestamp, : localtimestamp获取当前时间戳，</span></span><br></pre></td></tr></table></figure><h4 id="2、Print"><a href="#2、Print" class="headerlink" title="2、Print"></a>2、Print</h4><blockquote><p>print用于打印连续查询的结果的表</p><p>print只能用于sink表</p></blockquote><ul><li>基于已有的表结构创建print表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- LIKE： 基于已有的表创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><ul><li>打印数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="operator">|</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> datagen</span><br></pre></td></tr></table></figure><ul><li>手动设置字段</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table (</span><br><span class="line"> age <span class="type">INT</span>,</span><br><span class="line"> num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>统计年龄额人数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> age_num</span><br><span class="line"><span class="keyword">select</span> age ,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> datagen</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> age</span><br></pre></td></tr></table></figure><h4 id="3、BlackHole"><a href="#3、BlackHole" class="headerlink" title="3、BlackHole"></a>3、BlackHole</h4><blockquote><p>用于flink性能测试</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> blackhole_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;blackhole&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><h4 id="4、Kafka"><a href="#4、Kafka" class="headerlink" title="4、Kafka"></a>4、Kafka</h4><ul><li>kafka依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>csv依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-csv<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>kafka source</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>参选介绍</p><p>scan.startup.mode：<br>    earliest-offset: 读取所有的数据<br>    latest-offset：读取最新的数据，只能读取到任务启动之后生产的数据<br>    group-offsets（默认值）： 基于以消费者组读取数据，如果消费者组不存在读取最新的数据<br>    timestamp ：指定时间戳读取数据<br>    specific-offsets：指定偏移量读取数据<br>format：<br>    csv: 文本格式，指定字段时需要按照顺序映射，flink sql会自动解析</p><ul><li>kafka sink， 使用flink向kafka中写数据存在两种情况，<ul><li>将append only流写入kafka</li></ul></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_nan&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;\t&#x27;</span> <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 非聚合类的连续查询返回的动态表是一个append only表，可以可以写入到kafka中</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span></span><br><span class="line">student_kafka_source</span><br><span class="line"><span class="keyword">where</span> gender <span class="operator">=</span><span class="string">&#x27;男&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic student_nan</span></span><br></pre></td></tr></table></figure><ul><li>更新的流写入kafka</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> gender_num_sink (</span><br><span class="line">    gender STRING,</span><br><span class="line">num <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (gender) <span class="keyword">NOT</span> ENFORCED<span class="comment">-- 设置唯一主键</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;upsert-kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;gender_num&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;key.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 将更新的流写入kafka</span></span><br><span class="line"><span class="comment">-- 已唯一的主键作为kafka中key</span></span><br><span class="line"><span class="comment">-- 已数据作为kafkavalue</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> gender_num_sink</span><br><span class="line"><span class="keyword">select</span> gender,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> student_kafka</span><br><span class="line"><span class="keyword">where</span> gender <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> gender</span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic gender_num</span></span><br></pre></td></tr></table></figure><ul><li><p>提交到集群运行需要先将kafka依赖包上传到flink  lib目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink-sql-connector-kafka-1.15.0.jar</span><br></pre></td></tr></table></figure></li></ul><h4 id="5、JDBC"><a href="#5、JDBC" class="headerlink" title="5、JDBC"></a>5、JDBC</h4><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>jdbc source   — 有界流</p><blockquote><p>jdbc 字段按照名称和类型进行映射的，flink sql中表的字段和类型必须和数据库中保持一致</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建jdbc source表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_mysql (</span><br><span class="line">  id <span class="type">BIGINT</span>,</span><br><span class="line">  name STRING,</span><br><span class="line">  age <span class="type">BIGINT</span>,</span><br><span class="line">  gender STRING,</span><br><span class="line">  clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;students&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建print sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_mysql (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_mysql</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>jdbc sink</p><blockquote><p>实时读取kafka中学生表的数据，实时统计每个班级学生的人数，将统计的结果保存到mysql中</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- flink sql kafka source表  学生表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 在mysql中创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `clazz_num` (</span><br><span class="line">  `clazz` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `num` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`clazz`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- flink sql  jdbc sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> clazz_num_mysql (</span><br><span class="line">  clazz STRING,</span><br><span class="line">  num <span class="type">BIGINT</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (clazz) <span class="keyword">NOT</span> ENFORCED <span class="comment">-- 按照主键更新数据</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata?useUnicode=true&amp;characterEncoding=UTF-8&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;clazz_num&#x27;</span>, <span class="comment">-- 需要手动到数据库中创建表</span></span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 以下查询返回的是一个更新流，flinksql会自动按照主键更新数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> clazz_num_mysql</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span> </span><br><span class="line">student_kafka</span><br><span class="line"><span class="keyword">where</span> clazz <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student</span></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>将包含jdbc代码提交到集群运行</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、将flink-connector-jdbc-1.15.0.jar依赖上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、将mysql-connector-java-5.1.49.jar mysql 驱动上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是使用yarn-session模式徐娅偶先重启yarn-session</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭</span></span><br><span class="line">yarm application -kill application_1658546198162_0005</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">yarn-session-.sh -d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将代码打包上传到服务器提交任务</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0007  -c com.shujia.flink.sql.Demo9JDBCSink  flink-1.0.jar</span><br></pre></td></tr></table></figure><h4 id="7、FIleSystem"><a href="#7、FIleSystem" class="headerlink" title="7、FIleSystem"></a>7、FIleSystem</h4><blockquote><p>本地文件，hdfs  其它的文件系统</p></blockquote><ul><li><p>读取文件  </p><blockquote><p>可以使用batch模式处理数据</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 文件 source</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file (</span><br><span class="line">    id STRINg,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.txt&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>                     <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 读取csv格式字段需要按照顺序映射</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--print sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line">(</span><br><span class="line">    clazz STRING,</span><br><span class="line">    num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span></span><br><span class="line">student_file</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br></pre></td></tr></table></figure><ul><li>写入文件</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    ts <span class="keyword">AS</span> <span class="built_in">localtimestamp</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;500&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.gender.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;1&#x27;</span>,   </span><br><span class="line"> <span class="string">&#x27;fields.clazz.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;5&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建file sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> file_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    `<span class="keyword">day</span>` STRING,</span><br><span class="line">    `<span class="keyword">hour</span>` STRING</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (`<span class="keyword">day</span>`,`<span class="keyword">hour</span>`) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span><span class="operator">=</span><span class="string">&#x27;filesystem&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span><span class="operator">=</span><span class="string">&#x27;data/flink_sink&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span><span class="operator">=</span><span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;sink.rolling-policy.file-size&#x27;</span> <span class="operator">=</span><span class="string">&#x27;100kb&#x27;</span><span class="comment">--滚动生成新的文件的大小，默认128M</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> file_sink</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">id,name,age,gender,clazz,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>) <span class="keyword">as</span> `<span class="keyword">day</span>`,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;HH&#x27;</span>)  <span class="keyword">as</span> `<span class="keyword">hour</span>`</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">datagen</span><br></pre></td></tr></table></figure><h3 id="2、format"><a href="#2、format" class="headerlink" title="2、format"></a>2、format</h3><h4 id="1、json"><a href="#1、json" class="headerlink" title="1、json"></a>1、json</h4><blockquote><p>json格式表结构按照字段名和类型进行映射</p></blockquote><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>读取json格式的数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_file_json (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><ul><li>将数据保存为json格式</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- kafka sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_flink_json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><h3 id="3、练习"><a href="#3、练习" class="headerlink" title="3、练习"></a>3、练习</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 1、使用flink sql 统计每个城市总的车流量</span></span><br><span class="line"><span class="comment">-- 2、source 使用文件sourcecars_sample.json</span></span><br><span class="line"><span class="comment">-- 3、将统计好的结果保存到mysql中，mysql中只保留最新的结果</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink SQL的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>FLink集群搭建</title>
    <link href="http://example.com/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-17T16:00:00.000Z</published>
    <updated>2022-07-25T14:33:49.471Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FLink集群搭建"><a href="#FLink集群搭建" class="headerlink" title="FLink集群搭建"></a>FLink集群搭建</h1><h2 id="独立集群"><a href="#独立集群" class="headerlink" title="独立集群"></a>独立集群</h2><blockquote><p>独立集群不需要依赖任何框架，独立运行</p></blockquote><p>1、上传解压配置环境变量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf flink-1.15.0-bin-scala_2.12.tgz </span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p>2、修改配置文件</p><p>vim conf&#x2F;flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">jobmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">rest.bind-address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.numberOfTaskSlots:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>vim conf&#x2F;masters</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master:8081</span><br></pre></td></tr></table></figure><p>vim workers</p><p>分布式写node1,node2（伪分布式只写master）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><p>3、将flink文件同步到另外两个节点中</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r flink-1.15.0/ node1:`pwd`</span><br><span class="line">scp -r flink-1.15.0/ node2:`pwd`</span><br></pre></td></tr></table></figure><p>4、需要修改node1和node2中的配置文件</p><p>vim flink-conf.yaml</p><p>node1节点改成node1,node2的节点改成node2</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">taskmanager.host:</span> <span class="string">node1/node2</span></span><br></pre></td></tr></table></figure><p>5、启动flink的独立集群</p><p>在master中启动集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-cluster.sh</span><br><span class="line"></span><br><span class="line">关闭</span><br><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>6、访问flink的页面</p><p><a href="http://master:8081/">http://master:8081</a></p><h2 id="flink-提交任务的方式"><a href="#flink-提交任务的方式" class="headerlink" title="flink 提交任务的方式"></a>flink 提交任务的方式</h2><p>1、将项目打包在网页上提交</p><p>2、将jar包上传到集群使用flink命令提交</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink run -c com.shujia.core.Demo1WordCount flink-1.0.jar</span><br></pre></td></tr></table></figure><h2 id="FLINK-on-YARN"><a href="#FLINK-on-YARN" class="headerlink" title="FLINK on YARN"></a>FLINK on YARN</h2><blockquote><p>将flink的任务提交到yarn上运行</p></blockquote><p>1、可以先关闭flink的独立集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>2、配置HADOOP_CLASSPATH</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加</span></span><br><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>3、启动hadoop</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h2 id="提交任务到yarn上运行"><a href="#提交任务到yarn上运行" class="headerlink" title="提交任务到yarn上运行"></a>提交任务到yarn上运行</h2><h3 id="1、Application-Mode"><a href="#1、Application-Mode" class="headerlink" title="1、Application Mode"></a>1、Application Mode</h3><p>Application Mode模式主要时为了让flink可以在K8S上运行</p><blockquote><p>为每一个flink任务在yarn上启动一个集群，提交任务的main运行在jobmanager,  数据流程图在jobmanager中构建</p><p>每一个任务启动一个jobmanager</p></blockquote><p>将项目打包上传到服务器</p><p>提交任务</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">flink run-application -t yarn-application -c com.shujia.flink.core.Demo2Submit  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-application -Dyarn.application.id=application_1654846044068_0002</span><br></pre></td></tr></table></figure><p>关闭任务</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-application -Dyarn.application.id=application_1654846044068_0002 52b325d666be767b24698f459bb5dda9</span><br></pre></td></tr></table></figure><h3 id="2、Per-Job-Cluster-Mode"><a href="#2、Per-Job-Cluster-Mode" class="headerlink" title="2、Per-Job Cluster Mode"></a>2、Per-Job Cluster Mode</h3><blockquote><p>为每一个flink任务在yarn上启动一个集群, 在本地构建数据流程图，再将数据流程图提交到jobmanager中运行</p><p>每一个任务启动一个jobmanager</p></blockquote><p>提交任务</p><p>–detached: 客户端提交成功之后会退出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-per-job --detached -c com.shujia.flink.core.Demo2Submit   flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003</span><br></pre></td></tr></table></figure><p>取消任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003 86d6973d3d79a7040bfdf75b7cad88d0</span><br></pre></td></tr></table></figure><h3 id="3、Session-Mode"><a href="#3、Session-Mode" class="headerlink" title="3、Session Mode"></a>3、Session Mode</h3><blockquote><p>先再yarn中启动一个flink的集群，再通过命令将任务提交到这个集群中运行</p><p>所有的任务共享同一个jobmanager</p></blockquote><p>启动yarn session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn-session.sh -d</span><br></pre></td></tr></table></figure><p>提交任务- 可以提交多个任务，多个任务共享同一个jobmanager</p><p>1、可以在网页中提交任务</p><p>2、可以通过命令行提交任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1654852007237_0008  -c com.shujia.core.Demo12ValueState  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>退出yarn-session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -kill application_1654846044068_0004</span><br></pre></td></tr></table></figure><p>Application Mode:  每一个任务启动一个集群，任何和任务之前互不影响，在jobmanager中构建JobGraph </p><p>Per-Job Cluster Mode：每一个任务启动一个集群，任何和任务之前互不影响，在本地构建JobGraph 再将JobGraph 提交到jobmanager中运行</p><p>Session Mode: 通过sessIon模式提交的任务共用同一个集群（同一个jobmanager），如果有一个任务执行出了问题，可能会影响其它任务，一般Session 用来测试使用，因为占用的资源要少一点, 在提交任务时在动态申请taskmanager</p><p>在集群中读取kafka的数据</p><p>java.lang.ClassNotFoundException: org.apache.flink.connector.kafka.source.KafkaSource</p><p>需要将flink-sql-connector-kafka-1.15.0.jar 包上传到flink的lib目录下</p><h2 id="yarn-资源不足问题"><a href="#yarn-资源不足问题" class="headerlink" title="yarn 资源不足问题"></a>yarn 资源不足问题</h2><p>修改yarn-site.xml文件</p><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">将配置文件同步到另外两个节点</span><br><span class="line">scp yarn-site.xml node1:`pwd`</span><br><span class="line">scp yarn-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line">重启yarn</span><br><span class="line">stop-yarn.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>Spark-Sql</title>
    <link href="http://example.com/2022/07/15/Spark-Sql/"/>
    <id>http://example.com/2022/07/15/Spark-Sql/</id>
    <published>2022-07-14T16:00:00.000Z</published>
    <updated>2022-07-18T13:05:44.688Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1、sparkWordCount"><a href="#1、sparkWordCount" class="headerlink" title="1、sparkWordCount"></a>1、sparkWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    linesDF.printSchema() <span class="comment">//打印表结构</span></span><br><span class="line">    linesDF.show() <span class="comment">//打印数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、将DataFrame注册成一个视图，才能写sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    linesDF.createOrReplaceTempView(<span class="string">&quot;lines&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、写Spark的SQl来统计单词的数量</span></span><br><span class="line"><span class="comment">     * sparkSQl的语法完全兼容hive sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">DataFrame</span> = spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |select word,count(1) as c from</span></span><br><span class="line"><span class="string">        |(select explode(split(line,&#x27;,&#x27;)) as word</span></span><br><span class="line"><span class="string">        |from</span></span><br><span class="line"><span class="string">        |lines) as a</span></span><br><span class="line"><span class="string">        |group by word</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、将数据保存到本地</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    result</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)<span class="comment">//指定文件类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;,&quot;</span>)<span class="comment">//数据分隔符</span></span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)<span class="comment">//覆盖数据</span></span><br><span class="line">      .save(<span class="string">&quot;data/wc1&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2、WslWordCount"><a href="#2、WslWordCount" class="headerlink" title="2、WslWordCount"></a>2、WslWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2DSLWC</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL:类sql api，介于代码和SQL之间的一种写法</span></span><br><span class="line"><span class="comment">     * 在写DSL之前需要导入sparkSql的函数和隐式转换</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//$&quot;line&quot; 获取列对象</span></span><br><span class="line">    linesDF</span><br><span class="line">      <span class="comment">//将一行中的多个单词拆分成多行</span></span><br><span class="line">      .select(explode(split($<span class="string">&quot;line&quot;</span>, <span class="string">&quot;,&quot;</span>)) as <span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//按照单词分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//统计单词的数量</span></span><br><span class="line">      .agg(count($<span class="string">&quot;word&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保存数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/wc2&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3、DslAPI"><a href="#3、DslAPI" class="headerlink" title="3、DslAPI"></a>3、DslAPI</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3DSLAPI</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建spark连接</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> session: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;Demo3DslAPI&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partition&quot;</span>,<span class="number">1</span>) <span class="comment">//指定在shuffle之后的分区数，默认是200，类似hive中设置reduce的数量</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL API</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取一个json格式文件,spark会自动识别json中的列名</span></span><br><span class="line">    <span class="keyword">val</span> dataFrame: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>) <span class="comment">//指定读取数据的格式为json</span></span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    dataFrame.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * show：查看df中数据，相当于rdd的action算子，会触发任务的执行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    dataFrame.show()</span><br><span class="line">    <span class="comment">//指定打印多少行</span></span><br><span class="line">    dataFrame.show(<span class="number">20</span>)</span><br><span class="line">    <span class="comment">//完整打印每一列的数据</span></span><br><span class="line">    dataFrame.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * select:选择数据，和sql中的select用法基本一致</span></span><br><span class="line"><span class="comment">     * dsl中select 不能使用聚合函数需要在agg中使用聚合函数</span></span><br><span class="line"><span class="comment">     * select相当于rdd中的转换算子</span></span><br><span class="line"><span class="comment">     * selectExpr可以传一个sql的表达式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame.select(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age&quot;</span>)</span><br><span class="line">    dataFrame.selectExpr(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age+1 as age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//需要导入spark sql的函数才能在DSl中使用函数</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> session.implicits._</span><br><span class="line">    <span class="comment">//使用列对象的方式</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;name&quot;</span>, $<span class="string">&quot;age&quot;</span> + <span class="number">1</span> as <span class="string">&quot;age&quot;</span>).show()</span><br><span class="line">    <span class="comment">//在sql中使用spark函数</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;id&quot;</span>, substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) as <span class="string">&quot;zz&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * where：过滤数据 也相当于一个转换算子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//字符串的sql表达式</span></span><br><span class="line">    dataFrame.where(<span class="string">&quot;gender = &#x27;女&#x27; and age = 23&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用列对象</span></span><br><span class="line">    dataFrame.where($<span class="string">&quot;gender&quot;</span> =!= <span class="string">&quot;男&quot;</span> and $<span class="string">&quot;age&quot;</span> === <span class="number">22</span>).show()</span><br><span class="line">    <span class="comment">//这个里面只能用函数不能写scala代码</span></span><br><span class="line">    dataFrame.where(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) === <span class="string">&quot;文科&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * groupBy agg ：分组聚合要一起使用不能单独使用</span></span><br><span class="line"><span class="comment">     * 分组聚合之后返回的DF只包含分组字段和聚合字段</span></span><br><span class="line"><span class="comment">     * 分组不能在select中聚合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>, floor(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age1&quot;</span>, ceil(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age2&quot;</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * orderBy : 排序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .orderBy($<span class="string">&quot;num&quot;</span>.desc)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * join:表关联</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,cid STRING,Sco DOUBLE&quot;</span>) <span class="comment">//指定列名</span></span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关联字段名不一样时</span></span><br><span class="line">    <span class="comment">//    scoreDF.join(dataFrame,$&quot;id&quot;===$&quot;sid&quot;,&quot;inner&quot;).show()</span></span><br><span class="line">    <span class="comment">//关联字段名一样时,直接写&quot;id&quot;</span></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = scoreDF.join(dataFrame, <span class="string">&quot;id&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开窗函数</span></span><br><span class="line"><span class="comment">     * 统计每个班级总分前十的学生</span></span><br><span class="line"><span class="comment">     * withColumn():在DF的基础上增加新的列</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF</span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>,$<span class="string">&quot;clazz&quot;</span>)<span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)<span class="comment">//计算总分</span></span><br><span class="line">      <span class="comment">//简写，在前面的基础上增加列</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>,row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      .where($<span class="string">&quot;r&quot;</span>&lt;=<span class="number">10</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF.createOrReplaceTempView(<span class="string">&quot;student_score&quot;</span>)</span><br><span class="line"></span><br><span class="line">    session.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select * from (</span></span><br><span class="line"><span class="string">        |select id as sid,clazz,sumSco,row_number() over(partition by clazz order by sumSco desc) as r from (</span></span><br><span class="line"><span class="string">        |select id,clazz,sum(sco) as  sumSco</span></span><br><span class="line"><span class="string">        |from student_score</span></span><br><span class="line"><span class="string">        |group by id,clazz</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |) as b</span></span><br><span class="line"><span class="string">        |where r&lt;=10</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、DataSource"><a href="#4、DataSource" class="headerlink" title="4、DataSource"></a>4、DataSource</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4DataSource</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;source&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * csv格式的数据</span></span><br><span class="line"><span class="comment">     * 选哟指定表结构，分隔符（默认时逗号），文件路径</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> csvDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING, clazz STRING&quot;</span>) <span class="comment">//指定列名和类的类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    csvDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据保持为csv格式</span></span><br><span class="line">    csvDF</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保持数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定保持数据的格式</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/clazz_num1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * json格式</span></span><br><span class="line"><span class="comment">     * spark 会自动将json中字段名和字段类型解析出来</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * json格式比csv格式占用的空间更大，在大数据场景下不适用json</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取json格式的数据</span></span><br><span class="line">    <span class="keyword">val</span> jsonDF: <span class="type">DataFrame</span> = spark.read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    jsonDF.show()</span><br><span class="line">    <span class="comment">//将数据保存为json格式</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .groupBy($<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;gender&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/gender_num&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * parquet: 带表结构的压缩格式</span></span><br><span class="line"><span class="comment">     * 压缩：时间换空间</span></span><br><span class="line"><span class="comment">     * 压缩比取决于《信息熵》</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、将数据保存为parquet</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取parquet</span></span><br><span class="line"><span class="comment">     * parquet格式的数据自带了表结构，不需要手动指定</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> parquetDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parquetDF.printSchema()</span><br><span class="line">    parquetDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取JDBC中的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jdbcDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://master:3306&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;bigdata.students&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line"></span><br><span class="line">    jdbcDF.printSchema()</span><br><span class="line">    jdbcDF.show()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="5、RDDToDF"><a href="#5、RDDToDF" class="headerlink" title="5、RDDToDF"></a>5、RDDToDF</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5RDDToDF</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取sparkContext，使用rdd ppi</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studnetRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = linesRDD</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">          (id, name, age, gender, clazz)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将rdd转换成DF</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = studnetRDD.toDF(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;gender&quot;</span>, <span class="string">&quot;clazz&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line">    studentDF.show()</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .json()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6、DFToRDD"><a href="#6、DFToRDD" class="headerlink" title="6、DFToRDD"></a>6、DFToRDD</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6DFToRDD</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将DF转换成RDD</span></span><br><span class="line">    <span class="keyword">val</span> studentRDD: <span class="type">RDD</span>[<span class="type">Row</span>] = studentDF.rdd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stuRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map((row: <span class="type">Row</span>) =&gt; &#123;</span><br><span class="line">      <span class="comment">//通过列名获取数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = row.getAs[<span class="type">Long</span>](<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      (id, name, age, gender, clazz)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//stuRDD.foreach(println)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> caseRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map &#123;</span><br><span class="line">      <span class="comment">//需要注意字段顺序</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Row</span>(age: <span class="type">Long</span>, clazz: <span class="type">String</span>, gender: <span class="type">String</span>, id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    caseRDD.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="7、开窗"><a href="#7、开窗" class="headerlink" title="7、开窗"></a>7、开窗</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 窗口函数</span></span><br><span class="line"><span class="comment">     * row_number</span></span><br><span class="line"><span class="comment">     * rank</span></span><br><span class="line"><span class="comment">     * sum</span></span><br><span class="line"><span class="comment">     * count</span></span><br><span class="line"><span class="comment">     * avg</span></span><br><span class="line"><span class="comment">     * max</span></span><br><span class="line"><span class="comment">     * min</span></span><br><span class="line"><span class="comment">     * lag 取当前行前面</span></span><br><span class="line"><span class="comment">     * lead： 取当前行后面的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;window&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//学生表</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING,clazz STRING&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;sid STRING,cid STRING,sco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//科目表</span></span><br><span class="line">    <span class="keyword">val</span> subjectDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;cid STRING,cname STRING,ssco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/subject.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = studentDF.join(scoreDF, $<span class="string">&quot;id&quot;</span> === $<span class="string">&quot;sid&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计总分年级排名前十学生各科的分数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * sum over 由两种用法</span></span><br><span class="line"><span class="comment">     * 1、之分区不拍戏----总和</span></span><br><span class="line"><span class="comment">     * 2、分区也排序-----累计求和</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//按总分排名</span></span><br><span class="line">      .orderBy($<span class="string">&quot;sumSco&quot;</span>.desc)</span><br><span class="line">      <span class="comment">//取top</span></span><br><span class="line">      .limit(<span class="number">60</span>)</span><br><span class="line">    <span class="comment">//.show(60)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计每科都及格的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreDF</span><br><span class="line">      <span class="comment">//关联科目表</span></span><br><span class="line">      .join(subjectDF, <span class="string">&quot;cid&quot;</span>)</span><br><span class="line">      <span class="comment">//1过滤不及格的分数</span></span><br><span class="line">      .where($<span class="string">&quot;sco&quot;</span> &gt;= $<span class="string">&quot;ssco&quot;</span> * <span class="number">0.6</span>)</span><br><span class="line">      <span class="comment">//统计每个学生几个的科目数</span></span><br><span class="line">      .withColumn(<span class="string">&quot;jige&quot;</span>, count($<span class="string">&quot;sid&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;sid&quot;</span>))</span><br><span class="line">      <span class="comment">//取出都及格的学生</span></span><br><span class="line">      .where($<span class="string">&quot;jige&quot;</span> === <span class="number">6</span>)</span><br><span class="line">    <span class="comment">//.show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、统计总分大于年级平均分的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//计算年级平均分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;avgSco&quot;</span>, avg($<span class="string">&quot;sumSco&quot;</span>) over <span class="type">Window</span>.partitionBy(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">      .where($<span class="string">&quot;sumSco&quot;</span> &gt; $<span class="string">&quot;avgSco&quot;</span>)</span><br><span class="line">    <span class="comment">//.show(1000)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计每个班级每个名次分数差</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * lag:取当前行前面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     * lead 取当前行后面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>, $<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      <span class="comment">//增加排名</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>, row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//取前一个名次的总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;headSumSco&quot;</span>, lag($<span class="string">&quot;sumSco&quot;</span>, <span class="number">1</span>, <span class="number">750</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//计算分数差</span></span><br><span class="line">      .withColumn(<span class="string">&quot;cha&quot;</span>, $<span class="string">&quot;headSumSco&quot;</span> - $<span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="8、练习"><a href="#8、练习" class="headerlink" title="8、练习"></a>8、练习</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Column</span>, <span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Burks</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;burk&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取数据</span></span><br><span class="line">    <span class="keyword">val</span> burksDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;burk STRING,year STRING,tsl01 DOUBLE,tsl02 DOUBLE,tsl03 DOUBLE,tsl04 DOUBLE,tsl05 DOUBLE,tsl06 DOUBLE,tsl07 DOUBLE,tsl08 DOUBLE,tsl09 DOUBLE,tsl10 DOUBLE,tsl11 DOUBLE,tsl12 DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/burks.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    burksDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计每个公司每年按月累计收入  行转列 --&gt; sum窗口函数</span></span><br><span class="line"><span class="comment">     * 输出结果</span></span><br><span class="line"><span class="comment">     * 公司代码,年度,月份,当月收入,累计收入</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    burksDF.createOrReplaceTempView(<span class="string">&quot;burks&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |burk,year,month,plc,</span></span><br><span class="line"><span class="string">        |sum(plc) over(partition by burk,year order by month) as leiji</span></span><br><span class="line"><span class="string">        | from (</span></span><br><span class="line"><span class="string">        |select burk,year,month,plc</span></span><br><span class="line"><span class="string">        |from burks</span></span><br><span class="line"><span class="string">        |lateral view explode(map(1,tsl01,2,tsl02,3,tsl03,4,tsl04,5,tsl05,6,tsl06,7,tsl07,8,tsl08,9,tsl09,10,tsl10,11,tsl11,12,tsl12)) T as month,plc</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">    <span class="comment">// .show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> m: <span class="type">Column</span> = map(</span><br><span class="line">      expr(<span class="string">&quot;1&quot;</span>), $<span class="string">&quot;tsl01&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;2&quot;</span>), $<span class="string">&quot;tsl02&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;3&quot;</span>), $<span class="string">&quot;tsl03&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;4&quot;</span>), $<span class="string">&quot;tsl04&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;5&quot;</span>), $<span class="string">&quot;tsl05&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;6&quot;</span>), $<span class="string">&quot;tsl06&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;7&quot;</span>), $<span class="string">&quot;tsl07&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;8&quot;</span>), $<span class="string">&quot;tsl08&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;9&quot;</span>), $<span class="string">&quot;tsl09&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;10&quot;</span>), $<span class="string">&quot;tsl10&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;11&quot;</span>), $<span class="string">&quot;tsl11&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;12&quot;</span>), $<span class="string">&quot;tsl12&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    burksDF</span><br><span class="line">      <span class="comment">//一行转换成多行</span></span><br><span class="line">      .select($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>, explode(m) as <span class="type">Array</span>(<span class="string">&quot;month&quot;</span>, <span class="string">&quot;plc&quot;</span>))</span><br><span class="line">      <span class="comment">//计算按月累计</span></span><br><span class="line">      .withColumn(<span class="string">&quot;leiji&quot;</span>, sum($<span class="string">&quot;plc&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>).orderBy($<span class="string">&quot;month&quot;</span>))</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="9、Spark-Sql"><a href="#9、Spark-Sql" class="headerlink" title="9、Spark Sql"></a>9、Spark Sql</h5><p><strong>spark-sql  写代码方式</strong></p><h6 id="1、idea里面将代码编写好打包上传到集群中运行，上线使用"><a href="#1、idea里面将代码编写好打包上传到集群中运行，上线使用" class="headerlink" title="1、idea里面将代码编写好打包上传到集群中运行，上线使用"></a>1、idea里面将代码编写好打包上传到集群中运行，上线使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--conf spark.sql.shuffle.partitions=1 -- 设置spark sqlshuffle之后分区数据马，和代码里面设置是一样的，代码中优先级高</span><br><span class="line">spark-submit提交</span><br><span class="line">spark-submit --master yarn-client --class com.shujia.spark.sql.Demo9Submit --conf spark.sql.shuffle.partitions=1 spark-1.0.jar </span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用"><a href="#2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用" class="headerlink" title="2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用"></a>2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark-shell --master yarn-client</span><br><span class="line">不能使用yarn-cluster Driver必须再本地启动</span><br></pre></td></tr></table></figure><h6 id="3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql"><a href="#3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql" class="headerlink" title="3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql"></a>3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在spark-sql时完全兼容hive sql的</span><br><span class="line">spark-sql底层使用的时spark进行计算的</span><br><span class="line">hive 底层使用的是MR进行计算的</span><br></pre></td></tr></table></figure><h5 id="10、spark-sql整合hive"><a href="#10、spark-sql整合hive" class="headerlink" title="10、spark sql整合hive"></a>10、spark sql整合hive</h5><blockquote><p>在spark sql中使用hive的元数据</p><p>spark sql是使用spark进行计算的，hive使用MR进行计算的</p></blockquote><h6 id="1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"><a href="#1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务" class="headerlink" title="1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"></a>1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务</h6><p>cd &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hive-1.2.1&#x2F;conf&#x2F;</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://master:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h6 id="2、启动hive元数据服务-将hvie的元数据暴露给第三方使用"><a href="#2、启动hive元数据服务-将hvie的元数据暴露给第三方使用" class="headerlink" title="2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用"></a>2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup  hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="3、将hive-site-xml-复制到spark-conf目录下"><a href="#3、将hive-site-xml-复制到spark-conf目录下" class="headerlink" title="3、将hive-site.xml  复制到spark conf目录下"></a>3、将hive-site.xml  复制到spark conf目录下</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp hive-site.xml /usr/local/soft/spark-2.4.5/conf/</span><br></pre></td></tr></table></figure><h6 id="4、-将mysql-驱动包复制到spark-jars目录下"><a href="#4、-将mysql-驱动包复制到spark-jars目录下" class="headerlink" title="4、 将mysql 驱动包复制到spark jars目录下"></a>4、 将mysql 驱动包复制到spark jars目录下</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/hive-1.2.1/lib</span><br><span class="line">cp mysql-connector-java-5.1.49.jar /usr/local/soft/spark-2.4.5/jars/</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="5、整合好之后在spark-sql-里面就可以使用hive的表了"><a href="#5、整合好之后在spark-sql-里面就可以使用hive的表了" class="headerlink" title="5、整合好之后在spark-sql 里面就可以使用hive的表了"></a>5、整合好之后在spark-sql 里面就可以使用hive的表了</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模式是<span class="built_in">local</span>模式</span></span><br><span class="line">spark-sql -conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用yarn-client模式</span></span><br><span class="line">spark-sql --master yarn-client  --conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在spark-sql中设置运行参数</span></span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-e"><a href="#spark-sql-e" class="headerlink" title="spark-sql -e"></a>spark-sql -e</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 执行一条sql语句，执行完，自动退出</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>e &quot;select * from student&quot;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-f"><a href="#spark-sql-f" class="headerlink" title="spark-sql -f"></a>spark-sql -f</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">vim a.sql</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student</span><br><span class="line"><span class="comment">-- 执行一个sql文件</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>f a.sql</span><br></pre></td></tr></table></figure><h6 id="当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表"><a href="#当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表" class="headerlink" title="当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表"></a>当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表</h6><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">.builder()</span><br><span class="line">.appName(<span class="string">&quot;onhive&quot;</span>)</span><br><span class="line">.enableHiveSupport() <span class="comment">//开启hive的元数据支持，在代码中读取hive的元数据</span></span><br><span class="line">.getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">//读取hie的表</span></span><br><span class="line"><span class="keyword">val</span> studentDF = spark.talbe(<span class="string">&quot;studnet&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//写好的代码不能再本地运行， 需要打包上传到集群运行</span></span><br></pre></td></tr></table></figure><h6 id="spark-sql和hvie的建表语句一样"><a href="#spark-sql和hvie的建表语句一样" class="headerlink" title="spark sql和hvie的建表语句一样"></a>spark sql和hvie的建表语句一样</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">(</span><br><span class="line">id  string,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span>,</span><br><span class="line">gender string,</span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/student/&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score</span><br><span class="line">(</span><br><span class="line">student_id  string,</span><br><span class="line">cource_id string,</span><br><span class="line">sco <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/score/&#x27;</span>;</span><br></pre></td></tr></table></figure><h6 id="禁用集群spark日志"><a href="#禁用集群spark日志" class="headerlink" title="禁用集群spark日志"></a>禁用集群spark日志</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/conf</span><br><span class="line">mv log4j.properties.template log4j.properties</span><br><span class="line">vim log4j.properties</span><br><span class="line">修改配置</span><br><span class="line">log4j.rootCategory=ERROR, console</span><br></pre></td></tr></table></figure><h5 id="11、spark-sql和hive区别"><a href="#11、spark-sql和hive区别" class="headerlink" title="11、spark sql和hive区别"></a>11、spark sql和hive区别</h5><h6 id="1、spark-sql缓存"><a href="#1、spark-sql缓存" class="headerlink" title="1、spark sql缓存"></a>1、spark sql缓存</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 进入spark sql命令行</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span></span><br><span class="line"><span class="comment">-- 可以通过一个网址访问spark任务</span></span><br><span class="line">http:<span class="operator">/</span><span class="operator">/</span>master:<span class="number">4040</span></span><br><span class="line"><span class="comment">-- 设置并行度</span></span><br><span class="line"><span class="keyword">set</span> spark.sql.shuffle.partitions<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再spark-sql中对同一个表进行多次查询的时候可以将表缓存起来</span></span><br><span class="line">cache <span class="keyword">table</span> student;</span><br><span class="line"><span class="comment">-- 删除缓存</span></span><br><span class="line">uncache <span class="keyword">table</span> student;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再代码中也可以缓存DF</span></span><br><span class="line"> studentDF.persist(StorageLevel.MEMORY_ONLY)</span><br></pre></td></tr></table></figure><h6 id="2、spark-sql-mapjoin-—-广播变量"><a href="#2、spark-sql-mapjoin-—-广播变量" class="headerlink" title="2、spark sql mapjoin    — 广播变量"></a>2、spark sql mapjoin    — 广播变量</h6><h5 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><h5 id="MapJoin"><a href="#MapJoin" class="headerlink" title="MapJoin"></a>MapJoin</h5><blockquote><p>当一个大表关联小表的时候可以将小表加载到内存中进行关联—- 广播变量</p><p>在map端进行表关联，不会产生shuffle</p></blockquote> <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+broadcast(a)  */</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><blockquote><p>&#x2F;*+broadcast(a)  *&#x2F;   HINT:给sql加提示的语法</p></blockquote><h5 id="12、Spaark-JDBC"><a href="#12、Spaark-JDBC" class="headerlink" title="12、Spaark JDBC"></a>12、Spaark JDBC</h5><h6 id="1、开启hive的元数据服务"><a href="#1、开启hive的元数据服务" class="headerlink" title="1、开启hive的元数据服务"></a>1、开启hive的元数据服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="2、开启spark-jdbc-服务"><a href="#2、开启spark-jdbc-服务" class="headerlink" title="2、开启spark jdbc  服务"></a>2、开启spark jdbc  服务</h6><blockquote><p>saprkjdbc服务使用的就是hive的jdbc服务</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/sbin/</span><br><span class="line">./start-thriftserver.sh --master yarn-client</span><br></pre></td></tr></table></figure><h6 id="3、使用命令链接spark-sql-jdbc服务"><a href="#3、使用命令链接spark-sql-jdbc服务" class="headerlink" title="3、使用命令链接spark sql  jdbc服务"></a>3、使用命令链接spark sql  jdbc服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/bin/</span><br><span class="line">./beeline </span><br><span class="line">输入</span><br><span class="line">!connect jdbc:hive2://master:10000</span><br><span class="line"></span><br><span class="line">设置sparkshuffle并行度</span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="4、使用scala代码远程链接spark-sql-jdbc服务"><a href="#4、使用scala代码远程链接spark-sql-jdbc服务" class="headerlink" title="4、使用scala代码远程链接spark sql jdbc服务"></a>4、使用scala代码远程链接spark sql jdbc服务</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">-- 1、在maven增加增加jdbc驱动</span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">-- 2、编写java jdbc代码</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Spark-Sql的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark搭建</title>
    <link href="http://example.com/2022/07/12/spark%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/12/spark%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-11T16:00:00.000Z</published>
    <updated>2022-07-18T12:55:56.541Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Spark搭建"><a href="#Spark搭建" class="headerlink" title="Spark搭建"></a>Spark搭建</h3><h4 id="一、standalone模式"><a href="#一、standalone模式" class="headerlink" title="一、standalone模式"></a>一、standalone模式</h4><h5 id="1、上传解压，配置环境变量-配置bin目录"><a href="#1、上传解压，配置环境变量-配置bin目录" class="headerlink" title="1、上传解压，配置环境变量 配置bin目录"></a>1、上传解压，配置环境变量 配置bin目录</h5><p>解压</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf spark-2.4.5-bin-hadoop2.7.tgz </span><br></pre></td></tr></table></figure><p>重命名</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5</span><br></pre></td></tr></table></figure><p>配置环境变量<br><img src="https://s2.loli.net/2022/07/13/JhzWDHme6kwMncb.png" alt="image-20220713092425892"></p><h5 id="2、修改配置文件-conf"><a href="#2、修改配置文件-conf" class="headerlink" title="2、修改配置文件(conf)"></a>2、修改配置文件(conf)</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"></span><br><span class="line">export SPARK_WORKER_CORES=2</span><br><span class="line">export SPARK_WORKER_INSTANCES=1</span><br><span class="line">export SPARK_WORKER_MEMORY=2g</span><br><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><p>master相当于RM  worker相当于NM</p><p>增加从节点配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim slaves</span><br><span class="line">增加从节点</span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><h5 id="3、复制到其它节点"><a href="#3、复制到其它节点" class="headerlink" title="3、复制到其它节点"></a>3、复制到其它节点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r spark-2.4.5 node1:`pwd`</span><br><span class="line">scp -r spark-2.4.5 node2:`pwd`</span><br></pre></td></tr></table></figure><h5 id="4、在主节点执行启动命令"><a href="#4、在主节点执行启动命令" class="headerlink" title="4、在主节点执行启动命令"></a>4、在主节点执行启动命令</h5><p>​    启动集群，在master中执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./sbin/start-all.sh</span><br></pre></td></tr></table></figure><figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">http://master:8080/  访问spark ui</span><br></pre></td></tr></table></figure><h5 id="5、两种spark提交任务的方式"><a href="#5、两种spark提交任务的方式" class="headerlink" title="5、两种spark提交任务的方式"></a>5、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><p>（1）standalone client模式 日志在本地输出，一般用于上线前测试(bin&#x2F;下执行)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512m --total-executor-cores 1 spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）standalone cluster模式，上线使用，不会再本地打印日志</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512M --total-executor-cores 1 --deploy-mode cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码"><a href="#6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码" class="headerlink" title="6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码"></a>6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-shell master spark://master:7077</span><br></pre></td></tr></table></figure><h4 id="二、spark整合yarn"><a href="#二、spark整合yarn" class="headerlink" title="二、spark整合yarn"></a>二、spark整合yarn</h4><p>​        在公司一般不适用standalone模式，因为公司一般已经有yarn，不需要搞两个资源管理框架</p><p>首先停止spark集群，在spark sbin目录下执行  .&#x2F;stop-all.sh，也要保证hadoop也是关闭的</p><p>spark整合yarn只需要在一个节点整合, 可以删除node1 和node2中所有的spark 文件（也可以不删除）</p><h5 id="1、增加hadoop-配置文件地址"><a href="#1、增加hadoop-配置文件地址" class="headerlink" title="1、增加hadoop 配置文件地址"></a>1、增加hadoop 配置文件地址</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim spark-env.sh</span><br><span class="line">增加配置</span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/soft/hadoop-2.7.6/etc/hadoop</span><br></pre></td></tr></table></figure><h5 id="2、往yarn提交任务需要增加两个配置-yarn-site-xml"><a href="#2、往yarn提交任务需要增加两个配置-yarn-site-xml" class="headerlink" title="2、往yarn提交任务需要增加两个配置  yarn-site.xml"></a>2、往yarn提交任务需要增加两个配置  yarn-site.xml</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/soft/hadoop-2.7.6/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="3、同步到其他节点，重启yarn"><a href="#3、同步到其他节点，重启yarn" class="headerlink" title="3、同步到其他节点，重启yarn"></a>3、同步到其他节点，重启yarn</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r yarn-site.xml node1:`pwd`</span><br><span class="line">scp -r yarn-site.xml node2:`pwd`</span><br></pre></td></tr></table></figure><p>启动yarn</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h5 id="4、两种spark提交任务的方式"><a href="#4、两种spark提交任务的方式" class="headerlink" title="4、两种spark提交任务的方式"></a>4、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><p>（1）spark on yarn client模式，日志在本地输出，一般用于上线前测试</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）spark on yarn cluster模式，上线使用，不会再本地打印日志减少io</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="5、获取yarn程序执行日志-执行成功之后才能获取到"><a href="#5、获取yarn程序执行日志-执行成功之后才能获取到" class="headerlink" title="5、获取yarn程序执行日志  执行成功之后才能获取到"></a>5、获取yarn程序执行日志  执行成功之后才能获取到</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><h5 id="6、杀掉进行的任务"><a href="#6、杀掉进行的任务" class="headerlink" title="6、杀掉进行的任务"></a>6、杀掉进行的任务</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><p>hdfs web ui<br><a href="http://node1:50070/">http://node1:50070</a></p><p>yarn ui<br><a href="http://node1:8088/">http://node1:8088</a></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark代码</title>
    <link href="http://example.com/2022/07/11/spark%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/11/spark%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-10T16:00:00.000Z</published>
    <updated>2022-07-25T14:28:50.966Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1、编写wordcount-（standalone模式）"><a href="#1、编写wordcount-（standalone模式）" class="headerlink" title="1、编写wordcount    （standalone模式）"></a>1、编写wordcount    （standalone模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  建立连接</span></span><br><span class="line"><span class="comment">     *  提交到集群运行需要注释setMaster</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo18SparkSubmit&quot;</span>)</span><br><span class="line"><span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> valuesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">List</span>(<span class="string">&quot;java,java,hadoop&quot;</span>, <span class="string">&quot;spark,scala,java&quot;</span>, <span class="string">&quot;hadoop,hadoop,scala&quot;</span>)) </span><br><span class="line">    valuesRDD.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_+_) <span class="comment">//按key聚合</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master spark://master:7077 spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="2、编写wordcount-（on-yarn模式）"><a href="#2、编写wordcount-（on-yarn模式）" class="headerlink" title="2、编写wordcount    （on yarn模式）"></a>2、编写wordcount    （on yarn模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 建立连接，注释掉setMaster一行</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line"></span><br><span class="line">    conf.setAppName(<span class="string">&quot;submit on yarn&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">Configuration</span>()</span><br><span class="line">    <span class="keyword">val</span> fileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystem</span>.get(conf)</span><br><span class="line">    <span class="keyword">if</span> (fileSystem.exists(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>))) &#123;</span><br><span class="line">      fileSystem.delete(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>), <span class="literal">true</span>)<span class="comment">//若存在，删除目标路径</span></span><br><span class="line"></span><br><span class="line">    sc.textFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs的输入路径</span></span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_ + _)</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> (word: <span class="type">String</span>, count: <span class="type">Int</span>) =&gt;</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$word</span>\t<span class="subst">$count</span>&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">      .saveAsTextFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs输出目录，保证目标路径不存在</span></span><br><span class="line">    </span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master yarn-client spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="3、用spark代码实现PI的计算"><a href="#3、用spark代码实现PI的计算" class="headerlink" title="3、用spark代码实现PI的计算"></a>3、用spark代码实现PI的计算</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20PI</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建spark环境</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo20PI&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//生成一个大集合</span></span><br><span class="line">    <span class="keyword">val</span> list: <span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="number">0</span> to <span class="number">100000</span></span><br><span class="line">    <span class="comment">//构建一个很大的RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.parallelize(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//随机生成正方形内的点</span></span><br><span class="line">    <span class="keyword">val</span> squareRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = rdd.map(i =&gt; &#123;</span><br><span class="line">      <span class="comment">//随机生成x和y，范围是[-1,1]</span></span><br><span class="line">      <span class="keyword">val</span> x: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> y: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      (x, y)</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="comment">//取出圆内的点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> circleRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = squareRDD.filter &#123;</span><br><span class="line">      <span class="keyword">case</span> (x, y) =&gt;</span><br><span class="line">        x * x + y * y &lt; <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">PI</span>: <span class="type">Double</span> = <span class="number">4.0</span> * circleRDD.count() / squareRDD.count()</span><br><span class="line"></span><br><span class="line">    println(<span class="type">PI</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、spark代码的坑（引出累加器）"><a href="#4、spark代码的坑（引出累加器）" class="headerlink" title="4、spark代码的坑（引出累加器）"></a>4、spark代码的坑（引出累加器）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">  count += <span class="number">1</span></span><br><span class="line">  println(count)</span><br><span class="line">&#125;)</span><br><span class="line">  println (<span class="string">s&quot;count:<span class="subst">$&#123;count&#125;</span>&quot;</span>) <span class="comment">//不要这么写</span></span><br></pre></td></tr></table></figure><p>在spark编程中算子内的代码会被封装成Task发送到<strong>Executor</strong>中去执行，而算子外的代码运行在driver端，Executor和Driver属于不同的JVM，所以当在算子内修改算子外的一个普通变量时不会生效，当算子内使用算子外的一个普通变量时，这个变量会以变量副本的形式发送给Executor中去。</p><p><strong>累加器</strong></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、定义一个累加器</span></span><br><span class="line">   <span class="keyword">val</span> accumulator: <span class="type">LongAccumulator</span> = sc.longAccumulator</span><br><span class="line"></span><br><span class="line">   studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="comment">//2、对累加器进行累加</span></span><br><span class="line">     accumulator.add(<span class="number">1</span>)</span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="comment">//3、再从Driver端读取累加结果</span></span><br><span class="line">   println(<span class="string">s&quot;accumulator:<span class="subst">$&#123;accumulator.value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>累加器原理</strong></p><p>1、现在每一个task中局部做累加</p><p>2、当job执行完成之后，将多个累加结果汇总到Driver端合并成一个结果</p><p><strong>累加器使用的限制</strong></p><p>1、只能在Driver端定义累加器</p><p>2、只能在Executor端进行累加</p><p>3、只能在Driver端读取结果</p><p>在spark写代码的过程中，rdd不能嵌套使用，在算子内不能使用rdd</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">       println(stu)</span><br><span class="line">     &#125;)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><p>在算子内 不能使用SparkContext，算子会被封装成一个Task，而Task不能被序列化（Task需要网络传输）</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line">     scoreRDD.foreach(println)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><h5 id="5、广播变量"><a href="#5、广播变量" class="headerlink" title="5、广播变量"></a>5、广播变量</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Broadcast</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo23Broadcast&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 广播变量</span></span><br><span class="line"><span class="comment">     * 当算子内使用算子外的一个比较大的变量时，可以将这个变量广播出去，可以减少变量的副本数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">      <span class="comment">//读取学生表，以学号作为key构建一个map集合</span></span><br><span class="line">    <span class="keyword">val</span> studentMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">      .getLines()</span><br><span class="line">      .toList</span><br><span class="line">      .map(stu =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> id: <span class="type">String</span> = stu.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">        (id, stu)</span><br><span class="line">      &#125;)</span><br><span class="line">      .toMap</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关联学生表和分数表</span></span><br><span class="line"><span class="comment">     * 循环分数表，使用学号到学生表的map集合中查询学生的信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreRDD.map(sco=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = sco.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">      <span class="comment">//使用学号到学生表中获取学生的信息</span></span><br><span class="line">      <span class="keyword">val</span> studentInfo: <span class="type">String</span> = studentMap.getOrElse(id, <span class="string">&quot;默认值&quot;</span>)</span><br><span class="line">      (sco,studentInfo)</span><br><span class="line">    &#125;)</span><br><span class="line">      .foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在使用算子内使用算子外的一个普通变量时，普通变量会以变量副本的形式封装到Task中，将Task发送到Executor中执行。</p><p>如果rdd有10个分区，则会产生10个Task，汇总产生10个变量副本</p><p>广播变量的使用（在spark中常用于<strong>mapJoin</strong>）</p><p>1、在Driver端定义广播变量</p><p>2、到Executor使用广播变量</p><p>如果不使用广播变量，每一个task都需要携带一个变量副本每增加网络IO，增加副本数</p><p>使用广播每一个Executor中的一个变量副本</p><p>正常情况时task的数量远小于Executor的数量</p><p>mapJoin不产生shuffle，性能比reduceJoin好</p><p>mapJoin只适合小表关联大表（小表的数据量不超1G）</p><p><img src="https://s2.loli.net/2022/07/14/tSmhnvJM327pbxF.png" alt="blockmanasger"></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark概述</title>
    <link href="http://example.com/2022/07/10/spark%E6%A6%82%E8%BF%B0/"/>
    <id>http://example.com/2022/07/10/spark%E6%A6%82%E8%BF%B0/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2022-07-13T01:59:05.797Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/07/13/v6e4yxQ98YuOZKD.png" alt="屏幕截图 2022-07-13 095014"></p><p>MapReduce执行流程</p><p><img src="https://s2.loli.net/2022/07/13/b91AKcnLVuo3UvE.png" alt="mr执行流程"></p><p>RDD基础</p><p><img src="https://s2.loli.net/2022/07/13/9pGtPZL3gwcxoq4.png" alt="image-20220713095434515"></p><p>reduceByKey和groupByKey的区别</p><p><img src="https://s2.loli.net/2022/07/13/eGU2wRthNzT9Fbq.png" alt="reduceByKey金额groupByKey的区别"></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>scala概述及使用</title>
    <link href="http://example.com/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://example.com/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/</id>
    <published>2022-07-05T16:00:00.000Z</published>
    <updated>2022-07-13T11:24:51.551Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、scala介绍"><a href="#1、scala介绍" class="headerlink" title="1、scala介绍"></a>1、scala介绍</h3><p>Scala 是 Scalable Language 的简写，是一门多范式的编程语言</p><p>联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计Scala。</p><p>Scala是把函数式编程思想和面向对象编程思想结合的一种编程语言。</p><p>大数据计算引擎Spark由Scala编写</p><h3 id="2、Scala特点"><a href="#2、Scala特点" class="headerlink" title="2、Scala特点"></a>2、Scala特点</h3><p><strong>多范式</strong>：面向对象，函数式编程</p><p><strong>兼容JAVA</strong>：类库调用，互操作</p><p><strong>语法简洁</strong>：代码行短，类型推断，抽象控制</p><p><strong>静态类型化</strong>：可检验，安全重构</p><p><strong>支持并发控制</strong>：强计算能力，自定义其他控制结构</p><p>在面向对象编程中，我们把对象传来传去，那在函数式编程中，我们要做的是把函数传来传去，而这个，说成术语，我们把他叫做高阶函数。</p><p>在函数式编程中，函数是基本单位，，他几乎被用作一切，包括最简单的计算，甚至连变量都被计算所取代。在函数式编程中，变量只是一个名称，而不是一个存储单元，这是函数式编程与传统的命令式编程最典型的不同之处。</p><h3 id="3、scala和java的联系"><a href="#3、scala和java的联系" class="headerlink" title="3、scala和java的联系"></a>3、scala和java的联系</h3><p><img src="https://s2.loli.net/2022/07/13/4ahsL5tkqSGlf2m.png" alt="屏幕截图 2022-07-13 102038"></p><h3 id="4、环境准备及代码编写"><a href="#4、环境准备及代码编写" class="headerlink" title="4、环境准备及代码编写"></a>4、环境准备及代码编写</h3><h4 id="1、在idea中增加scala插件"><a href="#1、在idea中增加scala插件" class="headerlink" title="1、在idea中增加scala插件"></a>1、在idea中增加scala插件</h4><p><img src="https://s2.loli.net/2022/07/13/DogYxlEBcjnZVKy.png" alt="image-20220713102325386"></p><h4 id="2、新建一个maven项目，在pom中增加Scala和java的编译插件"><a href="#2、新建一个maven项目，在pom中增加Scala和java的编译插件" class="headerlink" title="2、新建一个maven项目，在pom中增加Scala和java的编译插件"></a>2、新建一个maven项目，在pom中增加Scala和java的编译插件</h4><h5 id="（1）在pom文件中增加依赖"><a href="#（1）在pom文件中增加依赖" class="headerlink" title="（1）在pom文件中增加依赖"></a>（1）在pom文件中增加依赖</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-reflect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="（2）在pom中增加Scala和java的编译插件"><a href="#（2）在pom中增加Scala和java的编译插件" class="headerlink" title="（2）在pom中增加Scala和java的编译插件"></a>（2）在pom中增加Scala和java的编译插件</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Scala Compiler --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-scala-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="3、scala样例类"><a href="#3、scala样例类" class="headerlink" title="3、scala样例类"></a>3、scala样例类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8CaseClass</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> user1 = <span class="keyword">new</span> <span class="type">User</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;张三&quot;</span>)</span><br><span class="line">    <span class="comment">//直接通过属性获取值</span></span><br><span class="line">    println(user1.id)</span><br><span class="line">    println(user1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//样例类可以不适用new创建对象</span></span><br><span class="line">    <span class="keyword">val</span> user2: <span class="type">User</span> = <span class="type">User</span>(<span class="string">&quot;002&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="number">24</span>)</span><br><span class="line">    println(user2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//修改属性,需要在属性上增加var</span></span><br><span class="line">    user2.name = <span class="string">&quot;王五&quot;</span></span><br><span class="line">    println(user2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 样例类</span></span><br><span class="line"><span class="comment"> * scala会在编译的时候给样例类动态增加新的方法，属性，toString，序列化</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * age: Int = 0: 参数默认值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id: <span class="type">String</span>,var name: <span class="type">String</span>, age: <span class="type">Int</span> = 0</span>)</span></span><br></pre></td></tr></table></figure><h4 id="4、List"><a href="#4、List" class="headerlink" title="4、List"></a>4、List</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo15List</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合</span></span><br><span class="line"><span class="comment">     * 1、List: 有序，不唯一</span></span><br><span class="line"><span class="comment">     * 2、Set ：无序，唯一</span></span><br><span class="line"><span class="comment">     * 3、Map: kv格式   key是唯一的</span></span><br><span class="line"><span class="comment">     * 4、Tuple: 元组，固定长度集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * List集合</span></span><br><span class="line"><span class="comment">     * scal的集合比java的集合好用-多了很多的方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//不可变的List</span></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标获取数据</span></span><br><span class="line">    println(list(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">//获取第一个元素</span></span><br><span class="line">    println(list.head)</span><br><span class="line">    <span class="comment">//获取最后一个元素</span></span><br><span class="line">    println(list.last)</span><br><span class="line">    <span class="comment">//获取不包含第一个元素的所有的元素</span></span><br><span class="line">    println(list.tail)</span><br><span class="line">    <span class="comment">//将集合中的元素拼接成一个字符串</span></span><br><span class="line">    println(list.mkString(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment">//反转，返回一个新的List</span></span><br><span class="line">    println(list.reverse)</span><br><span class="line">    <span class="comment">//取前n个元素</span></span><br><span class="line">    println(list.take(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//取后n个元素</span></span><br><span class="line">    println(list.takeRight(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//去重</span></span><br><span class="line">    println(list.distinct)</span><br><span class="line">    <span class="comment">//求和，集合元素的类型必须是可以求和的类型</span></span><br><span class="line">    println(list.sum)</span><br><span class="line">    <span class="comment">//取最大值</span></span><br><span class="line">    println(list.max)</span><br><span class="line">    <span class="comment">//最小值</span></span><br><span class="line">    println(list.min)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * foreach: 循环集合，将集合中的元素一个一个传递给后面的函数，foreach没有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">var</span> sum = <span class="number">0</span></span><br><span class="line">    <span class="comment">//循环统计总和</span></span><br><span class="line">    list.foreach((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      sum += i</span><br><span class="line">    &#125;)</span><br><span class="line">    println(sum)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个元素加一（处理集合中的元素）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- list) &#123;</span><br><span class="line">      <span class="keyword">val</span> j = i * <span class="number">2</span></span><br><span class="line">      println(j)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map:循环集合将集合中的元素一个一个传递给后面的函数，函数的返回值会构建出一个新的集合</span></span><br><span class="line"><span class="comment">     * i代表的是集合中所有的元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mapList: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    println(mapList)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理集合中的元素，偶数加1，奇数乘以2</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        i * <span class="number">2</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        i + <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    println(list2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 取出集合中奇数</span></span><br><span class="line"><span class="comment">     * Filter: 循环集合，将集合中的元素一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 如果函数返回true保留数据，如果函数返回false过滤数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> jishuList: <span class="type">List</span>[<span class="type">Int</span>] = list.filter((i: <span class="type">Int</span>) =&gt; i % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">    println(jishuList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将一行中的多个单词拆分出来，一个单纯一行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesList = <span class="type">List</span>(<span class="string">&quot;java,spark,hadoop&quot;</span>, <span class="string">&quot;datax,scala,java&quot;</span>, <span class="string">&quot;hadoop,hive,sqoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (line &lt;- linesList) &#123;</span><br><span class="line">      <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">        println(word)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * flatMap: 循环集合中的元素，将袁术一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 函数返回一个集合，flatMap会将返回的集合拆分出来构建成一个新的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> wordsList: <span class="type">List</span>[<span class="type">String</span>] = linesList.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    wordsList.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 多集合排序</span></span><br><span class="line"><span class="comment">     * sortBy: 需要指定一个排序的字段，默认是升序</span></span><br><span class="line"><span class="comment">     * sortWith: 指定一个排序的比较规则</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">32</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortByList = list3.sortBy((i: <span class="type">Int</span>) =&gt; -i)</span><br><span class="line">    println(sortByList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortWithList = list3.sortWith((x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x &gt; y)</span><br><span class="line">    println(sortWithList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * groupBy: 分组，需要指定一个分组的字段</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> words = <span class="type">List</span>(<span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    groupByList.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 以下所有的方法都是返回新的集合，不会修改原始的集合</span></span><br><span class="line"><span class="comment">     * 同时以下这些方法在set集合中也有，除了sort</span></span><br><span class="line"><span class="comment">     * foreach:遍历数据</span></span><br><span class="line"><span class="comment">     * map：一条一条处理数据</span></span><br><span class="line"><span class="comment">     * filter：过滤数据</span></span><br><span class="line"><span class="comment">     * flatMap:将一行转换成多行</span></span><br><span class="line"><span class="comment">     * sortBy：排序</span></span><br><span class="line"><span class="comment">     * groupBy：分组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Set"><a href="#5、Set" class="headerlink" title="5、Set"></a>5、Set</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo16Set</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Set集合，无序，唯一</span></span><br><span class="line"><span class="comment">     * set集合比List集合少了排序的方法，其它的方法基本一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> set = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line">    println(set)</span><br><span class="line">    println(set.mkString(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line">    set.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> s1 = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">val</span> s2 = <span class="type">Set</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    println(s1 &amp; s2)<span class="comment">//交集</span></span><br><span class="line">    println(s1 | s2)<span class="comment">//并集</span></span><br><span class="line">    println(s1 &amp;~ s2)<span class="comment">//差集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 集合之前的转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line">    println(list)</span><br><span class="line">    <span class="keyword">val</span> listSet = list.toSet</span><br><span class="line">    println(listSet)</span><br><span class="line">    println(listSet.toList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、Mutable"><a href="#6、Mutable" class="headerlink" title="6、Mutable"></a>6、Mutable</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo17Mutable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变集合</span></span><br><span class="line"><span class="comment">     * ListBuffer:List有的方法ListBuffer都有，只是ListBuffer是可以改变的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listBuffer = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    listBuffer.+=(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    listBuffer += <span class="string">&quot;spark&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;hadoop&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;flume&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    listBuffer -= <span class="string">&quot;java&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用下标删除钠元素</span></span><br><span class="line">    listBuffer.remove(<span class="number">1</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//批量插入元素</span></span><br><span class="line">    listBuffer ++= <span class="type">List</span>(<span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//更新元素</span></span><br><span class="line">    listBuffer.update(<span class="number">1</span>, <span class="string">&quot;shujia&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标插入元素</span></span><br><span class="line">    listBuffer.insert(<span class="number">2</span>, <span class="string">&quot;大数据&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变Set</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashSet = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">Int</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    hashSet += <span class="number">1</span></span><br><span class="line">    hashSet += <span class="number">2</span></span><br><span class="line">    hashSet += <span class="number">3</span></span><br><span class="line">    hashSet += <span class="number">4</span></span><br><span class="line">    hashSet += <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    println(hashSet)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashSet -= <span class="number">1</span></span><br><span class="line">    println(hashSet)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Tuple"><a href="#7、Tuple" class="headerlink" title="7、Tuple"></a>7、Tuple</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo18Tuple</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 元组：固定长度集合</span></span><br><span class="line"><span class="comment">     * 可以通过下划线加上下标获取数据, 可以避免下标越界异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 元组最多只能存22个元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//val tuple = Tuple6(1, 2, 3, 4, 5, 6)</span></span><br><span class="line">    <span class="comment">//简写</span></span><br><span class="line">    <span class="keyword">val</span> tuple = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    println(tuple._6)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Map"><a href="#8、Map" class="headerlink" title="8、Map"></a>8、Map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo19Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map：kv格式的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = <span class="type">Map</span>((<span class="string">&quot;001&quot;</span>, <span class="number">23</span>), (<span class="string">&quot;002&quot;</span>, <span class="number">24</span>), <span class="string">&quot;003&quot;</span> -&gt; <span class="number">25</span>)</span><br><span class="line">    println(map)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以通过key获取value</span></span><br><span class="line">    <span class="keyword">val</span> value = map(<span class="string">&quot;001&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果key不存在返回默认值</span></span><br><span class="line">    <span class="keyword">val</span> age = map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="number">0</span>)</span><br><span class="line">    println(age)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个人的年龄加一</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * map集合的map方法，函数的参数是一个二元组,</span></span><br><span class="line"><span class="comment">     * 返回一个新的map</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> addAge: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map.map((kv: (<span class="type">String</span>, <span class="type">Int</span>)) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> id = kv._1</span><br><span class="line">      <span class="keyword">val</span> age = kv._2</span><br><span class="line">      (id, age + <span class="number">1</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">    println(addAge)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取所有的key和value</span></span><br><span class="line">    println(map.keys)</span><br><span class="line">    println(map.values)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变map集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//插入元素</span></span><br><span class="line">    hashMap += <span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;王五&quot;</span></span><br><span class="line"></span><br><span class="line">    println(hashMap)</span><br><span class="line">    <span class="comment">//如果key存在自动覆盖</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;赵六&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashMap.remove(<span class="string">&quot;003&quot;</span>)</span><br><span class="line">    hashMap -= <span class="string">&quot;002&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、WordCount"><a href="#9、WordCount" class="headerlink" title="9、WordCount"></a>9、WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计单纯的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//链式调用</span></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/words.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将一行中的多个单纯展开，变成一个单词一行</span></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">List</span>[<span class="type">String</span>] = lines.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、按照单词分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、统计单词的数量</span></span><br><span class="line">    <span class="keyword">val</span> wordCount: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupBy.map((kv: (<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])) =&gt; &#123;</span><br><span class="line">      <span class="comment">//分组单词</span></span><br><span class="line">      <span class="keyword">val</span> word: <span class="type">String</span> = kv._1</span><br><span class="line">      <span class="comment">//组内所有的单词</span></span><br><span class="line">      <span class="keyword">val</span> values: <span class="type">List</span>[<span class="type">String</span>] = kv._2</span><br><span class="line">      <span class="comment">//计算单词的数量</span></span><br><span class="line">      <span class="keyword">val</span> count = values.length</span><br><span class="line">      <span class="comment">//返回单词和单词的数量</span></span><br><span class="line">      (word, count)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印结果</span></span><br><span class="line">    wordCount.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 简写</span></span><br><span class="line"><span class="comment">     * 链式调用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/words.txt&quot;</span>)<span class="comment">//读取文件</span></span><br><span class="line">      .getLines()<span class="comment">//获取所有行</span></span><br><span class="line">      .toList<span class="comment">//转换成集合</span></span><br><span class="line">      .flatMap(_.split(<span class="string">&quot;,&quot;</span>))<span class="comment">//将数据展开</span></span><br><span class="line">      .groupBy(w =&gt; w)<span class="comment">//安装单词分组</span></span><br><span class="line">      .map(kv =&gt; (kv._1, kv._2.length))<span class="comment">//统计单词的数量</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="10、统计学生的总分"><a href="#10、统计学生的总分" class="headerlink" title="10、统计学生的总分"></a>10、统计学生的总分</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Case</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoresList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、安装逗号拆分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoLost: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoresList.map(sco =&gt; sco.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> filterList: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoLost.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * case 也可以匹配数组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = filterList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _: <span class="type">String</span>, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当需要处理的集合中的数据格式是一个很复杂的元组时，使用case语法，代码的可读性会更高</span></span><br><span class="line"><span class="comment">     * 以函数作为参数的另一种写法</span></span><br><span class="line"><span class="comment">     * 没有使用的变量可以使用下划线占位</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sumScoList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupByList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, scores: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//取出分数</span></span><br><span class="line">        <span class="keyword">val</span> scos: <span class="type">List</span>[<span class="type">Int</span>] = scores.map &#123; <span class="keyword">case</span> (_: <span class="type">String</span>, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line">        <span class="keyword">val</span> sumSco: <span class="type">Int</span> = scos.sum</span><br><span class="line">        (id, sumSco)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sumScoList.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="11、scala连接Mysql（JDBC）"><a href="#11、scala连接Mysql（JDBC）" class="headerlink" title="11、scala连接Mysql（JDBC）"></a>11、scala连接Mysql（JDBC）</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>, <span class="type">ResultSet</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo24Jdbc</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在scala语法中链接数据库</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//需要先在pom中增加mysql驱动的依赖</span></span><br><span class="line">    <span class="comment">//1、加载驱动</span></span><br><span class="line">    <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">    <span class="comment">//2、建立数据库链接</span></span><br><span class="line">    <span class="keyword">val</span> con: <span class="type">Connection</span> = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master/test?useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、编写sql查询数据</span></span><br><span class="line">    <span class="keyword">val</span> stat: <span class="type">PreparedStatement</span> = con.prepareStatement(<span class="string">&quot;select * from students where clazz=?&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、给参数赋值</span></span><br><span class="line">    stat.setString(<span class="number">1</span>, <span class="string">&quot;文科六班&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、执行查询</span></span><br><span class="line">    <span class="keyword">val</span> resultSet: <span class="type">ResultSet</span> = stat.executeQuery()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6、解析数据</span></span><br><span class="line">    <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">      <span class="comment">//通过列名取出数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$gender</span>\t<span class="subst">$clazz</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7、关闭连接</span></span><br><span class="line">    stat.close()</span><br><span class="line">    con.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="12、scala解析Json数据"><a href="#12、scala解析Json数据" class="headerlink" title="12、scala解析Json数据"></a>12、scala解析Json数据</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONArray</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo25JSON</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 第三方解析json工具  fastJson  Gson</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/users.json&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将读到的数据拼接成一个字符串</span></span><br><span class="line">    <span class="keyword">val</span> jsonStr: <span class="type">String</span> = lines.mkString(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    println(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用FastJson解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userArray: <span class="type">JSONArray</span> = <span class="type">JSON</span>.parseArray(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (index &lt; userArray.size()) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过下标获取每一个用户</span></span><br><span class="line">      <span class="keyword">val</span> userObject: <span class="type">JSONObject</span> = userArray.getJSONObject(index)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过列名获取列值</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = userObject.getString(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> nane: <span class="type">String</span> = userObject.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: lang.<span class="type">Long</span> = userObject.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line"></span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$nane</span>\t<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      index += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="13、scala和java中的集合相互转换"><a href="#13、scala和java中的集合相互转换" class="headerlink" title="13、scala和java中的集合相互转换"></a>13、scala和java中的集合相互转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo26ScalaOnJava</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//java中的集合</span></span><br><span class="line">    <span class="keyword">val</span> arrayList = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    arrayList.add(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hive&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;scala&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * java 集合转换成scala集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//下划线相当于java中的*</span></span><br><span class="line">    <span class="comment">//导入隐式转换(动态给对象增加新的方法)</span></span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConverters</span>._</span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scalaList: <span class="type">List</span>[<span class="type">String</span>] = arrayList.asScala.toList</span><br><span class="line"></span><br><span class="line">    println(scalaList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合转换成java集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> javaList: util.<span class="type">List</span>[<span class="type">Int</span>] = list.asJava</span><br><span class="line"></span><br><span class="line">    println(javaList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="14、Match"><a href="#14、Match" class="headerlink" title="14、Match"></a>14、Match</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo27Match</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * java中的模式匹配可以匹配基本数据类型，字符串，枚举</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * scala的模式匹配，可以匹配基本数据类型，字符串，对象，元组，数组，匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、匹配基本数据类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 模式匹配只有一个能匹配成功</span></span><br><span class="line"><span class="comment">     * 下划线代表其其它情况</span></span><br><span class="line"><span class="comment">     * 在写代码是需要考虑到所有的情况</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> i = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    i <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">10</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是10&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">20</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是20&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">100</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是100&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">&quot;其他&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、匹配字符串</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> str: <span class="type">String</span> = <span class="string">&quot;java&quot;</span></span><br><span class="line"></span><br><span class="line">    str <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;java&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;spark&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;其它&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、匹配元组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> t: (<span class="type">String</span>, <span class="type">Int</span>, <span class="type">String</span>) = (<span class="string">&quot;张三&quot;</span>, <span class="number">23</span>, <span class="string">&quot;001&quot;</span>)</span><br><span class="line"></span><br><span class="line">    t <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//替代下划线</span></span><br><span class="line">    <span class="keyword">val</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) = t</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、匹配数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[<span class="type">Any</span>] = <span class="type">Array</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;李四&quot;</span>)</span><br><span class="line"></span><br><span class="line">    array <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">Int</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\4<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 5、匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> obj: <span class="type">Any</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    obj <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> i: <span class="type">Int</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Int类型：<span class="subst">$i</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">String</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个String类型:<span class="subst">$s</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> d: <span class="type">Double</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Double类型:<span class="subst">$d</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">s&quot;其它类型：<span class="subst">$obj</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配可以有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i1: <span class="type">Int</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ty: <span class="type">String</span> = i1 % <span class="number">2</span> <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">&quot;奇数&quot;</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="string">&quot;偶数&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(ty)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配在map集合的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> map = <span class="type">Map</span>(<span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span>, <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span>)</span><br><span class="line">    println(map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="string">&quot;默认值&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Option：是一个可选的取值有有两个取值</span></span><br><span class="line"><span class="comment">     * Some ：有值</span></span><br><span class="line"><span class="comment">     * None: 没有值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> value: <span class="type">Option</span>[<span class="type">String</span>] = map.get(<span class="string">&quot;005&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mvalue: <span class="type">String</span> = map.get(<span class="string">&quot;003&quot;</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; v</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="string">&quot;默认值&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(mvalue)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配结合函数的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照逗号分割数据</span></span><br><span class="line">    <span class="keyword">val</span> arrays: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//匹配取出数据</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = arrays.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="15、隐式转换"><a href="#15、隐式转换" class="headerlink" title="15、隐式转换"></a>15、隐式转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo28Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换  -- 隐式类型转换  -- 可以动态可以对象增加新的方法</span></span><br><span class="line"><span class="comment">     * 1、隐式转换变量</span></span><br><span class="line"><span class="comment">     * 2、隐式转换方法: 可以隐式将方法的参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     * 3、隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//        val s:String = &quot;100&quot;</span></span><br><span class="line">    <span class="comment">//        val i: Int = s.toInt</span></span><br><span class="line">    <span class="comment">//        println(i)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span></span>(i: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(i * i)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">100</span>)</span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//fun(&quot;100&quot;.toInt)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义一个隐式转换方法</span></span><br><span class="line"><span class="comment">     * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 隐式转换的方法和方法名无关,和参数类型返回值类有关</span></span><br><span class="line"><span class="comment">     * 同一个作用域中只能存储一个相同类型的隐式转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//将String 转换成Int的隐式转换的方法</span></span><br><span class="line">    <span class="comment">//当前作用域中所有的String都可以当成Int类使用</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">strToInt</span></span>(s: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;strToInt被调用&quot;</span>)</span><br><span class="line">      <span class="type">Integer</span>.parseInt(s)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="string">&quot;200&quot;</span>)</span><br><span class="line">    <span class="comment">//等同于</span></span><br><span class="line">    fun(strToInt(<span class="string">&quot;200&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">douToInt</span></span>(d: <span class="type">Double</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;douToInt被调用&quot;</span>)</span><br><span class="line">      d.toInt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">3.14</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 应用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//导入隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> com.shujia.scala.<span class="type">Test</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentPsPath: <span class="type">String</span> = <span class="string">&quot;data/students.txt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[<span class="type">String</span>] = studentPsPath.getLines().toList</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.getLines().toList</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换</span></span><br><span class="line"><span class="comment">   * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(path: <span class="type">String</span>): <span class="type">BufferedSource</span> = &#123;</span><br><span class="line">    <span class="type">Source</span>.fromFile(path)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="16、隐式转换类"><a href="#16、隐式转换类" class="headerlink" title="16、隐式转换类"></a>16、隐式转换类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo29Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> read = <span class="keyword">new</span> <span class="type">Read</span>(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = read.read()</span><br><span class="line">    println(lines)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用隐式转换</span></span><br><span class="line">    <span class="comment">//相当于String被隐式转换成了Read类型</span></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.read()</span><br><span class="line">    println(scores)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换类：可以隐式的将类的构造函数参数类型转换成当前类的类型</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">Read</span>(<span class="params">path: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(): <span class="type">List</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">      <span class="comment">//读取文件</span></span><br><span class="line">      <span class="type">Source</span>.fromFile(path).getLines().toList</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="17、隐式转换变量"><a href="#17、隐式转换变量" class="headerlink" title="17、隐式转换变量"></a>17、隐式转换变量</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Codec</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo30Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换变量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(x: <span class="type">Int</span>)(<span class="keyword">implicit</span> y: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      x + y</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i: <span class="type">Int</span> = add(<span class="number">100</span>)(<span class="number">200</span>)</span><br><span class="line">    println(i)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义一个隐式转换变量</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> a: <span class="type">Int</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用方法时，会自动使用当前作用域同类型的隐式转换变量填补上发方法的隐式转换参数</span></span><br><span class="line">    <span class="keyword">val</span> j: <span class="type">Int</span> = add(<span class="number">200</span>)</span><br><span class="line">    println(j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换变量的应用</span></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>)(<span class="type">Codec</span>(<span class="string">&quot;Utf-8&quot;</span>))</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="18、统计偏科最严重的前100名学生"><a href="#18、统计偏科最严重的前100名学生" class="headerlink" title="18、统计偏科最严重的前100名学生"></a>18、统计偏科最严重的前100名学生</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.immutable</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo31Student</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、统计偏科最严重的前100名学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 偏科评估的标准： 方差</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、切分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreArr: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreFilter: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoreArr.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = scoreFilter.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算方差</span></span><br><span class="line">    <span class="keyword">val</span> std: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = groupBy.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, list: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//一个学生所有的分数</span></span><br><span class="line">        <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">Int</span>] = list.map &#123; <span class="keyword">case</span> (_, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 计算方差</span></span><br><span class="line"><span class="comment">         * 1、计算总数</span></span><br><span class="line"><span class="comment">         * 2、计算平均值</span></span><br><span class="line"><span class="comment">         * 3、计算方差</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//科目数</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">N</span>: <span class="type">Double</span> = scores.length.toDouble</span><br><span class="line">        <span class="comment">//平均数</span></span><br><span class="line">        <span class="keyword">val</span> avg: <span class="type">Double</span> = scores.sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算方差</span></span><br><span class="line">        <span class="keyword">val</span> std: <span class="type">Double</span> = scores.map((sco: <span class="type">Int</span>) =&gt; (sco - avg) * (sco - avg)).sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        (id, std, list)</span><br><span class="line">    &#125;.toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照方差排序，取前100</span></span><br><span class="line">    <span class="keyword">val</span> sortByStd: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = std.sortBy(kv =&gt; -kv._2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//取前100</span></span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = sortByStd.take(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习scala的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="scala" scheme="http://example.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="http://example.com/2022/06/16/Sqoop/"/>
    <id>http://example.com/2022/06/16/Sqoop/</id>
    <published>2022-06-15T16:00:00.000Z</published>
    <updated>2022-06-20T15:11:10.559Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SQOOP安装"><a href="#SQOOP安装" class="headerlink" title="SQOOP安装"></a>SQOOP安装</h3><h4 id="1、上传并解压"><a href="#1、上传并解压" class="headerlink" title="1、上传并解压"></a>1、上传并解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /usr/local/soft/</span><br></pre></td></tr></table></figure><h4 id="2、修改文件夹名字"><a href="#2、修改文件夹名字" class="headerlink" title="2、修改文件夹名字"></a>2、修改文件夹名字</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop-1.4.6</span><br></pre></td></tr></table></figure><h4 id="3、修改配置文件"><a href="#3、修改配置文件" class="headerlink" title="3、修改配置文件"></a>3、修改配置文件</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换到sqoop配置文件目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/conf</span><br><span class="line"><span class="comment"># 复制配置文件并重命名</span></span><br><span class="line"><span class="built_in">cp</span> sqoop-env-template.sh sqoop-env.sh</span><br><span class="line"><span class="comment"># vim sqoop-env.sh 编辑配置文件，并加入以下内容</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/usr/local/soft/hadoop-2.7.6/share/hadoop/mapreduce</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/local/soft/hbase-1.4.6</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/soft/hive-1.2.1</span><br><span class="line"><span class="built_in">export</span> ZOOCFGDIR=/usr/local/soft/zookeeper-3.4.6/conf</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到bin目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/bin</span><br><span class="line"><span class="comment"># vim configure-sqoop 修改配置文件，注释掉没用的内容（就是为了去掉警告信息）</span></span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/wQgeExBmpyDju1t.png" alt="image.png" style="zoom:50%;" /><h4 id="4、修改环境变量"><a href="#4、修改环境变量" class="headerlink" title="4、修改环境变量"></a>4、修改环境变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sqoop的目录加入环境变量</span></span><br></pre></td></tr></table></figure><h4 id="5、添加MySQL连接驱动"><a href="#5、添加MySQL连接驱动" class="headerlink" title="5、添加MySQL连接驱动"></a>5、添加MySQL连接驱动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从HIVE中复制MySQL连接驱动到<span class="variable">$SQOOP_HOME</span>/lib</span></span><br><span class="line">cp /usr/local/soft/hive-1.2.1/lib/mysql-connector-java-5.1.49.jar /usr/local/soft/sqoop-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打印sqoop版本</span></span><br><span class="line">sqoop version</span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/6N1HJzVD7i9P3r5.png" alt="image.png" style="zoom:50%;" /><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试MySQL连通性</span></span><br><span class="line">sqoop list-databases -connect jdbc:mysql://master:3306/ -username root -password 123456</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/fos2dlvrMLQm4wa.png" alt="image-20220620200744244"></p><h3 id="准备MySQL数据"><a href="#准备MySQL数据" class="headerlink" title="准备MySQL数据"></a>准备MySQL数据</h3><h4 id="登录MySQL数据库"><a href="#登录MySQL数据库" class="headerlink" title="登录MySQL数据库"></a>登录MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p123456;</span><br></pre></td></tr></table></figure><h4 id="创建student数据库"><a href="#创建student数据库" class="headerlink" title="创建student数据库"></a>创建student数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create database student;</span><br></pre></td></tr></table></figure><h4 id="切换数据库并导入数据"><a href="#切换数据库并导入数据" class="headerlink" title="切换数据库并导入数据"></a>切换数据库并导入数据</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mysql shell中执行</span></span><br><span class="line">use student;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/student.sql;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/score.sql;</span><br></pre></td></tr></table></figure><h4 id="另外一种导入数据的方式"><a href="#另外一种导入数据的方式" class="headerlink" title="另外一种导入数据的方式"></a>另外一种导入数据的方式</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">linux shell中执行</span></span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/student.sql</span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/score.sql</span><br></pre></td></tr></table></figure><h4 id="使用Navicat运行SQL文件"><a href="#使用Navicat运行SQL文件" class="headerlink" title="使用Navicat运行SQL文件"></a>使用Navicat运行SQL文件</h4><blockquote><p>也可以通过Navicat导入</p></blockquote><h4 id="导出MySQL数据库"><a href="#导出MySQL数据库" class="headerlink" title="导出MySQL数据库"></a>导出MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqldump -u root -p123456 数据库名&gt;任意一个文件名.sql</span><br></pre></td></tr></table></figure><h3 id="SQOOP–import"><a href="#SQOOP–import" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h3><blockquote><p>从传统的关系型数据库导入HDFS、HIVE、HBASE……</p></blockquote><h4 id="MySQLToHDFS"><a href="#MySQLToHDFS" class="headerlink" title="MySQLToHDFS"></a>MySQLToHDFS</h4><h5 id="编写脚本，保存为MySQLToHDFS-conf"><a href="#编写脚本，保存为MySQLToHDFS-conf" class="headerlink" title="编写脚本，保存为MySQLToHDFS.conf"></a>编写脚本，保存为MySQLToHDFS.conf</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop执行脚本有两种方式：</span><br><span class="line">第一种方式：直接在命令行窗口中直接输入脚本；</span><br><span class="line">第二种方式是将命令封装成一个脚本文件，然后使用另一个命令执行</span><br><span class="line"></span><br><span class="line">第一种方式：</span><br><span class="line">sqoop import \</span><br><span class="line">--append \</span><br><span class="line">--connect jdbc:mysql://master:3306/test \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table student \</span><br><span class="line">--m 4 \</span><br><span class="line">--split-by age \</span><br><span class="line">--target-dir /shujia/bigdata17/student1/ \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">第二种方式：</span><br><span class="line">import</span><br><span class="line">--append</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/test</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">4</span><br><span class="line">--split-by</span><br><span class="line">age</span><br><span class="line">--target-dir</span><br><span class="line">/shujia/bigdata17/student21/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本"><a href="#执行脚本" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHDFS.conf</span><br></pre></td></tr></table></figure><h5 id="注意事项："><a href="#注意事项：" class="headerlink" title="注意事项："></a>注意事项：</h5><p>1、–m 表示指定生成多少个Map任务，不是越多越好，因为MySQL Server的承载能力有限</p><p>2、当指定的Map任务数&gt;1，那么需要结合<code>--split-by</code>参数，指定分割键，以确定每个map任务到底读取哪一部分数据，最好指定数值型的列，最好指定主键（或者分布均匀的列&#x3D;&gt;避免每个map任务处理的数据量差别过大）</p><p>3、如果指定的分割键数据分布不均，可能导致数据倾斜问题</p><p>4、分割的键最好指定数值型的，而且字段的类型为int、bigint这样的数值型</p><p>5、编写脚本的时候，注意：例如：<code>--username</code>参数，参数值不能和参数名同一行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--username root  // 错误的</span><br><span class="line"></span><br><span class="line">// 应该分成两行</span><br><span class="line">--username</span><br><span class="line">root</span><br></pre></td></tr></table></figure><p>6、运行的时候会报错<strong>InterruptedException</strong>，hadoop2.7.6自带的问题，忽略即可</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">21/01/25 14:32:32 WARN hdfs.DFSClient: Caught exception </span><br><span class="line">java.lang.InterruptedException</span><br><span class="line">at java.lang.Object.wait(Native Method)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1252)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1326)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:716)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:476)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:652)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>7、实际上sqoop在读取mysql数据的时候，用的是JDBC的方式，所以当数据量大的时候，效率不是很高</p><p>8、sqoop底层通过MapReduce完成数据导入导出，只需要Map任务，不许需要Reduce任务  part-m-00000</p><p>9、每个Map任务会生成一个文件</p><h4 id="MySQLToHive"><a href="#MySQLToHive" class="headerlink" title="MySQLToHive"></a>MySQLToHive</h4><blockquote><p>先会将MySQL的数据导出来并在HDFS上找个目录临时存放，默认为：&#x2F;user&#x2F;用户名&#x2F;表名</p><p>然后再将数据加载到Hive中，加载完成后，会将临时存放的目录删除</p></blockquote><h5 id="编写脚本，并保存为MySQLToHive-conf文件"><a href="#编写脚本，并保存为MySQLToHive-conf文件" class="headerlink" title="编写脚本，并保存为MySQLToHive.conf文件"></a>编写脚本，并保存为MySQLToHive.conf文件</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">score</span><br><span class="line">--m</span><br><span class="line">3</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore</span><br><span class="line"></span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h5 id="执行脚本-1"><a href="#执行脚本-1" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHive.conf</span><br></pre></td></tr></table></figure><h5 id="–direct"><a href="#–direct" class="headerlink" title="–direct"></a>–direct</h5><blockquote><p>加上这个参数，可以在导出MySQL数据的时候，使用MySQL提供的导出工具mysqldump，加快导出速度，提高效率</p></blockquote><p>需要将master上的&#x2F;usr&#x2F;bin&#x2F;mysqldump分发至 node1、node2的&#x2F;usr&#x2F;bin目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp /usr/bin/mysqldump node1:/usr/bin/</span><br><span class="line">scp /usr/bin/mysqldump node2:/usr/bin/</span><br></pre></td></tr></table></figure><h5 id="–e参数的使用"><a href="#–e参数的使用" class="headerlink" title="–e参数的使用"></a>–e参数的使用</h5><blockquote><p>sqoop在导入数据时，可以使用–e搭配sql来指定查询条件，并且还需在sql中添加$CONDITIONS，来实现并行运行mr的功能。</p><p>只要有–e+sql，就需要加$CONDITIONS，哪怕只有一个maptask。</p></blockquote><blockquote><p>sqoop通过继承hadoop的并行性来执行高效的数据传输。 为了帮助sqoop将查询拆分为多个可以并行传输的块，需要在查询的where子句中包含$conditions占位符。 sqoop将自动用生成的条件替换这个占位符，这些条件指定每个任务应该传输哪个数据片。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--m</span><br><span class="line">2</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--e</span><br><span class="line">&quot;select * from score where student_id=1500100001 and $CONDITIONS&quot;</span><br><span class="line">--target-dir</span><br><span class="line">/testE</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore3</span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h4 id="MySQLToHBase"><a href="#MySQLToHBase" class="headerlink" title="MySQLToHBase"></a>MySQLToHBase</h4><h5 id="编写脚本，并保存为MySQLToHBase-conf"><a href="#编写脚本，并保存为MySQLToHBase-conf" class="headerlink" title="编写脚本，并保存为MySQLToHBase.conf"></a>编写脚本，并保存为MySQLToHBase.conf</h5><blockquote><p>sqoop1.4.6 只支持 HBase1.0.1 之前的版本的自动创建 HBase 表的功能</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id</span><br><span class="line">--m</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h5 id="在HBase中创建student表"><a href="#在HBase中创建student表" class="headerlink" title="在HBase中创建student表"></a>在HBase中创建student表</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create &#x27;studentsq&#x27;,&#x27;cf1&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本-2"><a href="#执行脚本-2" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHBase.conf</span><br></pre></td></tr></table></figure><h4 id="SQOOP–import-1"><a href="#SQOOP–import-1" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h4><h4 id="HDFSToMySQL"><a href="#HDFSToMySQL" class="headerlink" title="HDFSToMySQL"></a>HDFSToMySQL</h4><h5 id="编写脚本，并保存为HDFSToMySQL-conf"><a href="#编写脚本，并保存为HDFSToMySQL-conf" class="headerlink" title="编写脚本，并保存为HDFSToMySQL.conf"></a>编写脚本，并保存为HDFSToMySQL.conf</h5><blockquote><p><strong>在往关系型数据库中导出的时候我们要先在关系型数据库中创建好库以及表，这些sqoop不会帮我们完成。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student?useUnicode=true&amp;characterEncoding=UTF-8</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="先清空MySQL-student表中的数据，不然会造成主键冲突"><a href="#先清空MySQL-student表中的数据，不然会造成主键冲突" class="headerlink" title="先清空MySQL student表中的数据，不然会造成主键冲突"></a>先清空MySQL student表中的数据，不然会造成主键冲突</h5><h5 id="执行脚本-3"><a href="#执行脚本-3" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file HDFSToMySQL.conf</span><br></pre></td></tr></table></figure><h4 id="查看sqoop-help"><a href="#查看sqoop-help" class="headerlink" title="查看sqoop help"></a>查看sqoop help</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop help</span><br><span class="line"></span><br><span class="line">21/04/26 15:50:36 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">usage: sqoop COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  codegen            Generate code to interact with database records</span><br><span class="line">  create-hive-table  Import a table definition into Hive</span><br><span class="line">  eval               Evaluate a SQL statement and display the results</span><br><span class="line">  export             Export an HDFS directory to a database table</span><br><span class="line">  help               List available commands</span><br><span class="line">  import             Import a table from a database to HDFS</span><br><span class="line">  import-all-tables  Import tables from a database to HDFS</span><br><span class="line">  import-mainframe   Import datasets from a mainframe server to HDFS</span><br><span class="line">  job                Work with saved jobs</span><br><span class="line">  list-databases     List available databases on a server</span><br><span class="line">  list-tables        List available tables in a database</span><br><span class="line">  merge              Merge results of incremental imports</span><br><span class="line">  metastore          Run a standalone Sqoop metastore</span><br><span class="line">  version            Display version information</span><br><span class="line"></span><br><span class="line">See &#x27;sqoop help COMMAND&#x27; for information on a specific command.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看import的详细帮助</span><br><span class="line">sqoop import --help</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、并行度不能太高，就是 -m</span><br><span class="line">2、如果没有主键的时候，-m 不是1的时候就要指定分割字段，不然会报错，如果有主键的时候，-m 不是1 可以不去指定分割字段，默认是主键，不指定 -m 的时候，Sqoop会默认是分4个map任务。</span><br></pre></td></tr></table></figure><h4 id="Sqoop-在从HDFS中导出到关系型数据库时的一些问题"><a href="#Sqoop-在从HDFS中导出到关系型数据库时的一些问题" class="headerlink" title="Sqoop 在从HDFS中导出到关系型数据库时的一些问题"></a>Sqoop 在从HDFS中导出到关系型数据库时的一些问题</h4><h5 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a><strong>问题一：</strong></h5><p>在上传过程中遇到这种问题：</p><p><strong>ERROR tool.ExportTool: Encountered IOException running export job: java.io.IOException: No columns to generate for ClassWriter</strong></p><p><img src="https://s2.loli.net/2022/06/20/746cVG2nRzkPTsd.png" alt="image-20220620213336190"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">驱动版本的过低导致的，其实在尝试这个方法的时候我们可以先进行这样：加一行命令，--driver com.mysql.jdbc.Driver \  然后问题解决！！！</span><br><span class="line"></span><br><span class="line">如果添加命令之后还没有解决就把jar包换成高点版本的。</span><br></pre></td></tr></table></figure><h5 id="问题二："><a href="#问题二：" class="headerlink" title="问题二："></a><strong>问题二：</strong></h5><p><strong>依旧是导出的时候，会报错，但是我们很神奇的发现，也有部分数据导入了。这也就是下一个问题。</strong></p><p><strong>Caused by: java.lang.NumberFormatException: For input string: “null”</strong></p><p><img src="https://s2.loli.net/2022/06/20/ZDp6kQ5V2UOghCl.png" alt="image-20220620213402824"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">解决方式：因为数据有存在null值得导致的</span><br><span class="line"></span><br><span class="line">在命令中加入一行（方式一中的修改方式，方式二也就是转换一下格式）：--input-null-string &#x27;\\N&#x27; \  </span><br><span class="line"></span><br><span class="line">--input-null-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure><h5 id="问题三："><a href="#问题三：" class="headerlink" title="问题三：**"></a>问题三：**</h5><p><strong>java.lang.RuntimeException: Can’t parse input data: ‘1998&#x2F;5&#x2F;11’</strong></p><p><img src="https://s2.loli.net/2022/06/20/nRyQel6fvAr9UXT.png" alt="image-20220620213425310"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">出现像这样的问题，大多是因为HDFS上的数据与关系型数据库创建表的字段类型不匹配导致的。仔细对比修改后，就不会有这个报错啦！！</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/8QFgr9AG4wRyZSH.png" alt="image-20220620230831268"></p><p>数据有问题有个@符号，虽然报错但是也能导出数据</p><h3 id="增量同步数据"><a href="#增量同步数据" class="headerlink" title="增量同步数据"></a>增量同步数据</h3><p>我们之前导入的都是全量导入，一次性全部导入，但是实际开发并不是这样，例如web端进行用户注册，mysql就增加了一条数据，但是HDFS中的数据并没有进行更新，但是又再全部导入一次又完全没有必要。</p><p>所以，sqoop提供了增量导入的方法。</p><p>1、数据准备：</p><p><img src="https://s2.loli.net/2022/06/20/tHPlkEISReUA4Ya.png" alt="image-20220620213457114"></p><p>2、将其先用全量导入到HDFS(hive)中去</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br></pre></td></tr></table></figure><p>3、先在mysql中添加一条数据，在使用命令进行追加</p><p>4、根据时间进行大量追加（不去重）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前面的案例中，hive本身的数据也是存储在HDFS上的，所以我今后要做增量操作的时候，需要指定HDFS上的路径</span></span><br><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--incremental </span><br><span class="line">append</span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结果：但是我们发现有两个重复的字段</p><p><img src="https://s2.loli.net/2022/06/20/vPN8seuwOUkgYqR.png" alt="img"></p><p>5、往往开发中需要进行去重操作：sqoop提供了一个方法进行去重，内部是先开一个map任务将数据导入进来，然后再开一个map任务根据指定的字段进行合并去重</p><p>结果：</p><p><img src="https://s2.loli.net/2022/06/20/7tW4nmR5OUes3MP.png" alt="img"></p><blockquote><p> <strong>之前有重复的也进行合并去重操作，最后生成一个结果。</strong></p></blockquote><blockquote><p>总结：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">–check-column</span><br><span class="line">用来指定一些列，这些列在增量导入时用来检查这些数据是否作为增量数据进行导入，和关系型数据库中的自增字段及时间戳类似. </span><br><span class="line">注意:这些被指定的列的类型不能使任意字符类型，如char、varchar等类型都是不可以的，同时–check-column可以去指定多个列</span><br><span class="line">–incremental</span><br><span class="line">用来指定增量导入的模式，两种模式分别为Append和Lastmodified</span><br><span class="line">–last-value</span><br><span class="line">指定上一次导入中检查列指定字段最大值</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">RDBMS--&gt;</span><span class="language-bash">HDFS     import</span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">RDBMS    <span class="built_in">export</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">Mysql---&gt;</span><span class="language-bash">HDFS(hive)</span></span><br><span class="line">要知道你要数据的来源和数据的目的地</span><br><span class="line">mysql:</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">hive:</span><br><span class="line">1)</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table  (如果表不存在，自动创建，如果存在，报错，就不需要这个参数)</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">2)</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增量需要添加的参数=================================================</span></span><br><span class="line">--incremental </span><br><span class="line">append </span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line">（或者是）------------------------------------------------------------</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--check-column （hive的列名）</span><br><span class="line">last_mod</span><br><span class="line">--incremental</span><br><span class="line">lastmodified</span><br><span class="line">--last-value</span><br><span class="line">&quot;2022-06-18 16:40:09&quot;</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">========================================================================</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果需要去重，请先搞清楚根据什么去重，否则结果可能不是你想要的</span></span><br><span class="line">--merge-key</span><br><span class="line">name   （这里是根据姓名去重，你可以改成自己的去重列名）</span><br><span class="line"></span><br><span class="line">hbase:（因为我们的hbase版本是1.4.6，而sqoop1.4.6不支持hbase1.0.1以后的自动创建表，所以我们在做同步到hbase的时候，需要手动先将表创建好）</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id  (mysql中的列名)</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">mysql</span></span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果数据分割出来的字段值有空值，需要添加以下参数（面试可能会面到）</span></span><br><span class="line">--null-string </span><br><span class="line">&#x27;\\N&#x27; </span><br><span class="line">--null-non-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Sqoop的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Sqoop" scheme="http://example.com/tags/Sqoop/"/>
    
  </entry>
  
  <entry>
    <title>Hbase高级操作</title>
    <link href="http://example.com/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/"/>
    <id>http://example.com/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/</id>
    <published>2022-06-12T16:00:00.000Z</published>
    <updated>2022-06-15T07:53:47.676Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、HBase的读写流程"><a href="#一、HBase的读写流程" class="headerlink" title="一、HBase的读写流程"></a>一、HBase的读写流程</h2><p><img src="https://s2.loli.net/2022/06/15/tel8cnYuW4o6EiI.png" alt="image-20220615154028494"></p><h3 id="1-1-HBase读流程"><a href="#1-1-HBase读流程" class="headerlink" title="1.1    HBase读流程"></a>1.1    HBase读流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hbase读取数据的流程：</span><br><span class="line">1）是由客户端发起读取数据的请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取一个hbase:meta表位置信息，被哪一个regionserver所管理着</span><br><span class="line">     hbase:meta表：hbase的元数据表，在这个表中存储了自定义表相关的元数据，包括表名，表有哪些列簇，表有哪些reguion,每个region存储的位置，每个region被哪个regionserver所管理，这个表也是存储在某一个region上的，并且这个meta表只会被一个regionserver所管理。这个表的位置信息只有zookeeper知道。</span><br><span class="line">3）连接这个meta表对应的regionserver,从meta表中获取当前你要读取的这个表对应的regionsever是谁。</span><br><span class="line">     当一个表多个region怎么办呢？</span><br><span class="line">     如果我们获取数据是以get的方式，只会返回一个regionserver</span><br><span class="line">     如果我们获取数据是以scan的方式，会将所有的region对应的regionserver的地址全部返回。</span><br><span class="line">4）连接要读取表的对应的regionserver,从regionserver上的开始读取数据：</span><br><span class="line">       读取顺序：memstore--&gt;blockcache--&gt;storefile--&gt;Hfile中</span><br><span class="line">       注意：如果是scan操作，就不仅仅去blockcache了，而是所有都会去找。</span><br></pre></td></tr></table></figure><h3 id="1-2-HBase写流程"><a href="#1-2-HBase写流程" class="headerlink" title="1.2    HBase写流程"></a>1.2    HBase写流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--------------------------1-4步是客户端写入数据的流程-----------------</span><br><span class="line"></span><br><span class="line">Hbase的写入数据流程：</span><br><span class="line">1）由客户端发起写数据请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取hbase:meta表被哪一个regionserver所管理</span><br><span class="line">3）连接hbase:meta表中获取对应的regionserver地址 (从meta表中获取当前要写入数据的表对应的region所管理的regionserver) 只会返回一个regionserver地址</span><br><span class="line">4）与要写入数据的regionserver建立连接，然后开始写入数据，将数据首先会写入到HLog，然后将数据写入到对应store模块中的memstore中</span><br><span class="line">（可能会写多个），当这两个地方都写入完成之后，表示数据写入完成。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-------------------------后面的步骤是服务器内部的操作-----------------</span><br><span class="line">异步操作</span><br><span class="line">5）随着客户端不断地写入数据，memstore中的数据会越来多，当内存中的数据达到阈值（128M/1h）的时候，放入到blockchache中，生成新的memstore接收用户过来的数据，然后当blockcache的大小达到一定阈值（0.85）的时候，开始触发flush机制，将数据最终刷新到HDFS中形成小的Hfile文件。</span><br><span class="line"></span><br><span class="line">6）随着不断地刷新，storefile不断地在HDFS上生成小HFIle文件，当小的HFile文件达到阈值的时候（3个及3个以上）,就会触发Compaction机制，将小的HFile合并成一个大的HFile.</span><br><span class="line"></span><br><span class="line">7）随着不断地合并，大的HFile文件会越来越大，当达到一定阈值（最终10G）的时候，会触发分裂机制（split）,将大的HFile文件进行一分为二，同时管理这个大的HFile的region也会被一分为二，形成两个新的region和两个新的HFile文件，一对一的进行管理，将原来旧的region和分裂之前大的HFile文件慢慢地就会下线处理。</span><br></pre></td></tr></table></figure><h2 id="二、Region的分裂策略"><a href="#二、Region的分裂策略" class="headerlink" title="二、Region的分裂策略"></a>二、Region的分裂策略</h2><blockquote><p>region中存储的是一张表的数据，当region中的数据条数过多的时候，会直接影响查询效率。当region过大的时候，region会被拆分为两个region，HMaster会将分裂的region分配到不同的regionserver上，这样可以让请求分散到不同的RegionServer上，已达到负载均衡 , 这也是HBase的一个优点 。</p></blockquote><ul><li><p>ConstantSizeRegionSplitPolicy</p><blockquote><p>0.94版本前，HBase region的默认切分策略 </p></blockquote><p>当region中最大的store大小超过某个阈值(hbase.hregion.max.filesize&#x3D;10G)之后就会触发切分，一个region等分为2个region。</p><p>但是在生产线上这种切分策略却有相当大的弊端（切分策略对于大表和小表没有明显的区分）：</p><ul><li>阈值(hbase.hregion.max.filesize)设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，形成热点，这对业务来说并不是什么好事。</li><li>如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</li></ul></li><li><p>IncreasingToUpperBoundRegionSplitPolicy</p><blockquote><p>0.94版本~2.0版本默认切分策略 </p></blockquote><p>​        总体看和ConstantSizeRegionSplitPolicy思路相同，一个region中最大的store大小大于设置阈值就会触发切分。<br>但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系.</p><p>region split阈值的计算公式是：</p><ul><li><p>设regioncount：是region所属表在当前regionserver上的region的个数</p></li><li><p>阈值 &#x3D; regioncount^3 * 128M * 2，当然阈值并不会无限增长，最大不超过MaxRegionFileSize（10G),当region中最大的store的大小达到该阈值的时候进行region split</p></li></ul><p>例如：</p><ul><li>第一次split阈值 &#x3D; 1^3 * 256 &#x3D; 256MB</li><li>第二次split阈值 &#x3D; 2^3 * 256 &#x3D; 2048MB</li><li>第三次split阈值 &#x3D; 3^3 * 256 &#x3D; 6912MB</li><li>第四次split阈值 &#x3D; 4^3 * 256 &#x3D; 16384MB &gt; 10GB，因此取较小的值10GB</li><li>后面每次split的size都是10GB了</li></ul><p><strong>特点</strong></p><ul><li>相比ConstantSizeRegionSplitPolicy，可以自适应大表、小表；</li><li>在集群规模比较大的情况下，对大表的表现比较优秀</li><li>对小表不友好，小表可能产生大量的小region，分散在各regionserver上</li><li>小表达不到多次切分条件，导致每个split都很小，所以分散在各个regionServer上</li></ul></li><li><p>SteppingSplitPolicy</p><blockquote><p>2.0版本默认切分策略</p></blockquote><p>​    相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些<br>​    region切分的阈值依然和待分裂region所属表在当前regionserver上的region个数有关系</p><ul><li>如果region个数等于1，切分阈值为flush size 128M * 2</li><li>否则为MaxRegionFileSize。</li></ul><blockquote><p>这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小region，而是适可而止。</p></blockquote></li><li><p>KeyPrefixRegionSplitPolicy</p><blockquote><p>根据rowKey的前缀对数据进行分区，这里是指定rowKey的前多少位作为前缀，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在相同的region中。</p></blockquote></li><li><p>DelimitedKeyPrefixRegionSplitPolicy</p><blockquote><p>保证相同前缀的数据在同一个region中，例如rowKey的格式为：userid_eventtype_eventid，指定的delimiter为 _ ，则split的的时候会确保userid相同的数据在同一个region中。<br>按照分隔符进行切分，而KeyPrefixRegionSplitPolicy是按照指定位数切分。</p></blockquote></li><li><p>BusyRegionSplitPolicy</p><blockquote><p>按照一定的策略判断Region是不是Busy状态，如果是即进行切分</p><p>如果你的系统常常会出现热点Region，而你对性能有很高的追求，那么这种策略可能会比较适合你。它会通过拆分热点Region来缓解热点Region的压力，但是根据热点来拆分Region也会带来很多不确定性因素，因为你也不知道下一个被拆分的Region是哪个。</p></blockquote></li><li><p>DisabledRegionSplitPolicy</p><blockquote><p>不启用自动拆分, 需要指定手动拆分</p></blockquote></li></ul><h2 id="三、Compaction操作"><a href="#三、Compaction操作" class="headerlink" title="三、Compaction操作"></a>三、Compaction操作</h2><h4 id="Minor-Compaction："><a href="#Minor-Compaction：" class="headerlink" title="Minor Compaction："></a>Minor Compaction：</h4><ul><li>指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次 Minor Compaction 的结果是更少并且更大的StoreFile。</li></ul><h4 id="Major-Compaction："><a href="#Major-Compaction：" class="headerlink" title="Major Compaction："></a>Major Compaction：</h4><ul><li>指将<strong>所有的StoreFile</strong>合并成一个StoreFile，这个过程会清理三类没有意义的数据：<strong>被删除的数据</strong>、<strong>TTL过期数据</strong>、<strong>版本号超过设定版本号的数据</strong>。另外，一般情况下，major compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发major compaction功能，改为手动在业务低峰期触发。</li></ul><blockquote><p>参考文档：<a href="https://cloud.tencent.com/developer/article/1488439">https://cloud.tencent.com/developer/article/1488439</a></p></blockquote><h2 id="四、面对百亿数据，HBase为什么查询速度依然非常快？"><a href="#四、面对百亿数据，HBase为什么查询速度依然非常快？" class="headerlink" title="四、面对百亿数据，HBase为什么查询速度依然非常快？"></a>四、面对百亿数据，HBase为什么查询速度依然非常快？</h2><p>HBase适合存储PB级别的海量数据（百亿千亿量级条记录），如果根据记录主键Rowkey来查询，能在几十到百毫秒内返回数据。</p><p><strong>那么HBase是如何做到的呢？</strong></p><p>下面，简单阐述一下数据的查询思路和过程。</p><h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h2><h5 id="第1步："><a href="#第1步：" class="headerlink" title="第1步："></a>第1步：</h5><p>项目有100亿业务数据，存储在一个HBase集群上（由多个服务器数据节点构成），每个数据节点上有若干个Region（区域），每个Region实际上就是HBase中一批数据的集合（一段连续范围rowkey的数据）。</p><p>我们现在开始根据主键RowKey来查询对应的记录，通过meta表可以帮我们迅速定位到该记录所在的数据节点，以及数据节点中的Region，目前我们有100亿条记录，占空间10TB。所有记录被切分成5000个Region，那么现在，每个Region就是2G。</p><p><strong>由于记录在1个Region中，所以现在我们只要查询这2G的记录文件，就能找到对应记录。</strong></p><h5 id="第2步："><a href="#第2步：" class="headerlink" title="第2步："></a>第2步：</h5><p>由于HBase存储数据是按照列族存储的。比如一条记录有400个字段，前100个字段是人员信息相关，这是一个列簇（列的集合）；中间100个字段是公司信息相关，是一个列簇。另外100个字段是人员交易信息相关，也是一个列簇；最后还有100个字段是其他信息，也是一个列簇</p><p>这四个列簇是分开存储的，这时，假设2G的Region文件中，分为4个列族，那么每个列族就是500M。</p><p><strong>到这里，我们只需要遍历这500M的列簇就可以找到对应的记录。</strong></p><h5 id="第3步："><a href="#第3步：" class="headerlink" title="第3步："></a>第3步：</h5><p>如果要查询的记录在其中1个列族上，1个列族在HDFS中会包含1个或者多个HFile。</p><p>如果一个HFile一般的大小为100M，那么该列族包含5个HFile在磁盘上或内存中。</p><p>由于HBase的内存进而磁盘中的数据是排好序的，要查询的记录有可能在最前面，也有可能在最后面，按平均来算，<strong>我们只需遍历2.5个HFile共250M，即可找到对应的记录。</strong></p><h5 id="第4步："><a href="#第4步：" class="headerlink" title="第4步："></a>第4步：</h5><p>每个HFile中，是以键值对(key&#x2F;value)方式存储，只要遍历文件中的key位置并判断符合条件即可</p><p>一般key是有限的长度，假设key&#x2F;value比是1:24，<strong>最终只需要10M的数据量，就可获取的对应的记录。</strong></p><p>如果数据在机械磁盘上，按其访问速度100M&#x2F;S，只需0.1秒即可查到。</p><p>如果是SSD的话，0.01秒即可查到。</p><p>当然，扫描HFile时还可以通过布隆过滤器快速定位到对应的HFile，以及HBase是有内存缓存机制的，如果数据在内存中，效率会更高。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>正因为以上大致的查询思路，保证了HBase即使随着数据量的剧增，也不会导致查询性能的下降。</p><p>同时，HBase是一个面向列存储的数据库（列簇机制），当表字段非常多时，可以把其中一些字段独立出来放在一部分机器上，而另外一些字段放到另一部分机器上，分散存储，分散列查询。</p><p>正由于这样复杂的存储结构和分布式的存储方式，保证了HBase海量数据下的查询效率。</p><h2 id="五、HBase与Hive的集成"><a href="#五、HBase与Hive的集成" class="headerlink" title="五、HBase与Hive的集成"></a>五、HBase与Hive的集成</h2><blockquote><p>HBase与Hive的对比</p></blockquote><p><strong>hive:</strong></p><p>数据仓库：Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p><p>用于数据分析、清洗：Hive适用于离线的数据分析和清洗，延迟较高。</p><p>基于HDFS、MapReduce：Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</p><p><strong>HBase</strong></p><p>数据库：是一种面向列族存储的非关系型数据库。</p><p>用于存储结构化和非结构化的数据：适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p><p>基于HDFS：数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</p><p>延迟较低，接入在线业务使用：面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p><blockquote><p>在<code>hive-site.xml</code>中添加zookeeper的属性</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102,hadoop103,hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.client.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><h2 id="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"><a href="#HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表" class="headerlink" title="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"></a>HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表</h2></blockquote><blockquote><p>建立外部表的字段名要和hbase中的列名一致</p><p>前提是hbase中已经有表了</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> students_hbase</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string,</span><br><span class="line">gender string, </span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:name,</span><br><span class="line">info:age,</span><br><span class="line">info:gender,</span><br><span class="line">info:clazz</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:students&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> score_hbase2</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">score_dan string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:score_dan</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:score&quot;);</span><br></pre></td></tr></table></figure><blockquote><p>关联后就可以使用Hive函数进行一些分析操作了</p></blockquote><h2 id="六、Phoenix"><a href="#六、Phoenix" class="headerlink" title="六、Phoenix"></a>六、Phoenix</h2><blockquote><p>Hbase适合存储大量的对关系运算要求低的NOSQL数据，受Hbase 设计上的限制不能直接使用原生的API执行在关系数据库中普遍使用的条件判断和聚合等操作。Hbase很优秀，一些团队寻求在Hbase之上提供一种更面向普通开发人员的操作方式，Apache Phoenix即是。</p></blockquote><blockquote><p>Phoenix 基于Hbase给面向业务的开发人员提供了以标准SQL的方式对Hbase进行查询操作，并支持标准SQL中大部分特性:条件运算,分组，分页，等高级查询语法。</p></blockquote><h3 id="1、Phoenix搭建"><a href="#1、Phoenix搭建" class="headerlink" title="1、Phoenix搭建"></a>1、Phoenix搭建</h3><p><strong>Phoenix 4.15    HBase 1.4.6    hadoop 2.7.6</strong></p><h4 id="1、关闭hbase集群，在master中执行"><a href="#1、关闭hbase集群，在master中执行" class="headerlink" title="1、关闭hbase集群，在master中执行"></a>1、关闭hbase集群，在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="2、上传解压配置环境变量"><a href="#2、上传解压配置环境变量" class="headerlink" title="2、上传解压配置环境变量"></a>2、上传解压配置环境变量</h4><p>解压</p><p><code>tar -xvf apache-phoenix-4.15.0-HBase-1.4-bin.tar.gz -C /usr/local/soft/</code></p><p>改名</p><p><code>mv apache-phoenix-4.15.0-HBase-1.4-bin phoenix-4.15.0</code></p><h4 id="3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下"><a href="#3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下" class="headerlink" title="3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下"></a>3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar master:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node1:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node2:/usr/local/soft/hbase-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="4、启动hbase-，-在master中执行"><a href="#4、启动hbase-，-在master中执行" class="headerlink" title="4、启动hbase ， 在master中执行"></a>4、启动hbase ， 在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="5、配置环境变量"><a href="#5、配置环境变量" class="headerlink" title="5、配置环境变量"></a>5、配置环境变量</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、Phoenix使用"><a href="#2、Phoenix使用" class="headerlink" title="2、Phoenix使用"></a>2、Phoenix使用</h3><h4 id="1、连接sqlline"><a href="#1、连接sqlline" class="headerlink" title="1、连接sqlline"></a>1、连接sqlline</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqlline.py master,node1,node2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">出现即已连接成功</span></span><br><span class="line">163/163 (100%) Done</span><br><span class="line">Done</span><br><span class="line">sqlline version 1.5.0</span><br><span class="line">0: jdbc:phoenix:master,node1,node2&gt; </span><br></pre></td></tr></table></figure><h4 id="2、常用命令"><a href="#2、常用命令" class="headerlink" title="2、常用命令"></a>2、常用命令</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="number">1</span>、创建表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> student (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> name <span class="type">VARCHAR</span>,</span><br><span class="line"> age <span class="type">BIGINT</span>, </span><br><span class="line"> gender <span class="type">VARCHAR</span> ,</span><br><span class="line"> clazz <span class="type">VARCHAR</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、显示所有表</span><br><span class="line"> <span class="operator">!</span><span class="keyword">table</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、插入数据</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100004&#x27;</span>,<span class="string">&#x27;葛德曜&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100005&#x27;</span>,<span class="string">&#x27;宣谷芹&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科六班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100006&#x27;</span>,<span class="string">&#x27;羿彦昌&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、查询数据,支持大部分<span class="keyword">sql</span>语法，</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> age<span class="operator">=</span><span class="number">24</span>;</span><br><span class="line"><span class="keyword">select</span> gender ,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> STUDENT <span class="keyword">group</span> <span class="keyword">by</span> gender;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student <span class="keyword">order</span> <span class="keyword">by</span> gender;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、删除数据</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> id<span class="operator">=</span><span class="string">&#x27;1500100004&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>、删除表</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> STUDENT;</span><br><span class="line"> </span><br><span class="line"># <span class="number">7</span>、退出命令行</span><br><span class="line"><span class="operator">!</span>quit</span><br><span class="line"></span><br><span class="line">更多语法参照官网</span><br><span class="line">https:<span class="operator">/</span><span class="operator">/</span>phoenix.apache.org<span class="operator">/</span><span class="keyword">language</span><span class="operator">/</span>index.html#upsert_select</span><br></pre></td></tr></table></figure><h4 id="3、phoenix表映射"><a href="#3、phoenix表映射" class="headerlink" title="3、phoenix表映射"></a>3、phoenix表映射</h4><blockquote><p> 默认情况下，直接在hbase中创建的表，通过phoenix是查看不到的</p></blockquote><blockquote><p>如果需要在phoenix中操作直接在hbase中创建的表，则需要在phoenix中进行表的映射。映射方式有两种：视图映射和表映射</p></blockquote><h5 id="3-1、视图映射"><a href="#3-1、视图映射" class="headerlink" title="3.1、视图映射"></a>3.1、视图映射</h5><blockquote><p> Phoenix创建的视图是只读的，所以只能用来做查询，无法通过视图对源数据进行修改等操作</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># hbase shell 进入hbase命令行</span><br><span class="line">hbase shell </span><br><span class="line"></span><br><span class="line"># 创建hbase表</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;company&#x27;</span> </span><br><span class="line"></span><br><span class="line"># 插入数据</span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:firstname&#x27;</span>,<span class="string">&#x27;zhangsan1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:lastname&#x27;</span>,<span class="string">&#x27;zhangsan2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:name&#x27;</span>,<span class="string">&#x27;数加&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:address&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span></span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> TEST <span class="keyword">values</span>(<span class="string">&#x27;002&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># 在phoenix创建视图， <span class="keyword">primary</span> key 对应到hbase中的rowkey</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> &quot;test&quot;(</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">view</span> &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 在phoenix查询数据，表名通过双引号引起来</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> &quot;test&quot;;</span><br><span class="line"></span><br><span class="line"># 删除视图</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">view</span> &quot;test&quot;;</span><br></pre></td></tr></table></figure><h5 id="3-2、表映射"><a href="#3-2、表映射" class="headerlink" title="3.2、表映射"></a>3.2、表映射</h5><p>使用Apache Phoenix创建对HBase的表映射，有两类：</p><p>1） 当HBase中已经存在表时，可以以类似创建视图的方式创建关联表，只需要将create view改为create table即可。</p><p>2）当HBase中不存在表时，可以直接使用create table指令创建需要的表，并且在创建指令中可以根据需要对HBase表结构进行显示的说明。</p><p>第1）种情况下，如在之前的基础上已经存在了test表，则表映射的语句如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> &quot;test&quot; (</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;<span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">)column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span>  &quot;test&quot;  <span class="keyword">values</span>(<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;score&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;score_dan&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>使用create table创建的关联表，如果对表进行了修改，源数据也会改变，同时如果关联表被删除，源表也会被删除。但是视图就不会，如果删除视图，源数据不会发生改变。</p><h2 id="七、bulkLoad实现批量导入"><a href="#七、bulkLoad实现批量导入" class="headerlink" title="七、bulkLoad实现批量导入"></a>七、bulkLoad实现批量导入</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ol><li><p>如果我们一次性入库hbase巨量数据，处理速度慢不说，还特别占用Region资源， 一个比较高效便捷的方法就是使用 “Bulk Loading”方法，即HBase提供的HFileOutputFormat类。</p></li><li><p>它是利用hbase的数据信息按照特定格式存储在hdfs内这一原理，直接生成这种hdfs内存储的数据格式文件，然后上传至合适位置，即完成巨量数据快速入库的办法。配合mapreduce完成，高效便捷，而且不占用region资源，增添负载。</p></li></ol><h3 id="限制："><a href="#限制：" class="headerlink" title="限制："></a>限制：</h3><ol><li>仅适合初次数据导入，即表内数据为空，或者每次入库表内都无数据的情况。</li><li>HBase集群与Hadoop集群为同一集群，即HBase所基于的HDFS为生成HFile的MR的集群</li></ol><h3 id="代码编写："><a href="#代码编写：" class="headerlink" title="代码编写："></a>代码编写：</h3><blockquote><p>提前在Hbase中创建好表</p><p>生成Hfile基本流程：</p><ol><li><p>设置Mapper的输出KV类型：     </p><p>K： ImmutableBytesWritable（代表行键）</p><p>V： KeyValue  （代表cell）</p></li></ol><p>​    2.  开发Mapper</p><p>​        读取你的原始数据，按你的需求做处理</p><p>​        输出rowkey作为K，输出一些KeyValue（Put）作为V</p><p>​    3.  配置job参数</p><p>​        a. Zookeeper的连接地址</p><p>​        b. 配置输出的OutputFormat为HFileOutputFormat2，并为其设置参数</p><p>​    4.  提交job</p><p>​            导入HFile到RegionServer的流程</p><p>​                构建一个表描述对象</p><p>​            构建一个region定位工具</p><p>​            然后用LoadIncrementalHFiles来doBulkload操作</p></blockquote><blockquote><p>pom文件：</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-bigdata17<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.shujia<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>had-hbase-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- compiler插件, 设定JDK版本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">showWarnings</span>&gt;</span>true<span class="tag">&lt;/<span class="name">showWarnings</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">&lt;!-- 带依赖jar 插件--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>电信数据</p></blockquote><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br></pre></td></tr></table></figure><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li><p>最终输出结果，无论是map还是reduce，输出部分key和value的类型必须是： &lt;ImmutableBytesWritable, KeyValue&gt;或者&lt;ImmutableBytesWritable, Put&gt;。</p></li><li><p>最终输出部分，Value类型是KeyValue 或Put，对应的Sorter分别是KeyValueSortReducer或PutSortReducer。</p></li><li><p>MR例子中HFileOutputFormat2.configureIncrementalLoad(job, dianxin_bulk, regionLocator);自动对job进行配置。SimpleTotalOrderPartitioner是需要先对key进行整体排序，然后划分到每个reduce中，保证每一个reducer中的的key最小最大值区间范围，是不会有交集的。因为入库到HBase的时候，作为一个整体的Region，key是绝对有序的。</p></li><li><p>MR例子中最后生成HFile存储在HDFS上，输出路径下的子目录是各个列族。如果对HFile进行入库HBase，相当于move HFile到HBase的Region中，HFile子目录的列族内容没有了，但不能直接使用mv命令移动，因为直接移动不能更新HBase的元数据。</p></li><li><p>HFile入库到HBase通过HBase中 LoadIncrementalHFiles的doBulkLoad方法，对生成的HFile文件入库</p></li></ol><h2 id="八、HBase中rowkey的设计（重点）"><a href="#八、HBase中rowkey的设计（重点）" class="headerlink" title="八、HBase中rowkey的设计（重点）"></a>八、HBase中rowkey的设计（重点）</h2><p><strong>HBase的RowKey设计</strong></p><p>HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。</p><p>HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有两种方式：</p><p> 通过get方式，指定rowkey获取唯一一条记录</p><p> 通过scan方式，设置startRow和stopRow参数进行范围匹配</p><p> 全表扫描，即直接扫描整张表中所有行记录</p><p><strong>rowkey长度原则</strong></p><p>rowkey是一个二进制码流，可以是任意字符串，最大长度 <em>64kb</em> ，实际应用中一般为10-100bytes，以 byte[] 形式保存，一般设计成定长。</p><p>建议越短越好，不要超过16个字节，原因如下：</p><p> 数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w&#x3D;10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；</p><p> MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。</p><p> 目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p><p><strong>rowkey散列原则</strong></p><p>如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。</p><p><strong>rowkey唯一原则</strong></p><p>必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。</p><p><strong>什么是热点</strong></p><p>HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。</p><p>为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。</p><p>下面是一些常见的避免热点的方法以及它们的优缺点：</p><p><strong>加盐</strong></p><p>这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。</p><p><strong>哈希</strong></p><p>哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据</p><p><strong>反转</strong></p><p>第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。</p><p>反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题</p><p><strong>时间戳反转</strong></p><p>一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key]reverse_timestamp , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。</p><p>比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计</p><p>[userId反转]Long.Max_Value - timestamp，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转]000000000000,stopRow是[userId反转]Long.Max_Value - timestamp</p><p>如果需要查询某段时间的操作记录，startRow是[user反转]Long.Max_Value - 起始时间，stopRow是[userId反转]Long.Max_Value - 结束时间</p><p>其他一些建议</p><p> 尽量减少行和列的大小在HBase中，value永远和它的key一起传输的。当具体的值在系统间传输时，它的rowkey，列名，时间戳也会一起传输。如果你的rowkey和列名很大，甚至可以和具体的值相比较，那么你将会遇到一些有趣的问题。HBase storefiles中的索引（有助于随机访问）最终占据了HBase分配的大量内存，因为具体的值和它的key很大。可以增加block大小使得storefiles索引再更大的时间间隔增加，或者修改表的模式以减小rowkey和列名的大小。压缩也有助于更大的索引。</p><p> 列族尽可能越短越好，最好是一个字符</p><p> 冗长的属性名虽然可读性好，但是更短的属性名存储在HBase中会更好</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 原数据：以时间戳_user_id作为rowkey</span><br><span class="line"># 时间戳高位变化不大，太连续，最终可能会导致热点问题</span><br><span class="line">1638584124_user_id</span><br><span class="line">1638584135_user_id</span><br><span class="line">1638584146_user_id</span><br><span class="line">1638584157_user_id</span><br><span class="line">1638584168_user_id</span><br><span class="line">1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 解决方案：加盐、反转、哈希</span><br><span class="line"></span><br><span class="line"># 加盐</span><br><span class="line"># 加上随即前缀，随机的打散</span><br><span class="line"># 该过程无法预测 前缀时随机的</span><br><span class="line">00_1638584124_user_id</span><br><span class="line">05_1638584135_user_id</span><br><span class="line">03_1638584146_user_id</span><br><span class="line">04_1638584157_user_id</span><br><span class="line">02_1638584168_user_id</span><br><span class="line">06_1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 反转</span><br><span class="line"># 适用于高位变化不大，低位变化大的rowkey</span><br><span class="line">4214858361_user_id</span><br><span class="line">5314858361_user_id</span><br><span class="line">6414858361_user_id</span><br><span class="line">7514858361_user_id</span><br><span class="line">8614858361_user_id</span><br><span class="line">9714858361_user_id</span><br><span class="line"></span><br><span class="line"># 散列 md5、sha1、sha256......</span><br><span class="line">25531D7065AE158AAB6FA53379523979_user_id</span><br><span class="line">60F9A0072C0BD06C92D768DACF2DFDC3_user_id</span><br><span class="line">D2EFD883A6C0198DA3AF4FD8F82DEB57_user_id</span><br><span class="line">A9A4C265D61E0801D163927DE1299C79_user_id</span><br><span class="line">3F41251355E092D7D8A50130441B58A5_user_id</span><br><span class="line">5E6043C773DA4CF991B389D200B77379_user_id</span><br><span class="line"></span><br><span class="line"># 时间戳&quot;反转&quot;</span><br><span class="line"># rowkey：时间戳_user_id</span><br><span class="line"># rowkey是字典升序的，那么越新的记录会被排在最后面，不容易被获取到</span><br><span class="line"># 需求：让最新的记录排在最前面</span><br><span class="line"></span><br><span class="line"># 大数：9999999999</span><br><span class="line"># 大数-小数</span><br><span class="line"></span><br><span class="line">1638584124_user_id =&gt; 8361415875_user_id</span><br><span class="line">1638584135_user_id =&gt; 8361415864_user_id</span><br><span class="line">1638584146_user_id =&gt; 8361415853_user_id</span><br><span class="line">1638584157_user_id =&gt; 8361415842_user_id</span><br><span class="line">1638584168_user_id =&gt; 8361415831_user_id</span><br><span class="line">1638584179_user_id =&gt; 8361415820_user_id</span><br><span class="line"></span><br><span class="line">1638586193_user_id =&gt; 8361413806_user_id</span><br></pre></td></tr></table></figure><h3 id="合理设计rowkey实战（电信）"><a href="#合理设计rowkey实战（电信）" class="headerlink" title="合理设计rowkey实战（电信）"></a>合理设计rowkey实战（电信）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br><span class="line"></span><br><span class="line">将用户位置数据保存到hbase</span><br><span class="line">    查询需求</span><br><span class="line">        1、通过手机号查询用户最近10条位置记录</span><br><span class="line"></span><br><span class="line">        2、获取用户某一天在一个城市中的所有位置</span><br><span class="line"></span><br><span class="line">    怎么设计hbase表</span><br><span class="line">        1、rowkey</span><br><span class="line">        2、时间戳</span><br></pre></td></tr></table></figure><h2 id="九、二级索引"><a href="#九、二级索引" class="headerlink" title="九、二级索引"></a>九、二级索引</h2><blockquote><p><strong>二级索引的本质就是建立各列值与行键之间的映射关系</strong></p></blockquote><p><strong>Hbase的局限性：</strong></p><p>　　HBase本身只提供基于行键和全表扫描的查询，而行键索引单一，对于多维度的查询困难。</p><p><strong>所以我们引进一个二级索引的概念</strong></p><h3 id="常见的二级索引："><a href="#常见的二级索引：" class="headerlink" title="常见的二级索引："></a><strong>常见的二级索引：</strong></h3><p>HBase的一级索引就是rowkey，我们只能通过rowkey进行检索。如果我们相对hbase里面列族的列列进行一些组合查询，就需要采用HBase的二级索引方案来进行多条件的查询。 </p><p>  　　1. MapReduce方案<br>  　　2. ITHBASE（Indexed-Transanctional HBase）方案<br>  　　3. IHBASE（Index HBase）方案<br>  　　4. Hbase Coprocessor(协处理器)方案<br>  　　5. Solr+hbase方案  redis+hbase 方案</p><p>  　　6. CCIndex（complementalclustering index）方案</p><h3 id="二级索引的种类"><a href="#二级索引的种类" class="headerlink" title="二级索引的种类"></a><strong>二级索引的种类</strong></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">　　1、创建单列索引</span><br><span class="line"></span><br><span class="line">　　2、同时创建多个单列索引</span><br><span class="line"></span><br><span class="line">　　3、创建联合索引（最多同时支持3个列）</span><br><span class="line"></span><br><span class="line">　　4、只根据rowkey创建索引</span><br></pre></td></tr></table></figure><p><strong>单表建立二级索引</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.首先disable ‘表名’</span><br><span class="line">2.然后修改表</span><br><span class="line"></span><br><span class="line">alter &#x27;LogTable&#x27;,METHOD=&gt;&#x27;table_att&#x27;,&#x27;coprocessor&#x27;=&gt;&#x27;hdfs:///写好的Hbase协处理器（coprocessor）的jar包名|类的绝对路径名|1001&#x27;</span><br><span class="line"></span><br><span class="line">3. enable &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><strong>二级索引的设计思路</strong></p><p><img src="https://s2.loli.net/2022/06/15/74rQAdRhWFzasxm.png" alt="image-20220615155157645"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">二级索引的本质就是建立各列值与行键之间的映射关系</span><br><span class="line"></span><br><span class="line">如上图，当要对F:C1这列建立索引时，只需要建立F:C1各列值到其对应行键的映射关系，如C11-&gt;RK1等，这样就完成了对F:C1列值的二级索引的构建，当要查询符合F:C1=C11对应的F:C2的列值时（即根据C1=C11来查询C2的值,图1青色部分）</span><br><span class="line"></span><br><span class="line">其查询步骤如下：</span><br><span class="line"></span><br><span class="line">1. 根据C1=C11到索引数据中查找其对应的RK，查询得到其对应的RK=RK1</span><br><span class="line"></span><br><span class="line">2. 得到RK1后就自然能根据RK1来查询C2的值了 这是构建二级索引大概思路，其他组合查询的联合索引的建立也类似。</span><br></pre></td></tr></table></figure><h3 id="Mapreduce的方式创建二级索引"><a href="#Mapreduce的方式创建二级索引" class="headerlink" title="Mapreduce的方式创建二级索引"></a><strong>Mapreduce的方式创建二级索引</strong></h3><p>使用整合MapReduce的方式创建hbase索引。主要的流程如下：</p><p>1.1扫描输入表，使用hbase继承类TableMapper</p><p>1.2获取rowkey和指定字段名称和字段值</p><p>1.3创建Put实例， value&#x3D;” “, rowkey&#x3D;班级，column&#x3D;学号</p><p>1.4使用IdentityTableReducer将数据写入索引表</p><h4 id="案例："><a href="#案例：" class="headerlink" title="案例："></a>案例：</h4><blockquote><p><strong>1、在hbase中创建索引表 student_index</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;student_index&#x27;</span>,<span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>2、编写mapreduce代码</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Mutation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  编写整个mapreduce程序建立索引表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexMapper</span> <span class="keyword">extends</span> <span class="title class_">TableMapper</span>&lt;Text, NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(ImmutableBytesWritable key, Result value, Mapper&lt;ImmutableBytesWritable, Result, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(key.get());</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(value.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">key1</span> <span class="operator">=</span> id+<span class="string">&quot;_&quot;</span>+clazz;</span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(key1),NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * reduce端获取map端传过来的key</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexReduce</span> <span class="keyword">extends</span> <span class="title class_">TableReducer</span>&lt;Text,NullWritable,NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Reducer&lt;Text, NullWritable, NullWritable, Mutation&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        String[] strings = key.toString().split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> strings[<span class="number">0</span>];</span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> strings[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//索引表也是属于hbase的表，需要使用put实例添加数据</span></span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(clazz.getBytes());</span><br><span class="line">        put.add(<span class="string">&quot;info&quot;</span>.getBytes(),id.getBytes(),<span class="string">&quot;&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        context.write(NullWritable.get(),put);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndex</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        job.setJobName(<span class="string">&quot;建立学生索引表&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(HbaseIndex.class);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.addFamily(<span class="string">&quot;info&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定对哪张表建立索引，以及指定需要建索引的列所属的列簇</span></span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(<span class="string">&quot;students&quot;</span>,scan,IndexMapper.class,Text.class,NullWritable.class,job);</span><br><span class="line">        TableMapReduceUtil.initTableReducerJob(<span class="string">&quot;student_index&quot;</span>,IndexReduce.class,job);</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>3、打成jar包上传到hadoop中运行</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop jar had-hbase-demo-1.0-SNAPSHOT-jar-with-dependencies.jar com.shujia.hbaseapi.hbaseindexdemo.HbaseIndex</span><br></pre></td></tr></table></figure><blockquote><p><strong>4、编写查询代码，测试结果（先查询索引表，在查数据）</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.CompareFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SubstringComparator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndexToStudents</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> HConnection conn;</span><br><span class="line">    <span class="keyword">private</span> HBaseAdmin hAdmin;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1、获取Hadoop的相关配置环境</span></span><br><span class="line">            <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//2、获取zookeeper的配置</span></span><br><span class="line">            conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line">            <span class="comment">//获取与Hbase的连接，这个连接是将来可以用户获取hbase表的</span></span><br><span class="line">            conn = HConnectionManager.createConnection(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//将来我们要对表做DDL相关操作，而对表的操作在hbase架构中是有HMaster</span></span><br><span class="line">            hAdmin = <span class="keyword">new</span> <span class="title class_">HBaseAdmin</span>(conf);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;建立连接成功:&quot;</span> + conn + <span class="string">&quot;, HMaster获取成功：&quot;</span> + hAdmin);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过索引表进行查询数据</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * 需求：获取理科二班所有的学生信息，不适用过滤器，使用索引表查询</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">scanData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//创建一个集合存放查询到的学号</span></span><br><span class="line">            ArrayList&lt;Get&gt; gets = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取到索引表</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">student_index</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;student_index&quot;</span>);</span><br><span class="line">            <span class="comment">//创建Get实例</span></span><br><span class="line">            <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(<span class="string">&quot;理科二班&quot;</span>.getBytes());</span><br><span class="line">            <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> student_index.get(get);</span><br><span class="line">            List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">                <span class="comment">//每一个单元格的列名</span></span><br><span class="line">                <span class="type">byte</span>[] bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(bytes);</span><br><span class="line"></span><br><span class="line">                <span class="type">Get</span> <span class="variable">get1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(id.getBytes());</span><br><span class="line">                <span class="comment">//将学号添加到集合中</span></span><br><span class="line">                gets.add(get1);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            Result[] results = students.get(gets);</span><br><span class="line">            <span class="keyword">for</span> (Result result1 : results) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(result1.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">            <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;理科二班&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(), CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            scan.setFilter(singleColumnValueFilter);</span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (conn != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                conn.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;conn连接已经关闭.....&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (hAdmin != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hAdmin.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;HMaster已经关闭......&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十、Phoenix二级索引"><a href="#十、Phoenix二级索引" class="headerlink" title="十、Phoenix二级索引"></a>十、Phoenix二级索引</h2><blockquote><p>对于Hbase，如果想精确定位到某行记录，唯一的办法就是通过rowkey查询。如果不通过rowkey查找数据，就必须逐行比较每一行的值，对于较大的表，全表扫描的代价是不可接受的。</p></blockquote><h3 id="1、开启索引支持"><a href="#1、开启索引支持" class="headerlink" title="1、开启索引支持"></a>1、开启索引支持</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 关闭hbase集群</span><br><span class="line">stop-hbase.sh</span><br><span class="line"></span><br><span class="line"># 在/usr/local/soft/hbase-1.4.6/conf/hbase-site.xml中增加如下配置</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.wal.codec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 同步到所有节点</span><br><span class="line">scp hbase-site.xml node1:`pwd`</span><br><span class="line">scp hbase-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line"># 修改phoenix目录下的bin目录中的hbase-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 启动hbase</span><br><span class="line">start-hbase.sh</span><br><span class="line"># 重新进入phoenix客户端</span><br><span class="line">sqlline.py master,node1,node2</span><br></pre></td></tr></table></figure><h3 id="2、创建索引"><a href="#2、创建索引" class="headerlink" title="2、创建索引"></a>2、创建索引</h3><h4 id="2-1、全局索引"><a href="#2-1、全局索引" class="headerlink" title="2.1、全局索引"></a>2.1、全局索引</h4><blockquote><p>全局索引适合读多写少的场景。如果使用全局索引，读数据基本不损耗性能，所有的性能损耗都来源于写数据。数据表的添加、删除和修改都会更新相关的索引表（数据删除了，索引表中的数据也会删除；数据增加了，索引表的数据也会增加）</p></blockquote><blockquote><p>注意: 对于全局索引在默认情况下，在查询语句中检索的列如果不在索引表中，Phoenix不会使用索引表将，除非使用hint。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">手机号 进入网格的时间 离开网格的时间 区县编码 经度 纬度 基站标识 网格编号 业务类型</span><br><span class="line"></span><br><span class="line"># 创建DIANXIN.sql</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> DIANXIN (</span><br><span class="line">     mdn <span class="type">VARCHAR</span> ,</span><br><span class="line">     start_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     end_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     county <span class="type">VARCHAR</span>,</span><br><span class="line">     x <span class="keyword">DOUBLE</span> ,</span><br><span class="line">     y  <span class="keyword">DOUBLE</span>,</span><br><span class="line">     bsid <span class="type">VARCHAR</span>,</span><br><span class="line">     grid_id  <span class="type">VARCHAR</span>,</span><br><span class="line">     biz_type <span class="type">VARCHAR</span>, </span><br><span class="line">     event_type <span class="type">VARCHAR</span> , </span><br><span class="line">     data_source <span class="type">VARCHAR</span> ,</span><br><span class="line">     <span class="keyword">CONSTRAINT</span> PK <span class="keyword">PRIMARY</span> KEY (mdn,start_date)</span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 上传数据DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 导入数据</span><br><span class="line">psql.py master,node1,node2 DIANXIN.sql DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 创建全局索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX <span class="keyword">ON</span> DIANXIN ( end_date );</span><br><span class="line"></span><br><span class="line"># 查询数据 ( 索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 （索引生效） hint</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> start_date <span class="operator">=</span> <span class="string">&#x27;20180503154614&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 取索引列，（索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 创建多列索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX1 <span class="keyword">ON</span> DIANXIN ( end_date,COUNTY );</span><br><span class="line"></span><br><span class="line"># 多条件查询 （索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date,MDN,COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 （索引生效）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX1) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 单条件  (索引未生效)</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span>  COUNTY <span class="operator">=</span> <span class="string">&#x27;8340103&#x27;</span>;</span><br><span class="line"># 单条件  (索引生效) end_date 在前</span><br><span class="line"><span class="keyword">select</span> COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 删除索引</span><br><span class="line"><span class="keyword">drop</span> index DIANXIN_INDEX <span class="keyword">on</span> DIANXIN;</span><br></pre></td></tr></table></figure><h4 id="2-2、本地索引"><a href="#2-2、本地索引" class="headerlink" title="2.2、本地索引"></a>2.2、本地索引</h4><blockquote><p>本地索引适合写多读少的场景，或者存储空间有限的场景。和全局索引一样，Phoenix也会在查询的时候自动选择是否使用本地索引。本地索引因为索引数据和原数据存储在同一台机器上，避免网络数据传输的开销，所以更适合写多的场景。由于无法提前确定数据在哪个Region上，所以在读数据的时候，需要检查每个Region上的数据从而带来一些性能损耗。</p></blockquote><blockquote><p>注意:对于本地索引，查询中无论是否指定hint或者是查询的列是否都在索引表中，都会使用索引表。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建本地索引</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">LOCAL</span> INDEX DIANXIN_LOCAL_IDEX <span class="keyword">ON</span> DIANXIN(grid_id);</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> grid_id <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2-3、覆盖索引"><a href="#2-3、覆盖索引" class="headerlink" title="2.3、覆盖索引"></a>2.3、覆盖索引</h4><blockquote><p>覆盖索引是把原数据存储在索引数据表中，这样在查询时不需要再去HBase的原表获取数据就，直接返回查询结果。</p></blockquote><blockquote><p>注意：查询是 select 的列和 where 的列都需要在索引中出现。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建覆盖索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX_COVER <span class="keyword">ON</span> DIANXIN ( x,y ) INCLUDE ( county );</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 (索引生效)</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询索引中的列 (索引生效) mdn是DIANXIN表的RowKey中的一部分</span><br><span class="line"><span class="keyword">select</span> x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"><span class="keyword">select</span> mdn,x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询条件必须放在索引中  <span class="keyword">select</span> 中的列可以放在INCLUDE （将数据保存在索引中）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> x,y,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> DIANXIN <span class="keyword">group</span> <span class="keyword">by</span> x,y;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十一、Phoenix-JDBC"><a href="#十一、Phoenix-JDBC" class="headerlink" title="十一、Phoenix JDBC"></a>十一、Phoenix JDBC</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 导入依赖</span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.15.0-HBase-1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># 建立连接</span><br><span class="line"><span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:phoenix:master,node1,node2:2181&quot;</span>);</span><br><span class="line">        <span class="type">PreparedStatement</span> <span class="variable">ps</span> <span class="operator">=</span> conn.prepareStatement(<span class="string">&quot;select /*+ INDEX(DIANXIN DIANXIN_INDEX) */ * from DIANXIN where end_date=?&quot;</span>);</span><br><span class="line">        ps.setString(<span class="number">1</span>, <span class="string">&quot;20180503212649&quot;</span>);</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> ps.executeQuery();</span><br><span class="line">        <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">mdn</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;mdn&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">start_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;start_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">end_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;end_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">x</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;x&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">y</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;y&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">county</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;county&quot;</span>);</span><br><span class="line">            System.out.println(mdn + <span class="string">&quot;\t&quot;</span> + start_date + <span class="string">&quot;\t&quot;</span> + end_date + <span class="string">&quot;\t&quot;</span> + x + <span class="string">&quot;\t&quot;</span> + y + <span class="string">&quot;\t&quot;</span> + county);</span><br><span class="line">        &#125;</span><br><span class="line">        ps.close();</span><br><span class="line">        conn.close();</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习hbase JAVA API的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase-shell2</title>
    <link href="http://example.com/2022/06/11/Hbase%20Shell%202/"/>
    <id>http://example.com/2022/06/11/Hbase%20Shell%202/</id>
    <published>2022-06-10T16:00:00.000Z</published>
    <updated>2022-06-15T07:37:55.519Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Hbase-Shell-2"><a href="#一、Hbase-Shell-2" class="headerlink" title="一、Hbase Shell 2"></a>一、Hbase Shell 2</h2><h3 id="1、Region信息观察"><a href="#1、Region信息观察" class="headerlink" title="1、Region信息观察"></a>1、Region信息观察</h3><h4 id="创建表指定命名空间"><a href="#创建表指定命名空间" class="headerlink" title="创建表指定命名空间"></a>创建表指定命名空间</h4><blockquote><p>在创建表的时候可以选择创建到bigdata17这个namespace中，如何实现呢？<br>使用这种格式即可：‘命名空间名称:表名’<br>针对default这个命名空间，在使用的时候可以省略不写</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;bigdata17:t1&#x27;,&#x27;info&#x27;,&#x27;level&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/Dow6xBpHlRzQ8PG.png" alt="image-20220612212944281"></p><blockquote><p>此时使用list查看所有的表</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/CxKkf4Wui2Smh1A.png" alt="image-20220612212956679"></p><blockquote><p>如果只想查看bigdata17这个命名空间中的表，如何实现呢？<br>可以使用命令list_namespace_tables</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;n1&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/hnEFiVldA1Ksr6W.png" alt="image-20220612213004703"></p><blockquote><p>查看region中的某列簇数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase hfile -p -f /hbase/data/default/tbl_user/92994712513a45baaa12b72117dda5e5/info/d84e2013791845968917d876e2b438a5</span><br></pre></td></tr></table></figure><h4 id="1-1-查看表的所有region"><a href="#1-1-查看表的所有region" class="headerlink" title="1.1    查看表的所有region"></a>1.1    查看表的所有region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/bY5Oj38yBf4mnwL.png" alt="image-20220612213103879"></p><h4 id="1-2-强制将表切分出来一个region"><a href="#1-2-强制将表切分出来一个region" class="headerlink" title="1.2    强制将表切分出来一个region"></a>1.2    强制将表切分出来一个region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/yaqm2QU1oNlZRLE.png" alt="image-20220612213116364"></p><blockquote><p>但是在页面上可以看到三个：过一会会自动的把原来的删除</p></blockquote><p><img src="D:/bigdata%25E5%259F%25B9%25E8%25AE%25AD/Hbase/day02/Hbase%25E5%25AD%25A6%25E4%25B9%25A0%25EF%25BC%2588%25E4%25BA%258C%25EF%25BC%2589.assets/image-20220609215721140.png" alt="image-20220609215721140"></p><h4 id="1-2-查看某一行在哪个region中"><a href="#1-2-查看某一行在哪个region中" class="headerlink" title="1.2    查看某一行在哪个region中"></a>1.2    查看某一行在哪个region中</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate_region &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/GAjNmPi9SRoqJWU.png" alt="image-20220612213129838"></p><blockquote><p>可以hbase hfile -p -f xxxx 查看一下</p></blockquote><h3 id="2、预分region解决热点问题"><a href="#2、预分region解决热点问题" class="headerlink" title="2、预分region解决热点问题"></a>2、预分region解决热点问题</h3><blockquote><p>row设计的一个关键点是查询维度</p><p>(在建表的时候根据具体的查询业务  设计rowkey   预拆分)</p><p>在默认的拆分策略中 ,region的大小达到一定的阈值以后才会进行拆分,并且拆分的region在同一个regionserver中 ,只有达到负载均衡的时机时才会进行region重分配!并且开始如果有大量的数据进行插入操作,那么并发就会集中在单个RS中, 形成热点问题,所以如果有并发插入的时候尽量避免热点问题 ,应当预划分 Region的rowkeyRange范围 ,在建表的时候就指定预region范围 </p></blockquote><blockquote><p>查看命令使用(指定4个切割点，就会有5个region)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">help &#x27;create&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/onVxkTuJROsG2hE.png" alt="image-20220612213148593"></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;tb_split&#x27;,&#x27;cf&#x27;,SPLITS =&gt; [&#x27;e&#x27;,&#x27;h&#x27;,&#x27;l&#x27;,&#x27;r&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/sS8UjNJrlLAb5TQ.png" alt="image-20220612213201806"></p><blockquote><p>添加数据试试</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;c001&#x27;,&#x27;cf:name&#x27;,&#x27;first&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;f001&#x27;,&#x27;cf:name&#x27;,&#x27;second&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;z001&#x27;,&#x27;cf:name&#x27;,&#x27;last&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>hbase hfile -p –f xxxx 查看数据</p></blockquote><blockquote><p>如果没有数据，因为数据还在内存中，需要手动刷新内存到HDFS中，以HFile的形式存储</p></blockquote><h3 id="3、总结（写一个文档总结回顾）"><a href="#3、总结（写一个文档总结回顾）" class="headerlink" title="3、总结（写一个文档总结回顾）"></a>3、总结（写一个文档总结回顾）</h3><h3 id="4、日志查看"><a href="#4、日志查看" class="headerlink" title="4、日志查看"></a>4、日志查看</h3><blockquote><p>演示不启动hdfs 就启动hbase</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">日志目录：</span><br><span class="line">/usr/local/soft/hbase-1.7.1/logs</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/KIdYakN6uzUgGTb.png" alt="image-20220612213213973"></p><blockquote><p>start-all.sh发现HMaster没启动，hbase shell客户端也可以正常访问</p><p>再启动hbase就好了</p></blockquote><h3 id="5、scan进阶使用"><a href="#5、scan进阶使用" class="headerlink" title="5、scan进阶使用"></a>5、scan进阶使用</h3><blockquote><p>查看所有的命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace</span><br></pre></td></tr></table></figure><blockquote><p>查看某个命名空间下的所有表</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;default&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>修改命名空间,设置一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;set&#x27;,&#x27;author&#x27;=&gt;&#x27;wyh&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>查看命名空间属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">describe_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;unset&#x27;, NAME=&gt;&#x27;author&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drop_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>创建一张表</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">create <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;cf&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>添加数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:tid&#x27;,1</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0002&#x27;,&#x27;cf:tid&#x27;,2</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0003&#x27;,&#x27;cf:tid&#x27;,3</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;,4</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0005&#x27;,&#x27;cf:tid&#x27;,5</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:tid&#x27;,6</span><br></pre></td></tr></table></figure><blockquote><p>显示三行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid00001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/lE4SaAX3FCNtGOj.png" alt="image-20220612213223835"></p><blockquote><p>从后查三行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,REVERSED=&gt;true&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/ky7KZhD36bYxpCI.png" alt="image-20220612213231718"></p><blockquote><p>查看包含指定列的行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,COLUMNS=&gt;[&#x27;cf:name&#x27;]&#125;</span><br></pre></td></tr></table></figure><blockquote><p>简化写法：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,LIMIT=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>在已有的值后面追加值</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">append &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;123&#x27;</span><br></pre></td></tr></table></figure><h3 id="6、get进阶使用"><a href="#6、get进阶使用" class="headerlink" title="6、get进阶使用"></a>6、get进阶使用</h3><blockquote><p>简单使用，获取某一行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某个列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某一列（属性 ）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>可以新增一个列簇数据测试</p></blockquote><blockquote><p><strong>查看历史版本</strong></p><p>1、修改表可以存储多个版本</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,NAME=&gt;&#x27;cf&#x27;,VERSIONS=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>2、put四次相同rowkey和列的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu1&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu2&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu3&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu4&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>3、查看历史数据，默认是最新的</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#123;COLUMN=&gt;&#x27;cf:name&#x27;,VERSIONS=&gt;2&#125;</span><br></pre></td></tr></table></figure><blockquote><p>修改列簇的过期时间 TTL单位是秒，这个时间是与插入的时间比较，而不是现在开始60s</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,&#123;NAME=&gt;&#x27;cf2&#x27;,TTL=&gt;&#x27;60&#x27;&#125;</span><br></pre></td></tr></table></figure><h3 id="7、插入时间指定时间戳"><a href="#7、插入时间指定时间戳" class="headerlink" title="7、插入时间指定时间戳"></a>7、插入时间指定时间戳</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0007&#x27;,&#x27;cf2:job&#x27;,&#x27;bigdata17&#x27;,1654845442790</span><br></pre></td></tr></table></figure><blockquote><p>画图理解这个操作在实际生产的作用</p></blockquote><h3 id="8、delete-只能删除一个单元格，不能删除列簇"><a href="#8、delete-只能删除一个单元格，不能删除列簇" class="headerlink" title="8、delete(只能删除一个单元格，不能删除列簇)"></a>8、delete(只能删除一个单元格，不能删除列簇)</h3><blockquote><p>删除某一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">delete &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;</span><br></pre></td></tr></table></figure><h3 id="9、deleteall-删除不了某个列簇，但是可以删除多个单元格"><a href="#9、deleteall-删除不了某个列簇，但是可以删除多个单元格" class="headerlink" title="9、deleteall(删除不了某个列簇，但是可以删除多个单元格)"></a>9、deleteall(删除不了某个列簇，但是可以删除多个单元格)</h3><blockquote><p>删除一行，如果不指定类簇，删除的是一行中的所有列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除单元格</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;cf2:job&#x27;</span><br></pre></td></tr></table></figure><h3 id="10、incr和counter"><a href="#10、incr和counter" class="headerlink" title="10、incr和counter"></a>10、incr和counter</h3><blockquote><p>统计表有多少行(<strong>统计的是行键的个数</strong>)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">count &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>新建一个自增的一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br></pre></td></tr></table></figure><blockquote><p>每操作一次，自增1</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,10</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,100</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/o4DQfV6mOd5gGBY.png" alt="image-20220612213526090"></p><blockquote><p>配合counter取出数据,只能去incr字段</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_counter &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;</span><br></pre></td></tr></table></figure><h3 id="11、获取region的分割点，清除数据，快照"><a href="#11、获取region的分割点，清除数据，快照" class="headerlink" title="11、获取region的分割点，清除数据，快照"></a>11、获取region的分割点，清除数据，快照</h3><blockquote><p>获取region的分割点</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_splits &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>清除表数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">truncate &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>拍摄快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">snapshot &#x27;tb_split&#x27;,&#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>列出所有快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_table_snapshots &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>再添加一些数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;a001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>恢复快照(先禁用)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">disable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">restore_snapshot &#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">enable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><h3 id="12-修饰词"><a href="#12-修饰词" class="headerlink" title="12    修饰词"></a>12    修饰词</h3><h5 id="1、修饰词"><a href="#1、修饰词" class="headerlink" title="1、修饰词"></a>1、修饰词</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;列族名1:列名1&#x27;</span>, <span class="string">&#x27;列族名1:列名2&#x27;</span>, ...]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="2、TIMESTAMP-指定时间戳"><a href="#2、TIMESTAMP-指定时间戳" class="headerlink" title="2、TIMESTAMP 指定时间戳"></a>2、TIMESTAMP 指定时间戳</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[timestamp1, timestamp2]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[<span class="number">1551938004321</span>, <span class="number">1551938036450</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="3、VERSIONS"><a href="#3、VERSIONS" class="headerlink" title="3、VERSIONS"></a>3、VERSIONS</h5><blockquote><p>默认情况下一个列只能存储一个数据，后面如果修改数据就会将原来的覆盖掉，可以通过指定VERSIONS时HBase一列能存储多个值。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;columnFamily1&#x27;</span></span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_test&#x27;</span></span><br><span class="line"></span><br><span class="line"># 修改列族版本号</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_test&#x27;</span>, &#123; NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span> &#125;</span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value3&#x27;</span></span><br><span class="line"></span><br><span class="line"># 默认返回最新的一条数据</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,<span class="string">&#x27;columnFamily1:column1&#x27;</span></span><br><span class="line"></span><br><span class="line"># 返回<span class="number">3</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"># 返回<span class="number">2</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="4、STARTROW"><a href="#4、STARTROW" class="headerlink" title="4、STARTROW"></a>4、STARTROW</h5><blockquote><p>ROWKEY起始行。会先根据这个key定位到region，再向后扫描</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;vbirdbest&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"><a href="#5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据" class="headerlink" title="5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"></a>5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;xiaoming&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="6、LIMIT-返回的行数"><a href="#6、LIMIT-返回的行数" class="headerlink" title="6、LIMIT 返回的行数"></a>6、LIMIT 返回的行数</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> 行数&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2</span> &#125;</span><br></pre></td></tr></table></figure><h3 id="13-FILTER条件过滤器"><a href="#13-FILTER条件过滤器" class="headerlink" title="13    FILTER条件过滤器"></a>13    FILTER条件过滤器</h3><blockquote><p>过滤器之间可以使用AND、OR连接多个过滤器。</p></blockquote><h5 id="1、ValueFilter-值过滤器"><a href="#1、ValueFilter-值过滤器" class="headerlink" title="1、ValueFilter 值过滤器"></a>1、ValueFilter 值过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法：<span class="type">binary</span> 等于某个值</span><br><span class="line">scan <span class="string">&#x27;&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;binary:&#x27;)&quot;</span><br><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;substring:列值&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;binary:26&#x27;)&quot;</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;substring:6&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="2、ColumnPrefixFilter-列名前缀过滤器"><a href="#2、ColumnPrefixFilter-列名前缀过滤器" class="headerlink" title="2、ColumnPrefixFilter 列名前缀过滤器"></a>2、ColumnPrefixFilter 列名前缀过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;列名前缀&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;)&quot;</span><br><span class="line"># 通过括号、<span class="keyword">AND</span>和<span class="keyword">OR</span>的条件组合多个过滤器</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:26&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="3、rowKey字典排序"><a href="#3、rowKey字典排序" class="headerlink" title="3、rowKey字典排序"></a>3、rowKey字典排序</h5><blockquote><p>Table中的所有行都是按照row key的字典排序的</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/lHbNsQYjU8TCnMA.png" alt="image-20220612213543115"></p><h2 id="二、JAVA-API"><a href="#二、JAVA-API" class="headerlink" title="二、JAVA API"></a>二、JAVA API</h2><blockquote><p>pom文件</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习hbase shell的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase过滤器</title>
    <link href="http://example.com/2022/06/11/Hbase%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    <id>http://example.com/2022/06/11/Hbase%E8%BF%87%E6%BB%A4%E5%99%A8/</id>
    <published>2022-06-10T16:00:00.000Z</published>
    <updated>2022-06-12T13:43:34.353Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hbase过滤器"><a href="#Hbase过滤器" class="headerlink" title="Hbase过滤器"></a>Hbase过滤器</h2><blockquote><p>HBase 的基本 API，包括增、删、改、查等。<br>增、删都是相对简单的操作，与传统的 RDBMS 相比，这里的查询操作略显苍白，只能根据特性的行键进行查询（Get）或者根据行键的范围来查询（Scan）。<br>HBase 不仅提供了这些简单的查询，而且提供了更加高级的过滤器（Filter）来查询。</p><p>过滤器可以根据列族、列、版本等更多的条件来对数据进行过滤，</p><p>基于 HBase 本身提供的三维有序（行键，列，版本有序），这些过滤器可以高效地完成查询过滤的任务，带有过滤器条件的 RPC 查询请求会把过滤器分发到各个 RegionServer（这是一个服务端过滤器），这样也可以降低网络传输的压力。</p><p>使用过滤器至少需要两类参数：</p><p><strong>一类是抽象的操作符，另一类是比较器</strong></p></blockquote><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><ul><li>过滤器的作用是在<strong>服务端</strong>判断数据是否满足条件，然后只将满足条件的数据返回给<strong>客户端</strong></li><li>过滤器的类型很多，但是可以分为三大类：<ul><li>比较过滤器：可应用于rowkey、列簇、列、列值过滤器</li><li>专用过滤器：只能适用于特定的过滤器</li><li>包装过滤器：包装过滤器就是通过包装其他过滤器以实现某些拓展的功能。</li></ul></li></ul><h4 id="比较过滤器"><a href="#比较过滤器" class="headerlink" title="比较过滤器"></a>比较过滤器</h4><blockquote><p>所有比较过滤器均继承自 <code>CompareFilter</code>。创建一个比较过滤器需要两个参数，分别是<strong>比较运算符</strong>和<strong>比较器实例</strong>。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">CompareFilter</span><span class="params">(<span class="keyword">final</span> CompareOp compareOp,<span class="keyword">final</span> ByteArrayComparable comparator)</span> &#123;</span><br><span class="line">   <span class="built_in">this</span>.compareOp = compareOp;</span><br><span class="line">   <span class="built_in">this</span>.comparator = comparator;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h5 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h5><ul><li><p>LESS  &lt;</p></li><li><p>LESS_OR_EQUAL &lt;&#x3D;</p></li><li><p>EQUAL &#x3D;</p></li><li><p>NOT_EQUAL &lt;&gt;</p></li><li><p>GREATER_OR_EQUAL &gt;&#x3D;</p></li><li><p>GREATER &gt;</p></li><li><p>NO_OP 排除所有</p></li></ul><h5 id="常见的六大比较过滤器"><a href="#常见的六大比较过滤器" class="headerlink" title="常见的六大比较过滤器"></a>常见的六大比较过滤器</h5><h6 id="BinaryComparator"><a href="#BinaryComparator" class="headerlink" title="BinaryComparator"></a>BinaryComparator</h6><blockquote><p>按字节索引顺序比较指定字节数组，采用Bytes.compareTo(byte[])</p></blockquote><h6 id="BinaryPrefixComparator"><a href="#BinaryPrefixComparator" class="headerlink" title="BinaryPrefixComparator"></a>BinaryPrefixComparator</h6><blockquote><p>通BinaryComparator，只是比较左端前缀的数据是否相同</p></blockquote><h6 id="NullComparator"><a href="#NullComparator" class="headerlink" title="NullComparator"></a>NullComparator</h6><blockquote><p>判断给定的是否为空</p></blockquote><h6 id="BitComparator"><a href="#BitComparator" class="headerlink" title="BitComparator"></a>BitComparator</h6><blockquote><p>按位比较</p></blockquote><h6 id="RegexStringComparator"><a href="#RegexStringComparator" class="headerlink" title="RegexStringComparator"></a>RegexStringComparator</h6><blockquote><p>提供一个正则的比较器，仅支持 EQUAL 和非EQUAL</p></blockquote><h6 id="SubstringComparator"><a href="#SubstringComparator" class="headerlink" title="SubstringComparator"></a>SubstringComparator</h6><blockquote><p>判断提供的子串是否出现在中</p></blockquote><h5 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h5><h6 id="rowKey过滤器：RowFilter-行键过滤器"><a href="#rowKey过滤器：RowFilter-行键过滤器" class="headerlink" title="rowKey过滤器：RowFilter  行键过滤器"></a>rowKey过滤器：RowFilter  行键过滤器</h6><blockquote><p>通过RowFilter与BinaryComparator过滤比rowKey 1500100010小的所有值出来</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  行键过滤器</span></span><br><span class="line"><span class="comment">     *  通过RowFilter与BinaryComparator过滤比rowKey 1500100010小的所有值出来</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">RowFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;1500100010&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建一个行键过滤器的对象</span></span><br><span class="line">            <span class="type">RowFilter</span> <span class="variable">rowFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.LESS, binaryComparator);</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(rowFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            print(scanner);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *      专门用来打印数据的方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(ResultScanner scanner)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line"><span class="comment">//                List&lt;Cell&gt; cells = rs.listCells();</span></span><br><span class="line"><span class="comment">//                System.out.print(&quot;id:&quot; + id);</span></span><br><span class="line"><span class="comment">//                System.out.print(&quot;\t&quot;);</span></span><br><span class="line"><span class="comment">//                for (Cell cell : cells) &#123;</span></span><br><span class="line"><span class="comment">////                String s = Bytes.toString(cell.getValue());</span></span><br><span class="line"><span class="comment">//                    String col = Bytes.toString(CellUtil.cloneQualifier(cell));</span></span><br><span class="line"><span class="comment">//                    String s = Bytes.toString(CellUtil.cloneValue(cell));</span></span><br><span class="line"><span class="comment">//                    System.out.print(col + &quot;:&quot; + s);</span></span><br><span class="line"><span class="comment">//                    System.out.print(&quot;\t&quot;);</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//                System.out.println();</span></span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">            System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;,姓名：&quot;</span> + name + <span class="string">&quot;,年龄：&quot;</span> + age + <span class="string">&quot;,性别：&quot;</span> + gender + <span class="string">&quot;,班级：&quot;</span> + clazz);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h6 id="列簇过滤器：FamilyFilter"><a href="#列簇过滤器：FamilyFilter" class="headerlink" title="列簇过滤器：FamilyFilter"></a>列簇过滤器：FamilyFilter</h6><blockquote><p>通过FamilyFilter与SubstringComparator查询列簇名包含in的所有列簇下面的数据</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *      列簇过滤器案例1：通过FamilyFilter与SubstringComparator查询列簇名包含in的所有列簇下面的数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FamilyFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个比较器对象</span></span><br><span class="line">        <span class="comment">//只要列簇名中包含了in，就把该列簇下的所有列查询出来</span></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;in&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列簇过滤器</span></span><br><span class="line">        <span class="type">FamilyFilter</span> <span class="variable">familyFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FamilyFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(familyFilter);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取数据</span></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>通过FamilyFilter与 BinaryPrefixComparator 过滤出列簇以i开头的列簇下的所有数据</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列簇过滤器案例2：通过FamilyFilter与 BinaryPrefixComparator 过滤出列簇以i开头的列簇下的所有数据</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FamilyFilter2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建前缀比较器</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;i&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列簇过滤器</span></span><br><span class="line">        <span class="type">FamilyFilter</span> <span class="variable">familyFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FamilyFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(familyFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="列过滤器：QualifierFilter"><a href="#列过滤器：QualifierFilter" class="headerlink" title="列过滤器：QualifierFilter"></a>列过滤器：QualifierFilter</h6><blockquote><p>通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列过滤器案例1：通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">QualifierFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建包含比较器</span></span><br><span class="line">        <span class="comment">//age</span></span><br><span class="line">        <span class="comment">//gender</span></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;ge&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个列过滤器</span></span><br><span class="line">        <span class="type">QualifierFilter</span> <span class="variable">qualifierFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QualifierFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(qualifierFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出列的名字中 包含 “am” 所有的列 及列的值</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 列过滤器案例2：通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">QualifierFilter2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;am&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列过滤器</span></span><br><span class="line">        <span class="type">QualifierFilter</span> <span class="variable">qualifierFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QualifierFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(qualifierFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="列值过滤器：ValueFilter"><a href="#列值过滤器：ValueFilter" class="headerlink" title="列值过滤器：ValueFilter"></a>列值过滤器：ValueFilter</h6><blockquote><p>通过ValueFilter与BinaryPrefixComparator过滤出所有的cell中值以 “张” 开头的学生</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 列值过滤器案例1:通过ValueFilter与BinaryPrefixComparator过滤出所有的cell中值以 &quot;张&quot; 开头的学生</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">ValueFilter1</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建前缀比较器</span></span><br><span class="line">            <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;张&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建列值过滤器的对象</span></span><br><span class="line">            <span class="type">ValueFilter</span> <span class="variable">valueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(valueFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//因为ResultScanner类继承了迭代器</span></span><br><span class="line">            <span class="comment">//使用增强for循环遍历</span></span><br><span class="line"><span class="comment">//            for (Result rs : scanner) &#123;</span></span><br><span class="line"><span class="comment">//                String id = Bytes.toString(rs.getRow());</span></span><br><span class="line"><span class="comment">//                System.out.println(&quot;当前行的rowkey为：&quot; + id);</span></span><br><span class="line"><span class="comment">//                //继续增强for循环得到每一行中的每一个单元格（列）</span></span><br><span class="line"><span class="comment">//                //获取一行中的所有单元格</span></span><br><span class="line"><span class="comment">//                for (Cell cell : rs.listCells()) &#123;</span></span><br><span class="line"><span class="comment">//                    //获取该单元格属于的列簇</span></span><br><span class="line"><span class="comment">//                    String family = Bytes.toString(CellUtil.cloneFamily(cell));</span></span><br><span class="line"><span class="comment">//                    //获取该单元格的列名</span></span><br><span class="line"><span class="comment">//                    String colName = Bytes.toString(CellUtil.cloneQualifier(cell));</span></span><br><span class="line"><span class="comment">//                    //获取该单元格的列值</span></span><br><span class="line"><span class="comment">//                    String value = Bytes.toString(CellUtil.cloneValue(cell));</span></span><br><span class="line"><span class="comment">//                    System.out.println(family + &quot;:&quot; + colName + &quot;的值为：&quot; + value);</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"></span><br><span class="line">            print(scanner);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出文科的学生，只会返回以文科开头的数据列，其他列的数据不符合条件，不会返回</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *      列值过滤器案例2：&gt; 过滤出文科的学生，只会返回以文科开头的数据列，其他列的数据不符合条件，不会返回</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">ValueFilter12</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建正则比较器</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列值过滤器</span></span><br><span class="line">        <span class="type">ValueFilter</span> <span class="variable">valueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareFilter.CompareOp.EQUAL, regexStringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(valueFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="专用过滤器"><a href="#专用过滤器" class="headerlink" title="专用过滤器"></a>专用过滤器</h4><h6 id="单列值过滤器：SingleColumnValueFilter"><a href="#单列值过滤器：SingleColumnValueFilter" class="headerlink" title="单列值过滤器：SingleColumnValueFilter"></a>单列值过滤器：SingleColumnValueFilter</h6><blockquote><p>SingleColumnValueFilter会返回满足条件的cell所在行的所有cell的值（即会返回一行数据）</p><p>通过SingleColumnValueFilter与查询文科班所有学生信息</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 单列值过滤器</span></span><br><span class="line"><span class="comment">     * SingleColumnValueFilter会返回满足条件的cell所在行的所有cell的值（即会返回一行数据）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 通过SingleColumnValueFilter与查询文科班所有学生信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">SingleColumnValueFilter</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建一个正则比较器</span></span><br><span class="line">            <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建单列值过滤器对象</span></span><br><span class="line">            <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(</span><br><span class="line">                    <span class="string">&quot;info&quot;</span>.getBytes(),</span><br><span class="line">                    <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                    CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                    regexStringComparator</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(singleColumnValueFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 专门用来打印数据的方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(ResultScanner scanner)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">            List&lt;Cell&gt; cells = rs.listCells();</span><br><span class="line">            System.out.print(<span class="string">&quot;id:&quot;</span> + id);</span><br><span class="line">            System.out.print(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line"><span class="comment">//                String s = Bytes.toString(cell.getValue());</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">col</span> <span class="operator">=</span> Bytes.toString(CellUtil.cloneQualifier(cell));</span><br><span class="line">                <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> Bytes.toString(CellUtil.cloneValue(cell));</span><br><span class="line">                System.out.print(col + <span class="string">&quot;:&quot;</span> + s);</span><br><span class="line">                System.out.print(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println();</span><br><span class="line"></span><br><span class="line"><span class="comment">//            String name = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;name&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String age = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;age&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String gender = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;gender&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String clazz = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;clazz&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            System.out.println(&quot;学号：&quot; + id + &quot;,姓名：&quot; + name + &quot;,年龄：&quot; + age + &quot;,性别：&quot; + gender + &quot;,班级：&quot; + clazz);</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="列值排除过滤器：SingleColumnValueExcludeFilter"><a href="#列值排除过滤器：SingleColumnValueExcludeFilter" class="headerlink" title="列值排除过滤器：SingleColumnValueExcludeFilter"></a>列值排除过滤器：SingleColumnValueExcludeFilter</h6><blockquote><p>与SingleColumnValueFilter相反，会排除掉指定的列，其他的列全部返回</p><p>通过SingleColumnValueExcludeFilter与BinaryComparator查询文科一班所有学生信息，最终不返回clazz列</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列值排除过滤器</span></span><br><span class="line"><span class="comment"> * 与SingleColumnValueFilter相反，会排除掉指定的列，其他的列全部返回</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 通过SingleColumnValueExcludeFilter与BinaryComparator查询文科一班所有学生信息，最终不返回clazz列</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">SingleColumnValueExcludeFilter</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个二进制比较器</span></span><br><span class="line">        <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;文科一班&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个列值排除过滤器</span></span><br><span class="line">        <span class="type">SingleColumnValueExcludeFilter</span> <span class="variable">singleColumnValueExcludeFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueExcludeFilter</span>(</span><br><span class="line">                <span class="string">&quot;info&quot;</span>.getBytes(),</span><br><span class="line">                <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                binaryComparator</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(singleColumnValueExcludeFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="rowkey前缀过滤器：PrefixFilter"><a href="#rowkey前缀过滤器：PrefixFilter" class="headerlink" title="rowkey前缀过滤器：PrefixFilter"></a>rowkey前缀过滤器：PrefixFilter</h6><blockquote><p>通过PrefixFilter查询以150010008开头的所有前缀的rowkey</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * rowkey前缀过滤器</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 通过PrefixFilter查询以150010008开头的所有前缀的rowkey</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">PrefixFilter</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建rowkey前缀过滤器</span></span><br><span class="line">        <span class="type">PrefixFilter</span> <span class="variable">prefixFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrefixFilter</span>(<span class="string">&quot;150010008&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        scan.setFilter(prefixFilter);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="分页过滤器PageFilter"><a href="#分页过滤器PageFilter" class="headerlink" title="分页过滤器PageFilter"></a>分页过滤器PageFilter</h6><blockquote><p>通过PageFilter查询三页的数据，每页10条</p><p>使用PageFilter分页效率比较低，每次都需要扫描前面的数据，直到扫描到所需要查的数据</p><p>可设计一个合理的rowkey来实现分页需求</p></blockquote><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 注意事项：</span></span><br><span class="line">客户端进行分页查询，需要传递 startRow(起始 RowKey)，知道起始 startRow 后，就可以返回对应的 pageSize 行数据。这里唯一的问题就是，对于第一次查询，显然 startRow 就是表格的第一行数据，但是之后第二次、第三次查询我们并不知道 startRow，只能知道上一次查询的最后一条数据的 RowKey（简单称之为 lastRow）。</span><br><span class="line"></span><br><span class="line">我们不能将 lastRow 作为新一次查询的 startRow 传入，因为 scan 的查询区间是[startRow，endRow) ，即前开后闭区间，这样 startRow 在新的查询也会被返回，这条数据就重复了。</span><br><span class="line"></span><br><span class="line">同时在不使用第三方数据库存储 RowKey 的情况下，我们是无法通过知道 lastRow 的下一个 RowKey 的，因为 RowKey 的设计可能是连续的也有可能是不连续的。</span><br><span class="line"></span><br><span class="line">由于 Hbase 的 RowKey 是按照字典序进行排序的。这种情况下，就可以在 lastRow 后面加上 0 ，作为 startRow 传入，因为按照字典序的规则，某个值加上 0 后的新值，在字典序上一定是这个值的下一个值，对于 HBase 来说下一个 RowKey 在字典序上一定也是等于或者大于这个新值的。</span><br><span class="line"></span><br><span class="line">所以最后传入 lastRow+0，如果等于这个值的 RowKey 存在就从这个值开始 scan,否则从字典序的下一个 RowKey 开始 scan。</span><br><span class="line"></span><br><span class="line">25 个字母以及数字字符，字典排序如下:</span><br><span class="line"></span><br><span class="line">&#x27;0&#x27; &lt; &#x27;1&#x27; &lt; &#x27;2&#x27; &lt; ... &lt; &#x27;9&#x27; &lt; &#x27;a&#x27; &lt; &#x27;b&#x27; &lt; ... &lt; &#x27;z&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是在多台 Regin Services 上执行分页过滤的时候，由于并行执行的过滤器不能共享它们的状态和边界，所以有可能每个过滤器都会在完成扫描前获取了 PageCount 行的结果，这种情况下会返回比分页条数更多的数据，分页过滤器就有失效的可能。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 分页过滤器</span></span><br><span class="line"><span class="comment"> * 通过PageFilter查询三页的数据，每页10条</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">PageFilter</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">        <span class="comment">//定义要查询的页数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">pageNum</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line">        <span class="comment">//定义每页的条数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">pageSize</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一开始的行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">current_page_start_row</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= pageNum; i++) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;====================当前是第&quot;</span> + i + <span class="string">&quot;页===========================&quot;</span>);</span><br><span class="line">            <span class="comment">//创建一个分页过滤器</span></span><br><span class="line">            <span class="type">PageFilter</span> <span class="variable">pageFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PageFilter</span>(pageSize);</span><br><span class="line">            scan.setFilter(pageFilter);</span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            <span class="keyword">for</span> (Result rs : scanner) &#123;</span><br><span class="line">                current_page_start_row = Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="comment">//告诉扫描器是从哪一行开始获取数据</span></span><br><span class="line">                scan.withStartRow((current_page_start_row + <span class="number">0</span>).getBytes());</span><br><span class="line">                <span class="type">PageFilter</span> <span class="variable">pageFilter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PageFilter</span>(pageSize);</span><br><span class="line">                scan.setFilter(pageFilter1);</span><br><span class="line">                <span class="comment">//获取id</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;,姓名：&quot;</span> + name + <span class="string">&quot;,年龄：&quot;</span> + age + <span class="string">&quot;,性别：&quot;</span> + gender + <span class="string">&quot;,班级：&quot;</span> + clazz);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="包装过滤器"><a href="#包装过滤器" class="headerlink" title="包装过滤器"></a>包装过滤器</h4><h6 id="SkipFilter过滤器"><a href="#SkipFilter过滤器" class="headerlink" title="SkipFilter过滤器"></a>SkipFilter过滤器</h6><blockquote><p>SkipFilter包装一个过滤器，当被包装的过滤器遇到一个需要过滤的 KeyValue 实例时，则拓展过滤整行数据。下面是一个使用示例：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义 ValueFilter 过滤器</span></span><br><span class="line"><span class="type">Filter</span> <span class="variable">filter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareOperator.NOT_EQUAL,</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(Bytes.toBytes(<span class="string">&quot;xxx&quot;</span>)));</span><br><span class="line"><span class="comment">// 使用 SkipFilter 进行包装</span></span><br><span class="line"><span class="type">Filter</span> <span class="variable">filter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SkipFilter</span>(filter1);</span><br></pre></td></tr></table></figure><h6 id="WhileMatchFilter过滤器"><a href="#WhileMatchFilter过滤器" class="headerlink" title="WhileMatchFilter过滤器"></a>WhileMatchFilter过滤器</h6><blockquote><p>WhileMatchFilter 包装一个过滤器，当被包装的过滤器遇到一个需要过滤的 KeyValue 实例时，WhileMatchFilter 则结束本次扫描，返回已经扫描到的结果。下面是其使用示例：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">baoZhuang1</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Filter</span> <span class="variable">filter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.NOT_EQUAL,<span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;1500100009&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//不做包装</span></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(filter1);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner1</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> scanner1.next();</span><br><span class="line">        <span class="keyword">while</span> (rs != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">            System.out.println(id + <span class="string">&quot;\t&quot;</span> + name + <span class="string">&quot;\t&quot;</span> + age + <span class="string">&quot;\t&quot;</span> + gender + <span class="string">&quot;\t&quot;</span> + clazz + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            rs = scanner1.next();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;--------------------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用 WhileMatchFilter 进行包装</span></span><br><span class="line">        <span class="type">Filter</span> <span class="variable">filter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WhileMatchFilter</span>(filter1);</span><br><span class="line">        scan.setFilter(filter2);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs2</span> <span class="operator">=</span> scanner.next();</span><br><span class="line">        <span class="keyword">while</span> (rs2 != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs2.getRow());</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">            System.out.println(id + <span class="string">&quot;\t&quot;</span> + name + <span class="string">&quot;\t&quot;</span> + age + <span class="string">&quot;\t&quot;</span> + gender + <span class="string">&quot;\t&quot;</span> + clazz + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            rs2 = scanner.next();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="多过滤器综合查询"><a href="#多过滤器综合查询" class="headerlink" title="多过滤器综合查询"></a>多过滤器综合查询</h4><p>以上都是讲解单个过滤器的作用，当需要多个过滤器共同作用于一次查询的时候，就需要使用 <code>FilterList</code>。<code>FilterList</code> 支持通过构造器或者 <code>addFilter</code> 方法传入多个过滤器。</p><blockquote><p>通过运用4种比较器过滤出姓于，年纪大于23岁，性别为女，且是理科的学生。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需求：1 通过运用4种比较器过滤出姓于，年纪大于23岁，性别为女，且是理科的学生。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 正则比较器   RegexStringComparator</span></span><br><span class="line"><span class="comment"> * 包含比较器   SubstringComparator</span></span><br><span class="line"><span class="comment"> * 二进制前缀比较器   BinaryPrefixComparator</span></span><br><span class="line"><span class="comment"> * 二进制比较器      BinaryComparator</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FilterData1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *  第一个过滤器，过滤出是理科开头的班级</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^理科.*&quot;</span>);</span><br><span class="line">        <span class="comment">//单列值过滤器</span></span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, regexStringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第二个过滤器，过滤出性别是女生的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;女&quot;</span>);</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第三个过滤器，过滤出年龄大于23岁的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;20&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.GREATER, binaryComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第四个过滤器，过滤出姓于的学生</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;于&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//要想实现多个需求同时过滤，就需要创建多个过滤器，添加到一个过滤器列表中</span></span><br><span class="line">        <span class="comment">//然后将过滤器列表传给扫描器scan</span></span><br><span class="line">        <span class="type">FilterList</span> <span class="variable">filterList</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FilterList</span>();</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter1);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter2);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter3);</span><br><span class="line"></span><br><span class="line">        scan.setFilter(filterList);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line"></span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出学号是以15001001开头的文科学生</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 过滤出学号是以15001001开头的文科学生</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">filterData2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *  创建第一个过滤器，过滤是以15001001开头的rowkey</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;15001001&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//创建行键过滤器</span></span><br><span class="line">        <span class="type">RowFilter</span> <span class="variable">rowFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 创建第二个过滤器，过滤出文科的学生</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                regexStringComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">FilterList</span> <span class="variable">filterList</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FilterList</span>();</span><br><span class="line">        filterList.addFilter(rowFilter);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(filterList);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>作业：查询文科一班学生总分排名前10的学生（输出：学号，姓名，班级，总分）结果写到hbase</p></blockquote><h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><blockquote><p>本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉你 “<strong>某样东西一定不存在或者可能存在</strong>”。</p><p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。</p><p>实际上，布隆过滤器广泛应用于<strong>网页黑名单系统</strong>、<strong>垃圾邮件过滤系统</strong>、<strong>爬虫网址判重系统</strong>等，Google 著名的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的 IO 次数，Google Chrome 浏览器使用了布隆过滤器加速安全浏览服务。</p><p>在很多 Key-Value 系统中也使用了布隆过滤器来加快查询过程，如 Hbase，Accumulo，Leveldb，一般而言，Value 保存在磁盘中，访问磁盘需要花费大量时间，然而使用布隆过滤器可以快速判断某个 Key 对应的 Value 是否存在，因此可以避免很多不必要的磁盘 IO 操作。</p><p>通过一个 Hash 函数将一个元素映射成一个位阵列（Bit Array）中的一个点。这样一来，我们只要看看这个点是不是 1 就知道可以集合中有没有它了。这就是布隆过滤器的基本思想。</p></blockquote><h5 id="运用场景"><a href="#运用场景" class="headerlink" title="运用场景"></a>运用场景</h5><blockquote><p>1、目前有 10 亿数量的自然数，乱序排列，需要对其排序。限制条件在 32 位机器上面完成，内存限制为 2G。如何完成？</p><p>2、如何快速在亿级黑名单中快速定位 URL 地址是否在黑名单中？(每条 URL 平均 64 字节)</p><p>3、需要进行用户登陆行为分析，来确定用户的活跃情况？</p><p>4、网络爬虫-如何判断 URL 是否被爬过？</p><p>5、快速定位用户属性（黑名单、白名单等）？</p><p>6、数据存储在磁盘中，如何避免大量的无效 IO？</p><p>7、判断一个元素在亿级数据中是否存在？</p><p>8、缓存穿透。</p></blockquote><h5 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h5><blockquote><p>假设我们有个集合 A，A 中有 n 个元素。利用<strong>k个哈希散列</strong>函数，将A中的每个元素<strong>映射</strong>到一个长度为 a 位的数组 B中的不同位置上，这些位置上的二进制数均设置为 1。如果待检查的元素，经过这 k个哈希散列函数的映射后，发现其 k 个位置上的二进制数<strong>全部为 1</strong>，这个元素很可能属于集合A，反之，<strong>一定不属于集合A</strong>。</p><p>比如我们有 3 个 URL <code>&#123;URL1,URL2,URL3&#125;</code>，通过一个hash 函数把它们映射到一个长度为 16 的数组上，如下：</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/qAcJ4GLkDvZgjzt.png" alt="image-20220612214242813"></p><p>若当前哈希函数为 <code>Hash1()</code>，通过哈希运算映射到数组中，假设<code>Hash1(URL1) = 3</code>，<code>Hash1(URL2) = 6</code>，<code>Hash1(URL3) = 6</code>，如下：</p><p><img src="https://s2.loli.net/2022/06/12/NAO6aL8KT2isjZG.png" alt="image-20220612214254594"></p><blockquote><p>因此，如果我们需要判断<code>URL1</code>是否在这个集合中，则通过<code>Hash(urL1)</code>计算出其下标，并得到其值若为 1 则说明存在。</p><p>由于 Hash 存在哈希冲突，如上面<code>URL2,URL3</code>都定位到一个位置上，假设 Hash 函数是良好的，如果我们的数组长度为 m 个点，那么如果我们想将冲突率降低到例如 <strong>1%<strong>， 这个散列表就只能容纳 <code>m/100</code> 个元素，显然空间利用率就变低了，也就是没法做到</strong>空间有效</strong>（space-efficient）。</p><p>解决方法也简单，就是使用多个 Hash 算法，如果它们有一个说元素不在集合中，那肯定就不在，如下：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hash1(URL1) = 3,Hash2(URL1) = 5,Hash3(URL1) = 6</span><br><span class="line">Hash1(URL2) = 5,Hash2(URL2) = 8,Hash3(URL2) = 14</span><br><span class="line">Hash1(URL3) = 4,Hash2(URL3) = 7,Hash3(URL3) = 10</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/2y6qDXUfvg5Ic8k.png" alt="image-20220612214308660"></p><blockquote><p>以上就是布隆过滤器做法，使用了<strong>k个哈希函数</strong>，每个字符串跟 k 个 bit 对应，从而降低了冲突的概率。</p></blockquote><h5 id="误判现象"><a href="#误判现象" class="headerlink" title="误判现象"></a>误判现象</h5><blockquote><p>上面的做法同样存在问题，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断这个值存在。比如此时来一个不存在的 <code>URL1000</code>，经过哈希计算后，发现 bit 位为下：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hash1(URL1000) = 7,Hash2(URL1000) = 8,Hash3(URL1000) = 14</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/vkUtQ6bqMLwFj7c.png" alt="image-20220612214320802"></p><blockquote><p>但是上面这些 bit 位已经被<code>URL1,URL2,URL3</code>置为 1 了，此时程序就会判断 <code>URL1000</code> 值存在。</p><p>这就是布隆过滤器的误判现象，所以，<strong>布隆过滤器判断存在的不一定存在，但是，判断不存在的一定不存在。</strong></p><p>布隆过滤器可精确的代表一个集合，可精确判断某一元素是否在此集合中，精确程度由用户的具体设计决定，达到 100% 的正确是不可能的。但是布隆过滤器的优势在于，<strong>利用很少的空间可以达到较高的精确率</strong>。</p></blockquote><h5 id="控制粒度"><a href="#控制粒度" class="headerlink" title="控制粒度"></a>控制粒度</h5><blockquote><p><strong>a）ROW</strong><br>    根据KeyValue中的行来过滤storefile<br>    举例：假设有2个storefile文件sf1和sf2，<br>        sf1包含kv1（r1 cf：q1 v），kv2（r2 cf：q1 v）<br>        sf2包含kv3（r3 cf：q1 v），kv4（r4 cf：q1 v）<br>        若是设置了CF属性中的bloomfilter为ROW，那么得（r1）时就会过滤sf2，get（r3）就会过滤sf1<br><strong>b）ROWCOL</strong><br>    根据KeyValue中的行+限定符来过滤storefile<br>    举例：假设有2个storefile文件sf1和sf2，<br>        sf1包含kv1（r1 cf：q1 v），kv2（r2 cf：q1 v）<br>        sf2包含kv3（r1 cf：q2 v），kv4（r2 cf：q2 v）<br>        若是设置了CF属性中的布隆过滤器为ROW，不管获得（R1，Q1）仍是获得（R1，Q2），都会读取SF1 + SF2;而若是设置了CF属性中的布隆过滤器为        ROWCOL，那么GET（R1， q1）就会过滤sf2，get（r1，q2）就会过滤sf1<br><strong>c）NO</strong><br>    默认的值，默认不开启布隆过滤器</p></blockquote><h5 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h5><blockquote><p>在建立表时加入一个参数就能够了</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">//使用HTableDescriptor类创建一个表对象</span></span><br><span class="line">          <span class="type">HTableDescriptor</span> <span class="variable">students</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HTableDescriptor</span>(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">          <span class="comment">//在创建表的时候，至少指定一个列簇</span></span><br><span class="line">          <span class="type">HColumnDescriptor</span> <span class="variable">info</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HColumnDescriptor</span>(<span class="string">&quot;info&quot;</span>);</span><br><span class="line">          info.setBloomFilterType(BloomType.ROW); <span class="comment">//&lt;===========================================</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//将列簇添加到表中</span></span><br><span class="line">          students.addFamily(info);</span><br><span class="line">          <span class="comment">//真正的执行，是由HMaster</span></span><br><span class="line">          <span class="comment">//hAdmin</span></span><br><span class="line">          hAdmin.createTable(students);</span><br><span class="line">          System.out.println(Bytes.toString(students.getName()) + <span class="string">&quot;表 创建成功。。。&quot;</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          e.printStackTrace();</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Hbase过滤器的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase shell1</title>
    <link href="http://example.com/2022/06/10/Hbase%20Shell%201/"/>
    <id>http://example.com/2022/06/10/Hbase%20Shell%201/</id>
    <published>2022-06-09T16:00:00.000Z</published>
    <updated>2022-06-15T07:37:45.180Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Hbase-Shell-1"><a href="#一、Hbase-Shell-1" class="headerlink" title="一、Hbase Shell 1"></a>一、Hbase Shell 1</h2><table><thead><tr><th>命名</th><th>描述</th><th>语法</th></tr></thead><tbody><tr><td>help ‘命名名’</td><td>查看命令的使用描述</td><td>help ‘命令名’</td></tr><tr><td>whoami</td><td>我是谁</td><td>whoami</td></tr><tr><td>version</td><td>返回hbase版本信息</td><td>version</td></tr><tr><td>status</td><td>返回hbase集群的状态信息</td><td>status</td></tr><tr><td>table_help</td><td>查看如何操作表</td><td>table_help</td></tr><tr><td><strong>create</strong></td><td>创建表</td><td>create ‘表名’, ‘列族名1’, ‘列族名2’, ‘列族名N’</td></tr><tr><td><strong>alter</strong></td><td>修改列族</td><td>添加一个列族：alter ‘表名’, ‘列族名’ <br />删除列族：alter ‘表名’, {NAME&#x3D;&gt; ‘列族名’, METHOD&#x3D;&gt; ‘delete’}</td></tr><tr><td>describe</td><td>显示表相关的详细信息</td><td>describe ‘表名’</td></tr><tr><td><strong>list</strong></td><td>列出hbase中存在的所有表</td><td>list</td></tr><tr><td>exists</td><td>测试表是否存在</td><td>exists ‘表名’</td></tr><tr><td><strong>put</strong></td><td>添加或修改的表的值</td><td>put ‘表名’, ‘行键’, ‘列族名’, ‘列值’ <br />put ‘表名’, ‘行键’, ‘列族名:列名’, ‘列值’</td></tr><tr><td><strong>scan</strong></td><td>通过对表的扫描来获取对用的值</td><td>scan ‘表名’<br/>扫描某个列族： scan ‘表名’, {COLUMN&#x3D;&gt;‘列族名’}<br/>扫描某个列族的某个列： scan ‘表名’, {COLUMN&#x3D;&gt;‘列族名:列名’}<br/>查询同一个列族的多个列： scan ‘表名’, {COLUMNS &#x3D;&gt; [ ‘列族名1:列名1’, ‘列族名1:列名2’, …]}</td></tr><tr><td><strong>get</strong></td><td>获取行或单元（cell）的值</td><td>get ‘表名’, ‘行键’ <br />get ‘表名’, ‘行键’, ‘列族名’</td></tr><tr><td>count</td><td>统计表中行的数量</td><td>count ‘表名’</td></tr><tr><td>incr</td><td>增加指定表行或列的值</td><td>incr ‘表名’, ‘行键’, ‘列族:列名’, 步长值</td></tr><tr><td>get_counter</td><td>获取计数器</td><td>get_counter ‘表名’, ‘行键’, ‘列族:列名’</td></tr><tr><td><strong>delete</strong></td><td>删除指定对象的值（可以为表，行，列对应的值，另外也可以指定时间戳的值）</td><td>删除列族的某个列： delete ‘表名’, ‘行键’, ‘列族名:列名’</td></tr><tr><td>deleteall</td><td>删除指定行的所有元素值</td><td>deleteall ‘表名’, ‘行键’</td></tr><tr><td><strong>truncate</strong></td><td>重新创建指定表</td><td>truncate ‘表名’</td></tr><tr><td><strong>enable</strong></td><td>使表有效</td><td>enable ‘表名’</td></tr><tr><td>is_enabled</td><td>是否启用</td><td>is_enabled ‘表名’</td></tr><tr><td><strong>disable</strong></td><td>使表无效</td><td>disable ‘表名’</td></tr><tr><td><strong>is_disabled</strong></td><td>是否无效</td><td>is_disabled ‘表名’</td></tr><tr><td><strong>drop</strong></td><td>删除表</td><td>drop的表必须是disable的 <br />disable ‘表名’ <br />drop ‘表名’</td></tr><tr><td>shutdown</td><td>关闭hbase集群（与exit不同）</td><td></td></tr><tr><td>tools</td><td>列出hbase所支持的工具</td><td></td></tr><tr><td><strong>exit</strong></td><td>退出hbase shell</td><td></td></tr></tbody></table><p>HBase Shell 是官方提供的一组命令，用于操作HBase。如果配置了HBase的<strong>环境变量</strong>了，就可以知己在命令行中输入hbase shell 命令进入命令行。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/SXT6AIdLqjEc7CV.png" alt="image-20220608225844374"></p><h3 id="help命令"><a href="#help命令" class="headerlink" title="help命令"></a>help命令</h3><blockquote><p>可以通过 <code>help &#39;命名名称&#39;</code>来查看<strong>命令行</strong>的具体使用，包括命令的作用和用法。<br>通过help ‘hbase’ 命名来查看hbase shell 支持的所有命令，hbase将命令进行分组，其中ddl、dml使用较多。</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/hOgVHLT9FPvBnf6.png" alt="image-20220608230009607"></p><h3 id="1-2-general-类"><a href="#1-2-general-类" class="headerlink" title="1.2    general 类"></a>1.2    general 类</h3><h4 id="1-2-1-显示集群状态status"><a href="#1-2-1-显示集群状态status" class="headerlink" title="1.2.1    显示集群状态status"></a>1.2.1    显示集群状态status</h4><p><img src="https://s2.loli.net/2022/06/12/dCGBNJEuMOrcHI8.png" alt="image-20220612211516897"></p><h4 id="1-2-2-查询数据库版本version"><a href="#1-2-2-查询数据库版本version" class="headerlink" title="1.2.2     查询数据库版本version"></a>1.2.2     查询数据库版本version</h4><p><img src="https://s2.loli.net/2022/06/12/Tgupqb7tkDCvf5J.png" alt="image-20220612211524520"></p><h4 id="1-2-3-显示当前用户与组-whoami"><a href="#1-2-3-显示当前用户与组-whoami" class="headerlink" title="1.2.3    显示当前用户与组 whoami"></a>1.2.3    显示当前用户与组 whoami</h4><p><img src="https://s2.loli.net/2022/06/12/hBgJPd16uKf98Ck.png" alt="image-20220612211550680"></p><h4 id="1-2-4-查看操作表的命令table-help"><a href="#1-2-4-查看操作表的命令table-help" class="headerlink" title="1.2.4    查看操作表的命令table_help"></a>1.2.4    查看操作表的命令table_help</h4><p><img src="https://s2.loli.net/2022/06/12/zDu9nGlk46CLEs8.png" alt="image-20220612211739667"></p><h4 id="1-2-5-退出HBase-Shell-exit"><a href="#1-2-5-退出HBase-Shell-exit" class="headerlink" title="1.2.5    退出HBase Shell exit"></a>1.2.5    退出HBase Shell exit</h4><p><img src="https://s2.loli.net/2022/06/12/DcuwQTr8WmKxkIO.png" alt="image-20220612211758289"></p><h3 id="1-3-DDL相关"><a href="#1-3-DDL相关" class="headerlink" title="1.3    DDL相关"></a>1.3    DDL相关</h3><h4 id="1-3-1-创建表create"><a href="#1-3-1-创建表create" class="headerlink" title="1.3.1. 创建表create"></a>1.3.1. 创建表create</h4><blockquote><p>注意：创建表时只需要指定列族名称，不需要指定列名。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名1&#x27;</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名2&#x27;</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名3&#x27;</span>&#125;</span><br><span class="line"># 此种方式是上上面的简写方式，使用上面方式可以为列族指定更多的属性，如VERSIONS、TTL、BLOCKCACHE、CONFIGURATION等属性</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;列族名1&#x27;</span>, <span class="string">&#x27;列族名2&#x27;</span>, <span class="string">&#x27;列族名3&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> 版本号, TTL <span class="operator">=</span><span class="operator">&gt;</span> 过期时间, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_user&#x27;</span>, <span class="string">&#x27;info&#x27;</span>, <span class="string">&#x27;detail&#x27;</span></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;t1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1</span>, TTL <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2592000</span>, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/wUgQbz1Lpu6MKao.png" alt="image-20220612211844485"></p><h4 id="1-3-2-修改-添加、删除-表结构Schema-alter"><a href="#1-3-2-修改-添加、删除-表结构Schema-alter" class="headerlink" title="1.3.2    修改(添加、删除)表结构Schema alter"></a>1.3.2    修改(添加、删除)表结构Schema alter</h4><h5 id="1-3-2-1-添加一个列簇"><a href="#1-3-2-1-添加一个列簇" class="headerlink" title="1.3.2.1    添加一个列簇"></a>1.3.2.1    添加一个列簇</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_user&#x27;</span>, <span class="string">&#x27;address&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/sp2T48CcUBNaH6x.png" alt="image-20220612211857310"></p><h5 id="1-3-2-2-删除一个列簇"><a href="#1-3-2-2-删除一个列簇" class="headerlink" title="1.3.2.2    删除一个列簇"></a>1.3.2.2    删除一个列簇</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME<span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名&#x27;</span>, <span class="keyword">METHOD</span><span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;delete&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_user&#x27;</span>, &#123;NAME<span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;address&#x27;</span>, <span class="keyword">METHOD</span><span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;delete&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/GVo9jqBUNhpvgnm.png" alt="image-20220612211912064"></p><h5 id="1-3-2-3-修改列族的属性"><a href="#1-3-2-3-修改列族的属性" class="headerlink" title="1.3.2.3    修改列族的属性"></a>1.3.2.3    修改列族的属性</h5><blockquote><p>可以修改列族的VERSIONS、IN_MEMORY</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 修改f1列族的版本为<span class="number">5</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line"># 修改多个列族，修改f2为内存，版本号为<span class="number">5</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f2&#x27;</span>, IN_MEMORY <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f3&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line"># 也可以修改<span class="keyword">table</span><span class="operator">-</span><span class="keyword">scope</span>属性，例如MAX_FILESIZE, READONLY,MEMSTORE_FLUSHSIZE, DEFERRED_LOG_FLUSH等。</span><br><span class="line"># 例如，修改region的最大大小为<span class="number">128</span>MB：</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, MAX_FILESIZE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;134217728&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-3-获取表的描述describe"><a href="#1-3-3-获取表的描述describe" class="headerlink" title="1.3.3    获取表的描述describe"></a>1.3.3    获取表的描述describe</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/KeTgHt3YSZy8Aox.png" alt="image-20220612211927537"></p><h4 id="1-3-4-列举所有表list"><a href="#1-3-4-列举所有表list" class="headerlink" title="1.3.4    列举所有表list"></a>1.3.4    列举所有表list</h4><p><img src="https://s2.loli.net/2022/06/12/X4H17ytvEKNBbSp.png" alt="image-20220612211939477"></p><h4 id="1-3-5-表是否存在exists"><a href="#1-3-5-表是否存在exists" class="headerlink" title="1.3.5    表是否存在exists"></a>1.3.5    表是否存在exists</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">exists</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">exists</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/HcSG3VxYrj7mfno.png" alt="image-20220612211957306"></p><h4 id="1-3-6-启用表enable和禁用表disable"><a href="#1-3-6-启用表enable和禁用表disable" class="headerlink" title="1.3.6    启用表enable和禁用表disable"></a>1.3.6    启用表enable和禁用表disable</h4><blockquote><p>通过enable和disable来启用&#x2F;禁用这个表,相应的可以通过is_enabled和is_disabled来检查表是否被禁用。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">enable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">is_enabled <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line">disable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">is_disabled <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">disable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line">is_disabled <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line"></span><br><span class="line">enable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line">is_enabled <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-7-禁用满足正则表达式的所有表disable-all"><a href="#1-3-7-禁用满足正则表达式的所有表disable-all" class="headerlink" title="1.3.7    禁用满足正则表达式的所有表disable_all"></a>1.3.7    禁用满足正则表达式的所有表disable_all</h4><ul><li><code>.</code>匹配除“\n”和”\r”之外的任何单个字符</li><li><code>*</code>匹配前面的子表达式任意次</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 匹配以t开头的表名</span><br><span class="line">disable_all <span class="string">&#x27;t.*&#x27;</span></span><br><span class="line"># 匹配指定命名空间ns下的以t开头的所有表</span><br><span class="line">disable_all <span class="string">&#x27;ns:t.*&#x27;</span></span><br><span class="line"># 匹配ns命名空间下的所有表</span><br><span class="line">disable_all <span class="string">&#x27;ns:.*&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-8-启用满足正则表达式的所有表enable-all"><a href="#1-3-8-启用满足正则表达式的所有表enable-all" class="headerlink" title="1.3.8    启用满足正则表达式的所有表enable_all"></a>1.3.8    启用满足正则表达式的所有表enable_all</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">enable_all &#x27;t.*&#x27;</span><br><span class="line">enable_all &#x27;ns:t.*&#x27;</span><br><span class="line">enable_all &#x27;ns:.*&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-9-删除表drop"><a href="#1-3-9-删除表drop" class="headerlink" title="1.3.9    删除表drop"></a>1.3.9    删除表drop</h4><blockquote><p>需要先禁用表，然后再删除表，启用的表是不允许删除的</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">disable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">disable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>直接删除报错：</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/Ki8HoPqw1UCjSsX.png" alt="image-20220612212011296"></p><p>先禁用后删除</p><p><img src="https://s2.loli.net/2022/06/12/VP5UMTDBEg9LNop.png" alt="image-20220612212023082"></p><h4 id="1-3-10-删除满足正则表达式的所有表drop-all"><a href="#1-3-10-删除满足正则表达式的所有表drop-all" class="headerlink" title="1.3.10    删除满足正则表达式的所有表drop_all"></a>1.3.10    删除满足正则表达式的所有表drop_all</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drop_all &#x27;t.*&#x27;</span><br><span class="line">drop_all &#x27;ns:t.*&#x27;</span><br><span class="line">drop_all &#x27;ns:.*&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-11-获取某个表赋值给一个变量-get-table"><a href="#1-3-11-获取某个表赋值给一个变量-get-table" class="headerlink" title="1.3.11    获取某个表赋值给一个变量 get_table"></a>1.3.11    获取某个表赋值给一个变量 get_table</h4><blockquote><p>通过 var &#x3D; get_table ‘表名’ 赋值给一个变量对象，然后对象.来调用，就像面向对象编程一样，通过对象.方法来调用，这种方式在操作某个表时就不必每次列举表名了。</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/YhZ5EpCQijf2d1k.png" alt="image-20220612212036726"></p><h4 id="1-3-12-获取rowKey所在的区-locate-region"><a href="#1-3-12-获取rowKey所在的区-locate-region" class="headerlink" title="1.3.12    获取rowKey所在的区 locate_region"></a>1.3.12    获取rowKey所在的区 locate_region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate_region &#x27;表名&#x27;, &#x27;行键&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-13-显示hbase所支持的所有过滤器show-filters"><a href="#1-3-13-显示hbase所支持的所有过滤器show-filters" class="headerlink" title="1.3.13    显示hbase所支持的所有过滤器show_filters"></a>1.3.13    显示hbase所支持的所有过滤器show_filters</h4><blockquote><p>过滤器用于get和scan命令中作为筛选数据的条件，类型关系型数据库中的where的作用</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/dkL1wJREzvXOjxQ.png" alt="image-20220612212116009"></p><h3 id="1-4-namespace"><a href="#1-4-namespace" class="headerlink" title="1.4    namespace"></a>1.4    namespace</h3><blockquote><p><strong>hbase中没有数据库的概念 , 可以使用namespace来达到数据库分类别管理表的作用</strong></p></blockquote><h4 id="1-4-1-列举命名空间-list-namespace"><a href="#1-4-1-列举命名空间-list-namespace" class="headerlink" title="1.4.1    列举命名空间 list_namespace"></a>1.4.1    列举命名空间 list_namespace</h4><p><img src="https://s2.loli.net/2022/06/12/ndvMyJafYNrStip.png" alt="image-20220612212131363"></p><h4 id="1-4-2-获取命名空间描述-describe-namespace"><a href="#1-4-2-获取命名空间描述-describe-namespace" class="headerlink" title="1.4.2    获取命名空间描述 describe_namespace"></a>1.4.2    获取命名空间描述 describe_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">describe_namespace <span class="string">&#x27;default&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/fCoW9JQNq4YEgDG.png" alt="image-20220612212142303"></p><h4 id="1-4-3-查看命名空间下的所有表-list-namespace-tables"><a href="#1-4-3-查看命名空间下的所有表-list-namespace-tables" class="headerlink" title="1.4.3    查看命名空间下的所有表 list_namespace_tables"></a>1.4.3    查看命名空间下的所有表 list_namespace_tables</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">list_namespace_tables <span class="string">&#x27;default&#x27;</span></span><br><span class="line"></span><br><span class="line">list_namespace_tables <span class="string">&#x27;hbase&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/78yuhSa3n4HRfEU.png" alt="image-20220612212155514"></p><h4 id="1-4-4-创建命名空间create-namespace"><a href="#1-4-4-创建命名空间create-namespace" class="headerlink" title="1.4.4    创建命名空间create_namespace"></a>1.4.4    创建命名空间create_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">create_namespace <span class="string">&#x27;bigdata17&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-4-5-删除命名空间drop-namespace"><a href="#1-4-5-删除命名空间drop-namespace" class="headerlink" title="1.4.5    删除命名空间drop_namespace"></a>1.4.5    删除命名空间drop_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">drop_namespace <span class="string">&#x27;命名空间名称&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-5-DML"><a href="#1-5-DML" class="headerlink" title="1.5    DML"></a>1.5    DML</h3><h4 id="1-5-1-插入或者修改数据put"><a href="#1-5-1-插入或者修改数据put" class="headerlink" title="1.5.1    插入或者修改数据put"></a>1.5.1    插入或者修改数据put</h4><p><img src="https://s2.loli.net/2022/06/12/ItKsyROVx8p3DBg.png" alt="image-20220612212213476"></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"># 当列族中只有一个列时<span class="string">&#x27;列族名:列名&#x27;</span>使用<span class="string">&#x27;列族名&#x27;</span></span><br><span class="line">put <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span>, <span class="string">&#x27;列值&#x27;</span></span><br><span class="line">put <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名:列名&#x27;</span>, <span class="string">&#x27;列值&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"></span><br><span class="line"># 创建表</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;info&#x27;</span>, <span class="string">&#x27;detail&#x27;</span>, <span class="string">&#x27;address&#x27;</span></span><br><span class="line"></span><br><span class="line"># 第一行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;张三&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;28&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-26&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;abc@163.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-04 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;上海市&#x27;</span></span><br><span class="line"></span><br><span class="line"># 第二行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;李四&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;27&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-27&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;xxx@gmail.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-05 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;北京市&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 第三行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;3&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;王五&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;26&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-28&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;xyz@qq.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-06 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;杭州市&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-2-全表扫描scan"><a href="#1-5-2-全表扫描scan" class="headerlink" title="1.5.2    全表扫描scan"></a>1.5.2    全表扫描scan</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/MnSmobUu6JAG5Qd.png" alt="image-20220612212319590"></p><blockquote><p>扫描整个列簇</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;列族名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;info&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><blockquote><p>扫描整个列簇的某个列</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;列族名:列名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;info:age&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="1-5-3-获取数据get"><a href="#1-5-3-获取数据get" class="headerlink" title="1.5.3     获取数据get"></a>1.5.3     获取数据get</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>根据某一行某列族的数据</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建表，c1版本为<span class="number">4</span>， 元数据mykey<span class="operator">=</span>myvalue</span><br><span class="line">hbase(main):<span class="number">009</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="string">&#x27;t1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;, METADATA <span class="operator">=</span><span class="operator">&gt;</span> &#123; <span class="string">&#x27;mykey&#x27;</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;myvalue&#x27;</span> &#125;</span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">2.2810</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> Hbase::<span class="keyword">Table</span> <span class="operator">-</span> t1</span><br><span class="line"># 添加列族c2, c3</span><br><span class="line">hbase(main):<span class="number">010</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span></span><br><span class="line">Updating <span class="keyword">all</span> regions <span class="keyword">with</span> the <span class="keyword">new</span> schema...</span><br><span class="line"><span class="number">1</span><span class="operator">/</span><span class="number">1</span> regions updated.</span><br><span class="line">Done.</span><br><span class="line">Updating <span class="keyword">all</span> regions <span class="keyword">with</span> the <span class="keyword">new</span> schema...</span><br><span class="line"><span class="number">1</span><span class="operator">/</span><span class="number">1</span> regions updated.</span><br><span class="line">Done.</span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">3.8320</span> seconds</span><br><span class="line"></span><br><span class="line"># 出入数据，c1 插入<span class="number">4</span>个版本的值</span><br><span class="line">hbase(main):<span class="number">011</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v1&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.1000</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">012</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v11&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">013</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v111&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">014</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v1111&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line"># 插入c2、c3的值</span><br><span class="line">hbase(main):<span class="number">015</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;v2&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">016</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>, <span class="string">&#x27;v3&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0210</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1的一行记录</span><br><span class="line">hbase(main):<span class="number">017</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span></span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"> c3:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819398244</span>, <span class="keyword">value</span><span class="operator">=</span>v3</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0550</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1并且 <span class="number">1552819392398</span> <span class="operator">&lt;=</span> 时间戳范围 <span class="operator">&lt;</span> <span class="number">1552819398244</span></span><br><span class="line">hbase(main):<span class="number">018</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;TIMERANGE <span class="operator">=</span><span class="operator">&gt;</span> [<span class="number">1552819392398</span>, <span class="number">1552819398244</span>]&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0090</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定列的值</span><br><span class="line">hbase(main):<span class="number">019</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0160</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定列的值，多个值使用数组表示</span><br><span class="line">hbase(main):<span class="number">020</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> [<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>]&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"> c3:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819398244</span>, <span class="keyword">value</span><span class="operator">=</span>v3</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0170</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取c1的值，获取<span class="number">4</span>个版本的值，默认是按照时间戳降续排序的</span><br><span class="line">hbase(main):<span class="number">021</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819368993</span>, <span class="keyword">value</span><span class="operator">=</span>v11</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819362975</span>, <span class="keyword">value</span><span class="operator">=</span>v1</span><br><span class="line"><span class="number">4</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取c1的<span class="number">3</span>个版本值</span><br><span class="line">hbase(main):<span class="number">027</span>:<span class="number">0</span><span class="operator">*</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                               CELL</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819368993</span>, <span class="keyword">value</span><span class="operator">=</span>v11</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0090</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定时间戳版本的列</span><br><span class="line">hbase(main):<span class="number">022</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, <span class="type">TIMESTAMP</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1552819376343</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0170</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">023</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, <span class="type">TIMESTAMP</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1552819376343</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0130</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1中的值等于v2的所有列</span><br><span class="line">hbase(main):<span class="number">024</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">FILTER</span> <span class="operator">=</span><span class="operator">&gt;</span> &quot;ValueFilter(=, &#x27;binary:v2&#x27;)&quot;&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0510</span> seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">025</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, ATTRIBUTES <span class="operator">=</span><span class="operator">&gt;</span> &#123;<span class="string">&#x27;mykey&#x27;</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;myvalue&#x27;</span>&#125;&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0100</span> seconds</span><br></pre></td></tr></table></figure><h4 id="1-5-4-删除某个列族中的某个列delete"><a href="#1-5-4-删除某个列族中的某个列delete" class="headerlink" title="1.5.4    删除某个列族中的某个列delete"></a>1.5.4    删除某个列族中的某个列delete</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">语法</span></span><br><span class="line">delete &#x27;表名&#x27;, &#x27;行键&#x27;, &#x27;列族名:列名&#x27;</span><br><span class="line"></span><br><span class="line">delete &#x27;users&#x27;,&#x27;xiaoming&#x27;,&#x27;info:age&#x27;</span><br><span class="line"></span><br><span class="line">create &#x27;tbl_test&#x27;, &#x27;columnFamily1&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column1&#x27;, &#x27;value1&#x27;</span><br><span class="line">put &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column2&#x27;, &#x27;value2&#x27;</span><br><span class="line"></span><br><span class="line">delete &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column1&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-5-5-删除某行数据deleteall"><a href="#1-5-5-删除某行数据deleteall" class="headerlink" title="1.5.5     删除某行数据deleteall"></a>1.5.5     删除某行数据deleteall</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">deleteall <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">deleteall <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-6-清空整个表的数据truncate"><a href="#1-5-6-清空整个表的数据truncate" class="headerlink" title="1.5.6    清空整个表的数据truncate"></a>1.5.6    清空整个表的数据truncate</h4><blockquote><p>先disable表，然后再drop表，最后重新create表</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">truncate &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/vpx594qBNIhoGcU.png" alt="image-20220612212401461"></p><h4 id="1-5-7-自增incr"><a href="#1-5-7-自增incr" class="headerlink" title="1.5.7    自增incr"></a>1.5.7    自增incr</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">incr <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族:列名&#x27;</span>, 步长值</span><br><span class="line"></span><br><span class="line"># 示例 </span><br><span class="line"># 注意：incr 可以对不存的行键操作，如果行键已经存在会报错，如果使用put修改了incr的值再使用incr也会报错</span><br><span class="line"># ERROR: org.apache.hadoop.hbase.DoNotRetryIOException: Field <span class="keyword">is</span> <span class="keyword">not</span> a long, it<span class="string">&#x27;s 2 bytes wide</span></span><br><span class="line"><span class="string">incr &#x27;</span>tbl_user<span class="string">&#x27;, &#x27;</span>xiaohong<span class="string">&#x27;, &#x27;</span>info:age<span class="string">&#x27;, 1</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/lizvE4OsXNP9WjI.png" alt="image-20220612212416654"></p><h4 id="1-5-8-计数器get-counter"><a href="#1-5-8-计数器get-counter" class="headerlink" title="1.5.8    计数器get_counter"></a>1.5.8    计数器get_counter</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 点击量：日、周、月</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;daily&#x27;</span>, <span class="string">&#x27;weekly&#x27;</span>, <span class="string">&#x27;monthly&#x27;</span></span><br><span class="line">incr <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span>, <span class="number">1</span></span><br><span class="line">incr <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span>, <span class="number">1</span></span><br><span class="line">get_counter <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-9-修饰词"><a href="#1-5-9-修饰词" class="headerlink" title="1.5.9    修饰词"></a>1.5.9    修饰词</h4><h5 id="1、修饰词"><a href="#1、修饰词" class="headerlink" title="1、修饰词"></a>1、修饰词</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;列族名1:列名1&#x27;</span>, <span class="string">&#x27;列族名1:列名2&#x27;</span>, ...]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="2、TIMESTAMP-指定时间戳"><a href="#2、TIMESTAMP-指定时间戳" class="headerlink" title="2、TIMESTAMP 指定时间戳"></a>2、TIMESTAMP 指定时间戳</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[timestamp1, timestamp2]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[<span class="number">1551938004321</span>, <span class="number">1551938036450</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="3、VERSIONS"><a href="#3、VERSIONS" class="headerlink" title="3、VERSIONS"></a>3、VERSIONS</h5><blockquote><p>默认情况下一个列只能存储一个数据，后面如果修改数据就会将原来的覆盖掉，可以通过指定VERSIONS时HBase一列能存储多个值。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;columnFamily1&#x27;</span></span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_test&#x27;</span></span><br><span class="line"></span><br><span class="line"># 修改列族版本号</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_test&#x27;</span>, &#123; NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span> &#125;</span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value3&#x27;</span></span><br><span class="line"></span><br><span class="line"># 默认返回最新的一条数据</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,<span class="string">&#x27;columnFamily1:column1&#x27;</span></span><br><span class="line"></span><br><span class="line"># 返回<span class="number">3</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"># 返回<span class="number">2</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="4、STARTROW"><a href="#4、STARTROW" class="headerlink" title="4、STARTROW"></a>4、STARTROW</h5><blockquote><p>ROWKEY起始行。会先根据这个key定位到region，再向后扫描</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;vbirdbest&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"><a href="#5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据" class="headerlink" title="5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"></a>5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;xiaoming&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="6、LIMIT-返回的行数"><a href="#6、LIMIT-返回的行数" class="headerlink" title="6、LIMIT 返回的行数"></a>6、LIMIT 返回的行数</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> 行数&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2</span> &#125;</span><br></pre></td></tr></table></figure><h4 id="1-5-10-FILTER条件过滤器"><a href="#1-5-10-FILTER条件过滤器" class="headerlink" title="1.5.10    FILTER条件过滤器"></a>1.5.10    FILTER条件过滤器</h4><blockquote><p>过滤器之间可以使用AND、OR连接多个过滤器。</p></blockquote><h5 id="1、ValueFilter-值过滤器"><a href="#1、ValueFilter-值过滤器" class="headerlink" title="1、ValueFilter 值过滤器"></a>1、ValueFilter 值过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法：<span class="type">binary</span> 等于某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;binary:列值&#x27;)&quot;</span><br><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;substring:列值&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;binary:26&#x27;)&quot;</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;substring:6&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="2、ColumnPrefixFilter-列名前缀过滤器"><a href="#2、ColumnPrefixFilter-列名前缀过滤器" class="headerlink" title="2、ColumnPrefixFilter 列名前缀过滤器"></a>2、ColumnPrefixFilter 列名前缀过滤器</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan &#x27;表名&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;列名前缀&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan &#x27;tbl_user&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;birth&#x27;)&quot;</span><br><span class="line"># 通过括号、AND和OR的条件组合多个过滤器</span><br><span class="line">scan &#x27;tbl_user&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:26&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="3、rowKey字典排序"><a href="#3、rowKey字典排序" class="headerlink" title="3、rowKey字典排序"></a>3、rowKey字典排序</h5><blockquote><p>Table中的所有行都是按照row key的字典排序的</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/lHbNsQYjU8TCnMA.png" alt="image-20220612212431834"></p>]]></content>
    
    
    <summary type="html">对学习hbase shell的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase概述及搭建</title>
    <link href="http://example.com/2022/06/08/Hbase%E6%A6%82%E8%BF%B0%E5%8F%8A%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/06/08/Hbase%E6%A6%82%E8%BF%B0%E5%8F%8A%E6%90%AD%E5%BB%BA/</id>
    <published>2022-06-07T16:00:00.000Z</published>
    <updated>2022-06-15T07:35:16.894Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、了解HBase"><a href="#一、了解HBase" class="headerlink" title="一、了解HBase"></a>一、了解HBase</h2><p>官方文档：<a href="https://hbase.apache.org/book.html">https://hbase.apache.org/book.html</a></p><h3 id="1-1-HBase概述"><a href="#1-1-HBase概述" class="headerlink" title="1.1    HBase概述"></a>1.1    HBase概述</h3><blockquote><p>HBase 是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，用于存储海量的结构化或者半结构化，非结构化的数据</p><p>HBase是Hadoop的生态系统之一，是建立在Hadoop文件系统（HDFS）之上的分布式、面向列的数据库，通过利用Hadoop的文件系统提供容错能力。如果需要进行实时读写或者随机访问大规模的数据集的时候，会考虑使用HBase。</p><p>HBase作为Google Bigtable的开源实现，Google Bigtable利用GFS作为其文件存储系统类似，则HBase利用Hadoop HDFS作为其文件存储系统；Google通过运行MapReduce来处理Bigtable中的海量数据，同样，HBase利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用Chubby作为协同服务，HBase利用Zookeeper作为对应。在2010年5月，成为apache顶级项目</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/IYKfrEsFbvx2Q4A.png" alt="image-20220608204054001"></p><h3 id="1-2-HBase处理数据"><a href="#1-2-HBase处理数据" class="headerlink" title="1.2    HBase处理数据"></a>1.2    HBase处理数据</h3><blockquote><p>虽然Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，但是它不适用于提供实时计算；</p><p>HBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证期高容错性;</p><p>但是再生产环境中，HBase是如何基于hadoop提供实时性呢？ </p><p>HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；</p><p>但是HDFS并不知道的HBase用于存储什么，它只把存储文件认为是二进制文件，也就是说，HBase的存储数据对于HDFS文件系统是透明的。</p></blockquote><h3 id="1-3-HBase与HDFS"><a href="#1-3-HBase与HDFS" class="headerlink" title="1.3    HBase与HDFS"></a>1.3    HBase与HDFS</h3><blockquote><p>在下面的表格中，我们对HDFS与HBase进行比较：    </p></blockquote><table><thead><tr><th>HDFS</th><th>HBase</th></tr></thead><tbody><tr><td>HDFS适于存储大容量文件的分布式文件系统。</td><td>HBase是建立在HDFS之上的数据库。</td></tr><tr><td>HDFS不支持快速单独记录查找。</td><td>HBase提供在较大的表快速查找</td></tr><tr><td>HDFS提供了高延迟批量处理;没有批处理概念。</td><td>HBase提供了数十亿条记录低延迟访问单个行记录（随机存取）。</td></tr><tr><td>HDFS提供的数据只能顺序访问。</td><td>HBase内部使用哈希表和提供随机接入，并且其存储索引，可将在HDFS文件中的数据进行快速查找。</td></tr></tbody></table><p>Hbase—&gt;HashMap</p><h2 id="二、HBase相关概念"><a href="#二、HBase相关概念" class="headerlink" title="二、HBase相关概念"></a>二、HBase相关概念</h2><h3 id="2-1-分布式数据库"><a href="#2-1-分布式数据库" class="headerlink" title="2.1    分布式数据库"></a>2.1    分布式数据库</h3><p><img src="https://s2.loli.net/2022/06/09/N9gnjo1GSKQ2UY4.png" alt="image-20220609215840812"></p><h3 id="2-2-列式存储"><a href="#2-2-列式存储" class="headerlink" title="2.2    列式存储"></a>2.2    列式存储</h3><p><img src="https://s2.loli.net/2022/06/09/PmgjIZuvkKYE72C.png" alt="image-20220609215924536"></p><h3 id="2-3-稀疏性"><a href="#2-3-稀疏性" class="headerlink" title="2.3    稀疏性"></a>2.3    稀疏性</h3><blockquote><p>理解稀疏（rowkey）</p><p>HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“<strong>四维坐标</strong>”，即**[行键, 列族, 列限定符, 时间戳]**</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/kC42Rz8LeFw67vy.png" alt="稀疏性"></p><h3 id="2-4-数据模型"><a href="#2-4-数据模型" class="headerlink" title="2.4    数据模型"></a>2.4    数据模型</h3><blockquote><p>HBase通过表格的模式存储数据，每个表格由列和行组成，其中，每个列又被划分为若干个列族（colnum family），请参考下面的图：</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/eHQcAD7hfqXNRk4.png" alt="image-20220609220036643"></p><blockquote><p>          <strong>表：</strong>HBase的数据同样是用表来组织的，表由行和列组成，列分为若干个列族，行和列的坐标交叉决定了一个单元格。</p><p>       <strong>行：</strong>每个表由若干行组成，每个行有一个行键作为这一行的唯一标识。访问表中的行只有三种方式：通过单个行键进行查询、通过一个行键的区间来访问、全表扫描。</p><p>       <strong>列族：</strong>一个HBase表被分组成许多“列族”的集合，它是基本的访问控制单元。</p><p>       <strong>列修饰符（列限定符）：</strong>列族里的数据通过列限定符（或列）来定位</p><p>       <strong>单元格：</strong>在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，<strong>总被视为字节数组byte[]</strong></p><p>       <strong>时间戳：</strong>每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引</p></blockquote><h4 id="2-4-1-Hbase数据模型"><a href="#2-4-1-Hbase数据模型" class="headerlink" title="2.4.1    Hbase数据模型"></a>2.4.1    Hbase数据模型</h4><blockquote><p>HBase将数据存放在带有标签的<strong>表</strong>中，表由<strong>行和列</strong>组成，行和列交叉确定一个<strong>单元格</strong>，单元格有<strong>版本号</strong>，版本号自动分配，为数据插入该单元格时的<strong>时间戳</strong>。单元格的内容没有数据类型，<strong>所有数据都被视为未解释的字节数组</strong>。</p><p>  表格中每一行有一个<strong>行键</strong>（也是字节数组，任何形式的数据都可以表示成字符串，比如数据结构进行序列化之后），<strong>整个表根据行键的字节序来排序</strong>，所有对表的访问必须通过行键。</p><p>  表中的列又划分为多个<strong>列族</strong>（column family），同一个列族的所有成员具有相同的前缀，具体的列由列修饰符标识，因此，<strong>列族和列修饰符</strong>合起来才可以表示某一列，比如：info:format、cotents:image</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/JkNlnw1zLYGjP2u.png" alt="image-20220609220054289"></p><blockquote><p>在创建一个表的时候，列族必须作为模式定义的一部分预先给出，而<strong>列族是支持动态扩展的</strong>，也就是列族成员可以随后按需加入。物理上，所有的列族成员一起存放在文件系统上，所以实际上说HBase是面向列的数据库，更准确的应该是<strong>面向列族</strong>，调优和存储都是在列族这个层次上进行的。一般情况下，同一个列族的成员最后具有相同的访问模式和大小特征。</p><p>  总结起来，HBase表和我们熟知的RDBMS的表很像，不同之处在于：<strong>行按行键排序，列划分为列族，单元格有版本号，没有数据类型。</strong></p></blockquote><h4 id="2-4-2-Hbase数据坐标"><a href="#2-4-2-Hbase数据坐标" class="headerlink" title="2.4.2    Hbase数据坐标"></a>2.4.2    Hbase数据坐标</h4><blockquote><p>HBase中需要根据行键、列族、列限定符和时间戳来确定一个<strong>单元格(cell)<strong>，cell中的数据是没有类型的，全部是</strong>字节码</strong>形式存贮。，因此，可以视为一个“<strong>四维坐标</strong>”，即**[行键, 列族, 列限定符, 时间戳]**。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/kz6J29nxcSCYZlV.png" alt="image-20220609220127385"></p><blockquote><p>对于上图这样一个HBase表，其数据坐标举例如下：</p></blockquote><table><thead><tr><th>键</th><th>值</th></tr></thead><tbody><tr><td>[“201505003”, “Info”, “email”, 1174184619081]</td><td>“<a href="mailto:&#x78;&#x69;&#x65;&#x40;&#113;&#113;&#x2e;&#x63;&#x6f;&#x6d;">&#x78;&#x69;&#x65;&#x40;&#113;&#113;&#x2e;&#x63;&#x6f;&#x6d;</a>”</td></tr><tr><td>[“201505003”, “Info”, “email”, 1174184620720]</td><td>“<a href="mailto:&#x79;&#x6f;&#117;&#x40;&#x31;&#54;&#51;&#x2e;&#x63;&#111;&#x6d;">&#x79;&#x6f;&#117;&#x40;&#x31;&#54;&#51;&#x2e;&#x63;&#111;&#x6d;</a>”</td></tr></tbody></table><h4 id="2-4-3-HBase区域"><a href="#2-4-3-HBase区域" class="headerlink" title="2.4.3    HBase区域"></a>2.4.3    HBase区域</h4><blockquote><p>HBase自动把表水平划分为<strong>区域</strong>（Region），每个区域都是有若干连续行构成的，一个区域由<strong>所属的表、起始行、终止行（不包括这行）</strong>三个要素来表示。</p><p>  一开始，一个表只有一个区域，但是随着数据的增加，区域逐渐变大，等到它超出设定的阈值大小，就会在某行的边界上进行拆分，分成两个大小<strong>基本相同</strong>的区域。然后随着数据的再增加，区域就不断的增加，如果超出了单台服务器的容量，就可以把一些区域放到其他节点上去，构成一个集群。也就是说：<strong>集群中的每个节点（Region Server）管理整个表的若干个区域</strong>。所以，我们说：<strong>区域是HBase集群上分布数据的最小单位</strong>。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/4lDPXtMkmfhdz2C.png" alt="image-20220609220146716"></p><h2 id="三、HBase系统架构"><a href="#三、HBase系统架构" class="headerlink" title="三、HBase系统架构"></a>三、HBase系统架构</h2><h3 id="3-1-架构图"><a href="#3-1-架构图" class="headerlink" title="3.1    架构图"></a>3.1    架构图</h3><p><img src="https://s2.loli.net/2022/06/09/Dhl7Z3jRKHa8F2p.png" alt="image-20220609220202453"></p><h3 id="3-2-组件介绍"><a href="#3-2-组件介绍" class="headerlink" title="3.2    组件介绍"></a>3.2    组件介绍</h3><p>HBase由三种类型的服务器以主从模式构成：</p><ul><li>Region Server：负责数据的读写服务，用户通过与Region server交互来实现对数据的访问。</li><li>HBase HMaster：负责Region的分配及数据库的创建和删除等操作。</li><li>ZooKeeper：负责维护集群的状态（某台服务器是否在线，服务器之间数据的同步操作及master的选举等）。</li></ul><p>HDFS的DataNode负责存储所有Region Server所管理的数据，即HBase中的所有数据都是以HDFS文件的形式存储的。出于使Region server所管理的数据更加本地化的考虑，Region server是根据DataNode分布的。HBase的数据在写入的时候都存储在本地。但当某一个region被移除或被重新分配的时候，就可能产生数据不在本地的情况。这种情况只有在所谓的compaction之后才能解决。</p><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><blockquote><p>包含访问HBase的接口并维护cache来加快对HBase的访问</p></blockquote><h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><blockquote><p>保证任何时候，集群中只有一个master</p><p>存贮所有Region的寻址入口。</p><p>实时监控Region server的上线和下线信息。并实时通知Master</p><p>存储HBase的schema和table元数据</p></blockquote><h4 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h4><blockquote><p>为Region server分配region</p><p>负责Region server的负载均衡</p><p>发现失效的Region server并重新分配其上的region</p><p>管理用户对table的增删改操作</p></blockquote><h4 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h4><blockquote><p>Region server维护region，处理对这些region的IO请求</p><p>Region server负责切分在运行过程中变得过大的region　</p></blockquote><h4 id="HLog-WAL-log-："><a href="#HLog-WAL-log-：" class="headerlink" title="HLog(WAL log)："></a>HLog(WAL log)：</h4><blockquote><p>HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是 HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和 region名字外，同时还包括sequence number和timestamp，timestamp是” 写入时间”，sequence number的起始值为0，或者是最近一次存入文件系 统sequence number。</p><p>HLog SequeceFile的Value是HBase的KeyValue对象，即对应HFile中的 KeyValue</p></blockquote><h4 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h4><blockquote><p>HBase自动把表水平划分成多个区域(region)，每个region会保存一个表里面某段连续的数据；每个表一开始只有一个region，随着数据不断插 入表，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region（裂变）；</p><p>当table中的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Regionserver上。</p></blockquote><h4 id="Memstore-与-storefile"><a href="#Memstore-与-storefile" class="headerlink" title="Memstore 与 storefile"></a>Memstore 与 storefile</h4><blockquote><ol><li><p>一个region由多个store组成，一个store对应一个CF（列簇）</p></li><li><p>store包括位于内存中的memstore和位于磁盘的storefile写操作先写入 memstore，当memstore中的数据达到某个阈值，hregionserver会启动 flashcache进程写入storefile，每次写入形成单独的一个storefile</p></li><li><p>当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、 major compaction），在合并过程中会进行版本合并和删除工作 （majar），形成更大的storefile。</p></li><li><p>当一个region所有storefile的大小和超过一定阈值后，会把当前的region 分割为两个，并由hmaster分配到相应的regionserver服务器，实现负载均衡。</p></li><li><p>客户端检索数据，先在memstore找，找不到再找storefile</p></li><li><p>HRegion是HBase中分布式存储和负载均衡的最小单元。最小单元就表 示不同的HRegion可以分布在不同的HRegion server上。</p></li><li><p>HRegion由一个或者多个Store组成，每个store保存一个columns family。</p></li><li><p>每个Strore又由一个memStore和0至多个StoreFile组成。</p></li></ol><p>如图：StoreFile 以HFile格式保存在HDFS上。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/ckzY96POTFUQwtK.png" alt="image-20220609220217852"></p><p><img src="https://s2.loli.net/2022/06/09/B5yDYaUn7vM3lif.png" alt="image-20220609220227154"></p><h3 id="3-3-理解难点"><a href="#3-3-理解难点" class="headerlink" title="3.3    理解难点"></a>3.3    理解难点</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">　　1、flush刷新在HDFS上呈现究竟是怎么刷新的呢？？</span><br><span class="line">　　　　我们目前刚刚学习的时候，添加数据，都是一条一条的put进去，而我们在put的数据比较少（小于128M）的时候，我们put完去HDFS上并未查看到我们put的文件，这是因为数据还在内存中，也就是还在memStore中，所以要想在HDFS中查看到，我们必须手动刷新到磁盘中，这是将memStore的数据刷新到StoreFile中去，这样我们在HDFS中就可以查看到了。　　</span><br><span class="line"></span><br><span class="line">　　2、为什么Hbase不可以使用像Mysql那样进行查询？？</span><br><span class="line">　　　　首先，我们应该可以感受到，我们在插入的时候，每行数据，有多少列，列名叫什么完全是我们自己定义的，之所以不支持像MySql那样对列进行查询和操作，因为不确定列的个数和名称。</span><br><span class="line"></span><br><span class="line">　　3、数据最后存在HDFS上的，HDFS不支持删改，为什么Hbase就可以呢？？</span><br><span class="line">　　　　这里有个思想误区，的确，数据是以HFile形式存在HDFS上的，而且HDFS的确是不支持删改的，但是为什么Hbase就支持呢？首先，这里的删除并不是真正意义上的对数据进行删除，而是对数据进行打上标记，我们再去查的时，就不会查到这个打过标记的数据，这个数据Hmaster会每隔1小时清理。修改是put两次，Hbase会取最新的数据，过期数据也是这个方式被清理。</span><br></pre></td></tr></table></figure><h2 id="四、HBase1-4-6安装搭建"><a href="#四、HBase1-4-6安装搭建" class="headerlink" title="四、HBase1.4.6安装搭建"></a>四、HBase1.4.6安装搭建</h2><h3 id="4-1-hbase下载"><a href="#4-1-hbase下载" class="headerlink" title="4.1 hbase下载"></a>4.1 hbase下载</h3><p><strong>后期在测试时发现1.7.1不是很兼容，因此回退到1.4.6版本</strong></p><p>官网下载地址：<a href="https://archive.apache.org/dist/hbase/1.4.6/hbase-1.4.6-bin.tar.gz">https://archive.apache.org/dist/hbase/1.4.6/hbase-1.4.6-bin.tar.gz</a></p><p><img src="https://s2.loli.net/2022/06/09/duV1iZ2pMrFfqCO.png" alt="image-20220609220320634"></p><h3 id="4-2-前期准备（Hadoop-zookeeper-jdk）"><a href="#4-2-前期准备（Hadoop-zookeeper-jdk）" class="headerlink" title="4.2 前期准备（Hadoop,zookeeper,jdk）"></a>4.2 前期准备（Hadoop,zookeeper,jdk）</h3><blockquote><p>启动hadoop</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><blockquote><p>验证</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://master:50070</span><br></pre></td></tr></table></figure><blockquote><p>启动zookeeper（三台分别启动）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><blockquote><p>检查状态</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure><h3 id="4-3-搭建Hbase"><a href="#4-3-搭建Hbase" class="headerlink" title="4.3    搭建Hbase"></a>4.3    搭建Hbase</h3><h4 id="1、上传解压"><a href="#1、上传解压" class="headerlink" title="1、上传解压"></a>1、上传解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf hbase-1.4.6-bin.tar.gz</span><br></pre></td></tr></table></figure><h4 id="2、配置环境变量"><a href="#2、配置环境变量" class="headerlink" title="2、配置环境变量"></a>2、配置环境变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HBASE_HOME=/usr/local/soft/hbase-1.4.6</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HBASE_HOME/bin</span></span><br></pre></td></tr></table></figure><blockquote><p>source &#x2F;etc&#x2F;profile</p></blockquote><h4 id="3、修改hbase-env-sh文件"><a href="#3、修改hbase-env-sh文件" class="headerlink" title="3、修改hbase-env.sh文件"></a>3、修改hbase-env.sh文件</h4><blockquote><p>增加java配置</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><blockquote><p>关闭默认zk配置（原本是注释的，放开修改false）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure><h4 id="4、修改hbase-site-xml文件"><a href="#4、修改hbase-site-xml文件" class="headerlink" title="4、修改hbase-site.xml文件"></a>4、修改hbase-site.xml文件</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1,node2,master<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure><h4 id="5、修改regionservers文件"><a href="#5、修改regionservers文件" class="headerlink" title="5、修改regionservers文件"></a>5、修改regionservers文件</h4><blockquote><p>如果是伪分布式版本，增加master即可</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><h4 id="6、同步到所有节点（如果是伪分布式不需要同步）"><a href="#6、同步到所有节点（如果是伪分布式不需要同步）" class="headerlink" title="6、同步到所有节点（如果是伪分布式不需要同步）"></a>6、同步到所有节点（如果是伪分布式不需要同步）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r hbase-1.4.6 node1:`pwd`</span><br><span class="line">scp -r hbase-1.4.6 node2:`pwd`</span><br></pre></td></tr></table></figure><h4 id="7、启动hbase集群-，-在master上执行"><a href="#7、启动hbase集群-，-在master上执行" class="headerlink" title="7、启动hbase集群 ， 在master上执行"></a>7、启动hbase集群 ， 在master上执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/09/6ybGojvBhIMR2VP.png" alt="image-20220609220348414"></p><h4 id="8、验证hbase"><a href="#8、验证hbase" class="headerlink" title="8、验证hbase"></a>8、验证hbase</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://master:16010</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/09/GetFKMrWAZJDdqC.png" alt="image-20220609220410102"></p><blockquote><p>hbase日志文件所在的目录: &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hbase-1.7.1&#x2F;logs</p></blockquote><h4 id="9、关闭集群的命令"><a href="#9、关闭集群的命令" class="headerlink" title="9、关闭集群的命令"></a>9、关闭集群的命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure><h3 id="4-4-启动顺序"><a href="#4-4-启动顺序" class="headerlink" title="4.4    启动顺序"></a>4.4    启动顺序</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">启动顺序</span><br><span class="line">Hadoop及hbase集群启动顺序 zookeepeer -&gt; hadoop -&gt; hbase</span><br><span class="line"></span><br><span class="line">停止顺序</span><br><span class="line">Hadoop及hbase集群关闭顺序 hbase -&gt; hadoop -&gt; zookeepeer</span><br></pre></td></tr></table></figure><h3 id="4-5-重置hbase"><a href="#4-5-重置hbase" class="headerlink" title="4.5    重置hbase"></a>4.5    重置hbase</h3><h5 id="1、关闭hbase集群"><a href="#1、关闭hbase集群" class="headerlink" title="1、关闭hbase集群"></a>1、关闭hbase集群</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1)杀死进程</span><br><span class="line">   </span><br><span class="line">2)stop-hbase.sh</span><br></pre></td></tr></table></figure><h5 id="2、删除数据-hdfs"><a href="#2、删除数据-hdfs" class="headerlink" title="2、删除数据   hdfs"></a>2、删除数据   hdfs</h5> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs dfs -rmr /hbase</span><br></pre></td></tr></table></figure><h5 id="3、删除元数据-zk"><a href="#3、删除元数据-zk" class="headerlink" title="3、删除元数据 zk"></a>3、删除元数据 zk</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkCli.sh</span><br><span class="line">rmr /hbase</span><br></pre></td></tr></table></figure><h5 id="4、重新启动hbase"><a href="#4、重新启动hbase" class="headerlink" title="4、重新启动hbase"></a>4、重新启动hbase</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h5 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ntp -y</span><br><span class="line"></span><br><span class="line">ntpdate -u time.windows.com</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Hbase的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hive优化</title>
    <link href="http://example.com/2022/06/07/Hive%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/06/07/Hive%E4%BC%98%E5%8C%96/</id>
    <published>2022-06-06T16:00:00.000Z</published>
    <updated>2022-06-08T07:13:17.011Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h2><h2 id="1-1-hive的随机抓取策略"><a href="#1-1-hive的随机抓取策略" class="headerlink" title="1.1    hive的随机抓取策略"></a>1.1    <strong>hive的随机抓取策略</strong></h2><blockquote><p>理论上来说，Hive中的所有sql都需要进行mapreduce，但是hive的抓取策略帮我们<br>省略掉了这个过程，把切片split的过程提前帮我们做了。<br>set hive.fetch.task.conversion&#x3D;none;<br>(一旦进行这么设置，select字段名也是需要进行mapreduce的过程，默认是more)</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Fetch</span>抓取的模式</span><br><span class="line">可以通过 <span class="keyword">set</span> hive.fetch.task.conversion查看，有以下<span class="number">3</span>种模式：</span><br><span class="line"></span><br><span class="line"><span class="keyword">none</span>：所有涉及hdfs的读取查询都走mapreduce任务；</span><br><span class="line">mininal：在进行简单的<span class="keyword">select</span> <span class="operator">*</span>，简单的过滤或涉及分区字段的过滤时走mr；</span><br><span class="line">more:在mininal模式的基础上，增加了针对查询语句字段进行一些别名的计算操作。</span><br><span class="line">以下HQL，mininal模式与more模式下都不会走mr任务:</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">sale_ord_id,</span><br><span class="line">store_id</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">test_table</span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">dt <span class="operator">=</span> <span class="string">&#x27;2021-01-01&#x27;</span></span><br><span class="line"> limit <span class="number">10</span>;</span><br><span class="line"> </span><br><span class="line">以下HQL,mininal模式会走mr任务，more模式不会：</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">sale_ord_id,</span><br><span class="line">store_id,</span><br><span class="line">if(store_id <span class="operator">&gt;</span> <span class="number">20</span>,<span class="number">1</span>,<span class="number">0</span>) <span class="keyword">as</span> store_id_new</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">test_table</span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">dt <span class="operator">=</span> <span class="string">&#x27;2021-01-01&#x27;</span></span><br><span class="line"> limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure><blockquote><p>查看怎么将一个sql转化成一个MR任务的<br>explain sql语句<br>例如：<br>explain select count(*) from stu_dy1_1;<br>更加详细的查看，例如：<br><strong>explain extended select count(*) from stu_dy1_1;</strong><br>当你输入一个sql语句的时候，hive会将对其关键字进行截串，截完串之后，变成<br>都是一些TOK开头的一些东西，然后经过这样的抽象语法树，再转成具体的查询块，<br>最后变成逻辑查询计划</p></blockquote><h2 id="1-2-本地运行模式"><a href="#1-2-本地运行模式" class="headerlink" title="1.2    本地运行模式"></a>1.2    本地运行模式</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。不过，</span><br><span class="line">有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能</span><br><span class="line">会比实际 job 的执行时间要多的多。对于大多数这种情况， Hive 可以通过本地模式在单台机</span><br><span class="line">器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</span><br><span class="line">用户可以通过设置 hive.exec.mode.local.auto 的值为 true ，来让 Hive 在适当的时候自动</span><br><span class="line">启动这个优化。</span><br><span class="line"></span><br><span class="line">本地模式运行比集群模式块很多，33秒的任务降到2秒</span><br><span class="line">更改为本地模式：</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto=true</span><br><span class="line">注意：</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto.inputbytes.max=134217728     ---&gt; 128M</span><br><span class="line">（默认值就是128）</span><br><span class="line">表示加载文件的最大值，若大于该配置仍然会以集群的方式去运行。</span><br><span class="line">97万行数据，50MB</span><br><span class="line">当我们开发或者测试阶段，可以去使用本地模式进行运行，默认是集群模式</span><br><span class="line">但是，这里有个问题，当我们去更改为本地模式的时候，在8088的页面上就看不到</span><br><span class="line">任务的执行情况了。</span><br><span class="line"></span><br><span class="line">测试：select count(*) from emp group by deptno;</span><br></pre></td></tr></table></figure><h2 id="1-3-并行计算"><a href="#1-3-并行计算" class="headerlink" title="1.3    并行计算"></a>1.3    <strong>并行计算</strong></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过设置以下参数开启并行模式（默认是false）</span><br><span class="line">set hive.exec.parallel=true;</span><br><span class="line"></span><br><span class="line">注意：hive.exec.parallel.thread.number</span><br><span class="line">(一次SQl计算中允许并行执行的job个数最大值，默认是8个)</span><br><span class="line"></span><br><span class="line">举例：</span><br><span class="line">select t1.n1,t2.n2 from (select count(ename) as n1 from emp) t1,(select count(dname) as n2 from dept) t2;</span><br><span class="line">注意，有时候开启并行计算运行时间并没有不开启的快，那是因为，资源的问题。</span><br><span class="line">需要两套资源，资源申请会浪费点时间，最多可以并行8个，默认是8个。</span><br><span class="line">所以，并行的越多，不一定是越快，因为它涉及到一个资源申请的策略。</span><br></pre></td></tr></table></figure><h2 id="1-4-严格模式-理解为增加一些限制"><a href="#1-4-严格模式-理解为增加一些限制" class="headerlink" title="1.4    严格模式(理解为增加一些限制)"></a>1.4    <strong>严格模式(理解为增加一些限制)</strong></h2><p>​    <strong>1.什么是Hive的严格模式</strong><br>​        hive中的一种模式,在该模式下禁止一些不好SQL的执行。</p><p>​    <strong>2.Hive的严格模式不允许哪些SQL执行</strong><br>​        <strong>2.1 禁止分区表全表扫描</strong><br>               分区表往往数据量大,如果不加分区查询会带来巨大的资源消耗 。例如以下分区表<br>               SELECT DISTINCT(planner_id) FROM fracture_ins WHERE planner_id&#x3D;5;</p><p>​                报错如下:<br>​               FAILED: Error in semantic analysis: No Partition Predicate Found for Alias “fracture_ins” Table “fracture_ins</p><p>​               解决如下:<br>​              SELECT DISTINCT(planner_id) FROM fracture_ins WHERE planner_id&#x3D;5 AND hit_date&#x3D;20120101;</p><p>​      <strong>2.2 禁止排序不加limit</strong><br>​        排序最终是要都进到一个Reduce中操作,防止reducer额外执行很长一段时间<br>​        SELECT * FROM fracture_ins WHERE hit_date&gt;2012 ORDER BY planner_id;<br>​        出现如下错误<br>​               FAILED: Error in semantic analysis: line 1:56 In strict mode,limit must be specified if ORDER BY is present planner_id<br>​        解决方案就是增加一个limit关键字：<br>​               hive&gt; SELECT * FROM fracture_ins WHERE hit_date&gt;2012 ORDER BY planner_id LIMIT 100000;</p><p>​      <strong>2.3 禁止笛卡尔积</strong><br>​          笛卡尔积是什么: A&#x3D;{a,b}, B&#x3D;{0,1,2}，则 A×B&#x3D;{(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)}</p><p>​          SELECT * FROM fracture_act JOIN fracture_ads;<br>​        解决方法<br>​        SELECT * FROM fracture_act JOIN fracture_ads WHERE fracture_act.planner_id &#x3D; fracture_ads.planner_id;</p><p><strong>3.Hive的严格模式怎样开启</strong></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 查看当前严格模式的状态</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 设置为严格模式</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode<span class="operator">=</span>strict;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 设置为非严格模式</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode<span class="operator">=</span>nostrict;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意，这里的严格模式和动态分区的那个严格模式半毛钱关系没有）</span><br><span class="line">通过设置以下参数开启严格模式：</span><br><span class="line">set hive.mapred.mode=strict;</span><br><span class="line">(默认为：nonstrict非严格模式)</span><br><span class="line"></span><br><span class="line">查询限制：</span><br><span class="line">1、对于分区表，必须添加where对于分区字段的条件过滤</span><br><span class="line">2、order by 语句必须包含limit输出限制</span><br><span class="line">3、限制执行笛卡尔积的查询</span><br><span class="line">这些限制是帮助我们提高查询效率的。</span><br></pre></td></tr></table></figure><h2 id="1-5-Hive排序"><a href="#1-5-Hive排序" class="headerlink" title="1.5    Hive排序"></a>1.5    <strong>Hive排序</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> 对于查询结果做全排序，只允许有一个reduce处理</span><br><span class="line">（注意：它会把我们所有的字段或者查询结果全部放在一个reduce里进行处理</span><br><span class="line">当数据量较大时候，有可能reduce执行不完，所以，我们以后把这个给弃用掉）</span><br><span class="line"></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span>   sort <span class="keyword">by</span> 对于单个reduce进行排序 但是我们将每个reduce里面进行排序，没有考虑到</span><br><span class="line">每个reduce之间的排序。所以我们引出下一个</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span>   distribute <span class="keyword">by</span> 分区排序，通常结合sort <span class="keyword">by</span>一起使用</span><br><span class="line">（distribute <span class="keyword">by</span> <span class="keyword">column</span> sort <span class="keyword">by</span> <span class="keyword">column</span> <span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>）</span><br><span class="line"></span><br><span class="line">cluster <span class="keyword">by</span> 相当于distribute <span class="keyword">by</span> <span class="operator">+</span> sort <span class="keyword">by</span>  (注意，虽然是两个结合，但是我们也不去用它</span><br><span class="line">原因很简单，cluster <span class="keyword">by</span>不能通过<span class="keyword">asc</span> <span class="keyword">desc</span>的方式指定排序方式规则)</span><br></pre></td></tr></table></figure><h2 id="1-6-Hive-join数据倾斜"><a href="#1-6-Hive-join数据倾斜" class="headerlink" title="1.6    Hive join数据倾斜"></a>1.6    Hive join数据倾斜</h2><p>1、小表join小表 不管他</p><p>2、小表join大表   map-join</p><p>3、大表join大表  map-side</p><p>考虑会不会发生reduce,并且考虑reduce压力是否大（是否会出现某个reduce数据量庞大的情况）</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">join</span>计算的时候，将小表（驱动表）放在<span class="keyword">join</span>的左边</span><br><span class="line">Map <span class="keyword">join</span>：在Map端完成<span class="keyword">join</span></span><br><span class="line">两种实现方式：</span><br><span class="line"><span class="number">1</span>、<span class="keyword">sql</span>方式，在<span class="keyword">sql</span>语句中添加Mapjoin标记（mapjoin hint）</span><br><span class="line"><span class="operator">&gt;&gt;</span>语法：</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+MAPJOIN(smallTable)*/</span> smallTable.key bigTable.value <span class="keyword">from</span> smallTable <span class="keyword">join</span> bigTable <span class="keyword">on</span> smallTable.key<span class="operator">=</span>bigTable.key;</span><br><span class="line"><span class="number">2</span>、自动开启mapjoin</span><br><span class="line">通过修改以下配置启用自动的mapjoin：</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line">(注意：该参数为<span class="literal">true</span>的时候，Hive自动对左边的表统计量，如果</span><br><span class="line">是小表，就加入到内存，即对小表使用Mapjoin)</span><br><span class="line"></span><br><span class="line">相关配置参数</span><br><span class="line">　　hive.mapjoin.smalltable.filesize;(默认<span class="number">25</span>M,大表小表判断的阈值，如果表的大小小于该值则会被加载到内存中运行。)</span><br><span class="line">　　hive.ignore,mapjoin.hint;(默认值：<span class="literal">true</span>;是否忽略mapjoin hint的标记)</span><br><span class="line">　　hive.auto.convert.join.noconditionaltask;(默认值：<span class="literal">true</span>；将普通的<span class="keyword">join</span>转换为mapjoin时，是否将多个mapjoin转化为一个mapjoin)</span><br><span class="line">　　hive.auto.convert.join.noconditionaltask.size;(将多个mapjoin转化为一个mapjoin时，这个表的最大值)</span><br><span class="line"><span class="number">3</span>、尽可能使用相同的连接键，如果不同，多一个<span class="keyword">join</span>就会多开启一个mapreduce，执行速度变得慢。</span><br><span class="line"><span class="number">4</span>、大表<span class="keyword">join</span>大表（当两个都是大表的时候，只能发生reduce了，但是这里有两个优化策略）（面试的时候说，加分）</span><br><span class="line">　　a: 空key过滤:</span><br><span class="line">　　　　有时<span class="keyword">join</span>超时是因为某些key对应的数据太多,而相同key对应的数据都会发送到相同的 reducer上,从而导致内存不够。</span><br><span class="line">　　　　此时我们应该仔细分析这些异常的key,很多情况下,这些key对应的数据是异常数据,我们需要在<span class="keyword">SQL</span>语句中进行过滤。</span><br><span class="line">　　　　但是这个的前提条件是异常数据，但是我们一般拿到的数据都是经过ETL数据清洗过后的，一般影响不大，面试的时候可以说。</span><br><span class="line">　　b: 空key转换:</span><br><span class="line">　　　　有时虽然某个key为空对应的数据很多,但是相应的数据不是异常数据,必须要包含在<span class="keyword">join</span>的结果中,</span><br><span class="line">　　　　此时我们可以表a中key为空的字段赋随机的值,使得数据随机均匀地分不到不同的 reducer上。</span><br><span class="line">　　　　但是我们一般拿到的数据都是经过ETL数据清洗过后的，规则数据，一般影响不大，面试的时候可以说。</span><br><span class="line"><span class="number">5</span>、Map<span class="operator">-</span>Side聚合</span><br><span class="line">通过设置以下参数开启在Map端的聚合</span><br><span class="line"><span class="keyword">set</span> hive.map.aggr<span class="operator">=</span><span class="literal">true</span>;（一定要进行开启，虽然进行了两个mapreduce，但是当数据倾斜发生的时候，很多时候会根本跑不出结果，卡死在<span class="number">99</span><span class="operator">%</span>或者<span class="number">100</span><span class="operator">%</span>，慢总比出不来结果要好）！！！！！！！</span><br><span class="line">相关配置参数</span><br><span class="line">　　hive. groupby mapaggr. checkinterval;</span><br><span class="line">　　map端 igroup <span class="keyword">by</span>执行聚合时处理的多少行数据(默认:<span class="number">10000</span></span><br><span class="line">　　hive.map.aggr.hash.min.reduction;比例(若聚合之后的数据<span class="number">100</span>大该<span class="number">0.5</span>,map端聚合使用的内存的最大值</span><br><span class="line">　　hive.mapaggr.hashforce.flush.memory.threshold;map端做聚合操作是has表的最大可用内容,大于该值则会触发fush</span><br><span class="line">　　hive.groupby.skewindata<span class="operator">-</span>是否对 GroupBy产生的数据倾斜做优化,默认为<span class="literal">false</span>(十分重要！！！)</span><br><span class="line"><span class="number">6</span>、数据倾斜，尽可能地让我们的数据散列到不同的reduce里面去,负载均衡</span><br></pre></td></tr></table></figure><h2 id="1-7-合并小文件"><a href="#1-7-合并小文件" class="headerlink" title="1.7    合并小文件"></a>1.7    <strong>合并小文件</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Hive优化</span><br><span class="line">合并小文件</span><br><span class="line">文件数目小,容易在文件存储端造成压力,给hdfs造成压力,影响效率</span><br><span class="line">设置合并属性</span><br><span class="line">　　是否合并map输出文件: hive.merge.mapfiles<span class="operator">=</span><span class="literal">true</span></span><br><span class="line">　　是否合并reduce输出文件: hive.merge.mapredfiles<span class="operator">=</span><span class="literal">true</span></span><br><span class="line">　　合并文件的大小: hive.merge.size.per.task<span class="operator">=</span><span class="number">256</span><span class="operator">*</span><span class="number">1000</span><span class="operator">*</span><span class="number">1000</span></span><br><span class="line">去重统计</span><br><span class="line">数据量小的时候无所谓,数据量大的情况下,由于 COUNT <span class="keyword">DISTINCT</span>操作需要用一个 Reduce Task来完成,</span><br><span class="line">这一个 Reduce需要处理的数据量太大,就会导致整个JOb很难完成,一般 COUNT <span class="keyword">DISTINCT</span>使用先 <span class="keyword">GROUP</span> <span class="keyword">BY</span>再COUNT的方式替换</span><br></pre></td></tr></table></figure><h2 id="1-8-控制map和reduce的数量-一般情况下我们不去动它"><a href="#1-8-控制map和reduce的数量-一般情况下我们不去动它" class="headerlink" title="1.8    控制map和reduce的数量(一般情况下我们不去动它)"></a>1.8    <strong>控制map和reduce的数量(一般情况下我们不去动它)</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">控制Hive中Map以及 Reduce的数量</span><br><span class="line">Map数量相关的参数</span><br><span class="line">mapred.max.split.size;一个split的最大值,即每个map处理文件的最大值</span><br><span class="line">mapred.min.split.size.per.node个节点上split的最小值</span><br><span class="line">mapred.min.split.size.per.rack一个机架上spit的最小值</span><br><span class="line">Reduce数量相关的参数</span><br><span class="line">mapred.reduce.tasks;强制指定reduce任务的数量</span><br><span class="line">hive.exec.reducers.bytes.per.reducer每个reduce任务处理的数据量</span><br><span class="line">hive.exec.reducers.max每个任务最大的reduce数</span><br></pre></td></tr></table></figure><h2 id="1-9-JVM重用"><a href="#1-9-JVM重用" class="headerlink" title="1.9    JVM重用"></a>1.9    <strong>JVM重用</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">当我们的小文件个数过多，task个数过多，需要申请的资源过多的时候，我们可以先申请一部分资源，全部执行完毕后再释放，</span><br><span class="line">比我们申请一个释放一个要快。</span><br><span class="line">通过 <span class="keyword">set</span> mapred.job.reuse.jvm.num.tasks<span class="operator">=</span>n;来设置</span><br><span class="line">（n为task插槽个数）</span><br><span class="line">缺点：</span><br><span class="line">设置开启后，task插槽会一直占用资源，无论是否有task进行，直到所有的task,</span><br><span class="line">即整个job全部执行完毕后，才会释放所有的task插槽，所以我们要合理地设置这个n</span><br><span class="line">(比如，我们设置申请了<span class="number">10</span>个，但是现在来了<span class="number">6</span>个，剩下<span class="number">4</span>个插槽会在job全部执行完毕之前一直占用资源)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Hive的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hive" scheme="http://example.com/tags/Hive/"/>
    
  </entry>
  
</feed>
