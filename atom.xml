<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Notes</title>
  
  <subtitle>little notes</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-08-10T02:41:14.522Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>秋水一色</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DolphinScheduler搭建</title>
    <link href="http://example.com/2022/08/02/DolphinScheduler%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/08/02/DolphinScheduler%E6%90%AD%E5%BB%BA/</id>
    <published>2022-08-01T16:00:00.000Z</published>
    <updated>2022-08-10T02:41:14.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DolphinScheduler搭建"><a href="#DolphinScheduler搭建" class="headerlink" title="DolphinScheduler搭建"></a>DolphinScheduler搭建</h2><h4 id="1-上传解压"><a href="#1-上传解压" class="headerlink" title="1 上传解压"></a>1 上传解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf DolphinScheduler-bin.tar.</span><br></pre></td></tr></table></figure><h4 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2 修改配置文件"></a>2 修改配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd conf</span><br></pre></td></tr></table></figure><h5 id="2-1-修改mysql链接配置"><a href="#2-1-修改mysql链接配置" class="headerlink" title="2.1 修改mysql链接配置"></a>2.1 修改mysql链接配置</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim datasource.properties</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改一下配置</span></span><br><span class="line">spring.datasource.driver-class-name=com.mysql.jdbc.Driver</span><br><span class="line">spring.datasource.url=jdbc:mysql://node1:3306/dolphinscheduler?characterEncoding=UTF-8&amp;allowMultiQueries=<span class="literal">true</span></span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=123456</span><br></pre></td></tr></table></figure><h5 id="2-2-修改安装配置"><a href="#2-2-修改安装配置" class="headerlink" title="2.2 修改安装配置"></a>2.2 修改安装配置</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim config/install_config.conf</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql地址</span></span><br><span class="line">dbhost=<span class="string">&quot;master:3306&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql用户名</span></span><br><span class="line">username=<span class="string">&quot;root&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据库名</span></span><br><span class="line">dbname=<span class="string">&quot;dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql密码</span></span><br><span class="line">password=<span class="string">&quot;123456&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper链接地址</span></span><br><span class="line">zkQuorum=<span class="string">&quot;master:2181&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dolphinscheduler安装路径</span></span><br><span class="line">installPath=<span class="string">&quot;/usr/local/soft/dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装用户</span></span><br><span class="line">deployUser=<span class="string">&quot;root&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置邮箱服务器，需要开启邮箱smtp服务</span></span><br><span class="line">mailServerHost=<span class="string">&quot;smtp.163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 端口号</span></span><br><span class="line">mailServerPort=<span class="string">&quot;25&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 邮箱地址</span></span><br><span class="line">mailSender=<span class="string">&quot;mllib_fiy@163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户名和邮箱地址一致</span></span><br><span class="line">mailUser=<span class="string">&quot;mllib_fiy@163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 邮箱密码</span></span><br><span class="line">mailPassword=<span class="string">&quot;PQUFLTJBDEASRRSX&quot;</span></span><br><span class="line"></span><br><span class="line">starttlsEnable=<span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hdfs访问地址</span></span><br><span class="line">defaultFS=<span class="string">&quot;hdfs://master:9000&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dolphinscheduler上传到hdfs路径</span></span><br><span class="line">resourceUploadPath=<span class="string">&quot;/dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传文件使用的用户名</span></span><br><span class="line">hdfsRootUser=<span class="string">&quot;root&quot;</span></span><br></pre></td></tr></table></figure><h5 id="2-3-修改环境变量"><a href="#2-3-修改环境变量" class="headerlink" title="2.3 修改环境变量"></a>2.3 修改环境变量</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim env/dolphinscheduler_env.sh</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/local/soft/hadoop-2.7.6/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME2=/usr/local/soft/spark-2.4.5</span><br><span class="line"><span class="built_in">export</span> DATAX_HOME=/usr/local/soft/datax/bin/datax.py</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$SPARK_HOME2</span>/bin:<span class="variable">$PYTHON_HOME</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span>:<span class="variable">$FLINK_HOME</span>/bin:<span class="variable">$DATAX_HOME</span>:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h4 id="3-初始化数据库"><a href="#3-初始化数据库" class="headerlink" title="3 初始化数据库"></a>3 初始化数据库</h4><h5 id="3-1-进入mysql创建dolphinscheduler数据库"><a href="#3-1-进入mysql创建dolphinscheduler数据库" class="headerlink" title="3.1 进入mysql创建dolphinscheduler数据库"></a>3.1 进入mysql创建dolphinscheduler数据库</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p123456</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE dolphinscheduler <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br></pre></td></tr></table></figure><h5 id="3-2-执行脚本创建表"><a href="#3-2-执行脚本创建表" class="headerlink" title="3.2 执行脚本创建表"></a>3.2 执行脚本创建表</h5><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/soft/DolphinScheduler-bin/script</span><br><span class="line">sh create-dolphinscheduler.sh</span><br></pre></td></tr></table></figure><h5 id="3-3-启动zk-如果是多节点，每一节点中都需要启动"><a href="#3-3-启动zk-如果是多节点，每一节点中都需要启动" class="headerlink" title="3.3 启动zk  如果是多节点，每一节点中都需要启动"></a>3.3 启动zk  如果是多节点，每一节点中都需要启动</h5><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><h4 id="4-一键部署"><a href="#4-一键部署" class="headerlink" title="4 一键部署"></a>4 一键部署</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sh install.sh</span><br></pre></td></tr></table></figure><p>安装好之后可以到&#x2F;usr&#x2F;local&#x2F;soft&#x2F;dolphinscheduler&#x2F;log查看日志</p><h4 id="5-访问dolphinscheduler"><a href="#5-访问dolphinscheduler" class="headerlink" title="5 访问dolphinscheduler"></a>5 访问dolphinscheduler</h4><p>用户名：admin ， 密码：dolphinscheduler123</p><p><a href="http://192.168.129.201:12345/dolphinscheduler">http://192.168.129.201:12345/dolphinscheduler</a></p><h4 id="6-使用dolphinscheduler"><a href="#6-使用dolphinscheduler" class="headerlink" title="6 使用dolphinscheduler"></a>6 使用dolphinscheduler</h4><p>1 创建root租户–用于执行脚本的用户（权限）<br>2 将租户赋权给admin用户<br>3 创建项目<br>4 创建流程</p>]]></content>
    
    
    <summary type="html">对搭建DolphinScheduler的笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="DolphinScheduler" scheme="http://example.com/tags/DolphinScheduler/"/>
    
  </entry>
  
  <entry>
    <title>spark参数优化</title>
    <link href="http://example.com/2022/07/31/spark%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/07/31/spark%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/</id>
    <published>2022-07-30T16:00:00.000Z</published>
    <updated>2022-08-10T02:57:04.733Z</updated>
    
    <content type="html"><![CDATA[<h3 id="spark参数优化"><a href="#spark参数优化" class="headerlink" title="spark参数优化"></a>spark参数优化</h3><h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">--num-executors<span class="comment"># executor的数量</span></span><br><span class="line">--executor-memory<span class="comment"># 每一个executor的内存</span></span><br><span class="line">--executor-cores<span class="comment"># 每一个executor的核心数</span></span><br><span class="line">--driver-memory<span class="comment"># Driver的内存1G-2G(保存广播变量)</span></span><br><span class="line">--spark.storage.memoryFraction<span class="comment"># 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle</span></span><br><span class="line">--spark.shuffle.memoryFraction<span class="comment"># 用户shuffle的内存占比默认0.2</span></span><br></pre></td></tr></table></figure><p>总的内存&#x3D;num-executors<em>executor-memory<br>总的核数&#x3D;num-executors</em>executor-cores</p><h4 id="spark-on-yarn-资源设置标准"><a href="#spark-on-yarn-资源设置标准" class="headerlink" title="spark on yarn 资源设置标准"></a>spark on yarn 资源设置标准</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、单个任务总的内存和总的核数一般做多在yarn总资源的1/3到1/2之间</span><br><span class="line">比如公司集群有10太服务器</span><br><span class="line">单台服务器内存是128G,核数是40</span><br><span class="line">yarn总的内存=10*128G=1280G*0.8=960G   需要预留一般分内存给系统进程</span><br><span class="line">yarn总的核数=40*10=400</span><br><span class="line"></span><br><span class="line">提交单个spark任务资源上线</span><br><span class="line">总的内存=960G *(1/3| 1/2) = 300G-500G</span><br><span class="line">总的核数=400 * (1/3| 1/2) = 120 - 200</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 在上线内再按照需要处理的数据量来合理指定资源，最理想的情况是一个task对应一个core</span><br><span class="line"></span><br><span class="line">2.1 数据量比较小 比如10G</span><br><span class="line">10G = 80个block = rdd80分区 = 80个task</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最理想资源指定,剩余资源充足</span></span><br><span class="line">--num-executors=40</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"><span class="comment"># 资源里面最优的方式,剩余资源不是很充足时</span></span><br><span class="line">--num-executors=20</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"></span><br><span class="line">2.2 数据量比较大时 比如80G</span><br><span class="line">80G = 640block = 640分区 = 640task</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最理想资源指定,剩余资源充足, 如果剩余资源不够，还需要减少指定的资源</span></span><br><span class="line">--num-executors=100</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"></span><br><span class="line">--spark.locality.wait: spark task<span class="comment"># 再executor中执行前的等待时间 默认3秒</span></span><br><span class="line">--spark.yarn.executor.memoryOverhead<span class="comment"># 堆外内存 默认等于堆内存的10%</span></span><br><span class="line">--spark.network.timeout<span class="comment"># spark网络链接的超时时间 默认120s</span></span><br></pre></td></tr></table></figure><h4 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">spark-submit </span><br><span class="line">--master yarn-cluster</span><br><span class="line">--num-executors = 50</span><br><span class="line">--executor-memory = 4G</span><br><span class="line">--executor-cores = 2</span><br><span class="line">--driver-memory = 2G</span><br><span class="line">--conf spark.storage.memoryFraction=0.4</span><br><span class="line">--conf spark.shuffle.memoryFraction=0.4</span><br><span class="line">--conf spark.locality.wait=10s</span><br><span class="line">--conf spark.shuffle.file.buffer=64kb</span><br><span class="line">--conf spark.yarn.executor.memoryOverhead=1024</span><br><span class="line">--conf spark.network.timeout=200s</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习spark参数优化的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>项目总结</title>
    <link href="http://example.com/2022/07/28/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2022/07/28/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/</id>
    <published>2022-07-27T16:00:00.000Z</published>
    <updated>2022-08-10T02:59:37.834Z</updated>
    
    <content type="html"><![CDATA[<h2 id="项目总结"><a href="#项目总结" class="headerlink" title="项目总结"></a>项目总结</h2><h3 id="1-数据仓库搭建"><a href="#1-数据仓库搭建" class="headerlink" title="1 数据仓库搭建"></a>1 数据仓库搭建</h3><h4 id="1-1-开启hdfs的权限认证，-以及ACL认证"><a href="#1-1-开启hdfs的权限认证，-以及ACL认证" class="headerlink" title="1.1 开启hdfs的权限认证， 以及ACL认证"></a>1.1 开启hdfs的权限认证， 以及ACL认证</h4><ol><li><p>普通权限认证只能控制到当前用户，当前用户所属的组，其它用户，不能精确到每一个其它用户</p></li><li><p>ACL可以做到每一个用户权限认证</p></li></ol><blockquote><p>rwx r-x r-x<br>第一部分是当前用户的权限<br>第二部分是当前用户所在组的权限<br>第三部分其它用户的权限</p><p>Failed to move to trash: hdfs:&#x2F;&#x2F;master:9000&#x2F;data: Permission denied: user&#x3D;test, access&#x3D;WRITE, inode&#x3D;”&#x2F;“:root:supergroup:drwxr-xr<br>-x</p><p>用户test对&#x2F;这个目录没有权限，需要WRITE</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 修改hdfs-site.xml文件，将权限认证打开</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.acls.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是分布式集群需要同步配置文件，同步到所有节点</span></span><br><span class="line">scp hdfs-site.xml node1:`pwd`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启hadoop</span></span><br><span class="line">stop-all.sh</span><br><span class="line">start-all.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加权限的命令</span></span><br><span class="line">hadoop dfs -chmod 755 /user</span><br><span class="line">755: 其它用户可以读取，不能修改</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将hdfstmp的目录权限给所有的用户</span></span><br><span class="line">hadoop dfs -chmod -R 777 /tmp</span><br><span class="line"></span><br><span class="line">hadoop dfs -mkdir -p  /data/gender_num</span><br><span class="line">hadoop dfs -chmod 700 /data/gender_num</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">acl设置权限</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以单独为每一个用户设置权限</span></span><br><span class="line">hdfs dfs -setfacl -R -m user:shujia:r-x /data/gender_num</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">acl删除权限</span></span><br><span class="line">hdfs dfs -setfacl -R -x user:shujia /data/gender_num</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看权限</span></span><br><span class="line">hdfs dfs -getfacl /data/gender_num</span><br></pre></td></tr></table></figure><h4 id="1-2-为每一个层创建一个用户"><a href="#1-2-为每一个层创建一个用户" class="headerlink" title="1.2 为每一个层创建一个用户"></a>1.2 为每一个层创建一个用户</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd ods</span><br><span class="line">passwd ods</span><br><span class="line"></span><br><span class="line">useradd dwd</span><br><span class="line">passwd dwd</span><br><span class="line"></span><br><span class="line">useradd dws</span><br><span class="line">passwd dws</span><br><span class="line"></span><br><span class="line">useradd dim</span><br><span class="line">passwd dim</span><br><span class="line"></span><br><span class="line">useradd ads</span><br><span class="line">passwd ads</span><br></pre></td></tr></table></figure><h4 id="1-3-为每一个层创建一个hive的库"><a href="#1-3-为每一个层创建一个hive的库" class="headerlink" title="1.3 为每一个层创建一个hive的库"></a>1.3 为每一个层创建一个hive的库</h4><p>开启hive元数据服务</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span>  hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">create database ods;</span><br><span class="line">create database dwd;</span><br><span class="line">create database dws;</span><br><span class="line">create database dim;</span><br><span class="line">create database ads;</span><br></pre></td></tr></table></figure><h4 id="1-4-为每一个层在hdfs中创建一个目录"><a href="#1-4-为每一个层在hdfs中创建一个目录" class="headerlink" title="1.4 为每一个层在hdfs中创建一个目录"></a>1.4 为每一个层在hdfs中创建一个目录</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop dfs -<span class="built_in">mkdir</span> -p /daas/motl/ods</span><br><span class="line">hadoop dfs -<span class="built_in">mkdir</span> -p /daas/motl/dwd</span><br><span class="line">hadoop dfs -<span class="built_in">mkdir</span> -p /daas/motl/dws</span><br><span class="line">hadoop dfs -<span class="built_in">mkdir</span> -p /daas/motl/dim</span><br><span class="line">hadoop dfs -<span class="built_in">mkdir</span> -p /daas/motl/ads</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改权限</span></span><br><span class="line">hadoop dfs -<span class="built_in">chown</span> ods:ods /daas/motl/ods</span><br><span class="line">hadoop dfs -<span class="built_in">chown</span> dwd:dwd /daas/motl/dwd</span><br><span class="line">hadoop dfs -<span class="built_in">chown</span> dws:dws /daas/motl/dws</span><br><span class="line">hadoop dfs -<span class="built_in">chown</span> dim:dim /daas/motl/dim</span><br><span class="line">hadoop dfs -<span class="built_in">chown</span> ads:ads /daas/motl/ads</span><br><span class="line"></span><br><span class="line">hadoop dfs -<span class="built_in">chmod</span> 750 /daas/motl/ods</span><br><span class="line">hadoop dfs -<span class="built_in">chmod</span> 750 /daas/motl/dwd</span><br><span class="line">hadoop dfs -<span class="built_in">chmod</span> 750 /daas/motl/dws</span><br><span class="line">hadoop dfs -<span class="built_in">chmod</span> 750 /daas/motl/dim</span><br><span class="line">hadoop dfs -<span class="built_in">chmod</span> 750 /daas/motl/ads</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个层只有自己可以读写，其它用户没有读写权限，如果其它用户需要使用某一个层的数据，可以开通权限</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="1-5-解决hive-tmp目录权限不够问题"><a href="#1-5-解决hive-tmp目录权限不够问题" class="headerlink" title="1.5 解决hive tmp目录权限不够问题"></a>1.5 解决hive tmp目录权限不够问题</h4><p>1、修改hive-site.xml文件</p><p>删除以下三行配置的value</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2、替换spark中的hive-site.xml文件</p><p>cp &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hive-1.2.1&#x2F;conf&#x2F;hive-site.xml &#x2F;usr&#x2F;local&#x2F;soft&#x2F;spark-2.4.5&#x2F;conf&#x2F;</p><h4 id="1-6-测试"><a href="#1-6-测试" class="headerlink" title="1.6 测试"></a>1.6 测试</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">-- 使用ods用户进入hive测试</span></span><br><span class="line"><span class="comment">-- 切换到ods用户进入hive中创建表</span></span><br><span class="line"><span class="comment">-- 使用ods登录服务器</span></span><br><span class="line">ssh ods<span class="variable">@192</span><span class="number">.168</span><span class="number">.129</span><span class="number">.201</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 进入hive创建表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> ods.student</span><br><span class="line">(</span><br><span class="line">id  string,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span>,</span><br><span class="line">gender string,</span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/daas/motl/ods/student/&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 上传数据 需要使用ods用户上传数据</span></span><br><span class="line">hadoop dfs <span class="operator">-</span>put students.txt <span class="operator">/</span>daas<span class="operator">/</span>motl<span class="operator">/</span>ods<span class="operator">/</span>student</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 登录到dwd用户</span></span><br><span class="line">ssh dwd<span class="variable">@192</span><span class="number">.168</span><span class="number">.129</span><span class="number">.201</span></span><br><span class="line"><span class="comment">--  其它用户需要使用这个额表的时候设置权限</span></span><br><span class="line"><span class="comment">-- 需要使用ods这个用户来给dwd这个用户开通权限</span></span><br><span class="line"><span class="comment">-- 开通ods层的权限</span></span><br><span class="line">hdfs dfs <span class="operator">-</span>setfacl <span class="operator">-</span>m <span class="keyword">user</span>:dwd:r<span class="operator">-</span>x <span class="operator">/</span>daas<span class="operator">/</span>motl<span class="operator">/</span>ods</span><br><span class="line"></span><br><span class="line">hdfs dfs <span class="operator">-</span>setfacl <span class="operator">-</span>R <span class="operator">-</span>m <span class="keyword">user</span>:dwd:r<span class="operator">-</span>x <span class="operator">/</span>daas<span class="operator">/</span>motl<span class="operator">/</span>ods<span class="operator">/</span>student<span class="operator">/</span></span><br></pre></td></tr></table></figure><h3 id="2-数据采集"><a href="#2-数据采集" class="headerlink" title="2 数据采集"></a>2 数据采集</h3><h4 id="2-1-数据导入前置数据库"><a href="#2-1-数据导入前置数据库" class="headerlink" title="2.1 数据导入前置数据库"></a>2.1 数据导入前置数据库</h4><h5 id="t-fcj-nwrs-sellbargain-购房合同表"><a href="#t-fcj-nwrs-sellbargain-购房合同表" class="headerlink" title="t_fcj_nwrs_sellbargain  购房合同表"></a>t_fcj_nwrs_sellbargain  购房合同表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 在mysql中创建表导入数据</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span>  t_fcj_nwrs_sellbargain(</span><br><span class="line">    id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;身份证号码&#x27;</span>,</span><br><span class="line">    r_fwzl <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;房产地址&#x27;</span>,</span><br><span class="line">    htydjzmj <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;合同中约定房子面积&#x27;</span>,</span><br><span class="line">    tntjzmj <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;房子内建筑面积&#x27;</span>,</span><br><span class="line">    ftmj <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;房子分摊建筑面积&#x27;</span>,</span><br><span class="line">    time_tjba <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;商品房备案时间&#x27;</span>,</span><br><span class="line">    htzj <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;合同总价&#x27;</span></span><br><span class="line">);</span><br><span class="line"><span class="comment">--导入数据</span></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\t_fcj_nwrs_sellbargain.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_fcj_nwrs_sellbargain FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h5 id="t-ga-hjxx-czrkjbxx-：-人口户籍表"><a href="#t-ga-hjxx-czrkjbxx-：-人口户籍表" class="headerlink" title="t_ga_hjxx_czrkjbxx  ： 人口户籍表"></a>t_ga_hjxx_czrkjbxx  ： 人口户籍表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span>  <span class="keyword">TABLE</span>  t_ga_hjxx_czrkjbxx(</span><br><span class="line">GMSFHM         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;公民身份号码&#x27;</span>,</span><br><span class="line">QFJG           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;签发机关&#x27;</span>,</span><br><span class="line">YXQXQSRQ       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;有效期限起始日期&#x27;</span>,</span><br><span class="line">YXQXJZRQ       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;有效期限截止日期&#x27;</span>,</span><br><span class="line">XM             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;姓名&#x27;</span>,</span><br><span class="line">CYM            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;曾用名&#x27;</span>,</span><br><span class="line">XMPY           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;姓名拼音&#x27;</span>,</span><br><span class="line">CYMPY          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;曾用名拼音&#x27;</span>,</span><br><span class="line">XB             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;性别&#x27;</span>,</span><br><span class="line">MZ             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;民族&#x27;</span>,</span><br><span class="line">CSRQ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生日期&#x27;</span>,</span><br><span class="line">CSSJ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生时间&#x27;</span>,</span><br><span class="line">CSDGJDQ        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生地国家（地区）&#x27;</span>,</span><br><span class="line">CSDSSXQ        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生地省市县（区）&#x27;</span>,</span><br><span class="line">CSDXZ          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生地详址&#x27;</span>,</span><br><span class="line">DHHM           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;电话号码&#x27;</span>,</span><br><span class="line">JHRYXM         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人一姓名&#x27;</span>,</span><br><span class="line">JHRYGMSFHM     <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人一公民身份号码&#x27;</span>,</span><br><span class="line">JHRYJHGX       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人一监护关系&#x27;</span>,</span><br><span class="line">JHREXM         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人二姓名&#x27;</span>,</span><br><span class="line">JHREGMSFHM     <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人二公民身份号码&#x27;</span>,</span><br><span class="line">JHREJHGX       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;监护人二监护关系&#x27;</span>,</span><br><span class="line">FQXM           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;父亲姓名&#x27;</span>,</span><br><span class="line">FQGMSFHM       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;父亲公民身份号码&#x27;</span>,</span><br><span class="line">MQXM           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;母亲姓名&#x27;</span>,</span><br><span class="line">MQGMSFHM       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;母亲公民身份号码&#x27;</span>,</span><br><span class="line">POXM           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;配偶姓名&#x27;</span>,</span><br><span class="line">POGMSFHM       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;配偶公民身份号码&#x27;</span>,</span><br><span class="line">JGGJDQ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;籍贯国家（地区）&#x27;</span>,</span><br><span class="line">JGSSXQ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;籍贯省市县（区）&#x27;</span>,</span><br><span class="line">ZJXY           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;宗教信仰&#x27;</span>,</span><br><span class="line">WHCD           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;文化程度&#x27;</span>,</span><br><span class="line">HYZK           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;婚姻状况&#x27;</span>,</span><br><span class="line">BYZK           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;兵役状况&#x27;</span>,</span><br><span class="line">SG             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;身高&#x27;</span>,</span><br><span class="line">XX             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;血型&#x27;</span>,</span><br><span class="line">ZY             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;职业&#x27;</span>,</span><br><span class="line">ZYLB           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;职业类别&#x27;</span>,</span><br><span class="line">FWCS           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;服务处所&#x27;</span>,</span><br><span class="line">XXJB           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;信息级别&#x27;</span>,</span><br><span class="line">HSQL           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何时迁来&#x27;</span>,</span><br><span class="line">HYQL           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何因迁来&#x27;</span>,</span><br><span class="line">HGJDQQL        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何国家（地区）迁来&#x27;</span>,</span><br><span class="line">HSSXQQL        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何省市县（区）迁来&#x27;</span>,</span><br><span class="line">HXZQL          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何详址迁来&#x27;</span>,</span><br><span class="line">HSLBZ          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何时来本址&#x27;</span>,</span><br><span class="line">HYLBZ          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何因来本址&#x27;</span>,</span><br><span class="line">HGJDQLBZ       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何国家（地区）来本址&#x27;</span>,</span><br><span class="line">HSSSQLBZ       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何省市县（区）来本址&#x27;</span>,</span><br><span class="line">HXZLBZ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;何详址来本址&#x27;</span>,</span><br><span class="line">SWRQ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;死亡日期&#x27;</span>,</span><br><span class="line">SWZXLB         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;死亡注销类别&#x27;</span>,</span><br><span class="line">SWZXRQ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;死亡注销日期&#x27;</span>,</span><br><span class="line">QCRQ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;迁出日期&#x27;</span>,</span><br><span class="line">QCZXLB         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;迁出注销类别&#x27;</span>,</span><br><span class="line">QWDGJDQ        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;迁往地国家（地区）&#x27;</span>,</span><br><span class="line">QWDSSXQ        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;迁往地省市县（区）&#x27;</span>,</span><br><span class="line">QWDXZ          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;迁往地详址&#x27;</span>,</span><br><span class="line">CSZMBH         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生证明编号&#x27;</span>,</span><br><span class="line">CSZQFRQ        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;出生证签发日期&#x27;</span>,</span><br><span class="line">HYLB           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;行业类别&#x27;</span>,</span><br><span class="line">QTSSXQ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;其他省市县（区）&#x27;</span>,</span><br><span class="line">QTZZ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;其他住址&#x27;</span>,</span><br><span class="line">RYLB           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;人员类别&#x27;</span>,</span><br><span class="line">HB             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;户别&#x27;</span>,</span><br><span class="line">YHZGX          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;与户主关系&#x27;</span>,</span><br><span class="line">RYZT           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;人员状态&#x27;</span>,</span><br><span class="line">RYSDZT         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;人员锁定状态&#x27;</span>,</span><br><span class="line">LXDBID         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;离线DBID&#x27;</span>,</span><br><span class="line">BZ             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;备注&#x27;</span>,</span><br><span class="line">JLBZ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;记录标志&#x27;</span>,</span><br><span class="line">YWNR           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;业务内容&#x27;</span>,</span><br><span class="line">CJHJYWID       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;创建户籍业务ID&#x27;</span>,</span><br><span class="line">CCHJYWID       <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;撤除户籍业务ID&#x27;</span>,</span><br><span class="line">QYSJ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;起用时间&#x27;</span>,</span><br><span class="line">JSSJ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;结束时间&#x27;</span>,</span><br><span class="line">CXBZ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;冲销标志&#x27;</span>,</span><br><span class="line">JLX            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;街路巷&#x27;</span>,</span><br><span class="line">MLPH           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;门（楼）牌号&#x27;</span>,</span><br><span class="line">MLXZ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;门（楼）详址&#x27;</span>,</span><br><span class="line">PCS            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;派出所&#x27;</span>,</span><br><span class="line">ZRQ            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;责任区&#x27;</span>,</span><br><span class="line">XZJD           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;乡镇（街道）&#x27;</span>,</span><br><span class="line">JCWH           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;居（村）委会&#x27;</span>,</span><br><span class="line">PXH            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;排序号&#x27;</span>,</span><br><span class="line">MLPID          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;门（楼）牌ID&#x27;</span>,</span><br><span class="line">SSXQ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;省市县（区）&#x27;</span>,</span><br><span class="line">HH             <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;户号&#x27;</span>,</span><br><span class="line">HLX            <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;户类型&#x27;</span>,</span><br><span class="line">HHID           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;户号ID&#x27;</span>,</span><br><span class="line">BDFW           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;变动范围&#x27;</span>,</span><br><span class="line">XXQYSJ         <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;信息启用时间&#x27;</span>,</span><br><span class="line">DHHM2          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;电话号码2&#x27;</span>,</span><br><span class="line">GXSJ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;更新时间戳&#x27;</span>,</span><br><span class="line">ZXSJ           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;死亡，注销的注销时间&#x27;</span>,</span><br><span class="line">CRYNBID        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;人员nbidchar&#x27;</span>,</span><br><span class="line">CGMSFHM        <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;身份号码2&#x27;</span>,</span><br><span class="line">GXSJD          <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;日期格式更新时间&#x27;</span>,</span><br><span class="line">ZJLB           <span class="type">varchar</span>(<span class="number">200</span>)  comment<span class="string">&#x27;证件类别&#x27;</span>,</span><br><span class="line">last_modiy <span class="type">TIMESTAMP</span> <span class="keyword">DEFAULT</span> <span class="built_in">CURRENT_TIMESTAMP</span> <span class="keyword">ON</span> <span class="keyword">UPDATE</span> <span class="built_in">CURRENT_TIMESTAMP</span></span><br><span class="line"> );</span><br><span class="line"></span><br><span class="line"><span class="comment">--导入数据</span></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\T_GA_HJXX_CZRKJBXX1.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_ga_hjxx_czrkjbxx FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h5 id="t-gjj-sspersons-：公积金缴存表"><a href="#t-gjj-sspersons-：公积金缴存表" class="headerlink" title="t_gjj_sspersons ：公积金缴存表"></a>t_gjj_sspersons ：公积金缴存表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span>  <span class="keyword">TABLE</span>  t_gjj_sspersons(</span><br><span class="line">spcode <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;职工内码&#x27;</span>,</span><br><span class="line">hjstatus <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;缴汇状态&#x27;</span>,</span><br><span class="line">sncode <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;单位代码&#x27;</span>,</span><br><span class="line">spname <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;个人姓名&#x27;</span>,</span><br><span class="line">id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;身份证&#x27;</span>,</span><br><span class="line">spcard <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;卡号&#x27;</span>,</span><br><span class="line">sppassword <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;口令&#x27;</span>,</span><br><span class="line">zjfdm <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;助记符代码&#x27;</span>,</span><br><span class="line">spkhrq <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;开户日期&#x27;</span>,</span><br><span class="line">spperm <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;起缴年月&#x27;</span>,</span><br><span class="line">spgz <span class="type">decimal</span> comment <span class="string">&#x27;工资基数&#x27;</span>,</span><br><span class="line">spsingl <span class="type">decimal</span>  comment <span class="string">&#x27;职工缴交率&#x27;</span>,</span><br><span class="line">spjcbl <span class="type">decimal</span>  comment <span class="string">&#x27;单位缴交率&#x27;</span>,</span><br><span class="line">spmfact <span class="type">decimal</span>  comment <span class="string">&#x27;月缴额&#x27;</span>,</span><br><span class="line">spmfactzg <span class="type">decimal</span>  comment <span class="string">&#x27;职工月缴额&#x27;</span>,</span><br><span class="line">spjym <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;最后缴年月&#x27;</span>,</span><br><span class="line">ncye  <span class="type">decimal</span> comment <span class="string">&#x27;年初余额&#x27;</span>,</span><br><span class="line">splast  <span class="type">decimal</span> comment <span class="string">&#x27;定期余额&#x27;</span>,</span><br><span class="line">dwbfye  <span class="type">decimal</span> comment <span class="string">&#x27;余额单位部分&#x27;</span>,</span><br><span class="line">grbfye  <span class="type">decimal</span> comment <span class="string">&#x27;余额职工部分&#x27;</span>,</span><br><span class="line">spmend  <span class="type">decimal</span> comment <span class="string">&#x27;余额&#x27;</span>,</span><br><span class="line">splastlx  <span class="type">decimal</span> comment <span class="string">&#x27;年初利息&#x27;</span>,</span><br><span class="line">spout  <span class="type">decimal</span> comment <span class="string">&#x27;年内总支出&#x27;</span>,</span><br><span class="line">spin  <span class="type">decimal</span> comment <span class="string">&#x27;年内总收入&#x27;</span>,</span><br><span class="line">bnlx <span class="type">decimal</span>  comment <span class="string">&#x27;活期利息积数&#x27;</span>,</span><br><span class="line">nclx <span class="type">decimal</span>  comment <span class="string">&#x27;定期利息积数&#x27;</span>,</span><br><span class="line">dwhjny <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;单位汇缴年月&#x27;</span>,</span><br><span class="line">zghjny <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;职工汇缴年月&#x27;</span>,</span><br><span class="line">btyje  <span class="type">decimal</span> comment <span class="string">&#x27;补贴月缴额&#x27;</span>,</span><br><span class="line">btye  <span class="type">decimal</span> comment <span class="string">&#x27;余额补贴部分&#x27;</span>,</span><br><span class="line">btbl <span class="type">decimal</span>  comment <span class="string">&#x27;补贴计缴比例&#x27;</span>,</span><br><span class="line">bthjny <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;补贴汇缴年月&#x27;</span>,</span><br><span class="line">spxh <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;销户标志&#x27;</span>,</span><br><span class="line">spzy <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;转移标志&#x27;</span>,</span><br><span class="line">spxhrq <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;销户日期&#x27;</span>,</span><br><span class="line">splr <span class="type">decimal</span>  comment <span class="string">&#x27;录入员&#x27;</span>,</span><br><span class="line">spoldbankno <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;原帐号&#x27;</span>,</span><br><span class="line">spdk <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;是否贷款&#x27;</span>,</span><br><span class="line">spdy <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;是否抵押&#x27;</span>,</span><br><span class="line">zhdj <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;帐户冻结&#x27;</span>,</span><br><span class="line">spnote <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;备注&#x27;</span>,</span><br><span class="line">modifytime <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;最后修改时间&#x27;</span>,</span><br><span class="line">status <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;联名卡状态&#x27;</span>,</span><br><span class="line">cbank <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;联名卡发卡银行&#x27;</span>,</span><br><span class="line">bcyje  <span class="type">decimal</span> comment <span class="string">&#x27;补充月缴额&#x27;</span>,</span><br><span class="line">bcye  <span class="type">decimal</span> comment <span class="string">&#x27;余额补充&#x27;</span>,</span><br><span class="line">bcbl <span class="type">decimal</span>  comment <span class="string">&#x27;补充计缴比例&#x27;</span>,</span><br><span class="line">bchjny <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27; 补充最后汇款年月&#x27;</span>,</span><br><span class="line">zjzl <span class="type">decimal</span>  comment <span class="string">&#x27;缴存资金种类&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\T_GJJ_SSPERSONS.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_gjj_sspersons FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h5 id="t-gsj-reg-investor-：-工商股东名录"><a href="#t-gsj-reg-investor-：-工商股东名录" class="headerlink" title="t_gsj_reg_investor ： 工商股东名录"></a>t_gsj_reg_investor ： 工商股东名录</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_gsj_reg_investor(</span><br><span class="line">id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;证件编号&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入数据</span></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\T_GSJ_REG_INVESTOR.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_gsj_reg_investor FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h5 id="t-gsj-reg-legrepre：-工商法定代表人"><a href="#t-gsj-reg-legrepre：-工商法定代表人" class="headerlink" title="t_gsj_reg_legrepre： 工商法定代表人"></a>t_gsj_reg_legrepre： 工商法定代表人</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_gsj_reg_legrepre(</span><br><span class="line">id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;证件编号&#x27;</span>,</span><br><span class="line">position <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;职务&#x27;</span>,</span><br><span class="line">tel <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;联系电话&#x27;</span>,</span><br><span class="line">appounit <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;任免机构&#x27;</span>,</span><br><span class="line">accdside <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;派出单位&#x27;</span>,</span><br><span class="line">posbrmode <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;产生方式&#x27;</span>,</span><br><span class="line">offhfrom <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;任职期限起&#x27;</span>,</span><br><span class="line">offhto <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;任职期限止&#x27;</span>,</span><br><span class="line">stufftype <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;资料类型代码&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\T_GSJ_REG_LEGREPRE.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_gsj_reg_legrepre FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h5 id="t-rs-zhcs-az01bsbkxx：-社保卡信息表"><a href="#t-rs-zhcs-az01bsbkxx：-社保卡信息表" class="headerlink" title="t_rs_zhcs_az01bsbkxx： 社保卡信息表"></a>t_rs_zhcs_az01bsbkxx： 社保卡信息表</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span>  <span class="keyword">TABLE</span>  t_rs_zhcs_az01bsbkxx(</span><br><span class="line">id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;身份证号&#x27;</span>,</span><br><span class="line">citty_id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;城市代码&#x27;</span>,</span><br><span class="line">ss_id <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;社保卡号&#x27;</span>,</span><br><span class="line">fkrq <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;发卡日期&#x27;</span>,</span><br><span class="line">yxqz <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;有效期至&#x27;</span>,</span><br><span class="line">aaz502 <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;卡状态&#x27;</span>,</span><br><span class="line">aae008 <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;开户银行&#x27;</span>,</span><br><span class="line">aae008b <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;银行网点&#x27;</span>,</span><br><span class="line">aae010 <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;金融卡号&#x27;</span>,</span><br><span class="line">aae010a <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;金融帐户&#x27;</span>,</span><br><span class="line">aae010b <span class="type">varchar</span>(<span class="number">255</span>) comment <span class="string">&#x27;个人帐户&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">LOAD DATA <span class="keyword">local</span>  INFILE <span class="string">&#x27;C:\\Users\\qx\\\Desktop\\data\\T_RS_ZHCS_AZ01BSBKXX.csv&#x27;</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> pre.t_rs_zhcs_az01bsbkxx FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> ;</span><br></pre></td></tr></table></figure><h4 id="2-2-从前置数据库中采集数据"><a href="#2-2-从前置数据库中采集数据" class="headerlink" title="2.2 从前置数据库中采集数据"></a>2.2 从前置数据库中采集数据</h4><p>将hdfsuser这个目录的权限放开,使用root用户放开权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">回收站权限</span></span><br><span class="line">hadoop dfs -chmod 777 /user</span><br></pre></td></tr></table></figure><p>将ods层表的权限给dwd层</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用ods用户增加权限</span></span><br><span class="line">hdfs dfs -setfacl -m user:dwd:r-x /daas/motl/ods</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">按照需求给表增加权限 -R给里面的分区也增加权限</span></span><br><span class="line">hdfs dfs -setfacl -R -m user:dwd:r-x /daas/motl/ods/ods_t_fcj_nwrs_sellbargain</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>将dwd层表的权限给dws</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hdfs dfs -setfacl -m user:dws:r-x /daas/motl/dwd</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_fcj_nwrs_sellbargain_msk_d</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_ga_hjxx_czrkjbxx_msk_d</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_gjj_sspersons_msk_d</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_gsj_reg_investor_msk_d</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_gsj_reg_legrepre_msk_d</span><br><span class="line"></span><br><span class="line">hdfs dfs -setfacl -R -m user:dws:r-x /daas/motl/dwd/dwd_rs_zhcs_az01bsbkxx_msk_d</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取脚本所在的位置</span></span><br><span class="line">shell_home=<span class="string">&quot;<span class="subst">$( cd <span class="string">&quot;<span class="subst">$( dirname <span class="string">&quot;<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>&quot;</span> )</span>&quot;</span> &amp;&amp; pwd )</span>&quot;</span></span><br><span class="line"><span class="comment"># 切换</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$shell_home</span></span><br></pre></td></tr></table></figure><p>将dwd层人口户籍表的权限给dim</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs dfs -setfacl -m user:dim:r-x /daas/motl/dwd</span><br><span class="line">hdfs dfs -setfacl -R -m user:dim:r-x /daas/motl/dwd/dwd_ga_hjxx_czrkjbxx_msk_d</span><br></pre></td></tr></table></figure><p>将dws层和dim层的表授权给ads</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#dws用户给权限</span><br><span class="line">hdfs dfs -setfacl -m user:ads:r-x /daas/motl/dws</span><br><span class="line">hdfs dfs -setfacl -R -m user:ads:r-x /daas/motl/dws/dws_population_property_info_msk_d</span><br><span class="line"></span><br><span class="line">#dim用户给权限</span><br><span class="line">hdfs dfs -setfacl -m user:ads:r-x /daas/motl/dim</span><br><span class="line">hdfs dfs -setfacl -R -m user:ads:r-x /daas/motl/dim/dim_user_info_d</span><br></pre></td></tr></table></figure><h3 id="3-ods层"><a href="#3-ods层" class="headerlink" title="3 ods层"></a>3 ods层</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使用datax从前置数据库中采集数据</span><br><span class="line">采集数据分为全量和增量两种</span><br><span class="line">增量数据采集：1、表中由数据更新时间字段 2、数据量比较大</span><br><span class="line">全量量数据采集：数据量比较小的表可以直接采用增量数据采集，两个一个分区，在hdfs每天一个目录</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;errorLimit&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;record&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;root&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123456&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="string">&quot;id&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;r_fwzl&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;htydjzmj&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;tntjzmj&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;ftmj&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;time_tjba&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;htzj&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                  <span class="string">&quot;t_fcj_nwrs_sellbargain&quot;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                  <span class="string">&quot;jdbc:mysql://master:3306/pre&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">              <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfswriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://master:9000&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/daas/motl/ods/ods_t_fcj_nwrs_sellbargain/ds=$&#123;ds&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fileName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;xxxx&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;r_fwzl&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;htydjzmj&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tntjzmj&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ftmj&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;time_tjba&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;htzj&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;STRING&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;append&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="4-dwd层"><a href="#4-dwd层" class="headerlink" title="4 dwd层"></a>4 dwd层</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 让环境变量生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># shellcheck disable=SC2034</span></span><br><span class="line"><span class="comment"># 获取脚本所在的位置</span></span><br><span class="line">shell_home=<span class="string">&quot;<span class="subst">$( cd <span class="string">&quot;<span class="subst">$( dirname <span class="string">&quot;<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>&quot;</span> )</span>&quot;</span> &amp;&amp; pwd )</span>&quot;</span></span><br><span class="line"><span class="comment"># shellcheck disable=SC2164</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$shell_home</span></span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hzh.dwd</span><br><span class="line"><span class="keyword">import</span> com.hzh.common.<span class="type">SparkTool</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DwdFcjNwrsSellbargainMskDay</span> <span class="keyword">extends</span> <span class="title">SparkTool</span></span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 抽象方法</span></span><br><span class="line"><span class="comment">   * import org.apache.spark.sql.functions._</span></span><br><span class="line"><span class="comment">   * import spark.implicits._</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(spark: <span class="type">SparkSession</span>, ds: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取hive中购房合同表</span></span><br><span class="line"><span class="comment">     * 按照分区读取数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .table(<span class="string">&quot;ods.ods_t_fcj_nwrs_sellbargain&quot;</span>)</span><br><span class="line">      .where($<span class="string">&quot;ds&quot;</span> === ds)</span><br><span class="line">      .select(</span><br><span class="line">        upper(md5($<span class="string">&quot;id&quot;</span>)) as <span class="string">&quot;id&quot;</span>,</span><br><span class="line">        regexp_replace($<span class="string">&quot;r_fwzl&quot;</span>,<span class="string">&quot;\\d&quot;</span>,<span class="string">&quot;*&quot;</span>) as <span class="string">&quot;r_fwzl&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;htydjzmj&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;tntjzmj&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;ftmj&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;time_tjba&quot;</span>,</span><br><span class="line">        $<span class="string">&quot;htzj&quot;</span></span><br><span class="line">      )</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">      .save(<span class="string">s&quot;/daas/motl/dwd/dwd_fcj_nwrs_sellbargain_msk_d/ds=<span class="subst">$ds</span>&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hzh.common</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.internal.<span class="type">Logging</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkTool</span> <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、获取时间分区</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (args.length == <span class="number">0</span>) &#123;</span><br><span class="line">      logError(<span class="string">&quot;请指定分区&quot;</span>)</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//分区</span></span><br><span class="line">    <span class="keyword">val</span> ds: <span class="type">String</span> = args.head</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、创建spark环境</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .enableHiveSupport() <span class="comment">//开启元数据支持,开启之后可以在spark中去读hive的表，但是就不能在本地运行spark的代码</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用子类实现的抽象方法</span></span><br><span class="line">    <span class="keyword">this</span>.run(spark, ds)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * spark</span></span><br><span class="line"><span class="comment">      .table(&quot;ods.ods_t_fcj_nwrs_sellbargain&quot;)</span></span><br><span class="line"><span class="comment">      .where($&quot;ds&quot; === ds)</span></span><br><span class="line"><span class="comment">      .select(</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">      )</span></span><br><span class="line"><span class="comment">      .write</span></span><br><span class="line"><span class="comment">      .format(&quot;csv&quot;)</span></span><br><span class="line"><span class="comment">      .mode(SaveMode.Overwrite)</span></span><br><span class="line"><span class="comment">      .option(&quot;sep&quot;,&quot;\t&quot;)</span></span><br><span class="line"><span class="comment">      .save(s&quot;/daas/motl/dwd/dwd_fcj_nwrs_sellbargain_msk_d/ds=$ds&quot;)</span></span><br><span class="line"><span class="comment">   * 抽象方法</span></span><br><span class="line"><span class="comment">   * import org.apache.spark.sql.functions._</span></span><br><span class="line"><span class="comment">   * import spark.implicits._</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(spark: <span class="type">SparkSession</span>, ds: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分区</span></span><br><span class="line">ds=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 让环境变量生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># shellcheck disable=SC2034</span></span><br><span class="line"><span class="comment"># 获取脚本所在的位置</span></span><br><span class="line">shell_home=<span class="string">&quot;<span class="subst">$( cd <span class="string">&quot;<span class="subst">$( dirname <span class="string">&quot;<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>&quot;</span> )</span>&quot;</span> &amp;&amp; pwd )</span>&quot;</span></span><br><span class="line"><span class="comment"># shellcheck disable=SC2164</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$shell_home</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行任务</span></span><br><span class="line">spark-submit \</span><br><span class="line">--master yarn-client \</span><br><span class="line">--class com.hzh.dwd.DwdFcjNwrsSellbargainMskDay \</span><br><span class="line">--jars ../lib/common-1.0.jar \</span><br><span class="line">../target/dwd-1.0.jar \</span><br><span class="line"><span class="variable">$ds</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加分区</span></span><br><span class="line">hive -e <span class="string">&quot;alter table dwd.dwd_fcj_nwrs_sellbargain_msk_d add IF NOT EXISTS  partition (ds=&#x27;<span class="variable">$ds</span>&#x27;)&quot;</span></span><br></pre></td></tr></table></figure><h3 id="5-dws层"><a href="#5-dws层" class="headerlink" title="5 dws层"></a>5 dws层</h3><p>5.1 人口信息</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> dws.dws_population_property_info_msk_d <span class="keyword">partition</span>(ds<span class="operator">=</span>$&#123;ds&#125;)</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">a.id,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> b.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">end</span> sfyfc,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> b.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> b.sfyfc_num <span class="keyword">end</span> sfyfc_num,</span><br><span class="line">b.sfyfc_info <span class="keyword">as</span> sfyfc_info,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> c.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">end</span> sfygc,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> c.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> c.sfygc_num <span class="keyword">end</span> sfygc_num,</span><br><span class="line">c.sfygc_info <span class="keyword">as</span> sfygc_info,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> d.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">end</span> sywgd,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> d.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> d.sywgd_num <span class="keyword">end</span> sywgd_num,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> e.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">end</span> sfysb,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> e.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> e.sfysb_num <span class="keyword">end</span> sfysb_num,</span><br><span class="line">e.sfysb_info <span class="keyword">as</span> sfysb_info,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> f.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">end</span> sfygjj,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> f.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span> <span class="keyword">else</span> f.sfygjj_num <span class="keyword">end</span> sfygjj_num,</span><br><span class="line">f.sfygjj_info <span class="keyword">as</span> sfygjj_info</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span> id <span class="keyword">from</span> dwd.dwd_ga_hjxx_czrkjbxx_msk_d</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sfyfc_num,</span><br><span class="line">  to_json(</span><br><span class="line">    collect_list(</span><br><span class="line">      named_struct(</span><br><span class="line">        &quot;r_fwzl&quot;,r_fwzl,</span><br><span class="line">        &quot;htydjzmj&quot;,htydjzmj,</span><br><span class="line">        &quot;tntjzmj&quot;,tntjzmj,</span><br><span class="line">        &quot;ftmj&quot;,ftmj,</span><br><span class="line">        &quot;time_tjba&quot;,time_tjba,</span><br><span class="line">        &quot;htzj&quot;,htzj</span><br><span class="line">      ))) <span class="keyword">as</span> sfyfc_info</span><br><span class="line">  <span class="keyword">from</span> dwd.dwd_fcj_nwrs_sellbargain_msk_d</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sfygc_num,</span><br><span class="line">  to_json(</span><br><span class="line">    collect_list(</span><br><span class="line">      named_struct(</span><br><span class="line">        &quot;position&quot;,position,</span><br><span class="line">        &quot;tel&quot;,tel,</span><br><span class="line">        &quot;appounit&quot;,appounit,</span><br><span class="line">        &quot;accdside&quot;,accdside,</span><br><span class="line">        &quot;posbrmode&quot;,posbrmode,</span><br><span class="line">        &quot;offhfrom&quot;,offhfrom,</span><br><span class="line">        &quot;offhto&quot;,offhto,</span><br><span class="line">        &quot;stufftype&quot;,stufftype</span><br><span class="line">      ))) <span class="keyword">as</span> sfygc_info</span><br><span class="line">  <span class="keyword">from</span> dwd.dwd_gsj_reg_legrepre_msk_d</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> c</span><br><span class="line"><span class="keyword">on</span> a.id <span class="operator">=</span> c.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sywgd_num</span><br><span class="line">  <span class="keyword">from</span> dwd.dwd_gsj_reg_investor_msk_d</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> d</span><br><span class="line"><span class="keyword">on</span> a.id <span class="operator">=</span> d.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sfysb_num,</span><br><span class="line">  to_json(</span><br><span class="line">    collect_list(</span><br><span class="line">      named_struct(</span><br><span class="line">        &quot;citty_id&quot;,citty_id,</span><br><span class="line">        &quot;ss_id&quot;,ss_id,</span><br><span class="line">        &quot;fkrq&quot;,fkrq,</span><br><span class="line">        &quot;yxqz&quot;,yxqz,</span><br><span class="line">        &quot;aaz502&quot;,aaz502,</span><br><span class="line">        &quot;aae008&quot;,aae008,</span><br><span class="line">        &quot;aae008b&quot;,aae008b,</span><br><span class="line">        &quot;aae010&quot;,aae010,</span><br><span class="line">        &quot;aae010a&quot;,aae010a,</span><br><span class="line">        &quot;aae010b&quot;,aae010b</span><br><span class="line">      ))) <span class="keyword">as</span> sfysb_info</span><br><span class="line">  <span class="keyword">from</span></span><br><span class="line">  (</span><br><span class="line">    <span class="keyword">select</span> <span class="keyword">distinct</span> <span class="operator">*</span> <span class="keyword">from</span> dwd.dwd_rs_zhcs_az01bsbkxx_msk_d</span><br><span class="line">  ) <span class="keyword">as</span> t</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> e</span><br><span class="line"><span class="keyword">on</span> a.id <span class="operator">=</span> e.id</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  id,</span><br><span class="line">  <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sfygjj_num,</span><br><span class="line">  to_json(</span><br><span class="line">    collect_list(</span><br><span class="line">      named_struct(</span><br><span class="line">        &quot;spcode&quot;,spcode,</span><br><span class="line">        &quot;hjstatus&quot;,hjstatus,</span><br><span class="line">        &quot;sncode&quot;,sncode,</span><br><span class="line">        &quot;spname&quot;,spname,</span><br><span class="line">        &quot;spcard&quot;,spcard,</span><br><span class="line">        &quot;sppassword&quot;,sppassword,</span><br><span class="line">        &quot;zjfdm&quot;,zjfdm,</span><br><span class="line">        &quot;spkhrq&quot;,spkhrq,</span><br><span class="line">        &quot;spperm&quot;,spperm,</span><br><span class="line">        &quot;spgz&quot;,spgz,</span><br><span class="line">        &quot;spsingl&quot;,spsingl,</span><br><span class="line">        &quot;spjcbl&quot;,spjcbl,</span><br><span class="line">        &quot;spmfact&quot;,spmfact,</span><br><span class="line">        &quot;spmfactzg&quot;,spmfactzg,</span><br><span class="line">        &quot;spjym&quot;,spjym,</span><br><span class="line">        &quot;ncye&quot;,ncye,</span><br><span class="line">        &quot;splast&quot;,splast,</span><br><span class="line">        &quot;dwbfye&quot;,dwbfye,</span><br><span class="line">        &quot;grbfye&quot;,grbfye,</span><br><span class="line">        &quot;spmend&quot;,spmend,</span><br><span class="line">        &quot;splastlx&quot;,splastlx,</span><br><span class="line">        &quot;spout&quot;,spout,</span><br><span class="line">        &quot;spin&quot;,spin,</span><br><span class="line">        &quot;bnlx&quot;,bnlx,</span><br><span class="line">        &quot;nclx&quot;,nclx,</span><br><span class="line">        &quot;dwhjny&quot;,dwhjny,</span><br><span class="line">        &quot;zghjny&quot;,zghjny,</span><br><span class="line">        &quot;btyje&quot;,btyje,</span><br><span class="line">        &quot;btye&quot;,btye,</span><br><span class="line">        &quot;btbl&quot;,btbl,</span><br><span class="line">        &quot;bthjny&quot;,bthjny,</span><br><span class="line">        &quot;spxh&quot;,spxh,</span><br><span class="line">        &quot;spzy&quot;,spzy,</span><br><span class="line">        &quot;spxhrq&quot;,spxhrq,</span><br><span class="line">        &quot;splr&quot;,splr,</span><br><span class="line">        &quot;spoldbankno&quot;,spoldbankno,</span><br><span class="line">        &quot;spdk&quot;,spdk,</span><br><span class="line">        &quot;spdy&quot;,spdy,</span><br><span class="line">        &quot;zhdj&quot;,zhdj,</span><br><span class="line">        &quot;spnote&quot;,spnote,</span><br><span class="line">        &quot;modifytime&quot;,modifytime,</span><br><span class="line">        &quot;status&quot;,`status`,</span><br><span class="line">        &quot;cbank&quot;,cbank,</span><br><span class="line">        &quot;bcyje&quot;,bcyje,</span><br><span class="line">        &quot;bcye&quot;,bcye,</span><br><span class="line">        &quot;bcbl&quot;,bcbl,</span><br><span class="line">        &quot;bchjny&quot;,bchjny,</span><br><span class="line">        &quot;zjzl&quot;,zjzl</span><br><span class="line">      ))) <span class="keyword">as</span> sfygjj_info</span><br><span class="line">  <span class="keyword">from</span> dwd.dwd_gjj_sspersons_msk_d</span><br><span class="line">  <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> id</span><br><span class="line">) <span class="keyword">as</span> f</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>f.id;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分区</span></span><br><span class="line">ds=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 让环境变量生效</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment"># shellcheck disable=SC2034</span></span><br><span class="line"><span class="comment"># 获取脚本所在的位置</span></span><br><span class="line">shell_home=<span class="string">&quot;<span class="subst">$( cd <span class="string">&quot;<span class="subst">$( dirname <span class="string">&quot;<span class="variable">$&#123;BASH_SOURCE[0]&#125;</span>&quot;</span> )</span>&quot;</span> &amp;&amp; pwd )</span>&quot;</span></span><br><span class="line"><span class="comment"># shellcheck disable=SC2164</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$shell_home</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行任务</span></span><br><span class="line">spark-sql \</span><br><span class="line">--master yarn-client \</span><br><span class="line">--num-executors=1 \</span><br><span class="line">--executor-cores=2 \</span><br><span class="line">--executor-memory=4G \</span><br><span class="line">--conf spark.sql.shuffle.partitions=2 \</span><br><span class="line">-f dws_population_property_info_msk_d.sql \</span><br><span class="line">-d ds=<span class="variable">$ds</span></span><br></pre></td></tr></table></figure><h3 id="6-dim层"><a href="#6-dim层" class="headerlink" title="6 dim层"></a>6 dim层</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> dim.dim_user_info_d <span class="keyword">partition</span> (ds<span class="operator">=</span>$&#123;ds&#125;)</span><br><span class="line">  <span class="keyword">select</span> id,XM,XB,MZ,CSRQ,XZJD,JCWH,ZXSJ <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span></span><br><span class="line">    id,XM,XB,MZ,CSRQ,HSLBZ,substr(XZJD,<span class="number">1</span>,<span class="number">9</span>) <span class="keyword">as</span> XZJD ,JCWH,ZXSJ,</span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> HSLBZ <span class="keyword">desc</span>) r</span><br><span class="line">    <span class="keyword">from</span> dwd.dwd_ga_hjxx_czrkjbxx_msk_d</span><br><span class="line">    <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  ) <span class="keyword">as</span> a</span><br><span class="line">  <span class="keyword">where</span> r<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><h3 id="7-ads层"><a href="#7-ads层" class="headerlink" title="7 ads层"></a>7 ads层</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--多少人有房:</span></span><br><span class="line"><span class="comment">--有房人口的比例</span></span><br><span class="line"><span class="comment">--多少人有公司： 法定代表人和股东都算有公司</span></span><br><span class="line"><span class="comment">--有公司人口的比例</span></span><br><span class="line"><span class="comment">--多少人有公积金</span></span><br><span class="line"><span class="comment">--有公积金人口的比例</span></span><br><span class="line"><span class="comment">--多少人有社保</span></span><br><span class="line"><span class="comment">--有社保人口的比例</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> ads.ads_rk_ccxx_xz_index_d <span class="keyword">partition</span>(ds<span class="operator">=</span>$&#123;ds&#125;)</span><br><span class="line">  <span class="keyword">select</span></span><br><span class="line">  b.XZJD,</span><br><span class="line">  <span class="built_in">sum</span>(sfyfc) <span class="keyword">as</span> sfyfc_num,</span><br><span class="line">  round(<span class="built_in">sum</span>(sfyfc)<span class="operator">/</span><span class="built_in">count</span>(<span class="number">1</span>),<span class="number">4</span>) <span class="keyword">as</span> sfyfc_num_p,</span><br><span class="line">  <span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> sfygc<span class="operator">=</span><span class="number">1</span> <span class="keyword">or</span> sywgd <span class="operator">=</span><span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> sfygc_num,</span><br><span class="line">  round(<span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> sfygc<span class="operator">=</span><span class="number">1</span> <span class="keyword">or</span> sywgd <span class="operator">=</span><span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="operator">/</span> <span class="built_in">count</span>(<span class="number">1</span>),<span class="number">4</span>) <span class="keyword">as</span> sfygc_num_p,</span><br><span class="line">  <span class="built_in">sum</span>(sfygjj) <span class="keyword">as</span> sfygjj_num,</span><br><span class="line">  round(<span class="built_in">sum</span>(sfygjj)<span class="operator">/</span><span class="built_in">count</span>(<span class="number">1</span>),<span class="number">4</span>) <span class="keyword">as</span> sfygjj_num_p,</span><br><span class="line">  <span class="built_in">sum</span>(sfysb) <span class="keyword">as</span> sfysb_num,</span><br><span class="line">  round(<span class="built_in">sum</span>(sfysb)<span class="operator">/</span><span class="built_in">count</span>(<span class="number">1</span>),<span class="number">4</span>) <span class="keyword">as</span> sfysb_num_p</span><br><span class="line">  <span class="keyword">from</span></span><br><span class="line">  (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span></span><br><span class="line">    dws.dws_population_property_info_msk_d</span><br><span class="line">    <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  ) <span class="keyword">as</span> a</span><br><span class="line">  <span class="keyword">inner</span> <span class="keyword">join</span></span><br><span class="line">  (</span><br><span class="line">    <span class="keyword">select</span> id,XZJD <span class="keyword">from</span></span><br><span class="line">    dim.dim_user_info_d <span class="keyword">where</span> ds<span class="operator">=</span>$&#123;ds&#125;</span><br><span class="line">  ) <span class="keyword">as</span> b</span><br><span class="line">  <span class="keyword">on</span> a.id<span class="operator">=</span>b.id</span><br><span class="line">  <span class="keyword">group</span> <span class="keyword">by</span> b.XZJD</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;errorLimit&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;record&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfsreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/daas/motl/ads/ads_rk_ccxx_xz_index_d/ds=$&#123;ds&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://master:9000&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DOUBLE&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DOUBLE&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DOUBLE&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">7</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;long&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DOUBLE&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;ds&#125;&quot;</span></span><br><span class="line">              <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;encoding&quot;</span><span class="punctuation">:</span> <span class="string">&quot;UTF-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlwriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;replace&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;root&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123456&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="string">&quot;XZJD&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfyfc_num&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfyfc_num_p&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfygc_num&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfygc_num_p&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfygjj_num&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfygjj_num_p&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfysb_num&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;sfysb_num_p&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="string">&quot;ds&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">            <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">              <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jdbc:mysql://master:3306/ads?useUnicode=true&amp;characterEncoding=utf-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                  <span class="string">&quot;ads_rk_ccxx_xz_index_d&quot;</span></span><br><span class="line">                <span class="punctuation">]</span></span><br><span class="line">              <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="8-使用DolphinScheduler调度任务"><a href="#8-使用DolphinScheduler调度任务" class="headerlink" title="8 使用DolphinScheduler调度任务"></a>8 使用DolphinScheduler调度任务</h3><p>1 创建各个层的租户–用于执行脚本的用户（权限）</p><p><img src="https://s2.loli.net/2022/08/10/bfPMG52gO8BpqEQ.png" alt="屏幕截图 2022-08-10 104347"><br>3 创建项目流程</p><p><img src="/../../../Users/HZH/AppData/Roaming/Typora/typora-user-images/image-20220810104544526.png" alt="image-20220810104544526"></p><p><img src="https://s2.loli.net/2022/08/10/K2359WZXFiPGTYV.png" alt="image-20220810104651490"></p><p><img src="https://s2.loli.net/2022/08/10/LsbeGkWJUVYc3XP.png" alt="image-20220810104738945"></p><p><img src="https://s2.loli.net/2022/08/10/soSJXv8tKYD7pyc.png" alt="image-20220810104825620"></p>]]></content>
    
    
    <summary type="html">对项目总结的总结</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="总结" scheme="http://example.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Kafka代码</title>
    <link href="http://example.com/2022/07/25/kafka%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/25/kafka%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-25T14:44:58.432Z</published>
    <updated>2022-07-25T14:51:14.530Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、kafkaProducer"><a href="#1、kafkaProducer" class="headerlink" title="1、kafkaProducer"></a>1、kafkaProducer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1kafkaProducer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、向kafka中生产数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;test_topic2&quot;</span>, <span class="string">&quot;java&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//发送数据到kafka中</span></span><br><span class="line">    producer.send(record)</span><br><span class="line">    producer.flush()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、KafkaConsumer"><a href="#2、KafkaConsumer" class="headerlink" title="2、KafkaConsumer"></a>2、KafkaConsumer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerRecord</span>, <span class="type">ConsumerRecords</span>, <span class="type">KafkaConsumer</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"><span class="keyword">import</span> java.&#123;lang, util&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3KafkaConsumer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建消费者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key 和value 反序列化的类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * earliest</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费</span></span><br><span class="line"><span class="comment">     * latest  默认</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产认值生的该分区下的数据</span></span><br><span class="line"><span class="comment">     * none</span></span><br><span class="line"><span class="comment">     * topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;auto.offset.reset&quot;</span>, <span class="string">&quot;earliest&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者组</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;asdasd&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> consumer = <span class="keyword">new</span> <span class="type">KafkaConsumer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、订阅一个topic,可以一次订阅多个topic</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    topics.add(<span class="string">&quot;student&quot;</span>)</span><br><span class="line">    consumer.subscribe(topics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      println(<span class="string">&quot;正在消费&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 消费数据, 需要这一个超时时间</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">val</span> consumerRecords: <span class="type">ConsumerRecords</span>[<span class="type">String</span>, <span class="type">String</span>] = consumer</span><br><span class="line">        .poll(<span class="type">Duration</span>.ofSeconds(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//解析数据</span></span><br><span class="line">      <span class="keyword">val</span> records: lang.<span class="type">Iterable</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = consumerRecords</span><br><span class="line">        .records(<span class="string">&quot;student&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> iterRecord: util.<span class="type">Iterator</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = records.iterator()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (iterRecord.hasNext) &#123;</span><br><span class="line">        <span class="comment">//获取一行数据</span></span><br><span class="line">        <span class="keyword">val</span> record: <span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>] = iterRecord.next()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> topic: <span class="type">String</span> = record.topic() <span class="comment">//topic</span></span><br><span class="line">        <span class="keyword">val</span> offset: <span class="type">Long</span> = record.offset() <span class="comment">//数据偏移量</span></span><br><span class="line">        <span class="keyword">val</span> key: <span class="type">String</span> = record.key() <span class="comment">//数据的key ,默认没有指定的情况下时null</span></span><br><span class="line">        <span class="keyword">val</span> value: <span class="type">String</span> = record.value() <span class="comment">//保存的数据</span></span><br><span class="line">        <span class="keyword">val</span> ts: <span class="type">Long</span> = record.timestamp() <span class="comment">//时间戳，默认时存入的时间</span></span><br><span class="line"></span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$topic</span>\t<span class="subst">$offset</span>\t<span class="subst">$key</span>\t<span class="subst">$value</span>\t<span class="subst">$ts</span>&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    consumer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、StudnetToKafka"><a href="#3、StudnetToKafka" class="headerlink" title="3、StudnetToKafka"></a>3、StudnetToKafka</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2StudnetToKafka</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取学生表将数据批量写入kafka中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (student &lt;- studentList) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;student&quot;</span>, student)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//发送数据到kafka中</span></span><br><span class="line">      producer.send(record)</span><br><span class="line">      producer.flush()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、统计车流量-练习"><a href="#4、统计车流量-练习" class="headerlink" title="4、统计车流量-练习"></a>4、统计车流量-练习</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.&#123;<span class="type">SerializableTimestampAssigner</span>, <span class="type">WatermarkStrategy</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.<span class="type">KafkaSource</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.<span class="type">OffsetsInitializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.&#123;<span class="type">RichSinkFunction</span>, <span class="type">SinkFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingEventTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Cars</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、从kafka中读取卡口过车数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">KafkaSource</span>[<span class="type">String</span>] = <span class="type">KafkaSource</span></span><br><span class="line">      .builder[<span class="type">String</span>]</span><br><span class="line">      .setBootstrapServers(<span class="string">&quot;master:9092,node1:9092,node2:9092&quot;</span>) <span class="comment">//kafka集群broker列表</span></span><br><span class="line">      .setTopics(<span class="string">&quot;cars&quot;</span>) <span class="comment">//指定topic</span></span><br><span class="line">      .setGroupId(<span class="string">&quot;asdasdasd&quot;</span>) <span class="comment">//指定消费者组，一条数据在一个组内只被消费一次</span></span><br><span class="line">      .setStartingOffsets(<span class="type">OffsetsInitializer</span>.latest()) <span class="comment">//读取数据的位置，earliest：读取所有的数据，latest：读取最新的数据</span></span><br><span class="line">      .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()) <span class="comment">//反序列的类</span></span><br><span class="line">      .build</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用kafka source</span></span><br><span class="line">    <span class="keyword">val</span> carsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.fromSource(source, <span class="type">WatermarkStrategy</span>.noWatermarks(), <span class="string">&quot;Kafka Source&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式数据，将卡口编号和时间字段取出来</span></span><br><span class="line"><span class="comment">     * fastJson</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> cardAndTimeDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = carsDS.map(line =&gt; &#123;</span><br><span class="line">      <span class="comment">//将字符串转换成json对象</span></span><br><span class="line">      <span class="keyword">val</span> jsonObj: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="comment">//使用字段名获取字段值</span></span><br><span class="line">      <span class="comment">//卡口编号</span></span><br><span class="line">      <span class="keyword">val</span> card: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;card&quot;</span>)</span><br><span class="line">      <span class="comment">//事件时间，事件时间要求时毫秒级别</span></span><br><span class="line">      <span class="keyword">val</span> time: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;time&quot;</span>) * <span class="number">1000</span></span><br><span class="line">      (card, time)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 设置时间字段和水位线</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> assDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = cardAndTimeDS.assignTimestampsAndWatermarks(</span><br><span class="line">      <span class="type">WatermarkStrategy</span></span><br><span class="line">        <span class="comment">//设置水位线的生成策略，前移5秒</span></span><br><span class="line">        .forBoundedOutOfOrderness(<span class="type">Duration</span>.ofSeconds(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">//设置时间字段</span></span><br><span class="line">        .withTimestampAssigner(<span class="keyword">new</span> <span class="type">SerializableTimestampAssigner</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: (<span class="type">Long</span>, <span class="type">Long</span>), recordTimestamp: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            <span class="comment">//时间字段</span></span><br><span class="line">            element._2</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计车流量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = assDS.map(kv =&gt; (kv._1, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照卡口分组</span></span><br><span class="line">    <span class="keyword">val</span> keyBYDS: <span class="type">KeyedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>] = kvDS.keyBy(_._1)</span><br><span class="line">    <span class="comment">//开窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>, <span class="type">TimeWindow</span>] = keyBYDS</span><br><span class="line">      .window(<span class="type">SlidingEventTimeWindows</span>.of(<span class="type">Time</span>.minutes(<span class="number">15</span>), <span class="type">Time</span>.minutes(<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计车流量</span></span><br><span class="line">    <span class="keyword">val</span> flowDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将统计的结果保存到mysql中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    flowDS.addSink(<span class="keyword">new</span> <span class="type">RichSinkFunction</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">//插入数据</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: (<span class="type">Long</span>, <span class="type">Int</span>), context: <span class="type">SinkFunction</span>.<span class="type">Context</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;数据写入mysql&quot;</span>)</span><br><span class="line">        stat.setLong(<span class="number">1</span>, value._1)</span><br><span class="line">        stat.setInt(<span class="number">2</span>, value._2)</span><br><span class="line"></span><br><span class="line">        stat.execute()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> con: <span class="type">Connection</span> = _</span><br><span class="line">      <span class="keyword">var</span> stat: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//创建链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//1、加载驱动</span></span><br><span class="line">        <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">        <span class="comment">//创建链接</span></span><br><span class="line">        con = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master:3306/bigdata&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">        <span class="comment">//编写插入数据的sql</span></span><br><span class="line">        <span class="comment">//replace :如果不存在插入，如果存在就替换，需要在表中设置主键</span></span><br><span class="line">        stat = con.prepareStatement(<span class="string">&quot;replace into card_flow(card,flow) values(?,?)&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//关闭链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        stat.close()</span><br><span class="line">        con.close()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka搭建</title>
    <link href="http://example.com/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-25T14:24:58.265Z</published>
    <updated>2022-07-25T14:51:32.281Z</updated>
    
    <content type="html"><![CDATA[<h2 id="搭建Kafka"><a href="#搭建Kafka" class="headerlink" title="搭建Kafka"></a>搭建Kafka</h2><h3 id="1、上传解压修改环境变量"><a href="#1、上传解压修改环境变量" class="headerlink" title="1、上传解压修改环境变量"></a>1、上传解压修改环境变量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压</span></span><br><span class="line">tar -xvf kafka_2.11-1.0.0.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export KAFKA_HOME=/usr/local/soft/kafka_2.11-1.0.0</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、修改配置文件"><a href="#2、修改配置文件" class="headerlink" title="2、修改配置文件"></a>2、修改配置文件</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">broker.id</span>=<span class="string">0 每一个节点broker.id 要不一样</span></span><br><span class="line"><span class="attr">zookeeper.connect</span>=<span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/usr/local/soft/kafka_2.11-1.0.0/data   数据存放的位置</span></span><br></pre></td></tr></table></figure><h3 id="3、将kafka文件同步到node1-node2"><a href="#3、将kafka文件同步到node1-node2" class="headerlink" title="3、将kafka文件同步到node1,node2"></a>3、将kafka文件同步到node1,node2</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步kafka文件</span></span><br><span class="line">scp -r kafka_2.11-1.0.0/ node1:`pwd`</span><br><span class="line">scp -r kafka_2.11-1.0.0/ node2:`pwd`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将master中的而环境变量同步到node1和node2中</span></span><br><span class="line">scp /etc/profile node1:/etc/</span><br><span class="line">scp /etc/profile node2:/etc/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 在ndoe1和node2中执行<span class="built_in">source</span></span></span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4、修改node1和node2中的broker-id"><a href="#4、修改node1和node2中的broker-id" class="headerlink" title="4、修改node1和node2中的broker.id"></a>4、修改node1和node2中的broker.id</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># node1</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># node2</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">2</span></span><br></pre></td></tr></table></figure><h3 id="5、启动kafka"><a href="#5、启动kafka" class="headerlink" title="5、启动kafka"></a>5、启动kafka</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、需要先启动zookeeper,  kafka使用zk保存元数据</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要在每隔节点中执行启动的命令</span></span><br><span class="line">zkServer.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动的状态</span></span><br><span class="line">zkServer.sh status</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、启动kafka，每个节点中都要启动（去中心化的架构）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-daemon后台启动</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/soft/kafka_2.11-1.0.0/config/server.properties</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用kafka"><a href="#使用kafka" class="headerlink" title="使用kafka"></a>使用kafka</h3><h3 id="1、创建topic"><a href="#1、创建topic" class="headerlink" title="1、创建topic"></a>1、创建topic</h3><blockquote><p>在生产和消费数据时，如果topic不存在会自动创建一个分区为1，副本为1的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--replication-factor  ---每一个分区的副本数量, 同一个分区的副本不能放在同一个节点，副本的数量不能大于kafak集群节点的数量</span><br><span class="line">--partition   --分区数，  根据数据量设置</span><br><span class="line">--zookeeper zk的地址，将topic的元数据保存在zookeeper中</span><br><span class="line"></span><br><span class="line">kafka-topics.sh --create --zookeeper master:2181,node1:2181,node2:2181 --replication-factor 3 --partitions 3 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="2、查看topic描述信息"><a href="#2、查看topic描述信息" class="headerlink" title="2、查看topic描述信息"></a>2、查看topic描述信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --describe  --zookeeper master:2181,node1:2181,node2:2181 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="3、获取所有topic"><a href="#3、获取所有topic" class="headerlink" title="3、获取所有topic"></a>3、获取所有topic</h3><blockquote><p>__consumer_offsetsL kafka用于保存消费偏移量的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br></pre></td></tr></table></figure><h3 id="4、创建控制台生产者"><a href="#4、创建控制台生产者" class="headerlink" title="4、创建控制台生产者"></a>4、创建控制台生产者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list master:9092,node1:9092,node2:9092 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="5、创建控制台消费者"><a href="#5、创建控制台消费者" class="headerlink" title="5、创建控制台消费者"></a>5、创建控制台消费者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> --from-beginning   从头消费，如果不在执行消费的新的数据</span><br><span class="line">kafka-console-consumer.sh --bootstrap-server  master:9092,node1:9092,node2:9092 --from-beginning --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="kafka数据保存的方式"><a href="#kafka数据保存的方式" class="headerlink" title="kafka数据保存的方式"></a>kafka数据保存的方式</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、保存的文件</span></span><br><span class="line">/usr/local/soft/kafka_2.11-1.0.0/data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、每一个分区每一个副本对应一个目录</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3、每一个分区目录中可以有多个文件， 文件时滚动生成的</span></span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000000001.log</span><br><span class="line">00000000000000000002.log</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4、滚动生成文件的策略</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5、文件删除的策略，默认时7天，以文件为单位删除</span></span><br><span class="line">log.retention.hours=168</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>flink之Join</title>
    <link href="http://example.com/2022/07/24/flink%E4%B9%8BJoin/"/>
    <id>http://example.com/2022/07/24/flink%E4%B9%8BJoin/</id>
    <published>2022-07-23T16:00:00.000Z</published>
    <updated>2022-08-03T05:51:24.466Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Flink-Join"><a href="#Flink-Join" class="headerlink" title="Flink Join"></a>Flink Join</h2><p>flink可以维护PB级别的状态</p><h4 id="1、Regular-Joins"><a href="#1、Regular-Joins" class="headerlink" title="1、Regular  Joins"></a>1、Regular  Joins</h4><blockquote><p>可以一直关联上另一张表的历史数据，flink会将两张表的数据一直保存在状态中</p><p>优点：可以保证两张表的数据一直可以关联上，数据不是同时到达的也可以关联上</p><p>缺点：两个表的数据一直缓存在状态中，状态会越来越大，每checkpoint的所需要的时间也会越来越长，最后会导致flink出现反压，如果checkpoint多次超时失败，会导致flink任务失败</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建学生表流表，数据再kafka中</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_join (</span><br><span class="line"> id String,</span><br><span class="line"> name String,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> gender STRING,</span><br><span class="line"> clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">--- inner join</span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- left outer join</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- full outer join </span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">full</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100002</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student_join</span></span><br><span class="line"></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"><span class="number">1500100002</span>,吕金鹏,<span class="number">24</span>,男,文科七班</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2、Interval-Joins"><a href="#2、Interval-Joins" class="headerlink" title="2、Interval Joins"></a>2、Interval Joins</h4><blockquote><p>在一定时间范围内进行关联，这样flink只需要在状态中保存一段时间的数据，不需要保存所有的数据</p><p>优点：状态不会太大</p><p>缺点：如果时间设置的不合理会导致数据关联不上</p><p>前提是两个表有一个时间字段</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建学生表流表，数据再kafka中</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_join_proc (</span><br><span class="line"> id String,</span><br><span class="line"> name String,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> gender STRING,</span><br><span class="line"> clazz STRING,</span><br><span class="line"> stu_time <span class="keyword">as</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join_proc (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span>,</span><br><span class="line"> sco_time <span class="keyword">as</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Interval Joins</span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span></span><br><span class="line">student_join_proc <span class="keyword">as</span> a, score_join_proc <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">where</span> a.id<span class="operator">=</span>b.s_id </span><br><span class="line"><span class="keyword">and</span> a.stu_time <span class="keyword">BETWEEN</span> b.sco_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span> <span class="keyword">AND</span> b.sco_time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100002</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student_join</span></span><br><span class="line"></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"><span class="number">1500100002</span>,吕金鹏,<span class="number">24</span>,男,文科七班</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="3、Temporal-Joins"><a href="#3、Temporal-Joins" class="headerlink" title="3、Temporal Joins"></a>3、Temporal Joins</h4><blockquote><p>流表关联版本表（拉链表），关联版本表对应版本数据，不需要将两个表的数据一直保存在状态</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 订单表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders (</span><br><span class="line">    order_id    STRING, <span class="comment">-- 订单编号</span></span><br><span class="line">    price       <span class="type">DECIMAL</span>(<span class="number">32</span>,<span class="number">2</span>), <span class="comment">--订单的价格</span></span><br><span class="line">    currency    STRING, <span class="comment">-- 汇率表主键</span></span><br><span class="line">    order_time  <span class="type">TIMESTAMP</span>(<span class="number">3</span>), <span class="comment">-- 订单发生的事件</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="comment">-- 设置事件时间和水位线</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;orders&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">--汇率表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> currency_rates (</span><br><span class="line">    currency STRING, <span class="comment">-- 汇率表主键</span></span><br><span class="line">    conversion_rate <span class="type">DECIMAL</span>(<span class="number">32</span>, <span class="number">2</span>), <span class="comment">-- 汇率</span></span><br><span class="line">    update_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> <span class="string">&#x27;value.ingestion-timestamp&#x27;</span> VIRTUAL, <span class="comment">--汇率更新时间</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> update_time <span class="keyword">AS</span> update_time,<span class="comment">--时间字段和水位线</span></span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY(currency) <span class="keyword">NOT</span> ENFORCED<span class="comment">--设置主键</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test.currency_rates&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;canal-json&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;canal-json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Temporal Joins</span></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">     order_id,</span><br><span class="line">     price,</span><br><span class="line">     orders.currency,</span><br><span class="line">     conversion_rate,</span><br><span class="line">     order_time</span><br><span class="line"><span class="keyword">FROM</span> orders</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> currency_rates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> orders.order_time</span><br><span class="line"><span class="keyword">ON</span> orders.currency <span class="operator">=</span> currency_rates.currency;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 订单表数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic orders</span></span><br><span class="line"></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">08</span>:<span class="number">20</span></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">55</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="4、Lookup-Join"><a href="#4、Lookup-Join" class="headerlink" title="4、Lookup Join"></a>4、Lookup Join</h4><blockquote><p>用于流表关联维表</p><p>关联方式：当流表每来一条数据时，都会通过关联的字段到维表底层数据库中去查询数据</p><p>如果每一条数据都需要去查询数据库，吞吐量会比较低，可以在flink中设置数据缓存，需要设置两个参数，一个是缓存大小，还有缓存过期时间</p><p>查数据时先查询缓存，如果缓存中直接返回，如果缓存中没有再去查询数据库，并将查询的结果放在缓存中</p><p>会出现缓存穿透和缓存雪崩</p><p>什么是缓存穿透呢？缓存穿透问题在一定程度上与缓存命中率有关。如果我们的缓存设计的不合理，缓存的命中率非常低，那么，数据访问的绝大部分压力都会集中在后端数据库层面。</p><p>如果在某一时刻缓存集中失效，或者缓存系统出现故障，所有的并发流量就会直接到达数据库。数据存储层的调用量就会暴增，用不了多长时间，数据库就会被大流量压垮，这种级联式的服务故障，就叫作缓存雪崩。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建一个jdbc维表  -- 有界流</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_mysql (</span><br><span class="line">  id <span class="type">BIGINT</span>,</span><br><span class="line">  name STRING,</span><br><span class="line">  age <span class="type">BIGINT</span>,</span><br><span class="line">  gender STRING,</span><br><span class="line">  clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;students&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;lookup.cache.max-rows&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100&#x27;</span> ,<span class="comment">-- 开启缓存,指定缓存数据量,可以提高关联性能</span></span><br><span class="line">   <span class="string">&#x27;lookup.cache.ttl&#x27;</span>  <span class="operator">=</span> <span class="string">&#x27;30s&#x27;</span> <span class="comment">-- 缓存过期时间，一般会按照维表更新频率设置</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表  -- 无界流</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span>,</span><br><span class="line"> pro_time <span class="keyword">as</span> PROCTIME() <span class="comment">-- Lookup Join关联方式，流表需要有一个时间字段</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">b.id,b.name,b.age,a.sco</span><br><span class="line"><span class="keyword">FROM</span> score_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> student_mysql <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> a.pro_time <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">ON</span> <span class="built_in">cast</span>(a.s_id  <span class="keyword">as</span>  <span class="type">BIGINT</span>)<span class="operator">=</span> b.id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100003</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100004</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink Join的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>Canal搭建</title>
    <link href="http://example.com/2022/07/21/canal%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/21/canal%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-20T16:00:00.000Z</published>
    <updated>2022-07-25T14:44:33.158Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开启mysql-binlog"><a href="#开启mysql-binlog" class="headerlink" title="开启mysql binlog"></a>开启mysql binlog</h2><blockquote><p>默认没有开启</p><p>开启binlog之后mysql的性能会手动影响</p></blockquote><h3 id="1、修改mysql配置文件-x2F-etc-x2F-my-cnf"><a href="#1、修改mysql配置文件-x2F-etc-x2F-my-cnf" class="headerlink" title="1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf"></a>1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果配置文件不存在，复制一个过来</span></span><br><span class="line">cp /usr/share/mysql/my-medium.cnf /etc/my.cnf</span><br><span class="line"></span><br><span class="line">vim /etc/my.cnf </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在配置文件中增加二配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要将配置放在[mysqld]后面</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开binlog</span></span><br><span class="line">log-bin=mysql-bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择ROW(行)模式</span></span><br><span class="line">binlog-format=ROW</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置MySQL replaction需要定义，不要和canal的slaveId重复</span></span><br><span class="line">server_id=1</span><br></pre></td></tr></table></figure><h3 id="2、重启mysql"><a href="#2、重启mysql" class="headerlink" title="2、重启mysql"></a>2、重启mysql</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service mysqld restart</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看mysql binlog文件</span></span><br><span class="line">cd /var/lib/mysql</span><br><span class="line">mysql-bin.000001</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">改了配置文件之后，重启MySQL，使用命令查看是否打开binlog模式：</span></span><br><span class="line">mysql -uroot -p123456</span><br><span class="line">show variables like &#x27;log_bin&#x27;;</span><br></pre></td></tr></table></figure><h2 id="搭建Canal"><a href="#搭建Canal" class="headerlink" title="搭建Canal"></a>搭建Canal</h2><h3 id="2、上传解压，上传到soft目录"><a href="#2、上传解压，上传到soft目录" class="headerlink" title="2、上传解压，上传到soft目录"></a>2、上传解压，上传到soft目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建解压目录</span></span><br><span class="line">mkdir canal</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压到指定目录</span></span><br><span class="line">tar -xvf canal.deployer-1.1.4.tar.gz -C canal</span><br></pre></td></tr></table></figure><h3 id="3、修改配置文件conf-x2F-example-x2F-instance-properties"><a href="#3、修改配置文件conf-x2F-example-x2F-instance-properties" class="headerlink" title="3、修改配置文件conf&#x2F;example&#x2F;instance.properties"></a>3、修改配置文件conf&#x2F;example&#x2F;instance.properties</h3><p>vim conf&#x2F;example&#x2F;instance.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql 地址</span></span><br><span class="line"><span class="attr">canal.instance.master.address</span>=<span class="string">master:3306</span></span><br><span class="line"><span class="comment"># mysql用户名</span></span><br><span class="line"><span class="attr">canal.instance.dbUsername</span>=<span class="string">root</span></span><br><span class="line"><span class="comment"># mysql密码</span></span><br><span class="line"><span class="attr">canal.instance.dbPassword</span>=<span class="string">123456</span></span><br><span class="line"><span class="comment"># 数据写入kafka 的topic名称, 所有的数据写入同一个topic</span></span><br><span class="line"><span class="attr">canal.mq.topic</span>=<span class="string">example</span></span><br><span class="line"><span class="comment"># 为每一个表自动创建一个topic</span></span><br><span class="line"><span class="comment"># 监控bigdata数据库，不同的表发送到表名的topic上, topic命令方式bigdata.student</span></span><br><span class="line"><span class="attr">canal.mq.dynamicTopic</span>=<span class="string">bigdata\\..*</span></span><br></pre></td></tr></table></figure><h3 id="4、修改配置文件conf-x2F-canal-properties"><a href="#4、修改配置文件conf-x2F-canal-properties" class="headerlink" title="4、修改配置文件conf&#x2F;canal.properties"></a>4、修改配置文件conf&#x2F;canal.properties</h3><p>vim conf&#x2F;canal.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># zk地址 </span></span><br><span class="line"><span class="attr">canal.zkServers</span> = <span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="comment"># 数据保存到kafka</span></span><br><span class="line"><span class="attr">canal.serverMode</span> = <span class="string">kafka</span></span><br><span class="line"><span class="comment"># kafka集群地址</span></span><br><span class="line"><span class="attr">canal.mq.servers</span> = <span class="string">master:9092,node1:9092,node2:9092</span></span><br></pre></td></tr></table></figure><h3 id="5、启动canal"><a href="#5、启动canal" class="headerlink" title="5、启动canal"></a>5、启动canal</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/canal/bin/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动canal</span></span><br><span class="line">./startup.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动日志</span></span><br><span class="line">cd /usr/local/soft/canal/logs</span><br><span class="line">cat canal/*</span><br><span class="line">cat example/*</span><br></pre></td></tr></table></figure><h3 id="5、测试"><a href="#5、测试" class="headerlink" title="5、测试"></a>5、测试</h3><p>在test数据库创建一个订单表，并且执行几个简单的DML：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 登录mysql</span></span><br><span class="line">mysql <span class="operator">-</span>uroot <span class="operator">-</span>p123456</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 切换数据库</span></span><br><span class="line">use `bigdata`;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `<span class="keyword">order</span>`</span><br><span class="line">(</span><br><span class="line">    id          <span class="type">BIGINT</span> <span class="keyword">UNIQUE</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT COMMENT <span class="string">&#x27;主键&#x27;</span>,</span><br><span class="line">    order_id    <span class="type">VARCHAR</span>(<span class="number">64</span>)   COMMENT <span class="string">&#x27;订单ID&#x27;</span>,</span><br><span class="line">    amount      <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;订单金额&#x27;</span>,</span><br><span class="line">    create_time DATETIME       COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">    <span class="keyword">UNIQUE</span> uniq_order_id (`order_id`)</span><br><span class="line">) COMMENT <span class="string">&#x27;订单表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">order</span>`(order_id, amount) <span class="keyword">VALUES</span> (<span class="string">&#x27;10087&#x27;</span>, <span class="number">999</span>);</span><br><span class="line"><span class="keyword">UPDATE</span> `<span class="keyword">order</span>` <span class="keyword">SET</span> amount <span class="operator">=</span> <span class="number">99</span> <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"><span class="keyword">DELETE</span>  <span class="keyword">FROM</span> `<span class="keyword">order</span>` <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="6、可以利用Kafka的kafka-console-consumer消费数据"><a href="#6、可以利用Kafka的kafka-console-consumer消费数据" class="headerlink" title="6、可以利用Kafka的kafka-console-consumer消费数据"></a>6、可以利用Kafka的kafka-console-consumer消费数据</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否自动创建topic</span></span><br><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">消费数据</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server master:9092,node1:9092,node2:9092 --from-beginning --topic bigdata.order</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Kafka的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>spark优化</title>
    <link href="http://example.com/2022/07/20/spark%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/07/20/spark%E4%BC%98%E5%8C%96/</id>
    <published>2022-07-19T16:00:00.000Z</published>
    <updated>2022-07-21T11:36:59.635Z</updated>
    
    <content type="html"><![CDATA[<h1 id="spark优化"><a href="#spark优化" class="headerlink" title="spark优化"></a>spark优化</h1><h2 id="一、代码优化"><a href="#一、代码优化" class="headerlink" title="一、代码优化"></a>一、代码优化</h2><h3 id="1、多次使用的rdd-df-table进行缓存"><a href="#1、多次使用的rdd-df-table进行缓存" class="headerlink" title="**1、多次使用的rdd df table进行缓存 ***"></a>**1、多次使用的rdd df table进行缓存 ***</h3><ul><li><p>缓存级别</p><ul><li>数据量不大时可以使用MEMORY_ONLY</li><li>数据量超过了内存的限制 MEMORy_AND_DISK_SER</li></ul></li></ul><h3 id="2、使用高性能的算子"><a href="#2、使用高性能的算子" class="headerlink" title="**2、使用高性能的算子 ***"></a>**2、使用高性能的算子 ***</h3><ul><li><p>reduceByKey</p><ul><li>会再map端做预聚合</li></ul></li><li><p>aggregateByKey</p></li><li><p>mapPartition</p></li><li><p>foreachPartition</p><ul><li>主要用于将数据保存到外部数据库时</li><li>只需要为每一个分区创建一个网络链接</li></ul></li><li><p>coalesce</p><ul><li>如果代码产生了很多的小文件，可以再保存数据的时候合并小文件</li></ul></li></ul><h3 id="3、map-join"><a href="#3、map-join" class="headerlink" title="**3、map join ***"></a>**3、map join ***</h3><ul><li>当一个大表join小表的时候，可以将小表广播，在map端进行关联</li><li>小表不能超过1G</li></ul><h3 id="4、Kryo"><a href="#4、Kryo" class="headerlink" title="4、Kryo"></a>4、Kryo</h3><h3 id="5、优化数据结构"><a href="#5、优化数据结构" class="headerlink" title="5、优化数据结构"></a>5、优化数据结构</h3><ul><li>1、尽量使用字符串代替对象</li><li>2、尽量使用基本数据类型代替字符串</li><li>3、尽量使用数组代替集合</li></ul><h3 id="6、使用高性能的fastUtil库"><a href="#6、使用高性能的fastUtil库" class="headerlink" title="6、使用高性能的fastUtil库"></a>6、使用高性能的fastUtil库</h3><h2 id="二、参数优化"><a href="#二、参数优化" class="headerlink" title="二、参数优化"></a>二、参数优化</h2><h3 id="–num-executors-executor的数量"><a href="#–num-executors-executor的数量" class="headerlink" title="–num-executors executor的数量"></a><strong>–num-executors executor的数量</strong></h3><h3 id="–executor-memory-每一个executor的内存"><a href="#–executor-memory-每一个executor的内存" class="headerlink" title="–executor-memory 每一个executor的内存"></a><strong>–executor-memory 每一个executor的内存</strong></h3><h3 id="–executor-cores-每一个executor的核心数"><a href="#–executor-cores-每一个executor的核心数" class="headerlink" title="–executor-cores  每一个executor的核心数"></a><strong>–executor-cores  每一个executor的核心数</strong></h3><h3 id="–driver-memory-Driver的内存1G-2G-保存广播变量"><a href="#–driver-memory-Driver的内存1G-2G-保存广播变量" class="headerlink" title="–driver-memory  Driver的内存1G-2G(保存广播变量)"></a>–driver-memory  Driver的内存1G-2G(保存广播变量)</h3><h3 id="–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle"><a href="#–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle" class="headerlink" title="–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle"></a>–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle</h3><h3 id="–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2"><a href="#–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2" class="headerlink" title="–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2"></a>–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2</h3><h3 id="–spark-locality-wait-数据本地化等待时间"><a href="#–spark-locality-wait-数据本地化等待时间" class="headerlink" title="–spark.locality.wait 数据本地化等待时间"></a>–spark.locality.wait 数据本地化等待时间</h3><h3 id="–spark-yarn-executor-memoryOverhead堆外内存"><a href="#–spark-yarn-executor-memoryOverhead堆外内存" class="headerlink" title="–spark.yarn.executor.memoryOverhead堆外内存"></a>–spark.yarn.executor.memoryOverhead堆外内存</h3><h3 id="–spark-network-timeout-网络链接的超时时间"><a href="#–spark-network-timeout-网络链接的超时时间" class="headerlink" title="–spark.network.timeout 网络链接的超时时间"></a>–spark.network.timeout 网络链接的超时时间</h3><h2 id="三、数据倾斜"><a href="#三、数据倾斜" class="headerlink" title="三、数据倾斜"></a>三、数据倾斜</h2><h3 id="1、将数据倾斜提前带hive"><a href="#1、将数据倾斜提前带hive" class="headerlink" title="1、将数据倾斜提前带hive"></a><strong>1、将数据倾斜提前带hive</strong></h3><ul><li>hive比spark稳定</li></ul><h3 id="2、过滤少量导致倾斜的key"><a href="#2、过滤少量导致倾斜的key" class="headerlink" title="2、过滤少量导致倾斜的key"></a><strong>2、过滤少量导致倾斜的key</strong></h3><ul><li>key对业务不重要</li></ul><h3 id="3、提高shuffle的并行度"><a href="#3、提高shuffle的并行度" class="headerlink" title="3、提高shuffle的并行度"></a><strong>3、提高shuffle的并行度</strong></h3><ul><li>可以减少每一个reduce中分到的数据量，可以缓解数据倾斜</li></ul><h3 id="4、双重聚合"><a href="#4、双重聚合" class="headerlink" title="4、双重聚合"></a><strong>4、双重聚合</strong></h3><ul><li>先增加随机前缀聚合一次，再去掉前缀聚合一次</li></ul><h3 id="5、map-join"><a href="#5、map-join" class="headerlink" title="**5、map join **"></a>**5、map join **</h3><ul><li>适合大表关联小表，大表部分数据分布不均</li><li>mapjoin 不会产生shuffle,就不会导致数据倾斜</li></ul><h3 id="6、采样倾斜的key并拆分jon"><a href="#6、采样倾斜的key并拆分jon" class="headerlink" title="6、采样倾斜的key并拆分jon"></a><strong>6、采样倾斜的key并拆分jon</strong></h3><ul><li>当大表关联大表，有一个表部分key数据分布不均</li><li>把倾斜的数据单独拿出来使用mapjoin进行关联，避免了数据倾斜</li></ul>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>FLink代码</title>
    <link href="http://example.com/2022/07/19/FLink%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/19/FLink%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-25T14:43:16.297Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、flink编写WordCount"><a href="#1、flink编写WordCount" class="headerlink" title="1、flink编写WordCount"></a>1、flink编写WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建flink环境</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置flink任务的并行度</span></span><br><span class="line">    <span class="comment">//默认和电脑的核数有关</span></span><br><span class="line">    env.setParallelism(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据从上游发送到下游的超时时间</span></span><br><span class="line">    <span class="comment">//默认是200毫秒</span></span><br><span class="line">    env.setBufferTimeout(<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计单词的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//将一行转换成多行</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//转换成kv格式</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照单词进行分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//d对value进行汇总</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = groupByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、查看结果</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动flink程序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、map"><a href="#2、map" class="headerlink" title="2、map"></a>2、map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * map方法，每一条数据执行一次，传进来一条返回一条</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ： 一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">String</span>): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">4</span>)</span><br><span class="line">        (clazz, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    kvDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、Java-API"><a href="#3、Java-API" class="headerlink" title="3、Java API"></a>3、Java API</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.<span class="type">Tuple2</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">DataStreamSource</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">SingleOutputStreamOperator</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.<span class="type">StreamExecutionEnvironment</span>;</span><br><span class="line"></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Demo2JavaApi</span> </span>&#123;</span><br><span class="line">    public static void main(<span class="type">String</span>[] args) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">        <span class="comment">//创建flink环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="type">DataStreamSource</span>&lt;<span class="type">String</span>&gt; studentDS = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//java 代码</span></span><br><span class="line">        <span class="type">SingleOutputStreamOperator</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt; kvDS = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>&lt;<span class="type">String</span>, <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            public <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt; map(<span class="type">String</span> value) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">                <span class="type">String</span> clazz = value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">4</span>];</span><br><span class="line">                <span class="keyword">return</span> <span class="type">Tuple2</span>.of(clazz, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        kvDS.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、FlatMapFuncation"><a href="#4、FlatMapFuncation" class="headerlink" title="4、FlatMapFuncation"></a>4、FlatMapFuncation</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FlatMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3FlatMapFuncation</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(<span class="keyword">new</span> <span class="type">FlatMapFunction</span>[<span class="type">String</span>, <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * flatMap： 一条数据执行一次，传入一条数据可以返回多条数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @param out   ：用于将数据发送到下游</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: <span class="type">String</span>, out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = value.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">          <span class="comment">//将数据发送到下游</span></span><br><span class="line">          out.collect(word)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    wordsDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Filter"><a href="#5、Filter" class="headerlink" title="5、Filter"></a>5、Filter</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FilterFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.&#123;<span class="type">DataStream</span>, <span class="type">StreamExecutionEnvironment</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4Filter</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> filterDS: <span class="type">DataStream</span>[<span class="type">String</span>] = studentDS.filter(<span class="keyword">new</span> <span class="type">FilterFunction</span>[<span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 传如一条数据返回一个布尔值，返回true保留数据，返回false过滤数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> gender: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">3</span>)</span><br><span class="line">        <span class="string">&quot;女&quot;</span>.equals(gender)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    filterDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、KeyBy"><a href="#6、KeyBy" class="headerlink" title="6、KeyBy"></a>6、KeyBy</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.<span class="type">KeySelector</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5KeyBy</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(<span class="keyword">new</span> <span class="type">KeySelector</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKey</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>)): <span class="type">String</span> = &#123;</span><br><span class="line">        value._1</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key之后进行聚合计算</span></span><br><span class="line">    <span class="keyword">val</span> sumDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    sumDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Reduce"><a href="#7、Reduce" class="headerlink" title="7、Reduce"></a>7、Reduce</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">ReduceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Reduce</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再分组之后进行聚合计算</span></span><br><span class="line">    <span class="comment">//val reduceDS: DataStream[(String, Int)] = keyByDS.reduce((kv1, kv2) =&gt; (kv1._1, kv1._2 + kv2._2))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> reduceDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.reduce(<span class="keyword">new</span> <span class="type">ReduceFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(kv1: (<span class="type">String</span>, <span class="type">Int</span>), kv2: (<span class="type">String</span>, <span class="type">Int</span>)): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        (kv1._1, kv1._2 + kv2._2)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    reduceDS.print()</span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Window"><a href="#8、Window" class="headerlink" title="8、Window"></a>8、Window</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingProcessingTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计最近10秒单词的数量，每个5秒统计一次</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//滑动窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] = keyByDS</span><br><span class="line">      .window(<span class="type">SlidingProcessingTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">10</span>), <span class="type">Time</span>.seconds(<span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再开窗之后进行集合计算</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、Union"><a href="#9、Union" class="headerlink" title="9、Union"></a>9、Union</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Union</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ds1: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">    <span class="keyword">val</span> ds2: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//两个ds的类型要一致</span></span><br><span class="line">    <span class="keyword">val</span> unionDS: <span class="type">DataStream</span>[<span class="type">Int</span>] = ds1.union(ds2)</span><br><span class="line"></span><br><span class="line">    unionDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>Flink状态和checkPoint</title>
    <link href="http://example.com/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/"/>
    <id>http://example.com/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-27T02:18:40.568Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1、实时计算每一个班级的平均年龄"><a href="#1、实时计算每一个班级的平均年龄" class="headerlink" title="1、实时计算每一个班级的平均年龄"></a>1、实时计算每一个班级的平均年龄</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">RuntimeContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo14AvgAge</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取socket的数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> clazzAndAge: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = lines.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> splits: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = splits(<span class="number">4</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Int</span> = splits(<span class="number">2</span>).toInt</span><br><span class="line">      (clazz, age)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照班级分组</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = clazzAndAge.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 计算平均年龄</span></span><br><span class="line"><span class="comment">     * flink的状态可以在任务算子中使用，map，filter，process都可以（Rich）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> resultDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = keyByDS.process(<span class="keyword">new</span> <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 定义两个状态来保存总人数和总年龄</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">val</span> context: <span class="type">RuntimeContext</span> = getRuntimeContext</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总人数的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumNumDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumNum&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总年龄的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumAgeDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumAge&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        sumNumState = context.getState(sumNumDesc)</span><br><span class="line"></span><br><span class="line">        sumAgeState = context.getState(sumAgeDesc)</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总人数的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumNumState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总年龄的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumAgeState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>),</span><br><span class="line">                                  ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                  out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value._1</span><br><span class="line">        <span class="keyword">val</span> age: <span class="type">Int</span> = value._2</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1、获取之前的总人数和总的年龄</span></span><br><span class="line">        <span class="keyword">var</span> sumNum: <span class="type">Int</span> = sumNumState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumNum += <span class="number">1</span></span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumNumState.update(sumNum)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> sumAge: <span class="type">Int</span> = sumAgeState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumAge += age</span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumAgeState.update(sumAge)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算平均年龄</span></span><br><span class="line">        <span class="keyword">val</span> avgAge: <span class="type">Double</span> = sumAge / sumNum.toDouble</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将数据发送到下游</span></span><br><span class="line"></span><br><span class="line">        out.collect((clazz, avgAge))</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    resultDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、状态"><a href="#2、状态" class="headerlink" title="2、状态"></a>2、状态</h4><ol><li><p>flink用于保存之前计算结果的机制</p></li><li><p>flink会为每一个key保存一个状态</p></li><li><p>常用的sum（需要保存之前的计算结果）  window（需要保存一段时间内的数据）内部都是有状态的</p></li><li><p>flink也提供了几种查用的状态类</p><ol><li><strong>valueState: 单值状态</strong>，为每一个key保存一个值，可以是任何类型，必须可以序列化</li><li><strong>mapState: kv格式的状态</strong>，为每一个key保存一个kv格式的状态</li><li><strong>listState: 集合状态</strong>，为每一个key保存一个集合状态，集合中可以保存多个元素</li><li><strong>reducingState&#x2F;AggregatingState:聚合状态</strong>，为每一个key保存一个值，再定义状态时需要一个聚合函数</li></ol></li><li><p>flink的状态和普通变量的区别</p><ol><li>普通变量是保存再flink的内存中的，如果flink任务执行失败，变量的数据会丢失</li><li>flink的状态是一个特殊的变量，状态中的数据会被checkpoint持久化到hdfs中, 如果任务执行失败，重启任务，可以恢复状态</li></ol></li><li><p>状态后端，用于保存状态的位置</p><ol><li><p>HashMapStateBackend： </p><ol><li><p>将flink的状态先保存TaskManager的内存中，在触发checkpoint的时候将taskmanager中的状态再持久化到hdfs中</p></li><li><p>可以直接使用</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">HashMapStateBackend</span>())</span><br></pre></td></tr></table></figure></li></ol></li><li><p>EmbeddedRocksDBStateBackend：</p><ol><li><p>RocksDS是一个本地的轻量级的数据库，数据在磁盘上</p></li><li><p>再启动lfink任务的时候会在每一个taskManager所在的节点启动一个rocksDB进程</p></li><li><p>flink的状态会先保存在rocksDb数据库中，当触发checkpoint的时候将数据库中的状态持久化到hdfs中</p></li><li><p>可以支持增量快照</p></li><li><p>使用rocksDb状态后端需要带入依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-statebackend-rocksdb<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>使用方式</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br></pre></td></tr></table></figure></li></ol></li></ol></li></ol><h4 id="3、checkpoint"><a href="#3、checkpoint" class="headerlink" title="3、checkpoint"></a>3、checkpoint</h4><ol><li><p>checkpoint是flink用于持久化flink状态的机制</p></li><li><p>flink会定时将flink计算的状态持久化到hdfs中</p></li><li><p>开启checkpint的方法</p><ol><li><p>在代码中开启- 每一个代码单独开启，优先级最高</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 每 1000ms 开始一次 checkpoint</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>)</span><br><span class="line"><span class="comment">// 高级选项：</span></span><br><span class="line"><span class="comment">// 设置模式为精确一次 (这是默认值)</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)</span><br><span class="line"><span class="comment">// 确认 checkpoints 之间的时间会进行 500 ms</span></span><br><span class="line">env.getCheckpointConfig.setMinPauseBetweenCheckpoints(<span class="number">500</span>)</span><br><span class="line"><span class="comment">// Checkpoint 必须在一分钟内完成，否则就会被抛弃</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointTimeout(<span class="number">60000</span>)</span><br><span class="line"><span class="comment">// 允许两个连续的 checkpoint 错误</span></span><br><span class="line">env.getCheckpointConfig.setTolerableCheckpointFailureNumber(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// 同一时间只允许一个 checkpoint 进行</span></span><br><span class="line">env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// 使用 externalized checkpoints，这样 checkpoint 在作业取消后仍就会被保留</span></span><br><span class="line"><span class="comment">//RETAIN_ON_CANCELLATION: 当任务取消时保留checkpoint</span></span><br><span class="line">env.getCheckpointConfig.setExternalizedCheckpointCleanup(</span><br><span class="line">ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)</span><br><span class="line"><span class="comment">//指定状态后端</span></span><br><span class="line"><span class="comment">//EmbeddedRocksDBStateBackend eocksDb状态后端</span></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br><span class="line"><span class="comment">//将状态保存到hdfs中，在触发checkpoint的时候将状态持久化到hdfs中</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointStorage(<span class="string">&quot;hdfs://master:9000/flink/checkpoint&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>在flink的集群的配置文件中同意开启– flink新版才有</p><p>vim  flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">execution.checkpointing.interval:</span> <span class="string">3min</span></span><br><span class="line"><span class="attr">execution.checkpointing.externalized-checkpoint-retention:</span> <span class="string">RETAIN_ON_CANCELLATION</span></span><br><span class="line"><span class="attr">execution.checkpointing.max-concurrent-checkpoints:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">execution.checkpointing.min-pause:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">execution.checkpointing.mode:</span> <span class="string">EXACTLY_ONCE</span></span><br><span class="line"><span class="attr">execution.checkpointing.timeout:</span> <span class="string">10min</span></span><br><span class="line"><span class="attr">execution.checkpointing.tolerable-failed-checkpoints:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://master:9000/flink/checkpoint</span></span><br></pre></td></tr></table></figure></li><li><p>从checkpoint恢复任务</p></li><li><p>可以在网页中指定checkpint的路径恢复,路径需要带上前缀hdfs:&#x2F;&#x2F;master:9000</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35</span><br></pre></td></tr></table></figure></li><li><p>也可以在命令行中重新提交任务，指定恢复任务的位置, 需要先上传jar包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-s 恢复任务的位置</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0005  -c com.hzh.flink.core.Demo15RocksDB -s hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35 flink-1.0.jar</span><br></pre></td></tr></table></figure></li></ol></li></ol>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>flink SQL</title>
    <link href="http://example.com/2022/07/19/flink%20SQL/"/>
    <id>http://example.com/2022/07/19/flink%20SQL/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-30T00:55:23.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="1、连接器"><a href="#1、连接器" class="headerlink" title="1、连接器"></a>1、连接器</h3><h4 id="1、DataGen"><a href="#1、DataGen" class="headerlink" title="1、DataGen"></a>1、DataGen</h4><blockquote><p>用于生成随机数据的工具</p><p>只能用于source表</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line"> id STRING,</span><br><span class="line"> name STRING,</span><br><span class="line"> age <span class="type">INT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ts AS localtimestamp, : localtimestamp获取当前时间戳，</span></span><br></pre></td></tr></table></figure><h4 id="2、Print"><a href="#2、Print" class="headerlink" title="2、Print"></a>2、Print</h4><blockquote><p>print用于打印连续查询的结果的表</p><p>print只能用于sink表</p></blockquote><ul><li>基于已有的表结构创建print表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- LIKE： 基于已有的表创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><ul><li>打印数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="operator">|</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> datagen</span><br></pre></td></tr></table></figure><ul><li>手动设置字段</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table (</span><br><span class="line"> age <span class="type">INT</span>,</span><br><span class="line"> num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>统计年龄额人数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> age_num</span><br><span class="line"><span class="keyword">select</span> age ,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> datagen</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> age</span><br></pre></td></tr></table></figure><h4 id="3、BlackHole"><a href="#3、BlackHole" class="headerlink" title="3、BlackHole"></a>3、BlackHole</h4><blockquote><p>用于flink性能测试</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> blackhole_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;blackhole&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><h4 id="4、Kafka"><a href="#4、Kafka" class="headerlink" title="4、Kafka"></a>4、Kafka</h4><ul><li>kafka依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>csv依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-csv<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>kafka source</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>参选介绍</p><p>scan.startup.mode：<br>    earliest-offset: 读取所有的数据<br>    latest-offset：读取最新的数据，只能读取到任务启动之后生产的数据<br>    group-offsets（默认值）： 基于以消费者组读取数据，如果消费者组不存在读取最新的数据<br>    timestamp ：指定时间戳读取数据<br>    specific-offsets：指定偏移量读取数据<br>format：<br>    csv: 文本格式，指定字段时需要按照顺序映射，flink sql会自动解析</p><ul><li>kafka sink， 使用flink向kafka中写数据存在两种情况，<ul><li>将append only流写入kafka</li></ul></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_nan&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;\t&#x27;</span> <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 非聚合类的连续查询返回的动态表是一个append only表，可以可以写入到kafka中</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span></span><br><span class="line">student_kafka_source</span><br><span class="line"><span class="keyword">where</span> gender <span class="operator">=</span><span class="string">&#x27;男&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic student_nan</span></span><br></pre></td></tr></table></figure><ul><li>更新的流写入kafka</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> gender_num_sink (</span><br><span class="line">    gender STRING,</span><br><span class="line">num <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (gender) <span class="keyword">NOT</span> ENFORCED<span class="comment">-- 设置唯一主键</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;upsert-kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;gender_num&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;key.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 将更新的流写入kafka</span></span><br><span class="line"><span class="comment">-- 已唯一的主键作为kafka中key</span></span><br><span class="line"><span class="comment">-- 已数据作为kafkavalue</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> gender_num_sink</span><br><span class="line"><span class="keyword">select</span> gender,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> student_kafka</span><br><span class="line"><span class="keyword">where</span> gender <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> gender</span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic gender_num</span></span><br></pre></td></tr></table></figure><ul><li><p>提交到集群运行需要先将kafka依赖包上传到flink  lib目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink-sql-connector-kafka-1.15.0.jar</span><br></pre></td></tr></table></figure></li></ul><h4 id="5、JDBC"><a href="#5、JDBC" class="headerlink" title="5、JDBC"></a>5、JDBC</h4><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>jdbc source   — 有界流</p><blockquote><p>jdbc 字段按照名称和类型进行映射的，flink sql中表的字段和类型必须和数据库中保持一致</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建jdbc source表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_mysql (</span><br><span class="line">  id <span class="type">BIGINT</span>,</span><br><span class="line">  name STRING,</span><br><span class="line">  age <span class="type">BIGINT</span>,</span><br><span class="line">  gender STRING,</span><br><span class="line">  clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;students&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建print sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_mysql (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_mysql</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>jdbc sink</p><blockquote><p>实时读取kafka中学生表的数据，实时统计每个班级学生的人数，将统计的结果保存到mysql中</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- flink sql kafka source表  学生表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 在mysql中创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `clazz_num` (</span><br><span class="line">  `clazz` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `num` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`clazz`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- flink sql  jdbc sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> clazz_num_mysql (</span><br><span class="line">  clazz STRING,</span><br><span class="line">  num <span class="type">BIGINT</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (clazz) <span class="keyword">NOT</span> ENFORCED <span class="comment">-- 按照主键更新数据</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata?useUnicode=true&amp;characterEncoding=UTF-8&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;clazz_num&#x27;</span>, <span class="comment">-- 需要手动到数据库中创建表</span></span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 以下查询返回的是一个更新流，flinksql会自动按照主键更新数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> clazz_num_mysql</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span> </span><br><span class="line">student_kafka</span><br><span class="line"><span class="keyword">where</span> clazz <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student</span></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>将包含jdbc代码提交到集群运行</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、将flink-connector-jdbc-1.15.0.jar依赖上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、将mysql-connector-java-5.1.49.jar mysql 驱动上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是使用yarn-session模式徐娅偶先重启yarn-session</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭</span></span><br><span class="line">yarm application -kill application_1658546198162_0005</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">yarn-session-.sh -d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将代码打包上传到服务器提交任务</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0007  -c com.shujia.flink.sql.Demo9JDBCSink  flink-1.0.jar</span><br></pre></td></tr></table></figure><h4 id="7、FIleSystem"><a href="#7、FIleSystem" class="headerlink" title="7、FIleSystem"></a>7、FIleSystem</h4><blockquote><p>本地文件，hdfs  其它的文件系统</p></blockquote><ul><li><p>读取文件  </p><blockquote><p>可以使用batch模式处理数据</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 文件 source</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file (</span><br><span class="line">    id STRINg,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.txt&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>                     <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 读取csv格式字段需要按照顺序映射</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--print sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line">(</span><br><span class="line">    clazz STRING,</span><br><span class="line">    num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span></span><br><span class="line">student_file</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br></pre></td></tr></table></figure><ul><li>写入文件</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    ts <span class="keyword">AS</span> <span class="built_in">localtimestamp</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;500&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.gender.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;1&#x27;</span>,   </span><br><span class="line"> <span class="string">&#x27;fields.clazz.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;5&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建file sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> file_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    `<span class="keyword">day</span>` STRING,</span><br><span class="line">    `<span class="keyword">hour</span>` STRING</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (`<span class="keyword">day</span>`,`<span class="keyword">hour</span>`) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span><span class="operator">=</span><span class="string">&#x27;filesystem&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span><span class="operator">=</span><span class="string">&#x27;data/flink_sink&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span><span class="operator">=</span><span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;sink.rolling-policy.file-size&#x27;</span> <span class="operator">=</span><span class="string">&#x27;100kb&#x27;</span><span class="comment">--滚动生成新的文件的大小，默认128M</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> file_sink</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">id,name,age,gender,clazz,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>) <span class="keyword">as</span> `<span class="keyword">day</span>`,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;HH&#x27;</span>)  <span class="keyword">as</span> `<span class="keyword">hour</span>`</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">datagen</span><br></pre></td></tr></table></figure><h3 id="2、format"><a href="#2、format" class="headerlink" title="2、format"></a>2、format</h3><h4 id="1、json"><a href="#1、json" class="headerlink" title="1、json"></a>1、json</h4><blockquote><p>json格式表结构按照字段名和类型进行映射</p></blockquote><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>读取json格式的数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_file_json (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><ul><li>将数据保存为json格式</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- kafka sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_flink_json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><h3 id="3、练习"><a href="#3、练习" class="headerlink" title="3、练习"></a>3、练习</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 1、使用flink sql 统计每个城市总的车流量</span></span><br><span class="line"><span class="comment">-- 2、source 使用文件sourcecars_sample.json</span></span><br><span class="line"><span class="comment">-- 3、将统计好的结果保存到mysql中，mysql中只保留最新的结果</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink SQL的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>FLink集群搭建</title>
    <link href="http://example.com/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-17T16:00:00.000Z</published>
    <updated>2022-07-25T14:33:49.471Z</updated>
    
    <content type="html"><![CDATA[<h1 id="FLink集群搭建"><a href="#FLink集群搭建" class="headerlink" title="FLink集群搭建"></a>FLink集群搭建</h1><h2 id="独立集群"><a href="#独立集群" class="headerlink" title="独立集群"></a>独立集群</h2><blockquote><p>独立集群不需要依赖任何框架，独立运行</p></blockquote><p>1、上传解压配置环境变量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf flink-1.15.0-bin-scala_2.12.tgz </span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p>2、修改配置文件</p><p>vim conf&#x2F;flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">jobmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">rest.bind-address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.numberOfTaskSlots:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>vim conf&#x2F;masters</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master:8081</span><br></pre></td></tr></table></figure><p>vim workers</p><p>分布式写node1,node2（伪分布式只写master）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><p>3、将flink文件同步到另外两个节点中</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r flink-1.15.0/ node1:`pwd`</span><br><span class="line">scp -r flink-1.15.0/ node2:`pwd`</span><br></pre></td></tr></table></figure><p>4、需要修改node1和node2中的配置文件</p><p>vim flink-conf.yaml</p><p>node1节点改成node1,node2的节点改成node2</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">taskmanager.host:</span> <span class="string">node1/node2</span></span><br></pre></td></tr></table></figure><p>5、启动flink的独立集群</p><p>在master中启动集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-cluster.sh</span><br><span class="line"></span><br><span class="line">关闭</span><br><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>6、访问flink的页面</p><p><a href="http://master:8081/">http://master:8081</a></p><h2 id="flink-提交任务的方式"><a href="#flink-提交任务的方式" class="headerlink" title="flink 提交任务的方式"></a>flink 提交任务的方式</h2><p>1、将项目打包在网页上提交</p><p>2、将jar包上传到集群使用flink命令提交</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink run -c com.shujia.core.Demo1WordCount flink-1.0.jar</span><br></pre></td></tr></table></figure><h2 id="FLINK-on-YARN"><a href="#FLINK-on-YARN" class="headerlink" title="FLINK on YARN"></a>FLINK on YARN</h2><blockquote><p>将flink的任务提交到yarn上运行</p></blockquote><p>1、可以先关闭flink的独立集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>2、配置HADOOP_CLASSPATH</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加</span></span><br><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>3、启动hadoop</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h2 id="提交任务到yarn上运行"><a href="#提交任务到yarn上运行" class="headerlink" title="提交任务到yarn上运行"></a>提交任务到yarn上运行</h2><h3 id="1、Application-Mode"><a href="#1、Application-Mode" class="headerlink" title="1、Application Mode"></a>1、Application Mode</h3><p>Application Mode模式主要时为了让flink可以在K8S上运行</p><blockquote><p>为每一个flink任务在yarn上启动一个集群，提交任务的main运行在jobmanager,  数据流程图在jobmanager中构建</p><p>每一个任务启动一个jobmanager</p></blockquote><p>将项目打包上传到服务器</p><p>提交任务</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">flink run-application -t yarn-application -c com.shujia.flink.core.Demo2Submit  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-application -Dyarn.application.id=application_1654846044068_0002</span><br></pre></td></tr></table></figure><p>关闭任务</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-application -Dyarn.application.id=application_1654846044068_0002 52b325d666be767b24698f459bb5dda9</span><br></pre></td></tr></table></figure><h3 id="2、Per-Job-Cluster-Mode"><a href="#2、Per-Job-Cluster-Mode" class="headerlink" title="2、Per-Job Cluster Mode"></a>2、Per-Job Cluster Mode</h3><blockquote><p>为每一个flink任务在yarn上启动一个集群, 在本地构建数据流程图，再将数据流程图提交到jobmanager中运行</p><p>每一个任务启动一个jobmanager</p></blockquote><p>提交任务</p><p>–detached: 客户端提交成功之后会退出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-per-job --detached -c com.shujia.flink.core.Demo2Submit   flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003</span><br></pre></td></tr></table></figure><p>取消任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003 86d6973d3d79a7040bfdf75b7cad88d0</span><br></pre></td></tr></table></figure><h3 id="3、Session-Mode"><a href="#3、Session-Mode" class="headerlink" title="3、Session Mode"></a>3、Session Mode</h3><blockquote><p>先再yarn中启动一个flink的集群，再通过命令将任务提交到这个集群中运行</p><p>所有的任务共享同一个jobmanager</p></blockquote><p>启动yarn session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn-session.sh -d</span><br></pre></td></tr></table></figure><p>提交任务- 可以提交多个任务，多个任务共享同一个jobmanager</p><p>1、可以在网页中提交任务</p><p>2、可以通过命令行提交任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1654852007237_0008  -c com.shujia.core.Demo12ValueState  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>退出yarn-session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -kill application_1654846044068_0004</span><br></pre></td></tr></table></figure><p>Application Mode:  每一个任务启动一个集群，任何和任务之前互不影响，在jobmanager中构建JobGraph </p><p>Per-Job Cluster Mode：每一个任务启动一个集群，任何和任务之前互不影响，在本地构建JobGraph 再将JobGraph 提交到jobmanager中运行</p><p>Session Mode: 通过sessIon模式提交的任务共用同一个集群（同一个jobmanager），如果有一个任务执行出了问题，可能会影响其它任务，一般Session 用来测试使用，因为占用的资源要少一点, 在提交任务时在动态申请taskmanager</p><p>在集群中读取kafka的数据</p><p>java.lang.ClassNotFoundException: org.apache.flink.connector.kafka.source.KafkaSource</p><p>需要将flink-sql-connector-kafka-1.15.0.jar 包上传到flink的lib目录下</p><h2 id="yarn-资源不足问题"><a href="#yarn-资源不足问题" class="headerlink" title="yarn 资源不足问题"></a>yarn 资源不足问题</h2><p>修改yarn-site.xml文件</p><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">将配置文件同步到另外两个节点</span><br><span class="line">scp yarn-site.xml node1:`pwd`</span><br><span class="line">scp yarn-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line">重启yarn</span><br><span class="line">stop-yarn.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习FLink的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="FLink" scheme="http://example.com/tags/FLink/"/>
    
  </entry>
  
  <entry>
    <title>Spark-SQL</title>
    <link href="http://example.com/2022/07/15/Spark-Sql/"/>
    <id>http://example.com/2022/07/15/Spark-Sql/</id>
    <published>2022-07-14T16:00:00.000Z</published>
    <updated>2022-08-10T02:49:31.547Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1、sparkWordCount"><a href="#1、sparkWordCount" class="headerlink" title="1、sparkWordCount"></a>1、sparkWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    linesDF.printSchema() <span class="comment">//打印表结构</span></span><br><span class="line">    linesDF.show() <span class="comment">//打印数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、将DataFrame注册成一个视图，才能写sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    linesDF.createOrReplaceTempView(<span class="string">&quot;lines&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、写Spark的SQl来统计单词的数量</span></span><br><span class="line"><span class="comment">     * sparkSQl的语法完全兼容hive sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">DataFrame</span> = spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |select word,count(1) as c from</span></span><br><span class="line"><span class="string">        |(select explode(split(line,&#x27;,&#x27;)) as word</span></span><br><span class="line"><span class="string">        |from</span></span><br><span class="line"><span class="string">        |lines) as a</span></span><br><span class="line"><span class="string">        |group by word</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、将数据保存到本地</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    result</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)<span class="comment">//指定文件类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;,&quot;</span>)<span class="comment">//数据分隔符</span></span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)<span class="comment">//覆盖数据</span></span><br><span class="line">      .save(<span class="string">&quot;data/wc1&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2、WslWordCount"><a href="#2、WslWordCount" class="headerlink" title="2、WslWordCount"></a>2、WslWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2DSLWC</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL:类sql api，介于代码和SQL之间的一种写法</span></span><br><span class="line"><span class="comment">     * 在写DSL之前需要导入sparkSql的函数和隐式转换</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//$&quot;line&quot; 获取列对象</span></span><br><span class="line">    linesDF</span><br><span class="line">      <span class="comment">//将一行中的多个单词拆分成多行</span></span><br><span class="line">      .select(explode(split($<span class="string">&quot;line&quot;</span>, <span class="string">&quot;,&quot;</span>)) as <span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//按照单词分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//统计单词的数量</span></span><br><span class="line">      .agg(count($<span class="string">&quot;word&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保存数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/wc2&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3、DslAPI"><a href="#3、DslAPI" class="headerlink" title="3、DslAPI"></a>3、DslAPI</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3DSLAPI</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建spark连接</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> session: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;Demo3DslAPI&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partition&quot;</span>,<span class="number">1</span>) <span class="comment">//指定在shuffle之后的分区数，默认是200，类似hive中设置reduce的数量</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL API</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取一个json格式文件,spark会自动识别json中的列名</span></span><br><span class="line">    <span class="keyword">val</span> dataFrame: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>) <span class="comment">//指定读取数据的格式为json</span></span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    dataFrame.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * show：查看df中数据，相当于rdd的action算子，会触发任务的执行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    dataFrame.show()</span><br><span class="line">    <span class="comment">//指定打印多少行</span></span><br><span class="line">    dataFrame.show(<span class="number">20</span>)</span><br><span class="line">    <span class="comment">//完整打印每一列的数据</span></span><br><span class="line">    dataFrame.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * select:选择数据，和sql中的select用法基本一致</span></span><br><span class="line"><span class="comment">     * dsl中select 不能使用聚合函数需要在agg中使用聚合函数</span></span><br><span class="line"><span class="comment">     * select相当于rdd中的转换算子</span></span><br><span class="line"><span class="comment">     * selectExpr可以传一个sql的表达式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame.select(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age&quot;</span>)</span><br><span class="line">    dataFrame.selectExpr(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age+1 as age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//需要导入spark sql的函数才能在DSl中使用函数</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> session.implicits._</span><br><span class="line">    <span class="comment">//使用列对象的方式</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;name&quot;</span>, $<span class="string">&quot;age&quot;</span> + <span class="number">1</span> as <span class="string">&quot;age&quot;</span>).show()</span><br><span class="line">    <span class="comment">//在sql中使用spark函数</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;id&quot;</span>, substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) as <span class="string">&quot;zz&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * where：过滤数据 也相当于一个转换算子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//字符串的sql表达式</span></span><br><span class="line">    dataFrame.where(<span class="string">&quot;gender = &#x27;女&#x27; and age = 23&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用列对象</span></span><br><span class="line">    dataFrame.where($<span class="string">&quot;gender&quot;</span> =!= <span class="string">&quot;男&quot;</span> and $<span class="string">&quot;age&quot;</span> === <span class="number">22</span>).show()</span><br><span class="line">    <span class="comment">//这个里面只能用函数不能写scala代码</span></span><br><span class="line">    dataFrame.where(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) === <span class="string">&quot;文科&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * groupBy agg ：分组聚合要一起使用不能单独使用</span></span><br><span class="line"><span class="comment">     * 分组聚合之后返回的DF只包含分组字段和聚合字段</span></span><br><span class="line"><span class="comment">     * 分组不能在select中聚合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>, floor(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age1&quot;</span>, ceil(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age2&quot;</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * orderBy : 排序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .orderBy($<span class="string">&quot;num&quot;</span>.desc)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * join:表关联</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,cid STRING,Sco DOUBLE&quot;</span>) <span class="comment">//指定列名</span></span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关联字段名不一样时</span></span><br><span class="line">    <span class="comment">//    scoreDF.join(dataFrame,$&quot;id&quot;===$&quot;sid&quot;,&quot;inner&quot;).show()</span></span><br><span class="line">    <span class="comment">//关联字段名一样时,直接写&quot;id&quot;</span></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = scoreDF.join(dataFrame, <span class="string">&quot;id&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开窗函数</span></span><br><span class="line"><span class="comment">     * 统计每个班级总分前十的学生</span></span><br><span class="line"><span class="comment">     * withColumn():在DF的基础上增加新的列</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF</span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>,$<span class="string">&quot;clazz&quot;</span>)<span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)<span class="comment">//计算总分</span></span><br><span class="line">      <span class="comment">//简写，在前面的基础上增加列</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>,row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      .where($<span class="string">&quot;r&quot;</span>&lt;=<span class="number">10</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF.createOrReplaceTempView(<span class="string">&quot;student_score&quot;</span>)</span><br><span class="line"></span><br><span class="line">    session.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select * from (</span></span><br><span class="line"><span class="string">        |select id as sid,clazz,sumSco,row_number() over(partition by clazz order by sumSco desc) as r from (</span></span><br><span class="line"><span class="string">        |select id,clazz,sum(sco) as  sumSco</span></span><br><span class="line"><span class="string">        |from student_score</span></span><br><span class="line"><span class="string">        |group by id,clazz</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |) as b</span></span><br><span class="line"><span class="string">        |where r&lt;=10</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、DataSource"><a href="#4、DataSource" class="headerlink" title="4、DataSource"></a>4、DataSource</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4DataSource</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;source&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * csv格式的数据</span></span><br><span class="line"><span class="comment">     * 选哟指定表结构，分隔符（默认时逗号），文件路径</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> csvDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING, clazz STRING&quot;</span>) <span class="comment">//指定列名和类的类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    csvDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据保持为csv格式</span></span><br><span class="line">    csvDF</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保持数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定保持数据的格式</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/clazz_num1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * json格式</span></span><br><span class="line"><span class="comment">     * spark 会自动将json中字段名和字段类型解析出来</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * json格式比csv格式占用的空间更大，在大数据场景下不适用json</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取json格式的数据</span></span><br><span class="line">    <span class="keyword">val</span> jsonDF: <span class="type">DataFrame</span> = spark.read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    jsonDF.show()</span><br><span class="line">    <span class="comment">//将数据保存为json格式</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .groupBy($<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;gender&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/gender_num&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * parquet: 带表结构的压缩格式</span></span><br><span class="line"><span class="comment">     * 压缩：时间换空间</span></span><br><span class="line"><span class="comment">     * 压缩比取决于《信息熵》</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、将数据保存为parquet</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取parquet</span></span><br><span class="line"><span class="comment">     * parquet格式的数据自带了表结构，不需要手动指定</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> parquetDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parquetDF.printSchema()</span><br><span class="line">    parquetDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取JDBC中的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jdbcDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://master:3306&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;bigdata.students&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line"></span><br><span class="line">    jdbcDF.printSchema()</span><br><span class="line">    jdbcDF.show()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="5、RDDToDF"><a href="#5、RDDToDF" class="headerlink" title="5、RDDToDF"></a>5、RDDToDF</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5RDDToDF</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取sparkContext，使用rdd ppi</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studnetRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = linesRDD</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">          (id, name, age, gender, clazz)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将rdd转换成DF</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = studnetRDD.toDF(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;gender&quot;</span>, <span class="string">&quot;clazz&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line">    studentDF.show()</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .json()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6、DFToRDD"><a href="#6、DFToRDD" class="headerlink" title="6、DFToRDD"></a>6、DFToRDD</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6DFToRDD</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将DF转换成RDD</span></span><br><span class="line">    <span class="keyword">val</span> studentRDD: <span class="type">RDD</span>[<span class="type">Row</span>] = studentDF.rdd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stuRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map((row: <span class="type">Row</span>) =&gt; &#123;</span><br><span class="line">      <span class="comment">//通过列名获取数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = row.getAs[<span class="type">Long</span>](<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      (id, name, age, gender, clazz)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//stuRDD.foreach(println)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> caseRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map &#123;</span><br><span class="line">      <span class="comment">//需要注意字段顺序</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Row</span>(age: <span class="type">Long</span>, clazz: <span class="type">String</span>, gender: <span class="type">String</span>, id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    caseRDD.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="7、开窗"><a href="#7、开窗" class="headerlink" title="7、开窗"></a>7、开窗</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 窗口函数</span></span><br><span class="line"><span class="comment">     * row_number</span></span><br><span class="line"><span class="comment">     * rank</span></span><br><span class="line"><span class="comment">     * sum</span></span><br><span class="line"><span class="comment">     * count</span></span><br><span class="line"><span class="comment">     * avg</span></span><br><span class="line"><span class="comment">     * max</span></span><br><span class="line"><span class="comment">     * min</span></span><br><span class="line"><span class="comment">     * lag 取当前行前面</span></span><br><span class="line"><span class="comment">     * lead： 取当前行后面的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;window&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//学生表</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING,clazz STRING&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;sid STRING,cid STRING,sco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//科目表</span></span><br><span class="line">    <span class="keyword">val</span> subjectDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;cid STRING,cname STRING,ssco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/subject.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = studentDF.join(scoreDF, $<span class="string">&quot;id&quot;</span> === $<span class="string">&quot;sid&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计总分年级排名前十学生各科的分数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * sum over 由两种用法</span></span><br><span class="line"><span class="comment">     * 1、之分区不拍戏----总和</span></span><br><span class="line"><span class="comment">     * 2、分区也排序-----累计求和</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//按总分排名</span></span><br><span class="line">      .orderBy($<span class="string">&quot;sumSco&quot;</span>.desc)</span><br><span class="line">      <span class="comment">//取top</span></span><br><span class="line">      .limit(<span class="number">60</span>)</span><br><span class="line">    <span class="comment">//.show(60)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计每科都及格的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreDF</span><br><span class="line">      <span class="comment">//关联科目表</span></span><br><span class="line">      .join(subjectDF, <span class="string">&quot;cid&quot;</span>)</span><br><span class="line">      <span class="comment">//1过滤不及格的分数</span></span><br><span class="line">      .where($<span class="string">&quot;sco&quot;</span> &gt;= $<span class="string">&quot;ssco&quot;</span> * <span class="number">0.6</span>)</span><br><span class="line">      <span class="comment">//统计每个学生几个的科目数</span></span><br><span class="line">      .withColumn(<span class="string">&quot;jige&quot;</span>, count($<span class="string">&quot;sid&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;sid&quot;</span>))</span><br><span class="line">      <span class="comment">//取出都及格的学生</span></span><br><span class="line">      .where($<span class="string">&quot;jige&quot;</span> === <span class="number">6</span>)</span><br><span class="line">    <span class="comment">//.show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、统计总分大于年级平均分的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//计算年级平均分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;avgSco&quot;</span>, avg($<span class="string">&quot;sumSco&quot;</span>) over <span class="type">Window</span>.partitionBy(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">      .where($<span class="string">&quot;sumSco&quot;</span> &gt; $<span class="string">&quot;avgSco&quot;</span>)</span><br><span class="line">    <span class="comment">//.show(1000)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计每个班级每个名次分数差</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * lag:取当前行前面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     * lead 取当前行后面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>, $<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      <span class="comment">//增加排名</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>, row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//取前一个名次的总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;headSumSco&quot;</span>, lag($<span class="string">&quot;sumSco&quot;</span>, <span class="number">1</span>, <span class="number">750</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//计算分数差</span></span><br><span class="line">      .withColumn(<span class="string">&quot;cha&quot;</span>, $<span class="string">&quot;headSumSco&quot;</span> - $<span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="8、练习"><a href="#8、练习" class="headerlink" title="8、练习"></a>8、练习</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Column</span>, <span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Burks</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;burk&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取数据</span></span><br><span class="line">    <span class="keyword">val</span> burksDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;burk STRING,year STRING,tsl01 DOUBLE,tsl02 DOUBLE,tsl03 DOUBLE,tsl04 DOUBLE,tsl05 DOUBLE,tsl06 DOUBLE,tsl07 DOUBLE,tsl08 DOUBLE,tsl09 DOUBLE,tsl10 DOUBLE,tsl11 DOUBLE,tsl12 DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/burks.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    burksDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计每个公司每年按月累计收入  行转列 --&gt; sum窗口函数</span></span><br><span class="line"><span class="comment">     * 输出结果</span></span><br><span class="line"><span class="comment">     * 公司代码,年度,月份,当月收入,累计收入</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    burksDF.createOrReplaceTempView(<span class="string">&quot;burks&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |burk,year,month,plc,</span></span><br><span class="line"><span class="string">        |sum(plc) over(partition by burk,year order by month) as leiji</span></span><br><span class="line"><span class="string">        | from (</span></span><br><span class="line"><span class="string">        |select burk,year,month,plc</span></span><br><span class="line"><span class="string">        |from burks</span></span><br><span class="line"><span class="string">        |lateral view explode(map(1,tsl01,2,tsl02,3,tsl03,4,tsl04,5,tsl05,6,tsl06,7,tsl07,8,tsl08,9,tsl09,10,tsl10,11,tsl11,12,tsl12)) T as month,plc</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">    <span class="comment">// .show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> m: <span class="type">Column</span> = map(</span><br><span class="line">      expr(<span class="string">&quot;1&quot;</span>), $<span class="string">&quot;tsl01&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;2&quot;</span>), $<span class="string">&quot;tsl02&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;3&quot;</span>), $<span class="string">&quot;tsl03&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;4&quot;</span>), $<span class="string">&quot;tsl04&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;5&quot;</span>), $<span class="string">&quot;tsl05&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;6&quot;</span>), $<span class="string">&quot;tsl06&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;7&quot;</span>), $<span class="string">&quot;tsl07&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;8&quot;</span>), $<span class="string">&quot;tsl08&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;9&quot;</span>), $<span class="string">&quot;tsl09&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;10&quot;</span>), $<span class="string">&quot;tsl10&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;11&quot;</span>), $<span class="string">&quot;tsl11&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;12&quot;</span>), $<span class="string">&quot;tsl12&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    burksDF</span><br><span class="line">      <span class="comment">//一行转换成多行</span></span><br><span class="line">      .select($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>, explode(m) as <span class="type">Array</span>(<span class="string">&quot;month&quot;</span>, <span class="string">&quot;plc&quot;</span>))</span><br><span class="line">      <span class="comment">//计算按月累计</span></span><br><span class="line">      .withColumn(<span class="string">&quot;leiji&quot;</span>, sum($<span class="string">&quot;plc&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>).orderBy($<span class="string">&quot;month&quot;</span>))</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="9、Spark-Sql"><a href="#9、Spark-Sql" class="headerlink" title="9、Spark Sql"></a>9、Spark Sql</h5><p><strong>spark-sql  写代码方式</strong></p><h6 id="1、idea里面将代码编写好打包上传到集群中运行，上线使用"><a href="#1、idea里面将代码编写好打包上传到集群中运行，上线使用" class="headerlink" title="1、idea里面将代码编写好打包上传到集群中运行，上线使用"></a>1、idea里面将代码编写好打包上传到集群中运行，上线使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--conf spark.sql.shuffle.partitions=1 -- 设置spark sqlshuffle之后分区数据马，和代码里面设置是一样的，代码中优先级高</span><br><span class="line">spark-submit提交</span><br><span class="line">spark-submit --master yarn-client --class com.shujia.spark.sql.Demo9Submit --conf spark.sql.shuffle.partitions=1 spark-1.0.jar </span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用"><a href="#2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用" class="headerlink" title="2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用"></a>2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark-shell --master yarn-client</span><br><span class="line">不能使用yarn-cluster Driver必须再本地启动</span><br></pre></td></tr></table></figure><h6 id="3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql"><a href="#3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql" class="headerlink" title="3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql"></a>3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在spark-sql时完全兼容hive sql的</span><br><span class="line">spark-sql底层使用的时spark进行计算的</span><br><span class="line">hive 底层使用的是MR进行计算的</span><br></pre></td></tr></table></figure><h5 id="10、spark-sql整合hive"><a href="#10、spark-sql整合hive" class="headerlink" title="10、spark sql整合hive"></a>10、spark sql整合hive</h5><blockquote><p>在spark sql中使用hive的元数据</p><p>spark sql是使用spark进行计算的，hive使用MR进行计算的</p></blockquote><h6 id="1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"><a href="#1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务" class="headerlink" title="1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"></a>1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务</h6><p>cd &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hive-1.2.1&#x2F;conf&#x2F;</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://master:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h6 id="2、启动hive元数据服务-将hvie的元数据暴露给第三方使用"><a href="#2、启动hive元数据服务-将hvie的元数据暴露给第三方使用" class="headerlink" title="2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用"></a>2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup  hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="3、将hive-site-xml-复制到spark-conf目录下"><a href="#3、将hive-site-xml-复制到spark-conf目录下" class="headerlink" title="3、将hive-site.xml  复制到spark conf目录下"></a>3、将hive-site.xml  复制到spark conf目录下</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp hive-site.xml /usr/local/soft/spark-2.4.5/conf/</span><br></pre></td></tr></table></figure><h6 id="4、-将mysql-驱动包复制到spark-jars目录下"><a href="#4、-将mysql-驱动包复制到spark-jars目录下" class="headerlink" title="4、 将mysql 驱动包复制到spark jars目录下"></a>4、 将mysql 驱动包复制到spark jars目录下</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/hive-1.2.1/lib</span><br><span class="line">cp mysql-connector-java-5.1.49.jar /usr/local/soft/spark-2.4.5/jars/</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="5、整合好之后在spark-sql-里面就可以使用hive的表了"><a href="#5、整合好之后在spark-sql-里面就可以使用hive的表了" class="headerlink" title="5、整合好之后在spark-sql 里面就可以使用hive的表了"></a>5、整合好之后在spark-sql 里面就可以使用hive的表了</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模式是<span class="built_in">local</span>模式</span></span><br><span class="line">spark-sql -conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用yarn-client模式</span></span><br><span class="line">spark-sql --master yarn-client  --conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在spark-sql中设置运行参数</span></span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-e"><a href="#spark-sql-e" class="headerlink" title="spark-sql -e"></a>spark-sql -e</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 执行一条sql语句，执行完，自动退出</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>e &quot;select * from student&quot;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-f"><a href="#spark-sql-f" class="headerlink" title="spark-sql -f"></a>spark-sql -f</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">vim a.sql</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student</span><br><span class="line"><span class="comment">-- 执行一个sql文件</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>f a.sql</span><br></pre></td></tr></table></figure><h6 id="当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表"><a href="#当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表" class="headerlink" title="当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表"></a>当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表</h6><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">.builder()</span><br><span class="line">.appName(<span class="string">&quot;onhive&quot;</span>)</span><br><span class="line">.enableHiveSupport() <span class="comment">//开启hive的元数据支持，在代码中读取hive的元数据</span></span><br><span class="line">.getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">//读取hie的表</span></span><br><span class="line"><span class="keyword">val</span> studentDF = spark.talbe(<span class="string">&quot;studnet&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//写好的代码不能再本地运行， 需要打包上传到集群运行</span></span><br></pre></td></tr></table></figure><h6 id="spark-sql和hvie的建表语句一样"><a href="#spark-sql和hvie的建表语句一样" class="headerlink" title="spark sql和hvie的建表语句一样"></a>spark sql和hvie的建表语句一样</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">(</span><br><span class="line">id  string,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span>,</span><br><span class="line">gender string,</span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/student/&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score</span><br><span class="line">(</span><br><span class="line">student_id  string,</span><br><span class="line">cource_id string,</span><br><span class="line">sco <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/score/&#x27;</span>;</span><br></pre></td></tr></table></figure><h6 id="禁用集群spark日志"><a href="#禁用集群spark日志" class="headerlink" title="禁用集群spark日志"></a>禁用集群spark日志</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/conf</span><br><span class="line">mv log4j.properties.template log4j.properties</span><br><span class="line">vim log4j.properties</span><br><span class="line">修改配置</span><br><span class="line">log4j.rootCategory=ERROR, console</span><br></pre></td></tr></table></figure><h5 id="11、spark-sql和hive区别"><a href="#11、spark-sql和hive区别" class="headerlink" title="11、spark sql和hive区别"></a>11、spark sql和hive区别</h5><h6 id="1、spark-sql缓存"><a href="#1、spark-sql缓存" class="headerlink" title="1、spark sql缓存"></a>1、spark sql缓存</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 进入spark sql命令行</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span></span><br><span class="line"><span class="comment">-- 可以通过一个网址访问spark任务</span></span><br><span class="line">http:<span class="operator">/</span><span class="operator">/</span>master:<span class="number">4040</span></span><br><span class="line"><span class="comment">-- 设置并行度</span></span><br><span class="line"><span class="keyword">set</span> spark.sql.shuffle.partitions<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再spark-sql中对同一个表进行多次查询的时候可以将表缓存起来</span></span><br><span class="line">cache <span class="keyword">table</span> student;</span><br><span class="line"><span class="comment">-- 删除缓存</span></span><br><span class="line">uncache <span class="keyword">table</span> student;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再代码中也可以缓存DF</span></span><br><span class="line"> studentDF.persist(StorageLevel.MEMORY_ONLY)</span><br></pre></td></tr></table></figure><h6 id="2、spark-sql-mapjoin-—-广播变量"><a href="#2、spark-sql-mapjoin-—-广播变量" class="headerlink" title="2、spark sql mapjoin    — 广播变量"></a>2、spark sql mapjoin    — 广播变量</h6><h5 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><h5 id="MapJoin"><a href="#MapJoin" class="headerlink" title="MapJoin"></a>MapJoin</h5><blockquote><p>当一个大表关联小表的时候可以将小表加载到内存中进行关联—- 广播变量</p><p>在map端进行表关联，不会产生shuffle</p></blockquote> <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+broadcast(a)  */</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><blockquote><p>&#x2F;*+broadcast(a)  *&#x2F;   HINT:给sql加提示的语法</p></blockquote><h5 id="12、Spaark-JDBC"><a href="#12、Spaark-JDBC" class="headerlink" title="12、Spaark JDBC"></a>12、Spaark JDBC</h5><h6 id="1、开启hive的元数据服务"><a href="#1、开启hive的元数据服务" class="headerlink" title="1、开启hive的元数据服务"></a>1、开启hive的元数据服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="2、开启spark-jdbc-服务"><a href="#2、开启spark-jdbc-服务" class="headerlink" title="2、开启spark jdbc  服务"></a>2、开启spark jdbc  服务</h6><blockquote><p>saprkjdbc服务使用的就是hive的jdbc服务</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/sbin/</span><br><span class="line">./start-thriftserver.sh --master yarn-client</span><br></pre></td></tr></table></figure><h6 id="3、使用命令链接spark-sql-jdbc服务"><a href="#3、使用命令链接spark-sql-jdbc服务" class="headerlink" title="3、使用命令链接spark sql  jdbc服务"></a>3、使用命令链接spark sql  jdbc服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/bin/</span><br><span class="line">./beeline </span><br><span class="line">输入</span><br><span class="line">!connect jdbc:hive2://master:10000</span><br><span class="line"></span><br><span class="line">设置sparkshuffle并行度</span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="4、使用scala代码远程链接spark-sql-jdbc服务"><a href="#4、使用scala代码远程链接spark-sql-jdbc服务" class="headerlink" title="4、使用scala代码远程链接spark sql jdbc服务"></a>4、使用scala代码远程链接spark sql jdbc服务</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">-- 1、在maven增加增加jdbc驱动</span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">-- 2、编写java jdbc代码</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Spark-Sql的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark搭建</title>
    <link href="http://example.com/2022/07/12/spark%E6%90%AD%E5%BB%BA/"/>
    <id>http://example.com/2022/07/12/spark%E6%90%AD%E5%BB%BA/</id>
    <published>2022-07-11T16:00:00.000Z</published>
    <updated>2022-07-18T12:55:56.541Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Spark搭建"><a href="#Spark搭建" class="headerlink" title="Spark搭建"></a>Spark搭建</h3><h4 id="一、standalone模式"><a href="#一、standalone模式" class="headerlink" title="一、standalone模式"></a>一、standalone模式</h4><h5 id="1、上传解压，配置环境变量-配置bin目录"><a href="#1、上传解压，配置环境变量-配置bin目录" class="headerlink" title="1、上传解压，配置环境变量 配置bin目录"></a>1、上传解压，配置环境变量 配置bin目录</h5><p>解压</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf spark-2.4.5-bin-hadoop2.7.tgz </span><br></pre></td></tr></table></figure><p>重命名</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5</span><br></pre></td></tr></table></figure><p>配置环境变量<br><img src="https://s2.loli.net/2022/07/13/JhzWDHme6kwMncb.png" alt="image-20220713092425892"></p><h5 id="2、修改配置文件-conf"><a href="#2、修改配置文件-conf" class="headerlink" title="2、修改配置文件(conf)"></a>2、修改配置文件(conf)</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"></span><br><span class="line">export SPARK_WORKER_CORES=2</span><br><span class="line">export SPARK_WORKER_INSTANCES=1</span><br><span class="line">export SPARK_WORKER_MEMORY=2g</span><br><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><p>master相当于RM  worker相当于NM</p><p>增加从节点配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim slaves</span><br><span class="line">增加从节点</span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><h5 id="3、复制到其它节点"><a href="#3、复制到其它节点" class="headerlink" title="3、复制到其它节点"></a>3、复制到其它节点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r spark-2.4.5 node1:`pwd`</span><br><span class="line">scp -r spark-2.4.5 node2:`pwd`</span><br></pre></td></tr></table></figure><h5 id="4、在主节点执行启动命令"><a href="#4、在主节点执行启动命令" class="headerlink" title="4、在主节点执行启动命令"></a>4、在主节点执行启动命令</h5><p>​    启动集群，在master中执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./sbin/start-all.sh</span><br></pre></td></tr></table></figure><figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">http://master:8080/  访问spark ui</span><br></pre></td></tr></table></figure><h5 id="5、两种spark提交任务的方式"><a href="#5、两种spark提交任务的方式" class="headerlink" title="5、两种spark提交任务的方式"></a>5、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><p>（1）standalone client模式 日志在本地输出，一般用于上线前测试(bin&#x2F;下执行)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512m --total-executor-cores 1 spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）standalone cluster模式，上线使用，不会再本地打印日志</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512M --total-executor-cores 1 --deploy-mode cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码"><a href="#6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码" class="headerlink" title="6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码"></a>6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-shell master spark://master:7077</span><br></pre></td></tr></table></figure><h4 id="二、spark整合yarn"><a href="#二、spark整合yarn" class="headerlink" title="二、spark整合yarn"></a>二、spark整合yarn</h4><p>​        在公司一般不适用standalone模式，因为公司一般已经有yarn，不需要搞两个资源管理框架</p><p>首先停止spark集群，在spark sbin目录下执行  .&#x2F;stop-all.sh，也要保证hadoop也是关闭的</p><p>spark整合yarn只需要在一个节点整合, 可以删除node1 和node2中所有的spark 文件（也可以不删除）</p><h5 id="1、增加hadoop-配置文件地址"><a href="#1、增加hadoop-配置文件地址" class="headerlink" title="1、增加hadoop 配置文件地址"></a>1、增加hadoop 配置文件地址</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim spark-env.sh</span><br><span class="line">增加配置</span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/soft/hadoop-2.7.6/etc/hadoop</span><br></pre></td></tr></table></figure><h5 id="2、往yarn提交任务需要增加两个配置-yarn-site-xml"><a href="#2、往yarn提交任务需要增加两个配置-yarn-site-xml" class="headerlink" title="2、往yarn提交任务需要增加两个配置  yarn-site.xml"></a>2、往yarn提交任务需要增加两个配置  yarn-site.xml</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/soft/hadoop-2.7.6/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="3、同步到其他节点，重启yarn"><a href="#3、同步到其他节点，重启yarn" class="headerlink" title="3、同步到其他节点，重启yarn"></a>3、同步到其他节点，重启yarn</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r yarn-site.xml node1:`pwd`</span><br><span class="line">scp -r yarn-site.xml node2:`pwd`</span><br></pre></td></tr></table></figure><p>启动yarn</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h5 id="4、两种spark提交任务的方式"><a href="#4、两种spark提交任务的方式" class="headerlink" title="4、两种spark提交任务的方式"></a>4、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><p>（1）spark on yarn client模式，日志在本地输出，一般用于上线前测试</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）spark on yarn cluster模式，上线使用，不会再本地打印日志减少io</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="5、获取yarn程序执行日志-执行成功之后才能获取到"><a href="#5、获取yarn程序执行日志-执行成功之后才能获取到" class="headerlink" title="5、获取yarn程序执行日志  执行成功之后才能获取到"></a>5、获取yarn程序执行日志  执行成功之后才能获取到</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><h5 id="6、杀掉进行的任务"><a href="#6、杀掉进行的任务" class="headerlink" title="6、杀掉进行的任务"></a>6、杀掉进行的任务</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><p>hdfs web ui<br><a href="http://node1:50070/">http://node1:50070</a></p><p>yarn ui<br><a href="http://node1:8088/">http://node1:8088</a></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark代码</title>
    <link href="http://example.com/2022/07/11/spark%E4%BB%A3%E7%A0%81/"/>
    <id>http://example.com/2022/07/11/spark%E4%BB%A3%E7%A0%81/</id>
    <published>2022-07-10T16:00:00.000Z</published>
    <updated>2022-07-25T14:28:50.966Z</updated>
    
    <content type="html"><![CDATA[<h5 id="1、编写wordcount-（standalone模式）"><a href="#1、编写wordcount-（standalone模式）" class="headerlink" title="1、编写wordcount    （standalone模式）"></a>1、编写wordcount    （standalone模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  建立连接</span></span><br><span class="line"><span class="comment">     *  提交到集群运行需要注释setMaster</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo18SparkSubmit&quot;</span>)</span><br><span class="line"><span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> valuesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">List</span>(<span class="string">&quot;java,java,hadoop&quot;</span>, <span class="string">&quot;spark,scala,java&quot;</span>, <span class="string">&quot;hadoop,hadoop,scala&quot;</span>)) </span><br><span class="line">    valuesRDD.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_+_) <span class="comment">//按key聚合</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master spark://master:7077 spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="2、编写wordcount-（on-yarn模式）"><a href="#2、编写wordcount-（on-yarn模式）" class="headerlink" title="2、编写wordcount    （on yarn模式）"></a>2、编写wordcount    （on yarn模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 建立连接，注释掉setMaster一行</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line"></span><br><span class="line">    conf.setAppName(<span class="string">&quot;submit on yarn&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">Configuration</span>()</span><br><span class="line">    <span class="keyword">val</span> fileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystem</span>.get(conf)</span><br><span class="line">    <span class="keyword">if</span> (fileSystem.exists(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>))) &#123;</span><br><span class="line">      fileSystem.delete(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>), <span class="literal">true</span>)<span class="comment">//若存在，删除目标路径</span></span><br><span class="line"></span><br><span class="line">    sc.textFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs的输入路径</span></span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_ + _)</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> (word: <span class="type">String</span>, count: <span class="type">Int</span>) =&gt;</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$word</span>\t<span class="subst">$count</span>&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">      .saveAsTextFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs输出目录，保证目标路径不存在</span></span><br><span class="line">    </span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master yarn-client spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="3、用spark代码实现PI的计算"><a href="#3、用spark代码实现PI的计算" class="headerlink" title="3、用spark代码实现PI的计算"></a>3、用spark代码实现PI的计算</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20PI</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建spark环境</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo20PI&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//生成一个大集合</span></span><br><span class="line">    <span class="keyword">val</span> list: <span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="number">0</span> to <span class="number">100000</span></span><br><span class="line">    <span class="comment">//构建一个很大的RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.parallelize(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//随机生成正方形内的点</span></span><br><span class="line">    <span class="keyword">val</span> squareRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = rdd.map(i =&gt; &#123;</span><br><span class="line">      <span class="comment">//随机生成x和y，范围是[-1,1]</span></span><br><span class="line">      <span class="keyword">val</span> x: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> y: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      (x, y)</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="comment">//取出圆内的点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> circleRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = squareRDD.filter &#123;</span><br><span class="line">      <span class="keyword">case</span> (x, y) =&gt;</span><br><span class="line">        x * x + y * y &lt; <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">PI</span>: <span class="type">Double</span> = <span class="number">4.0</span> * circleRDD.count() / squareRDD.count()</span><br><span class="line"></span><br><span class="line">    println(<span class="type">PI</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、spark代码的坑（引出累加器）"><a href="#4、spark代码的坑（引出累加器）" class="headerlink" title="4、spark代码的坑（引出累加器）"></a>4、spark代码的坑（引出累加器）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">  count += <span class="number">1</span></span><br><span class="line">  println(count)</span><br><span class="line">&#125;)</span><br><span class="line">  println (<span class="string">s&quot;count:<span class="subst">$&#123;count&#125;</span>&quot;</span>) <span class="comment">//不要这么写</span></span><br></pre></td></tr></table></figure><p>在spark编程中算子内的代码会被封装成Task发送到<strong>Executor</strong>中去执行，而算子外的代码运行在driver端，Executor和Driver属于不同的JVM，所以当在算子内修改算子外的一个普通变量时不会生效，当算子内使用算子外的一个普通变量时，这个变量会以变量副本的形式发送给Executor中去。</p><p><strong>累加器</strong></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、定义一个累加器</span></span><br><span class="line">   <span class="keyword">val</span> accumulator: <span class="type">LongAccumulator</span> = sc.longAccumulator</span><br><span class="line"></span><br><span class="line">   studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="comment">//2、对累加器进行累加</span></span><br><span class="line">     accumulator.add(<span class="number">1</span>)</span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="comment">//3、再从Driver端读取累加结果</span></span><br><span class="line">   println(<span class="string">s&quot;accumulator:<span class="subst">$&#123;accumulator.value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>累加器原理</strong></p><p>1、现在每一个task中局部做累加</p><p>2、当job执行完成之后，将多个累加结果汇总到Driver端合并成一个结果</p><p><strong>累加器使用的限制</strong></p><p>1、只能在Driver端定义累加器</p><p>2、只能在Executor端进行累加</p><p>3、只能在Driver端读取结果</p><p>在spark写代码的过程中，rdd不能嵌套使用，在算子内不能使用rdd</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">       println(stu)</span><br><span class="line">     &#125;)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><p>在算子内 不能使用SparkContext，算子会被封装成一个Task，而Task不能被序列化（Task需要网络传输）</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line">     scoreRDD.foreach(println)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><h5 id="5、广播变量"><a href="#5、广播变量" class="headerlink" title="5、广播变量"></a>5、广播变量</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Broadcast</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo23Broadcast&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 广播变量</span></span><br><span class="line"><span class="comment">     * 当算子内使用算子外的一个比较大的变量时，可以将这个变量广播出去，可以减少变量的副本数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">      <span class="comment">//读取学生表，以学号作为key构建一个map集合</span></span><br><span class="line">    <span class="keyword">val</span> studentMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">      .getLines()</span><br><span class="line">      .toList</span><br><span class="line">      .map(stu =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> id: <span class="type">String</span> = stu.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">        (id, stu)</span><br><span class="line">      &#125;)</span><br><span class="line">      .toMap</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关联学生表和分数表</span></span><br><span class="line"><span class="comment">     * 循环分数表，使用学号到学生表的map集合中查询学生的信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreRDD.map(sco=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = sco.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">      <span class="comment">//使用学号到学生表中获取学生的信息</span></span><br><span class="line">      <span class="keyword">val</span> studentInfo: <span class="type">String</span> = studentMap.getOrElse(id, <span class="string">&quot;默认值&quot;</span>)</span><br><span class="line">      (sco,studentInfo)</span><br><span class="line">    &#125;)</span><br><span class="line">      .foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在使用算子内使用算子外的一个普通变量时，普通变量会以变量副本的形式封装到Task中，将Task发送到Executor中执行。</p><p>如果rdd有10个分区，则会产生10个Task，汇总产生10个变量副本</p><p>广播变量的使用（在spark中常用于<strong>mapJoin</strong>）</p><p>1、在Driver端定义广播变量</p><p>2、到Executor使用广播变量</p><p>如果不使用广播变量，每一个task都需要携带一个变量副本每增加网络IO，增加副本数</p><p>使用广播每一个Executor中的一个变量副本</p><p>正常情况时task的数量远小于Executor的数量</p><p>mapJoin不产生shuffle，性能比reduceJoin好</p><p>mapJoin只适合小表关联大表（小表的数据量不超1G）</p><p><img src="https://s2.loli.net/2022/07/14/tSmhnvJM327pbxF.png" alt="blockmanasger"></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Spark概述</title>
    <link href="http://example.com/2022/07/10/spark%E6%A6%82%E8%BF%B0/"/>
    <id>http://example.com/2022/07/10/spark%E6%A6%82%E8%BF%B0/</id>
    <published>2022-07-09T16:00:00.000Z</published>
    <updated>2022-07-13T01:59:05.797Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/07/13/v6e4yxQ98YuOZKD.png" alt="屏幕截图 2022-07-13 095014"></p><p>MapReduce执行流程</p><p><img src="https://s2.loli.net/2022/07/13/b91AKcnLVuo3UvE.png" alt="mr执行流程"></p><p>RDD基础</p><p><img src="https://s2.loli.net/2022/07/13/9pGtPZL3gwcxoq4.png" alt="image-20220713095434515"></p><p>reduceByKey和groupByKey的区别</p><p><img src="https://s2.loli.net/2022/07/13/eGU2wRthNzT9Fbq.png" alt="reduceByKey金额groupByKey的区别"></p>]]></content>
    
    
    <summary type="html">对学习Spark的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Spark" scheme="http://example.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>scala概述及使用</title>
    <link href="http://example.com/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://example.com/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/</id>
    <published>2022-07-05T16:00:00.000Z</published>
    <updated>2022-07-13T11:24:51.551Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1、scala介绍"><a href="#1、scala介绍" class="headerlink" title="1、scala介绍"></a>1、scala介绍</h3><p>Scala 是 Scalable Language 的简写，是一门多范式的编程语言</p><p>联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计Scala。</p><p>Scala是把函数式编程思想和面向对象编程思想结合的一种编程语言。</p><p>大数据计算引擎Spark由Scala编写</p><h3 id="2、Scala特点"><a href="#2、Scala特点" class="headerlink" title="2、Scala特点"></a>2、Scala特点</h3><p><strong>多范式</strong>：面向对象，函数式编程</p><p><strong>兼容JAVA</strong>：类库调用，互操作</p><p><strong>语法简洁</strong>：代码行短，类型推断，抽象控制</p><p><strong>静态类型化</strong>：可检验，安全重构</p><p><strong>支持并发控制</strong>：强计算能力，自定义其他控制结构</p><p>在面向对象编程中，我们把对象传来传去，那在函数式编程中，我们要做的是把函数传来传去，而这个，说成术语，我们把他叫做高阶函数。</p><p>在函数式编程中，函数是基本单位，，他几乎被用作一切，包括最简单的计算，甚至连变量都被计算所取代。在函数式编程中，变量只是一个名称，而不是一个存储单元，这是函数式编程与传统的命令式编程最典型的不同之处。</p><h3 id="3、scala和java的联系"><a href="#3、scala和java的联系" class="headerlink" title="3、scala和java的联系"></a>3、scala和java的联系</h3><p><img src="https://s2.loli.net/2022/07/13/4ahsL5tkqSGlf2m.png" alt="屏幕截图 2022-07-13 102038"></p><h3 id="4、环境准备及代码编写"><a href="#4、环境准备及代码编写" class="headerlink" title="4、环境准备及代码编写"></a>4、环境准备及代码编写</h3><h4 id="1、在idea中增加scala插件"><a href="#1、在idea中增加scala插件" class="headerlink" title="1、在idea中增加scala插件"></a>1、在idea中增加scala插件</h4><p><img src="https://s2.loli.net/2022/07/13/DogYxlEBcjnZVKy.png" alt="image-20220713102325386"></p><h4 id="2、新建一个maven项目，在pom中增加Scala和java的编译插件"><a href="#2、新建一个maven项目，在pom中增加Scala和java的编译插件" class="headerlink" title="2、新建一个maven项目，在pom中增加Scala和java的编译插件"></a>2、新建一个maven项目，在pom中增加Scala和java的编译插件</h4><h5 id="（1）在pom文件中增加依赖"><a href="#（1）在pom文件中增加依赖" class="headerlink" title="（1）在pom文件中增加依赖"></a>（1）在pom文件中增加依赖</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-reflect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="（2）在pom中增加Scala和java的编译插件"><a href="#（2）在pom中增加Scala和java的编译插件" class="headerlink" title="（2）在pom中增加Scala和java的编译插件"></a>（2）在pom中增加Scala和java的编译插件</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Scala Compiler --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-scala-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="3、scala样例类"><a href="#3、scala样例类" class="headerlink" title="3、scala样例类"></a>3、scala样例类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8CaseClass</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> user1 = <span class="keyword">new</span> <span class="type">User</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;张三&quot;</span>)</span><br><span class="line">    <span class="comment">//直接通过属性获取值</span></span><br><span class="line">    println(user1.id)</span><br><span class="line">    println(user1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//样例类可以不适用new创建对象</span></span><br><span class="line">    <span class="keyword">val</span> user2: <span class="type">User</span> = <span class="type">User</span>(<span class="string">&quot;002&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="number">24</span>)</span><br><span class="line">    println(user2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//修改属性,需要在属性上增加var</span></span><br><span class="line">    user2.name = <span class="string">&quot;王五&quot;</span></span><br><span class="line">    println(user2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 样例类</span></span><br><span class="line"><span class="comment"> * scala会在编译的时候给样例类动态增加新的方法，属性，toString，序列化</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * age: Int = 0: 参数默认值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id: <span class="type">String</span>,var name: <span class="type">String</span>, age: <span class="type">Int</span> = 0</span>)</span></span><br></pre></td></tr></table></figure><h4 id="4、List"><a href="#4、List" class="headerlink" title="4、List"></a>4、List</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo15List</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合</span></span><br><span class="line"><span class="comment">     * 1、List: 有序，不唯一</span></span><br><span class="line"><span class="comment">     * 2、Set ：无序，唯一</span></span><br><span class="line"><span class="comment">     * 3、Map: kv格式   key是唯一的</span></span><br><span class="line"><span class="comment">     * 4、Tuple: 元组，固定长度集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * List集合</span></span><br><span class="line"><span class="comment">     * scal的集合比java的集合好用-多了很多的方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//不可变的List</span></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标获取数据</span></span><br><span class="line">    println(list(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">//获取第一个元素</span></span><br><span class="line">    println(list.head)</span><br><span class="line">    <span class="comment">//获取最后一个元素</span></span><br><span class="line">    println(list.last)</span><br><span class="line">    <span class="comment">//获取不包含第一个元素的所有的元素</span></span><br><span class="line">    println(list.tail)</span><br><span class="line">    <span class="comment">//将集合中的元素拼接成一个字符串</span></span><br><span class="line">    println(list.mkString(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment">//反转，返回一个新的List</span></span><br><span class="line">    println(list.reverse)</span><br><span class="line">    <span class="comment">//取前n个元素</span></span><br><span class="line">    println(list.take(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//取后n个元素</span></span><br><span class="line">    println(list.takeRight(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//去重</span></span><br><span class="line">    println(list.distinct)</span><br><span class="line">    <span class="comment">//求和，集合元素的类型必须是可以求和的类型</span></span><br><span class="line">    println(list.sum)</span><br><span class="line">    <span class="comment">//取最大值</span></span><br><span class="line">    println(list.max)</span><br><span class="line">    <span class="comment">//最小值</span></span><br><span class="line">    println(list.min)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * foreach: 循环集合，将集合中的元素一个一个传递给后面的函数，foreach没有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">var</span> sum = <span class="number">0</span></span><br><span class="line">    <span class="comment">//循环统计总和</span></span><br><span class="line">    list.foreach((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      sum += i</span><br><span class="line">    &#125;)</span><br><span class="line">    println(sum)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个元素加一（处理集合中的元素）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- list) &#123;</span><br><span class="line">      <span class="keyword">val</span> j = i * <span class="number">2</span></span><br><span class="line">      println(j)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map:循环集合将集合中的元素一个一个传递给后面的函数，函数的返回值会构建出一个新的集合</span></span><br><span class="line"><span class="comment">     * i代表的是集合中所有的元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mapList: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    println(mapList)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理集合中的元素，偶数加1，奇数乘以2</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        i * <span class="number">2</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        i + <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    println(list2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 取出集合中奇数</span></span><br><span class="line"><span class="comment">     * Filter: 循环集合，将集合中的元素一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 如果函数返回true保留数据，如果函数返回false过滤数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> jishuList: <span class="type">List</span>[<span class="type">Int</span>] = list.filter((i: <span class="type">Int</span>) =&gt; i % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">    println(jishuList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将一行中的多个单词拆分出来，一个单纯一行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesList = <span class="type">List</span>(<span class="string">&quot;java,spark,hadoop&quot;</span>, <span class="string">&quot;datax,scala,java&quot;</span>, <span class="string">&quot;hadoop,hive,sqoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (line &lt;- linesList) &#123;</span><br><span class="line">      <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">        println(word)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * flatMap: 循环集合中的元素，将袁术一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 函数返回一个集合，flatMap会将返回的集合拆分出来构建成一个新的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> wordsList: <span class="type">List</span>[<span class="type">String</span>] = linesList.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    wordsList.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 多集合排序</span></span><br><span class="line"><span class="comment">     * sortBy: 需要指定一个排序的字段，默认是升序</span></span><br><span class="line"><span class="comment">     * sortWith: 指定一个排序的比较规则</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">32</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortByList = list3.sortBy((i: <span class="type">Int</span>) =&gt; -i)</span><br><span class="line">    println(sortByList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortWithList = list3.sortWith((x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x &gt; y)</span><br><span class="line">    println(sortWithList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * groupBy: 分组，需要指定一个分组的字段</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> words = <span class="type">List</span>(<span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    groupByList.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 以下所有的方法都是返回新的集合，不会修改原始的集合</span></span><br><span class="line"><span class="comment">     * 同时以下这些方法在set集合中也有，除了sort</span></span><br><span class="line"><span class="comment">     * foreach:遍历数据</span></span><br><span class="line"><span class="comment">     * map：一条一条处理数据</span></span><br><span class="line"><span class="comment">     * filter：过滤数据</span></span><br><span class="line"><span class="comment">     * flatMap:将一行转换成多行</span></span><br><span class="line"><span class="comment">     * sortBy：排序</span></span><br><span class="line"><span class="comment">     * groupBy：分组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Set"><a href="#5、Set" class="headerlink" title="5、Set"></a>5、Set</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo16Set</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Set集合，无序，唯一</span></span><br><span class="line"><span class="comment">     * set集合比List集合少了排序的方法，其它的方法基本一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> set = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line">    println(set)</span><br><span class="line">    println(set.mkString(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line">    set.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> s1 = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">val</span> s2 = <span class="type">Set</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    println(s1 &amp; s2)<span class="comment">//交集</span></span><br><span class="line">    println(s1 | s2)<span class="comment">//并集</span></span><br><span class="line">    println(s1 &amp;~ s2)<span class="comment">//差集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 集合之前的转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line">    println(list)</span><br><span class="line">    <span class="keyword">val</span> listSet = list.toSet</span><br><span class="line">    println(listSet)</span><br><span class="line">    println(listSet.toList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、Mutable"><a href="#6、Mutable" class="headerlink" title="6、Mutable"></a>6、Mutable</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo17Mutable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变集合</span></span><br><span class="line"><span class="comment">     * ListBuffer:List有的方法ListBuffer都有，只是ListBuffer是可以改变的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listBuffer = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    listBuffer.+=(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    listBuffer += <span class="string">&quot;spark&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;hadoop&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;flume&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    listBuffer -= <span class="string">&quot;java&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用下标删除钠元素</span></span><br><span class="line">    listBuffer.remove(<span class="number">1</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//批量插入元素</span></span><br><span class="line">    listBuffer ++= <span class="type">List</span>(<span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//更新元素</span></span><br><span class="line">    listBuffer.update(<span class="number">1</span>, <span class="string">&quot;shujia&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标插入元素</span></span><br><span class="line">    listBuffer.insert(<span class="number">2</span>, <span class="string">&quot;大数据&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变Set</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashSet = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">Int</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    hashSet += <span class="number">1</span></span><br><span class="line">    hashSet += <span class="number">2</span></span><br><span class="line">    hashSet += <span class="number">3</span></span><br><span class="line">    hashSet += <span class="number">4</span></span><br><span class="line">    hashSet += <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    println(hashSet)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashSet -= <span class="number">1</span></span><br><span class="line">    println(hashSet)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Tuple"><a href="#7、Tuple" class="headerlink" title="7、Tuple"></a>7、Tuple</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo18Tuple</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 元组：固定长度集合</span></span><br><span class="line"><span class="comment">     * 可以通过下划线加上下标获取数据, 可以避免下标越界异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 元组最多只能存22个元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//val tuple = Tuple6(1, 2, 3, 4, 5, 6)</span></span><br><span class="line">    <span class="comment">//简写</span></span><br><span class="line">    <span class="keyword">val</span> tuple = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    println(tuple._6)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Map"><a href="#8、Map" class="headerlink" title="8、Map"></a>8、Map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo19Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map：kv格式的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = <span class="type">Map</span>((<span class="string">&quot;001&quot;</span>, <span class="number">23</span>), (<span class="string">&quot;002&quot;</span>, <span class="number">24</span>), <span class="string">&quot;003&quot;</span> -&gt; <span class="number">25</span>)</span><br><span class="line">    println(map)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以通过key获取value</span></span><br><span class="line">    <span class="keyword">val</span> value = map(<span class="string">&quot;001&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果key不存在返回默认值</span></span><br><span class="line">    <span class="keyword">val</span> age = map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="number">0</span>)</span><br><span class="line">    println(age)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个人的年龄加一</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * map集合的map方法，函数的参数是一个二元组,</span></span><br><span class="line"><span class="comment">     * 返回一个新的map</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> addAge: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map.map((kv: (<span class="type">String</span>, <span class="type">Int</span>)) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> id = kv._1</span><br><span class="line">      <span class="keyword">val</span> age = kv._2</span><br><span class="line">      (id, age + <span class="number">1</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">    println(addAge)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取所有的key和value</span></span><br><span class="line">    println(map.keys)</span><br><span class="line">    println(map.values)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变map集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//插入元素</span></span><br><span class="line">    hashMap += <span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;王五&quot;</span></span><br><span class="line"></span><br><span class="line">    println(hashMap)</span><br><span class="line">    <span class="comment">//如果key存在自动覆盖</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;赵六&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashMap.remove(<span class="string">&quot;003&quot;</span>)</span><br><span class="line">    hashMap -= <span class="string">&quot;002&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、WordCount"><a href="#9、WordCount" class="headerlink" title="9、WordCount"></a>9、WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计单纯的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//链式调用</span></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/words.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将一行中的多个单纯展开，变成一个单词一行</span></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">List</span>[<span class="type">String</span>] = lines.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、按照单词分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、统计单词的数量</span></span><br><span class="line">    <span class="keyword">val</span> wordCount: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupBy.map((kv: (<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])) =&gt; &#123;</span><br><span class="line">      <span class="comment">//分组单词</span></span><br><span class="line">      <span class="keyword">val</span> word: <span class="type">String</span> = kv._1</span><br><span class="line">      <span class="comment">//组内所有的单词</span></span><br><span class="line">      <span class="keyword">val</span> values: <span class="type">List</span>[<span class="type">String</span>] = kv._2</span><br><span class="line">      <span class="comment">//计算单词的数量</span></span><br><span class="line">      <span class="keyword">val</span> count = values.length</span><br><span class="line">      <span class="comment">//返回单词和单词的数量</span></span><br><span class="line">      (word, count)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印结果</span></span><br><span class="line">    wordCount.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 简写</span></span><br><span class="line"><span class="comment">     * 链式调用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/words.txt&quot;</span>)<span class="comment">//读取文件</span></span><br><span class="line">      .getLines()<span class="comment">//获取所有行</span></span><br><span class="line">      .toList<span class="comment">//转换成集合</span></span><br><span class="line">      .flatMap(_.split(<span class="string">&quot;,&quot;</span>))<span class="comment">//将数据展开</span></span><br><span class="line">      .groupBy(w =&gt; w)<span class="comment">//安装单词分组</span></span><br><span class="line">      .map(kv =&gt; (kv._1, kv._2.length))<span class="comment">//统计单词的数量</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="10、统计学生的总分"><a href="#10、统计学生的总分" class="headerlink" title="10、统计学生的总分"></a>10、统计学生的总分</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Case</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoresList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、安装逗号拆分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoLost: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoresList.map(sco =&gt; sco.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> filterList: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoLost.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * case 也可以匹配数组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = filterList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _: <span class="type">String</span>, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当需要处理的集合中的数据格式是一个很复杂的元组时，使用case语法，代码的可读性会更高</span></span><br><span class="line"><span class="comment">     * 以函数作为参数的另一种写法</span></span><br><span class="line"><span class="comment">     * 没有使用的变量可以使用下划线占位</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sumScoList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupByList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, scores: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//取出分数</span></span><br><span class="line">        <span class="keyword">val</span> scos: <span class="type">List</span>[<span class="type">Int</span>] = scores.map &#123; <span class="keyword">case</span> (_: <span class="type">String</span>, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line">        <span class="keyword">val</span> sumSco: <span class="type">Int</span> = scos.sum</span><br><span class="line">        (id, sumSco)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sumScoList.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="11、scala连接Mysql（JDBC）"><a href="#11、scala连接Mysql（JDBC）" class="headerlink" title="11、scala连接Mysql（JDBC）"></a>11、scala连接Mysql（JDBC）</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>, <span class="type">ResultSet</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo24Jdbc</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在scala语法中链接数据库</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//需要先在pom中增加mysql驱动的依赖</span></span><br><span class="line">    <span class="comment">//1、加载驱动</span></span><br><span class="line">    <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">    <span class="comment">//2、建立数据库链接</span></span><br><span class="line">    <span class="keyword">val</span> con: <span class="type">Connection</span> = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master/test?useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、编写sql查询数据</span></span><br><span class="line">    <span class="keyword">val</span> stat: <span class="type">PreparedStatement</span> = con.prepareStatement(<span class="string">&quot;select * from students where clazz=?&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、给参数赋值</span></span><br><span class="line">    stat.setString(<span class="number">1</span>, <span class="string">&quot;文科六班&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、执行查询</span></span><br><span class="line">    <span class="keyword">val</span> resultSet: <span class="type">ResultSet</span> = stat.executeQuery()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6、解析数据</span></span><br><span class="line">    <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">      <span class="comment">//通过列名取出数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$gender</span>\t<span class="subst">$clazz</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7、关闭连接</span></span><br><span class="line">    stat.close()</span><br><span class="line">    con.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="12、scala解析Json数据"><a href="#12、scala解析Json数据" class="headerlink" title="12、scala解析Json数据"></a>12、scala解析Json数据</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONArray</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo25JSON</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 第三方解析json工具  fastJson  Gson</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/users.json&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将读到的数据拼接成一个字符串</span></span><br><span class="line">    <span class="keyword">val</span> jsonStr: <span class="type">String</span> = lines.mkString(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    println(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用FastJson解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userArray: <span class="type">JSONArray</span> = <span class="type">JSON</span>.parseArray(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (index &lt; userArray.size()) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过下标获取每一个用户</span></span><br><span class="line">      <span class="keyword">val</span> userObject: <span class="type">JSONObject</span> = userArray.getJSONObject(index)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过列名获取列值</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = userObject.getString(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> nane: <span class="type">String</span> = userObject.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: lang.<span class="type">Long</span> = userObject.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line"></span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$nane</span>\t<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      index += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="13、scala和java中的集合相互转换"><a href="#13、scala和java中的集合相互转换" class="headerlink" title="13、scala和java中的集合相互转换"></a>13、scala和java中的集合相互转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo26ScalaOnJava</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//java中的集合</span></span><br><span class="line">    <span class="keyword">val</span> arrayList = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    arrayList.add(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hive&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;scala&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * java 集合转换成scala集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//下划线相当于java中的*</span></span><br><span class="line">    <span class="comment">//导入隐式转换(动态给对象增加新的方法)</span></span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConverters</span>._</span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scalaList: <span class="type">List</span>[<span class="type">String</span>] = arrayList.asScala.toList</span><br><span class="line"></span><br><span class="line">    println(scalaList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合转换成java集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> javaList: util.<span class="type">List</span>[<span class="type">Int</span>] = list.asJava</span><br><span class="line"></span><br><span class="line">    println(javaList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="14、Match"><a href="#14、Match" class="headerlink" title="14、Match"></a>14、Match</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo27Match</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * java中的模式匹配可以匹配基本数据类型，字符串，枚举</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * scala的模式匹配，可以匹配基本数据类型，字符串，对象，元组，数组，匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、匹配基本数据类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 模式匹配只有一个能匹配成功</span></span><br><span class="line"><span class="comment">     * 下划线代表其其它情况</span></span><br><span class="line"><span class="comment">     * 在写代码是需要考虑到所有的情况</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> i = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    i <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">10</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是10&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">20</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是20&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">100</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是100&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">&quot;其他&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、匹配字符串</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> str: <span class="type">String</span> = <span class="string">&quot;java&quot;</span></span><br><span class="line"></span><br><span class="line">    str <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;java&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;spark&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;其它&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、匹配元组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> t: (<span class="type">String</span>, <span class="type">Int</span>, <span class="type">String</span>) = (<span class="string">&quot;张三&quot;</span>, <span class="number">23</span>, <span class="string">&quot;001&quot;</span>)</span><br><span class="line"></span><br><span class="line">    t <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//替代下划线</span></span><br><span class="line">    <span class="keyword">val</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) = t</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、匹配数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[<span class="type">Any</span>] = <span class="type">Array</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;李四&quot;</span>)</span><br><span class="line"></span><br><span class="line">    array <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">Int</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\4<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 5、匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> obj: <span class="type">Any</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    obj <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> i: <span class="type">Int</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Int类型：<span class="subst">$i</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">String</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个String类型:<span class="subst">$s</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> d: <span class="type">Double</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Double类型:<span class="subst">$d</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">s&quot;其它类型：<span class="subst">$obj</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配可以有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i1: <span class="type">Int</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ty: <span class="type">String</span> = i1 % <span class="number">2</span> <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">&quot;奇数&quot;</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="string">&quot;偶数&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(ty)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配在map集合的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> map = <span class="type">Map</span>(<span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span>, <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span>)</span><br><span class="line">    println(map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="string">&quot;默认值&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Option：是一个可选的取值有有两个取值</span></span><br><span class="line"><span class="comment">     * Some ：有值</span></span><br><span class="line"><span class="comment">     * None: 没有值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> value: <span class="type">Option</span>[<span class="type">String</span>] = map.get(<span class="string">&quot;005&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mvalue: <span class="type">String</span> = map.get(<span class="string">&quot;003&quot;</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; v</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="string">&quot;默认值&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(mvalue)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配结合函数的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照逗号分割数据</span></span><br><span class="line">    <span class="keyword">val</span> arrays: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//匹配取出数据</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = arrays.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="15、隐式转换"><a href="#15、隐式转换" class="headerlink" title="15、隐式转换"></a>15、隐式转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo28Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换  -- 隐式类型转换  -- 可以动态可以对象增加新的方法</span></span><br><span class="line"><span class="comment">     * 1、隐式转换变量</span></span><br><span class="line"><span class="comment">     * 2、隐式转换方法: 可以隐式将方法的参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     * 3、隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//        val s:String = &quot;100&quot;</span></span><br><span class="line">    <span class="comment">//        val i: Int = s.toInt</span></span><br><span class="line">    <span class="comment">//        println(i)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span></span>(i: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(i * i)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">100</span>)</span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//fun(&quot;100&quot;.toInt)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义一个隐式转换方法</span></span><br><span class="line"><span class="comment">     * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 隐式转换的方法和方法名无关,和参数类型返回值类有关</span></span><br><span class="line"><span class="comment">     * 同一个作用域中只能存储一个相同类型的隐式转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//将String 转换成Int的隐式转换的方法</span></span><br><span class="line">    <span class="comment">//当前作用域中所有的String都可以当成Int类使用</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">strToInt</span></span>(s: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;strToInt被调用&quot;</span>)</span><br><span class="line">      <span class="type">Integer</span>.parseInt(s)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="string">&quot;200&quot;</span>)</span><br><span class="line">    <span class="comment">//等同于</span></span><br><span class="line">    fun(strToInt(<span class="string">&quot;200&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">douToInt</span></span>(d: <span class="type">Double</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;douToInt被调用&quot;</span>)</span><br><span class="line">      d.toInt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">3.14</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 应用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//导入隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> com.shujia.scala.<span class="type">Test</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentPsPath: <span class="type">String</span> = <span class="string">&quot;data/students.txt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[<span class="type">String</span>] = studentPsPath.getLines().toList</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.getLines().toList</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换</span></span><br><span class="line"><span class="comment">   * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(path: <span class="type">String</span>): <span class="type">BufferedSource</span> = &#123;</span><br><span class="line">    <span class="type">Source</span>.fromFile(path)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="16、隐式转换类"><a href="#16、隐式转换类" class="headerlink" title="16、隐式转换类"></a>16、隐式转换类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo29Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> read = <span class="keyword">new</span> <span class="type">Read</span>(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = read.read()</span><br><span class="line">    println(lines)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用隐式转换</span></span><br><span class="line">    <span class="comment">//相当于String被隐式转换成了Read类型</span></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.read()</span><br><span class="line">    println(scores)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换类：可以隐式的将类的构造函数参数类型转换成当前类的类型</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">Read</span>(<span class="params">path: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(): <span class="type">List</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">      <span class="comment">//读取文件</span></span><br><span class="line">      <span class="type">Source</span>.fromFile(path).getLines().toList</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="17、隐式转换变量"><a href="#17、隐式转换变量" class="headerlink" title="17、隐式转换变量"></a>17、隐式转换变量</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Codec</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo30Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换变量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(x: <span class="type">Int</span>)(<span class="keyword">implicit</span> y: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      x + y</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i: <span class="type">Int</span> = add(<span class="number">100</span>)(<span class="number">200</span>)</span><br><span class="line">    println(i)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义一个隐式转换变量</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> a: <span class="type">Int</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用方法时，会自动使用当前作用域同类型的隐式转换变量填补上发方法的隐式转换参数</span></span><br><span class="line">    <span class="keyword">val</span> j: <span class="type">Int</span> = add(<span class="number">200</span>)</span><br><span class="line">    println(j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换变量的应用</span></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>)(<span class="type">Codec</span>(<span class="string">&quot;Utf-8&quot;</span>))</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="18、统计偏科最严重的前100名学生"><a href="#18、统计偏科最严重的前100名学生" class="headerlink" title="18、统计偏科最严重的前100名学生"></a>18、统计偏科最严重的前100名学生</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.immutable</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo31Student</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、统计偏科最严重的前100名学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 偏科评估的标准： 方差</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、切分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreArr: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreFilter: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoreArr.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = scoreFilter.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算方差</span></span><br><span class="line">    <span class="keyword">val</span> std: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = groupBy.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, list: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//一个学生所有的分数</span></span><br><span class="line">        <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">Int</span>] = list.map &#123; <span class="keyword">case</span> (_, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 计算方差</span></span><br><span class="line"><span class="comment">         * 1、计算总数</span></span><br><span class="line"><span class="comment">         * 2、计算平均值</span></span><br><span class="line"><span class="comment">         * 3、计算方差</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//科目数</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">N</span>: <span class="type">Double</span> = scores.length.toDouble</span><br><span class="line">        <span class="comment">//平均数</span></span><br><span class="line">        <span class="keyword">val</span> avg: <span class="type">Double</span> = scores.sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算方差</span></span><br><span class="line">        <span class="keyword">val</span> std: <span class="type">Double</span> = scores.map((sco: <span class="type">Int</span>) =&gt; (sco - avg) * (sco - avg)).sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        (id, std, list)</span><br><span class="line">    &#125;.toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照方差排序，取前100</span></span><br><span class="line">    <span class="keyword">val</span> sortByStd: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = std.sortBy(kv =&gt; -kv._2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//取前100</span></span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = sortByStd.take(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习scala的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="scala" scheme="http://example.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="http://example.com/2022/06/16/Sqoop/"/>
    <id>http://example.com/2022/06/16/Sqoop/</id>
    <published>2022-06-15T16:00:00.000Z</published>
    <updated>2022-06-20T15:11:10.559Z</updated>
    
    <content type="html"><![CDATA[<h3 id="SQOOP安装"><a href="#SQOOP安装" class="headerlink" title="SQOOP安装"></a>SQOOP安装</h3><h4 id="1、上传并解压"><a href="#1、上传并解压" class="headerlink" title="1、上传并解压"></a>1、上传并解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /usr/local/soft/</span><br></pre></td></tr></table></figure><h4 id="2、修改文件夹名字"><a href="#2、修改文件夹名字" class="headerlink" title="2、修改文件夹名字"></a>2、修改文件夹名字</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop-1.4.6</span><br></pre></td></tr></table></figure><h4 id="3、修改配置文件"><a href="#3、修改配置文件" class="headerlink" title="3、修改配置文件"></a>3、修改配置文件</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换到sqoop配置文件目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/conf</span><br><span class="line"><span class="comment"># 复制配置文件并重命名</span></span><br><span class="line"><span class="built_in">cp</span> sqoop-env-template.sh sqoop-env.sh</span><br><span class="line"><span class="comment"># vim sqoop-env.sh 编辑配置文件，并加入以下内容</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/usr/local/soft/hadoop-2.7.6/share/hadoop/mapreduce</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/local/soft/hbase-1.4.6</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/soft/hive-1.2.1</span><br><span class="line"><span class="built_in">export</span> ZOOCFGDIR=/usr/local/soft/zookeeper-3.4.6/conf</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到bin目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/bin</span><br><span class="line"><span class="comment"># vim configure-sqoop 修改配置文件，注释掉没用的内容（就是为了去掉警告信息）</span></span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/wQgeExBmpyDju1t.png" alt="image.png" style="zoom:50%;" /><h4 id="4、修改环境变量"><a href="#4、修改环境变量" class="headerlink" title="4、修改环境变量"></a>4、修改环境变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sqoop的目录加入环境变量</span></span><br></pre></td></tr></table></figure><h4 id="5、添加MySQL连接驱动"><a href="#5、添加MySQL连接驱动" class="headerlink" title="5、添加MySQL连接驱动"></a>5、添加MySQL连接驱动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从HIVE中复制MySQL连接驱动到<span class="variable">$SQOOP_HOME</span>/lib</span></span><br><span class="line">cp /usr/local/soft/hive-1.2.1/lib/mysql-connector-java-5.1.49.jar /usr/local/soft/sqoop-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打印sqoop版本</span></span><br><span class="line">sqoop version</span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/6N1HJzVD7i9P3r5.png" alt="image.png" style="zoom:50%;" /><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试MySQL连通性</span></span><br><span class="line">sqoop list-databases -connect jdbc:mysql://master:3306/ -username root -password 123456</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/fos2dlvrMLQm4wa.png" alt="image-20220620200744244"></p><h3 id="准备MySQL数据"><a href="#准备MySQL数据" class="headerlink" title="准备MySQL数据"></a>准备MySQL数据</h3><h4 id="登录MySQL数据库"><a href="#登录MySQL数据库" class="headerlink" title="登录MySQL数据库"></a>登录MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p123456;</span><br></pre></td></tr></table></figure><h4 id="创建student数据库"><a href="#创建student数据库" class="headerlink" title="创建student数据库"></a>创建student数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create database student;</span><br></pre></td></tr></table></figure><h4 id="切换数据库并导入数据"><a href="#切换数据库并导入数据" class="headerlink" title="切换数据库并导入数据"></a>切换数据库并导入数据</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mysql shell中执行</span></span><br><span class="line">use student;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/student.sql;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/score.sql;</span><br></pre></td></tr></table></figure><h4 id="另外一种导入数据的方式"><a href="#另外一种导入数据的方式" class="headerlink" title="另外一种导入数据的方式"></a>另外一种导入数据的方式</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">linux shell中执行</span></span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/student.sql</span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/score.sql</span><br></pre></td></tr></table></figure><h4 id="使用Navicat运行SQL文件"><a href="#使用Navicat运行SQL文件" class="headerlink" title="使用Navicat运行SQL文件"></a>使用Navicat运行SQL文件</h4><blockquote><p>也可以通过Navicat导入</p></blockquote><h4 id="导出MySQL数据库"><a href="#导出MySQL数据库" class="headerlink" title="导出MySQL数据库"></a>导出MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqldump -u root -p123456 数据库名&gt;任意一个文件名.sql</span><br></pre></td></tr></table></figure><h3 id="SQOOP–import"><a href="#SQOOP–import" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h3><blockquote><p>从传统的关系型数据库导入HDFS、HIVE、HBASE……</p></blockquote><h4 id="MySQLToHDFS"><a href="#MySQLToHDFS" class="headerlink" title="MySQLToHDFS"></a>MySQLToHDFS</h4><h5 id="编写脚本，保存为MySQLToHDFS-conf"><a href="#编写脚本，保存为MySQLToHDFS-conf" class="headerlink" title="编写脚本，保存为MySQLToHDFS.conf"></a>编写脚本，保存为MySQLToHDFS.conf</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop执行脚本有两种方式：</span><br><span class="line">第一种方式：直接在命令行窗口中直接输入脚本；</span><br><span class="line">第二种方式是将命令封装成一个脚本文件，然后使用另一个命令执行</span><br><span class="line"></span><br><span class="line">第一种方式：</span><br><span class="line">sqoop import \</span><br><span class="line">--append \</span><br><span class="line">--connect jdbc:mysql://master:3306/test \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table student \</span><br><span class="line">--m 4 \</span><br><span class="line">--split-by age \</span><br><span class="line">--target-dir /shujia/bigdata17/student1/ \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">第二种方式：</span><br><span class="line">import</span><br><span class="line">--append</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/test</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">4</span><br><span class="line">--split-by</span><br><span class="line">age</span><br><span class="line">--target-dir</span><br><span class="line">/shujia/bigdata17/student21/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本"><a href="#执行脚本" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHDFS.conf</span><br></pre></td></tr></table></figure><h5 id="注意事项："><a href="#注意事项：" class="headerlink" title="注意事项："></a>注意事项：</h5><p>1、–m 表示指定生成多少个Map任务，不是越多越好，因为MySQL Server的承载能力有限</p><p>2、当指定的Map任务数&gt;1，那么需要结合<code>--split-by</code>参数，指定分割键，以确定每个map任务到底读取哪一部分数据，最好指定数值型的列，最好指定主键（或者分布均匀的列&#x3D;&gt;避免每个map任务处理的数据量差别过大）</p><p>3、如果指定的分割键数据分布不均，可能导致数据倾斜问题</p><p>4、分割的键最好指定数值型的，而且字段的类型为int、bigint这样的数值型</p><p>5、编写脚本的时候，注意：例如：<code>--username</code>参数，参数值不能和参数名同一行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--username root  // 错误的</span><br><span class="line"></span><br><span class="line">// 应该分成两行</span><br><span class="line">--username</span><br><span class="line">root</span><br></pre></td></tr></table></figure><p>6、运行的时候会报错<strong>InterruptedException</strong>，hadoop2.7.6自带的问题，忽略即可</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">21/01/25 14:32:32 WARN hdfs.DFSClient: Caught exception </span><br><span class="line">java.lang.InterruptedException</span><br><span class="line">at java.lang.Object.wait(Native Method)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1252)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1326)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:716)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:476)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:652)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>7、实际上sqoop在读取mysql数据的时候，用的是JDBC的方式，所以当数据量大的时候，效率不是很高</p><p>8、sqoop底层通过MapReduce完成数据导入导出，只需要Map任务，不许需要Reduce任务  part-m-00000</p><p>9、每个Map任务会生成一个文件</p><h4 id="MySQLToHive"><a href="#MySQLToHive" class="headerlink" title="MySQLToHive"></a>MySQLToHive</h4><blockquote><p>先会将MySQL的数据导出来并在HDFS上找个目录临时存放，默认为：&#x2F;user&#x2F;用户名&#x2F;表名</p><p>然后再将数据加载到Hive中，加载完成后，会将临时存放的目录删除</p></blockquote><h5 id="编写脚本，并保存为MySQLToHive-conf文件"><a href="#编写脚本，并保存为MySQLToHive-conf文件" class="headerlink" title="编写脚本，并保存为MySQLToHive.conf文件"></a>编写脚本，并保存为MySQLToHive.conf文件</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">score</span><br><span class="line">--m</span><br><span class="line">3</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore</span><br><span class="line"></span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h5 id="执行脚本-1"><a href="#执行脚本-1" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHive.conf</span><br></pre></td></tr></table></figure><h5 id="–direct"><a href="#–direct" class="headerlink" title="–direct"></a>–direct</h5><blockquote><p>加上这个参数，可以在导出MySQL数据的时候，使用MySQL提供的导出工具mysqldump，加快导出速度，提高效率</p></blockquote><p>需要将master上的&#x2F;usr&#x2F;bin&#x2F;mysqldump分发至 node1、node2的&#x2F;usr&#x2F;bin目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp /usr/bin/mysqldump node1:/usr/bin/</span><br><span class="line">scp /usr/bin/mysqldump node2:/usr/bin/</span><br></pre></td></tr></table></figure><h5 id="–e参数的使用"><a href="#–e参数的使用" class="headerlink" title="–e参数的使用"></a>–e参数的使用</h5><blockquote><p>sqoop在导入数据时，可以使用–e搭配sql来指定查询条件，并且还需在sql中添加$CONDITIONS，来实现并行运行mr的功能。</p><p>只要有–e+sql，就需要加$CONDITIONS，哪怕只有一个maptask。</p></blockquote><blockquote><p>sqoop通过继承hadoop的并行性来执行高效的数据传输。 为了帮助sqoop将查询拆分为多个可以并行传输的块，需要在查询的where子句中包含$conditions占位符。 sqoop将自动用生成的条件替换这个占位符，这些条件指定每个任务应该传输哪个数据片。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--m</span><br><span class="line">2</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--e</span><br><span class="line">&quot;select * from score where student_id=1500100001 and $CONDITIONS&quot;</span><br><span class="line">--target-dir</span><br><span class="line">/testE</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore3</span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h4 id="MySQLToHBase"><a href="#MySQLToHBase" class="headerlink" title="MySQLToHBase"></a>MySQLToHBase</h4><h5 id="编写脚本，并保存为MySQLToHBase-conf"><a href="#编写脚本，并保存为MySQLToHBase-conf" class="headerlink" title="编写脚本，并保存为MySQLToHBase.conf"></a>编写脚本，并保存为MySQLToHBase.conf</h5><blockquote><p>sqoop1.4.6 只支持 HBase1.0.1 之前的版本的自动创建 HBase 表的功能</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id</span><br><span class="line">--m</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h5 id="在HBase中创建student表"><a href="#在HBase中创建student表" class="headerlink" title="在HBase中创建student表"></a>在HBase中创建student表</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create &#x27;studentsq&#x27;,&#x27;cf1&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本-2"><a href="#执行脚本-2" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHBase.conf</span><br></pre></td></tr></table></figure><h4 id="SQOOP–import-1"><a href="#SQOOP–import-1" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h4><h4 id="HDFSToMySQL"><a href="#HDFSToMySQL" class="headerlink" title="HDFSToMySQL"></a>HDFSToMySQL</h4><h5 id="编写脚本，并保存为HDFSToMySQL-conf"><a href="#编写脚本，并保存为HDFSToMySQL-conf" class="headerlink" title="编写脚本，并保存为HDFSToMySQL.conf"></a>编写脚本，并保存为HDFSToMySQL.conf</h5><blockquote><p><strong>在往关系型数据库中导出的时候我们要先在关系型数据库中创建好库以及表，这些sqoop不会帮我们完成。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student?useUnicode=true&amp;characterEncoding=UTF-8</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="先清空MySQL-student表中的数据，不然会造成主键冲突"><a href="#先清空MySQL-student表中的数据，不然会造成主键冲突" class="headerlink" title="先清空MySQL student表中的数据，不然会造成主键冲突"></a>先清空MySQL student表中的数据，不然会造成主键冲突</h5><h5 id="执行脚本-3"><a href="#执行脚本-3" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file HDFSToMySQL.conf</span><br></pre></td></tr></table></figure><h4 id="查看sqoop-help"><a href="#查看sqoop-help" class="headerlink" title="查看sqoop help"></a>查看sqoop help</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop help</span><br><span class="line"></span><br><span class="line">21/04/26 15:50:36 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">usage: sqoop COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  codegen            Generate code to interact with database records</span><br><span class="line">  create-hive-table  Import a table definition into Hive</span><br><span class="line">  eval               Evaluate a SQL statement and display the results</span><br><span class="line">  export             Export an HDFS directory to a database table</span><br><span class="line">  help               List available commands</span><br><span class="line">  import             Import a table from a database to HDFS</span><br><span class="line">  import-all-tables  Import tables from a database to HDFS</span><br><span class="line">  import-mainframe   Import datasets from a mainframe server to HDFS</span><br><span class="line">  job                Work with saved jobs</span><br><span class="line">  list-databases     List available databases on a server</span><br><span class="line">  list-tables        List available tables in a database</span><br><span class="line">  merge              Merge results of incremental imports</span><br><span class="line">  metastore          Run a standalone Sqoop metastore</span><br><span class="line">  version            Display version information</span><br><span class="line"></span><br><span class="line">See &#x27;sqoop help COMMAND&#x27; for information on a specific command.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看import的详细帮助</span><br><span class="line">sqoop import --help</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、并行度不能太高，就是 -m</span><br><span class="line">2、如果没有主键的时候，-m 不是1的时候就要指定分割字段，不然会报错，如果有主键的时候，-m 不是1 可以不去指定分割字段，默认是主键，不指定 -m 的时候，Sqoop会默认是分4个map任务。</span><br></pre></td></tr></table></figure><h4 id="Sqoop-在从HDFS中导出到关系型数据库时的一些问题"><a href="#Sqoop-在从HDFS中导出到关系型数据库时的一些问题" class="headerlink" title="Sqoop 在从HDFS中导出到关系型数据库时的一些问题"></a>Sqoop 在从HDFS中导出到关系型数据库时的一些问题</h4><h5 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a><strong>问题一：</strong></h5><p>在上传过程中遇到这种问题：</p><p><strong>ERROR tool.ExportTool: Encountered IOException running export job: java.io.IOException: No columns to generate for ClassWriter</strong></p><p><img src="https://s2.loli.net/2022/06/20/746cVG2nRzkPTsd.png" alt="image-20220620213336190"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">驱动版本的过低导致的，其实在尝试这个方法的时候我们可以先进行这样：加一行命令，--driver com.mysql.jdbc.Driver \  然后问题解决！！！</span><br><span class="line"></span><br><span class="line">如果添加命令之后还没有解决就把jar包换成高点版本的。</span><br></pre></td></tr></table></figure><h5 id="问题二："><a href="#问题二：" class="headerlink" title="问题二："></a><strong>问题二：</strong></h5><p><strong>依旧是导出的时候，会报错，但是我们很神奇的发现，也有部分数据导入了。这也就是下一个问题。</strong></p><p><strong>Caused by: java.lang.NumberFormatException: For input string: “null”</strong></p><p><img src="https://s2.loli.net/2022/06/20/ZDp6kQ5V2UOghCl.png" alt="image-20220620213402824"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">解决方式：因为数据有存在null值得导致的</span><br><span class="line"></span><br><span class="line">在命令中加入一行（方式一中的修改方式，方式二也就是转换一下格式）：--input-null-string &#x27;\\N&#x27; \  </span><br><span class="line"></span><br><span class="line">--input-null-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure><h5 id="问题三："><a href="#问题三：" class="headerlink" title="问题三：**"></a>问题三：**</h5><p><strong>java.lang.RuntimeException: Can’t parse input data: ‘1998&#x2F;5&#x2F;11’</strong></p><p><img src="https://s2.loli.net/2022/06/20/nRyQel6fvAr9UXT.png" alt="image-20220620213425310"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">出现像这样的问题，大多是因为HDFS上的数据与关系型数据库创建表的字段类型不匹配导致的。仔细对比修改后，就不会有这个报错啦！！</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/8QFgr9AG4wRyZSH.png" alt="image-20220620230831268"></p><p>数据有问题有个@符号，虽然报错但是也能导出数据</p><h3 id="增量同步数据"><a href="#增量同步数据" class="headerlink" title="增量同步数据"></a>增量同步数据</h3><p>我们之前导入的都是全量导入，一次性全部导入，但是实际开发并不是这样，例如web端进行用户注册，mysql就增加了一条数据，但是HDFS中的数据并没有进行更新，但是又再全部导入一次又完全没有必要。</p><p>所以，sqoop提供了增量导入的方法。</p><p>1、数据准备：</p><p><img src="https://s2.loli.net/2022/06/20/tHPlkEISReUA4Ya.png" alt="image-20220620213457114"></p><p>2、将其先用全量导入到HDFS(hive)中去</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br></pre></td></tr></table></figure><p>3、先在mysql中添加一条数据，在使用命令进行追加</p><p>4、根据时间进行大量追加（不去重）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前面的案例中，hive本身的数据也是存储在HDFS上的，所以我今后要做增量操作的时候，需要指定HDFS上的路径</span></span><br><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--incremental </span><br><span class="line">append</span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结果：但是我们发现有两个重复的字段</p><p><img src="https://s2.loli.net/2022/06/20/vPN8seuwOUkgYqR.png" alt="img"></p><p>5、往往开发中需要进行去重操作：sqoop提供了一个方法进行去重，内部是先开一个map任务将数据导入进来，然后再开一个map任务根据指定的字段进行合并去重</p><p>结果：</p><p><img src="https://s2.loli.net/2022/06/20/7tW4nmR5OUes3MP.png" alt="img"></p><blockquote><p> <strong>之前有重复的也进行合并去重操作，最后生成一个结果。</strong></p></blockquote><blockquote><p>总结：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">–check-column</span><br><span class="line">用来指定一些列，这些列在增量导入时用来检查这些数据是否作为增量数据进行导入，和关系型数据库中的自增字段及时间戳类似. </span><br><span class="line">注意:这些被指定的列的类型不能使任意字符类型，如char、varchar等类型都是不可以的，同时–check-column可以去指定多个列</span><br><span class="line">–incremental</span><br><span class="line">用来指定增量导入的模式，两种模式分别为Append和Lastmodified</span><br><span class="line">–last-value</span><br><span class="line">指定上一次导入中检查列指定字段最大值</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">RDBMS--&gt;</span><span class="language-bash">HDFS     import</span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">RDBMS    <span class="built_in">export</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">Mysql---&gt;</span><span class="language-bash">HDFS(hive)</span></span><br><span class="line">要知道你要数据的来源和数据的目的地</span><br><span class="line">mysql:</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">hive:</span><br><span class="line">1)</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table  (如果表不存在，自动创建，如果存在，报错，就不需要这个参数)</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">2)</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增量需要添加的参数=================================================</span></span><br><span class="line">--incremental </span><br><span class="line">append </span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line">（或者是）------------------------------------------------------------</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--check-column （hive的列名）</span><br><span class="line">last_mod</span><br><span class="line">--incremental</span><br><span class="line">lastmodified</span><br><span class="line">--last-value</span><br><span class="line">&quot;2022-06-18 16:40:09&quot;</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">========================================================================</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果需要去重，请先搞清楚根据什么去重，否则结果可能不是你想要的</span></span><br><span class="line">--merge-key</span><br><span class="line">name   （这里是根据姓名去重，你可以改成自己的去重列名）</span><br><span class="line"></span><br><span class="line">hbase:（因为我们的hbase版本是1.4.6，而sqoop1.4.6不支持hbase1.0.1以后的自动创建表，所以我们在做同步到hbase的时候，需要手动先将表创建好）</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id  (mysql中的列名)</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">mysql</span></span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果数据分割出来的字段值有空值，需要添加以下参数（面试可能会面到）</span></span><br><span class="line">--null-string </span><br><span class="line">&#x27;\\N&#x27; </span><br><span class="line">--null-non-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习Sqoop的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Sqoop" scheme="http://example.com/tags/Sqoop/"/>
    
  </entry>
  
  <entry>
    <title>Hbase高级操作</title>
    <link href="http://example.com/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/"/>
    <id>http://example.com/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/</id>
    <published>2022-06-12T16:00:00.000Z</published>
    <updated>2022-06-15T07:53:47.676Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、HBase的读写流程"><a href="#一、HBase的读写流程" class="headerlink" title="一、HBase的读写流程"></a>一、HBase的读写流程</h2><p><img src="https://s2.loli.net/2022/06/15/tel8cnYuW4o6EiI.png" alt="image-20220615154028494"></p><h3 id="1-1-HBase读流程"><a href="#1-1-HBase读流程" class="headerlink" title="1.1    HBase读流程"></a>1.1    HBase读流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hbase读取数据的流程：</span><br><span class="line">1）是由客户端发起读取数据的请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取一个hbase:meta表位置信息，被哪一个regionserver所管理着</span><br><span class="line">     hbase:meta表：hbase的元数据表，在这个表中存储了自定义表相关的元数据，包括表名，表有哪些列簇，表有哪些reguion,每个region存储的位置，每个region被哪个regionserver所管理，这个表也是存储在某一个region上的，并且这个meta表只会被一个regionserver所管理。这个表的位置信息只有zookeeper知道。</span><br><span class="line">3）连接这个meta表对应的regionserver,从meta表中获取当前你要读取的这个表对应的regionsever是谁。</span><br><span class="line">     当一个表多个region怎么办呢？</span><br><span class="line">     如果我们获取数据是以get的方式，只会返回一个regionserver</span><br><span class="line">     如果我们获取数据是以scan的方式，会将所有的region对应的regionserver的地址全部返回。</span><br><span class="line">4）连接要读取表的对应的regionserver,从regionserver上的开始读取数据：</span><br><span class="line">       读取顺序：memstore--&gt;blockcache--&gt;storefile--&gt;Hfile中</span><br><span class="line">       注意：如果是scan操作，就不仅仅去blockcache了，而是所有都会去找。</span><br></pre></td></tr></table></figure><h3 id="1-2-HBase写流程"><a href="#1-2-HBase写流程" class="headerlink" title="1.2    HBase写流程"></a>1.2    HBase写流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--------------------------1-4步是客户端写入数据的流程-----------------</span><br><span class="line"></span><br><span class="line">Hbase的写入数据流程：</span><br><span class="line">1）由客户端发起写数据请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取hbase:meta表被哪一个regionserver所管理</span><br><span class="line">3）连接hbase:meta表中获取对应的regionserver地址 (从meta表中获取当前要写入数据的表对应的region所管理的regionserver) 只会返回一个regionserver地址</span><br><span class="line">4）与要写入数据的regionserver建立连接，然后开始写入数据，将数据首先会写入到HLog，然后将数据写入到对应store模块中的memstore中</span><br><span class="line">（可能会写多个），当这两个地方都写入完成之后，表示数据写入完成。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-------------------------后面的步骤是服务器内部的操作-----------------</span><br><span class="line">异步操作</span><br><span class="line">5）随着客户端不断地写入数据，memstore中的数据会越来多，当内存中的数据达到阈值（128M/1h）的时候，放入到blockchache中，生成新的memstore接收用户过来的数据，然后当blockcache的大小达到一定阈值（0.85）的时候，开始触发flush机制，将数据最终刷新到HDFS中形成小的Hfile文件。</span><br><span class="line"></span><br><span class="line">6）随着不断地刷新，storefile不断地在HDFS上生成小HFIle文件，当小的HFile文件达到阈值的时候（3个及3个以上）,就会触发Compaction机制，将小的HFile合并成一个大的HFile.</span><br><span class="line"></span><br><span class="line">7）随着不断地合并，大的HFile文件会越来越大，当达到一定阈值（最终10G）的时候，会触发分裂机制（split）,将大的HFile文件进行一分为二，同时管理这个大的HFile的region也会被一分为二，形成两个新的region和两个新的HFile文件，一对一的进行管理，将原来旧的region和分裂之前大的HFile文件慢慢地就会下线处理。</span><br></pre></td></tr></table></figure><h2 id="二、Region的分裂策略"><a href="#二、Region的分裂策略" class="headerlink" title="二、Region的分裂策略"></a>二、Region的分裂策略</h2><blockquote><p>region中存储的是一张表的数据，当region中的数据条数过多的时候，会直接影响查询效率。当region过大的时候，region会被拆分为两个region，HMaster会将分裂的region分配到不同的regionserver上，这样可以让请求分散到不同的RegionServer上，已达到负载均衡 , 这也是HBase的一个优点 。</p></blockquote><ul><li><p>ConstantSizeRegionSplitPolicy</p><blockquote><p>0.94版本前，HBase region的默认切分策略 </p></blockquote><p>当region中最大的store大小超过某个阈值(hbase.hregion.max.filesize&#x3D;10G)之后就会触发切分，一个region等分为2个region。</p><p>但是在生产线上这种切分策略却有相当大的弊端（切分策略对于大表和小表没有明显的区分）：</p><ul><li>阈值(hbase.hregion.max.filesize)设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，形成热点，这对业务来说并不是什么好事。</li><li>如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</li></ul></li><li><p>IncreasingToUpperBoundRegionSplitPolicy</p><blockquote><p>0.94版本~2.0版本默认切分策略 </p></blockquote><p>​        总体看和ConstantSizeRegionSplitPolicy思路相同，一个region中最大的store大小大于设置阈值就会触发切分。<br>但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系.</p><p>region split阈值的计算公式是：</p><ul><li><p>设regioncount：是region所属表在当前regionserver上的region的个数</p></li><li><p>阈值 &#x3D; regioncount^3 * 128M * 2，当然阈值并不会无限增长，最大不超过MaxRegionFileSize（10G),当region中最大的store的大小达到该阈值的时候进行region split</p></li></ul><p>例如：</p><ul><li>第一次split阈值 &#x3D; 1^3 * 256 &#x3D; 256MB</li><li>第二次split阈值 &#x3D; 2^3 * 256 &#x3D; 2048MB</li><li>第三次split阈值 &#x3D; 3^3 * 256 &#x3D; 6912MB</li><li>第四次split阈值 &#x3D; 4^3 * 256 &#x3D; 16384MB &gt; 10GB，因此取较小的值10GB</li><li>后面每次split的size都是10GB了</li></ul><p><strong>特点</strong></p><ul><li>相比ConstantSizeRegionSplitPolicy，可以自适应大表、小表；</li><li>在集群规模比较大的情况下，对大表的表现比较优秀</li><li>对小表不友好，小表可能产生大量的小region，分散在各regionserver上</li><li>小表达不到多次切分条件，导致每个split都很小，所以分散在各个regionServer上</li></ul></li><li><p>SteppingSplitPolicy</p><blockquote><p>2.0版本默认切分策略</p></blockquote><p>​    相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些<br>​    region切分的阈值依然和待分裂region所属表在当前regionserver上的region个数有关系</p><ul><li>如果region个数等于1，切分阈值为flush size 128M * 2</li><li>否则为MaxRegionFileSize。</li></ul><blockquote><p>这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小region，而是适可而止。</p></blockquote></li><li><p>KeyPrefixRegionSplitPolicy</p><blockquote><p>根据rowKey的前缀对数据进行分区，这里是指定rowKey的前多少位作为前缀，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在相同的region中。</p></blockquote></li><li><p>DelimitedKeyPrefixRegionSplitPolicy</p><blockquote><p>保证相同前缀的数据在同一个region中，例如rowKey的格式为：userid_eventtype_eventid，指定的delimiter为 _ ，则split的的时候会确保userid相同的数据在同一个region中。<br>按照分隔符进行切分，而KeyPrefixRegionSplitPolicy是按照指定位数切分。</p></blockquote></li><li><p>BusyRegionSplitPolicy</p><blockquote><p>按照一定的策略判断Region是不是Busy状态，如果是即进行切分</p><p>如果你的系统常常会出现热点Region，而你对性能有很高的追求，那么这种策略可能会比较适合你。它会通过拆分热点Region来缓解热点Region的压力，但是根据热点来拆分Region也会带来很多不确定性因素，因为你也不知道下一个被拆分的Region是哪个。</p></blockquote></li><li><p>DisabledRegionSplitPolicy</p><blockquote><p>不启用自动拆分, 需要指定手动拆分</p></blockquote></li></ul><h2 id="三、Compaction操作"><a href="#三、Compaction操作" class="headerlink" title="三、Compaction操作"></a>三、Compaction操作</h2><h4 id="Minor-Compaction："><a href="#Minor-Compaction：" class="headerlink" title="Minor Compaction："></a>Minor Compaction：</h4><ul><li>指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次 Minor Compaction 的结果是更少并且更大的StoreFile。</li></ul><h4 id="Major-Compaction："><a href="#Major-Compaction：" class="headerlink" title="Major Compaction："></a>Major Compaction：</h4><ul><li>指将<strong>所有的StoreFile</strong>合并成一个StoreFile，这个过程会清理三类没有意义的数据：<strong>被删除的数据</strong>、<strong>TTL过期数据</strong>、<strong>版本号超过设定版本号的数据</strong>。另外，一般情况下，major compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发major compaction功能，改为手动在业务低峰期触发。</li></ul><blockquote><p>参考文档：<a href="https://cloud.tencent.com/developer/article/1488439">https://cloud.tencent.com/developer/article/1488439</a></p></blockquote><h2 id="四、面对百亿数据，HBase为什么查询速度依然非常快？"><a href="#四、面对百亿数据，HBase为什么查询速度依然非常快？" class="headerlink" title="四、面对百亿数据，HBase为什么查询速度依然非常快？"></a>四、面对百亿数据，HBase为什么查询速度依然非常快？</h2><p>HBase适合存储PB级别的海量数据（百亿千亿量级条记录），如果根据记录主键Rowkey来查询，能在几十到百毫秒内返回数据。</p><p><strong>那么HBase是如何做到的呢？</strong></p><p>下面，简单阐述一下数据的查询思路和过程。</p><h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h2><h5 id="第1步："><a href="#第1步：" class="headerlink" title="第1步："></a>第1步：</h5><p>项目有100亿业务数据，存储在一个HBase集群上（由多个服务器数据节点构成），每个数据节点上有若干个Region（区域），每个Region实际上就是HBase中一批数据的集合（一段连续范围rowkey的数据）。</p><p>我们现在开始根据主键RowKey来查询对应的记录，通过meta表可以帮我们迅速定位到该记录所在的数据节点，以及数据节点中的Region，目前我们有100亿条记录，占空间10TB。所有记录被切分成5000个Region，那么现在，每个Region就是2G。</p><p><strong>由于记录在1个Region中，所以现在我们只要查询这2G的记录文件，就能找到对应记录。</strong></p><h5 id="第2步："><a href="#第2步：" class="headerlink" title="第2步："></a>第2步：</h5><p>由于HBase存储数据是按照列族存储的。比如一条记录有400个字段，前100个字段是人员信息相关，这是一个列簇（列的集合）；中间100个字段是公司信息相关，是一个列簇。另外100个字段是人员交易信息相关，也是一个列簇；最后还有100个字段是其他信息，也是一个列簇</p><p>这四个列簇是分开存储的，这时，假设2G的Region文件中，分为4个列族，那么每个列族就是500M。</p><p><strong>到这里，我们只需要遍历这500M的列簇就可以找到对应的记录。</strong></p><h5 id="第3步："><a href="#第3步：" class="headerlink" title="第3步："></a>第3步：</h5><p>如果要查询的记录在其中1个列族上，1个列族在HDFS中会包含1个或者多个HFile。</p><p>如果一个HFile一般的大小为100M，那么该列族包含5个HFile在磁盘上或内存中。</p><p>由于HBase的内存进而磁盘中的数据是排好序的，要查询的记录有可能在最前面，也有可能在最后面，按平均来算，<strong>我们只需遍历2.5个HFile共250M，即可找到对应的记录。</strong></p><h5 id="第4步："><a href="#第4步：" class="headerlink" title="第4步："></a>第4步：</h5><p>每个HFile中，是以键值对(key&#x2F;value)方式存储，只要遍历文件中的key位置并判断符合条件即可</p><p>一般key是有限的长度，假设key&#x2F;value比是1:24，<strong>最终只需要10M的数据量，就可获取的对应的记录。</strong></p><p>如果数据在机械磁盘上，按其访问速度100M&#x2F;S，只需0.1秒即可查到。</p><p>如果是SSD的话，0.01秒即可查到。</p><p>当然，扫描HFile时还可以通过布隆过滤器快速定位到对应的HFile，以及HBase是有内存缓存机制的，如果数据在内存中，效率会更高。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>正因为以上大致的查询思路，保证了HBase即使随着数据量的剧增，也不会导致查询性能的下降。</p><p>同时，HBase是一个面向列存储的数据库（列簇机制），当表字段非常多时，可以把其中一些字段独立出来放在一部分机器上，而另外一些字段放到另一部分机器上，分散存储，分散列查询。</p><p>正由于这样复杂的存储结构和分布式的存储方式，保证了HBase海量数据下的查询效率。</p><h2 id="五、HBase与Hive的集成"><a href="#五、HBase与Hive的集成" class="headerlink" title="五、HBase与Hive的集成"></a>五、HBase与Hive的集成</h2><blockquote><p>HBase与Hive的对比</p></blockquote><p><strong>hive:</strong></p><p>数据仓库：Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p><p>用于数据分析、清洗：Hive适用于离线的数据分析和清洗，延迟较高。</p><p>基于HDFS、MapReduce：Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</p><p><strong>HBase</strong></p><p>数据库：是一种面向列族存储的非关系型数据库。</p><p>用于存储结构化和非结构化的数据：适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p><p>基于HDFS：数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</p><p>延迟较低，接入在线业务使用：面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p><blockquote><p>在<code>hive-site.xml</code>中添加zookeeper的属性</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102,hadoop103,hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.client.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><h2 id="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"><a href="#HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表" class="headerlink" title="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"></a>HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表</h2></blockquote><blockquote><p>建立外部表的字段名要和hbase中的列名一致</p><p>前提是hbase中已经有表了</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> students_hbase</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string,</span><br><span class="line">gender string, </span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:name,</span><br><span class="line">info:age,</span><br><span class="line">info:gender,</span><br><span class="line">info:clazz</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:students&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> score_hbase2</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">score_dan string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:score_dan</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:score&quot;);</span><br></pre></td></tr></table></figure><blockquote><p>关联后就可以使用Hive函数进行一些分析操作了</p></blockquote><h2 id="六、Phoenix"><a href="#六、Phoenix" class="headerlink" title="六、Phoenix"></a>六、Phoenix</h2><blockquote><p>Hbase适合存储大量的对关系运算要求低的NOSQL数据，受Hbase 设计上的限制不能直接使用原生的API执行在关系数据库中普遍使用的条件判断和聚合等操作。Hbase很优秀，一些团队寻求在Hbase之上提供一种更面向普通开发人员的操作方式，Apache Phoenix即是。</p></blockquote><blockquote><p>Phoenix 基于Hbase给面向业务的开发人员提供了以标准SQL的方式对Hbase进行查询操作，并支持标准SQL中大部分特性:条件运算,分组，分页，等高级查询语法。</p></blockquote><h3 id="1、Phoenix搭建"><a href="#1、Phoenix搭建" class="headerlink" title="1、Phoenix搭建"></a>1、Phoenix搭建</h3><p><strong>Phoenix 4.15    HBase 1.4.6    hadoop 2.7.6</strong></p><h4 id="1、关闭hbase集群，在master中执行"><a href="#1、关闭hbase集群，在master中执行" class="headerlink" title="1、关闭hbase集群，在master中执行"></a>1、关闭hbase集群，在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="2、上传解压配置环境变量"><a href="#2、上传解压配置环境变量" class="headerlink" title="2、上传解压配置环境变量"></a>2、上传解压配置环境变量</h4><p>解压</p><p><code>tar -xvf apache-phoenix-4.15.0-HBase-1.4-bin.tar.gz -C /usr/local/soft/</code></p><p>改名</p><p><code>mv apache-phoenix-4.15.0-HBase-1.4-bin phoenix-4.15.0</code></p><h4 id="3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下"><a href="#3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下" class="headerlink" title="3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下"></a>3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar master:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node1:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node2:/usr/local/soft/hbase-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="4、启动hbase-，-在master中执行"><a href="#4、启动hbase-，-在master中执行" class="headerlink" title="4、启动hbase ， 在master中执行"></a>4、启动hbase ， 在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="5、配置环境变量"><a href="#5、配置环境变量" class="headerlink" title="5、配置环境变量"></a>5、配置环境变量</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、Phoenix使用"><a href="#2、Phoenix使用" class="headerlink" title="2、Phoenix使用"></a>2、Phoenix使用</h3><h4 id="1、连接sqlline"><a href="#1、连接sqlline" class="headerlink" title="1、连接sqlline"></a>1、连接sqlline</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqlline.py master,node1,node2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">出现即已连接成功</span></span><br><span class="line">163/163 (100%) Done</span><br><span class="line">Done</span><br><span class="line">sqlline version 1.5.0</span><br><span class="line">0: jdbc:phoenix:master,node1,node2&gt; </span><br></pre></td></tr></table></figure><h4 id="2、常用命令"><a href="#2、常用命令" class="headerlink" title="2、常用命令"></a>2、常用命令</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="number">1</span>、创建表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> student (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> name <span class="type">VARCHAR</span>,</span><br><span class="line"> age <span class="type">BIGINT</span>, </span><br><span class="line"> gender <span class="type">VARCHAR</span> ,</span><br><span class="line"> clazz <span class="type">VARCHAR</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、显示所有表</span><br><span class="line"> <span class="operator">!</span><span class="keyword">table</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、插入数据</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100004&#x27;</span>,<span class="string">&#x27;葛德曜&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100005&#x27;</span>,<span class="string">&#x27;宣谷芹&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科六班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100006&#x27;</span>,<span class="string">&#x27;羿彦昌&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、查询数据,支持大部分<span class="keyword">sql</span>语法，</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> age<span class="operator">=</span><span class="number">24</span>;</span><br><span class="line"><span class="keyword">select</span> gender ,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> STUDENT <span class="keyword">group</span> <span class="keyword">by</span> gender;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student <span class="keyword">order</span> <span class="keyword">by</span> gender;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、删除数据</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> id<span class="operator">=</span><span class="string">&#x27;1500100004&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>、删除表</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> STUDENT;</span><br><span class="line"> </span><br><span class="line"># <span class="number">7</span>、退出命令行</span><br><span class="line"><span class="operator">!</span>quit</span><br><span class="line"></span><br><span class="line">更多语法参照官网</span><br><span class="line">https:<span class="operator">/</span><span class="operator">/</span>phoenix.apache.org<span class="operator">/</span><span class="keyword">language</span><span class="operator">/</span>index.html#upsert_select</span><br></pre></td></tr></table></figure><h4 id="3、phoenix表映射"><a href="#3、phoenix表映射" class="headerlink" title="3、phoenix表映射"></a>3、phoenix表映射</h4><blockquote><p> 默认情况下，直接在hbase中创建的表，通过phoenix是查看不到的</p></blockquote><blockquote><p>如果需要在phoenix中操作直接在hbase中创建的表，则需要在phoenix中进行表的映射。映射方式有两种：视图映射和表映射</p></blockquote><h5 id="3-1、视图映射"><a href="#3-1、视图映射" class="headerlink" title="3.1、视图映射"></a>3.1、视图映射</h5><blockquote><p> Phoenix创建的视图是只读的，所以只能用来做查询，无法通过视图对源数据进行修改等操作</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># hbase shell 进入hbase命令行</span><br><span class="line">hbase shell </span><br><span class="line"></span><br><span class="line"># 创建hbase表</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;company&#x27;</span> </span><br><span class="line"></span><br><span class="line"># 插入数据</span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:firstname&#x27;</span>,<span class="string">&#x27;zhangsan1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:lastname&#x27;</span>,<span class="string">&#x27;zhangsan2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:name&#x27;</span>,<span class="string">&#x27;数加&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:address&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span></span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> TEST <span class="keyword">values</span>(<span class="string">&#x27;002&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># 在phoenix创建视图， <span class="keyword">primary</span> key 对应到hbase中的rowkey</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> &quot;test&quot;(</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">view</span> &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 在phoenix查询数据，表名通过双引号引起来</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> &quot;test&quot;;</span><br><span class="line"></span><br><span class="line"># 删除视图</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">view</span> &quot;test&quot;;</span><br></pre></td></tr></table></figure><h5 id="3-2、表映射"><a href="#3-2、表映射" class="headerlink" title="3.2、表映射"></a>3.2、表映射</h5><p>使用Apache Phoenix创建对HBase的表映射，有两类：</p><p>1） 当HBase中已经存在表时，可以以类似创建视图的方式创建关联表，只需要将create view改为create table即可。</p><p>2）当HBase中不存在表时，可以直接使用create table指令创建需要的表，并且在创建指令中可以根据需要对HBase表结构进行显示的说明。</p><p>第1）种情况下，如在之前的基础上已经存在了test表，则表映射的语句如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> &quot;test&quot; (</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;<span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">)column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span>  &quot;test&quot;  <span class="keyword">values</span>(<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;score&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;score_dan&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>使用create table创建的关联表，如果对表进行了修改，源数据也会改变，同时如果关联表被删除，源表也会被删除。但是视图就不会，如果删除视图，源数据不会发生改变。</p><h2 id="七、bulkLoad实现批量导入"><a href="#七、bulkLoad实现批量导入" class="headerlink" title="七、bulkLoad实现批量导入"></a>七、bulkLoad实现批量导入</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ol><li><p>如果我们一次性入库hbase巨量数据，处理速度慢不说，还特别占用Region资源， 一个比较高效便捷的方法就是使用 “Bulk Loading”方法，即HBase提供的HFileOutputFormat类。</p></li><li><p>它是利用hbase的数据信息按照特定格式存储在hdfs内这一原理，直接生成这种hdfs内存储的数据格式文件，然后上传至合适位置，即完成巨量数据快速入库的办法。配合mapreduce完成，高效便捷，而且不占用region资源，增添负载。</p></li></ol><h3 id="限制："><a href="#限制：" class="headerlink" title="限制："></a>限制：</h3><ol><li>仅适合初次数据导入，即表内数据为空，或者每次入库表内都无数据的情况。</li><li>HBase集群与Hadoop集群为同一集群，即HBase所基于的HDFS为生成HFile的MR的集群</li></ol><h3 id="代码编写："><a href="#代码编写：" class="headerlink" title="代码编写："></a>代码编写：</h3><blockquote><p>提前在Hbase中创建好表</p><p>生成Hfile基本流程：</p><ol><li><p>设置Mapper的输出KV类型：     </p><p>K： ImmutableBytesWritable（代表行键）</p><p>V： KeyValue  （代表cell）</p></li></ol><p>​    2.  开发Mapper</p><p>​        读取你的原始数据，按你的需求做处理</p><p>​        输出rowkey作为K，输出一些KeyValue（Put）作为V</p><p>​    3.  配置job参数</p><p>​        a. Zookeeper的连接地址</p><p>​        b. 配置输出的OutputFormat为HFileOutputFormat2，并为其设置参数</p><p>​    4.  提交job</p><p>​            导入HFile到RegionServer的流程</p><p>​                构建一个表描述对象</p><p>​            构建一个region定位工具</p><p>​            然后用LoadIncrementalHFiles来doBulkload操作</p></blockquote><blockquote><p>pom文件：</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-bigdata17<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.shujia<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>had-hbase-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- compiler插件, 设定JDK版本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">showWarnings</span>&gt;</span>true<span class="tag">&lt;/<span class="name">showWarnings</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">&lt;!-- 带依赖jar 插件--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>电信数据</p></blockquote><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br></pre></td></tr></table></figure><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li><p>最终输出结果，无论是map还是reduce，输出部分key和value的类型必须是： &lt;ImmutableBytesWritable, KeyValue&gt;或者&lt;ImmutableBytesWritable, Put&gt;。</p></li><li><p>最终输出部分，Value类型是KeyValue 或Put，对应的Sorter分别是KeyValueSortReducer或PutSortReducer。</p></li><li><p>MR例子中HFileOutputFormat2.configureIncrementalLoad(job, dianxin_bulk, regionLocator);自动对job进行配置。SimpleTotalOrderPartitioner是需要先对key进行整体排序，然后划分到每个reduce中，保证每一个reducer中的的key最小最大值区间范围，是不会有交集的。因为入库到HBase的时候，作为一个整体的Region，key是绝对有序的。</p></li><li><p>MR例子中最后生成HFile存储在HDFS上，输出路径下的子目录是各个列族。如果对HFile进行入库HBase，相当于move HFile到HBase的Region中，HFile子目录的列族内容没有了，但不能直接使用mv命令移动，因为直接移动不能更新HBase的元数据。</p></li><li><p>HFile入库到HBase通过HBase中 LoadIncrementalHFiles的doBulkLoad方法，对生成的HFile文件入库</p></li></ol><h2 id="八、HBase中rowkey的设计（重点）"><a href="#八、HBase中rowkey的设计（重点）" class="headerlink" title="八、HBase中rowkey的设计（重点）"></a>八、HBase中rowkey的设计（重点）</h2><p><strong>HBase的RowKey设计</strong></p><p>HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。</p><p>HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有两种方式：</p><p> 通过get方式，指定rowkey获取唯一一条记录</p><p> 通过scan方式，设置startRow和stopRow参数进行范围匹配</p><p> 全表扫描，即直接扫描整张表中所有行记录</p><p><strong>rowkey长度原则</strong></p><p>rowkey是一个二进制码流，可以是任意字符串，最大长度 <em>64kb</em> ，实际应用中一般为10-100bytes，以 byte[] 形式保存，一般设计成定长。</p><p>建议越短越好，不要超过16个字节，原因如下：</p><p> 数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w&#x3D;10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；</p><p> MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。</p><p> 目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p><p><strong>rowkey散列原则</strong></p><p>如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。</p><p><strong>rowkey唯一原则</strong></p><p>必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。</p><p><strong>什么是热点</strong></p><p>HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。</p><p>为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。</p><p>下面是一些常见的避免热点的方法以及它们的优缺点：</p><p><strong>加盐</strong></p><p>这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。</p><p><strong>哈希</strong></p><p>哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据</p><p><strong>反转</strong></p><p>第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。</p><p>反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题</p><p><strong>时间戳反转</strong></p><p>一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key]reverse_timestamp , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。</p><p>比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计</p><p>[userId反转]Long.Max_Value - timestamp，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转]000000000000,stopRow是[userId反转]Long.Max_Value - timestamp</p><p>如果需要查询某段时间的操作记录，startRow是[user反转]Long.Max_Value - 起始时间，stopRow是[userId反转]Long.Max_Value - 结束时间</p><p>其他一些建议</p><p> 尽量减少行和列的大小在HBase中，value永远和它的key一起传输的。当具体的值在系统间传输时，它的rowkey，列名，时间戳也会一起传输。如果你的rowkey和列名很大，甚至可以和具体的值相比较，那么你将会遇到一些有趣的问题。HBase storefiles中的索引（有助于随机访问）最终占据了HBase分配的大量内存，因为具体的值和它的key很大。可以增加block大小使得storefiles索引再更大的时间间隔增加，或者修改表的模式以减小rowkey和列名的大小。压缩也有助于更大的索引。</p><p> 列族尽可能越短越好，最好是一个字符</p><p> 冗长的属性名虽然可读性好，但是更短的属性名存储在HBase中会更好</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 原数据：以时间戳_user_id作为rowkey</span><br><span class="line"># 时间戳高位变化不大，太连续，最终可能会导致热点问题</span><br><span class="line">1638584124_user_id</span><br><span class="line">1638584135_user_id</span><br><span class="line">1638584146_user_id</span><br><span class="line">1638584157_user_id</span><br><span class="line">1638584168_user_id</span><br><span class="line">1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 解决方案：加盐、反转、哈希</span><br><span class="line"></span><br><span class="line"># 加盐</span><br><span class="line"># 加上随即前缀，随机的打散</span><br><span class="line"># 该过程无法预测 前缀时随机的</span><br><span class="line">00_1638584124_user_id</span><br><span class="line">05_1638584135_user_id</span><br><span class="line">03_1638584146_user_id</span><br><span class="line">04_1638584157_user_id</span><br><span class="line">02_1638584168_user_id</span><br><span class="line">06_1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 反转</span><br><span class="line"># 适用于高位变化不大，低位变化大的rowkey</span><br><span class="line">4214858361_user_id</span><br><span class="line">5314858361_user_id</span><br><span class="line">6414858361_user_id</span><br><span class="line">7514858361_user_id</span><br><span class="line">8614858361_user_id</span><br><span class="line">9714858361_user_id</span><br><span class="line"></span><br><span class="line"># 散列 md5、sha1、sha256......</span><br><span class="line">25531D7065AE158AAB6FA53379523979_user_id</span><br><span class="line">60F9A0072C0BD06C92D768DACF2DFDC3_user_id</span><br><span class="line">D2EFD883A6C0198DA3AF4FD8F82DEB57_user_id</span><br><span class="line">A9A4C265D61E0801D163927DE1299C79_user_id</span><br><span class="line">3F41251355E092D7D8A50130441B58A5_user_id</span><br><span class="line">5E6043C773DA4CF991B389D200B77379_user_id</span><br><span class="line"></span><br><span class="line"># 时间戳&quot;反转&quot;</span><br><span class="line"># rowkey：时间戳_user_id</span><br><span class="line"># rowkey是字典升序的，那么越新的记录会被排在最后面，不容易被获取到</span><br><span class="line"># 需求：让最新的记录排在最前面</span><br><span class="line"></span><br><span class="line"># 大数：9999999999</span><br><span class="line"># 大数-小数</span><br><span class="line"></span><br><span class="line">1638584124_user_id =&gt; 8361415875_user_id</span><br><span class="line">1638584135_user_id =&gt; 8361415864_user_id</span><br><span class="line">1638584146_user_id =&gt; 8361415853_user_id</span><br><span class="line">1638584157_user_id =&gt; 8361415842_user_id</span><br><span class="line">1638584168_user_id =&gt; 8361415831_user_id</span><br><span class="line">1638584179_user_id =&gt; 8361415820_user_id</span><br><span class="line"></span><br><span class="line">1638586193_user_id =&gt; 8361413806_user_id</span><br></pre></td></tr></table></figure><h3 id="合理设计rowkey实战（电信）"><a href="#合理设计rowkey实战（电信）" class="headerlink" title="合理设计rowkey实战（电信）"></a>合理设计rowkey实战（电信）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br><span class="line"></span><br><span class="line">将用户位置数据保存到hbase</span><br><span class="line">    查询需求</span><br><span class="line">        1、通过手机号查询用户最近10条位置记录</span><br><span class="line"></span><br><span class="line">        2、获取用户某一天在一个城市中的所有位置</span><br><span class="line"></span><br><span class="line">    怎么设计hbase表</span><br><span class="line">        1、rowkey</span><br><span class="line">        2、时间戳</span><br></pre></td></tr></table></figure><h2 id="九、二级索引"><a href="#九、二级索引" class="headerlink" title="九、二级索引"></a>九、二级索引</h2><blockquote><p><strong>二级索引的本质就是建立各列值与行键之间的映射关系</strong></p></blockquote><p><strong>Hbase的局限性：</strong></p><p>　　HBase本身只提供基于行键和全表扫描的查询，而行键索引单一，对于多维度的查询困难。</p><p><strong>所以我们引进一个二级索引的概念</strong></p><h3 id="常见的二级索引："><a href="#常见的二级索引：" class="headerlink" title="常见的二级索引："></a><strong>常见的二级索引：</strong></h3><p>HBase的一级索引就是rowkey，我们只能通过rowkey进行检索。如果我们相对hbase里面列族的列列进行一些组合查询，就需要采用HBase的二级索引方案来进行多条件的查询。 </p><p>  　　1. MapReduce方案<br>  　　2. ITHBASE（Indexed-Transanctional HBase）方案<br>  　　3. IHBASE（Index HBase）方案<br>  　　4. Hbase Coprocessor(协处理器)方案<br>  　　5. Solr+hbase方案  redis+hbase 方案</p><p>  　　6. CCIndex（complementalclustering index）方案</p><h3 id="二级索引的种类"><a href="#二级索引的种类" class="headerlink" title="二级索引的种类"></a><strong>二级索引的种类</strong></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">　　1、创建单列索引</span><br><span class="line"></span><br><span class="line">　　2、同时创建多个单列索引</span><br><span class="line"></span><br><span class="line">　　3、创建联合索引（最多同时支持3个列）</span><br><span class="line"></span><br><span class="line">　　4、只根据rowkey创建索引</span><br></pre></td></tr></table></figure><p><strong>单表建立二级索引</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.首先disable ‘表名’</span><br><span class="line">2.然后修改表</span><br><span class="line"></span><br><span class="line">alter &#x27;LogTable&#x27;,METHOD=&gt;&#x27;table_att&#x27;,&#x27;coprocessor&#x27;=&gt;&#x27;hdfs:///写好的Hbase协处理器（coprocessor）的jar包名|类的绝对路径名|1001&#x27;</span><br><span class="line"></span><br><span class="line">3. enable &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><strong>二级索引的设计思路</strong></p><p><img src="https://s2.loli.net/2022/06/15/74rQAdRhWFzasxm.png" alt="image-20220615155157645"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">二级索引的本质就是建立各列值与行键之间的映射关系</span><br><span class="line"></span><br><span class="line">如上图，当要对F:C1这列建立索引时，只需要建立F:C1各列值到其对应行键的映射关系，如C11-&gt;RK1等，这样就完成了对F:C1列值的二级索引的构建，当要查询符合F:C1=C11对应的F:C2的列值时（即根据C1=C11来查询C2的值,图1青色部分）</span><br><span class="line"></span><br><span class="line">其查询步骤如下：</span><br><span class="line"></span><br><span class="line">1. 根据C1=C11到索引数据中查找其对应的RK，查询得到其对应的RK=RK1</span><br><span class="line"></span><br><span class="line">2. 得到RK1后就自然能根据RK1来查询C2的值了 这是构建二级索引大概思路，其他组合查询的联合索引的建立也类似。</span><br></pre></td></tr></table></figure><h3 id="Mapreduce的方式创建二级索引"><a href="#Mapreduce的方式创建二级索引" class="headerlink" title="Mapreduce的方式创建二级索引"></a><strong>Mapreduce的方式创建二级索引</strong></h3><p>使用整合MapReduce的方式创建hbase索引。主要的流程如下：</p><p>1.1扫描输入表，使用hbase继承类TableMapper</p><p>1.2获取rowkey和指定字段名称和字段值</p><p>1.3创建Put实例， value&#x3D;” “, rowkey&#x3D;班级，column&#x3D;学号</p><p>1.4使用IdentityTableReducer将数据写入索引表</p><h4 id="案例："><a href="#案例：" class="headerlink" title="案例："></a>案例：</h4><blockquote><p><strong>1、在hbase中创建索引表 student_index</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;student_index&#x27;</span>,<span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>2、编写mapreduce代码</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Mutation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  编写整个mapreduce程序建立索引表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexMapper</span> <span class="keyword">extends</span> <span class="title class_">TableMapper</span>&lt;Text, NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(ImmutableBytesWritable key, Result value, Mapper&lt;ImmutableBytesWritable, Result, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(key.get());</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(value.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">key1</span> <span class="operator">=</span> id+<span class="string">&quot;_&quot;</span>+clazz;</span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(key1),NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * reduce端获取map端传过来的key</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexReduce</span> <span class="keyword">extends</span> <span class="title class_">TableReducer</span>&lt;Text,NullWritable,NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Reducer&lt;Text, NullWritable, NullWritable, Mutation&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        String[] strings = key.toString().split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> strings[<span class="number">0</span>];</span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> strings[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//索引表也是属于hbase的表，需要使用put实例添加数据</span></span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(clazz.getBytes());</span><br><span class="line">        put.add(<span class="string">&quot;info&quot;</span>.getBytes(),id.getBytes(),<span class="string">&quot;&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        context.write(NullWritable.get(),put);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndex</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        job.setJobName(<span class="string">&quot;建立学生索引表&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(HbaseIndex.class);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.addFamily(<span class="string">&quot;info&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定对哪张表建立索引，以及指定需要建索引的列所属的列簇</span></span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(<span class="string">&quot;students&quot;</span>,scan,IndexMapper.class,Text.class,NullWritable.class,job);</span><br><span class="line">        TableMapReduceUtil.initTableReducerJob(<span class="string">&quot;student_index&quot;</span>,IndexReduce.class,job);</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>3、打成jar包上传到hadoop中运行</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop jar had-hbase-demo-1.0-SNAPSHOT-jar-with-dependencies.jar com.shujia.hbaseapi.hbaseindexdemo.HbaseIndex</span><br></pre></td></tr></table></figure><blockquote><p><strong>4、编写查询代码，测试结果（先查询索引表，在查数据）</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.CompareFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SubstringComparator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndexToStudents</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> HConnection conn;</span><br><span class="line">    <span class="keyword">private</span> HBaseAdmin hAdmin;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1、获取Hadoop的相关配置环境</span></span><br><span class="line">            <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//2、获取zookeeper的配置</span></span><br><span class="line">            conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line">            <span class="comment">//获取与Hbase的连接，这个连接是将来可以用户获取hbase表的</span></span><br><span class="line">            conn = HConnectionManager.createConnection(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//将来我们要对表做DDL相关操作，而对表的操作在hbase架构中是有HMaster</span></span><br><span class="line">            hAdmin = <span class="keyword">new</span> <span class="title class_">HBaseAdmin</span>(conf);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;建立连接成功:&quot;</span> + conn + <span class="string">&quot;, HMaster获取成功：&quot;</span> + hAdmin);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过索引表进行查询数据</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * 需求：获取理科二班所有的学生信息，不适用过滤器，使用索引表查询</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">scanData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//创建一个集合存放查询到的学号</span></span><br><span class="line">            ArrayList&lt;Get&gt; gets = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取到索引表</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">student_index</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;student_index&quot;</span>);</span><br><span class="line">            <span class="comment">//创建Get实例</span></span><br><span class="line">            <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(<span class="string">&quot;理科二班&quot;</span>.getBytes());</span><br><span class="line">            <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> student_index.get(get);</span><br><span class="line">            List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">                <span class="comment">//每一个单元格的列名</span></span><br><span class="line">                <span class="type">byte</span>[] bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(bytes);</span><br><span class="line"></span><br><span class="line">                <span class="type">Get</span> <span class="variable">get1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(id.getBytes());</span><br><span class="line">                <span class="comment">//将学号添加到集合中</span></span><br><span class="line">                gets.add(get1);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            Result[] results = students.get(gets);</span><br><span class="line">            <span class="keyword">for</span> (Result result1 : results) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(result1.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">            <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;理科二班&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(), CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            scan.setFilter(singleColumnValueFilter);</span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (conn != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                conn.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;conn连接已经关闭.....&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (hAdmin != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hAdmin.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;HMaster已经关闭......&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十、Phoenix二级索引"><a href="#十、Phoenix二级索引" class="headerlink" title="十、Phoenix二级索引"></a>十、Phoenix二级索引</h2><blockquote><p>对于Hbase，如果想精确定位到某行记录，唯一的办法就是通过rowkey查询。如果不通过rowkey查找数据，就必须逐行比较每一行的值，对于较大的表，全表扫描的代价是不可接受的。</p></blockquote><h3 id="1、开启索引支持"><a href="#1、开启索引支持" class="headerlink" title="1、开启索引支持"></a>1、开启索引支持</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 关闭hbase集群</span><br><span class="line">stop-hbase.sh</span><br><span class="line"></span><br><span class="line"># 在/usr/local/soft/hbase-1.4.6/conf/hbase-site.xml中增加如下配置</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.wal.codec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 同步到所有节点</span><br><span class="line">scp hbase-site.xml node1:`pwd`</span><br><span class="line">scp hbase-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line"># 修改phoenix目录下的bin目录中的hbase-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 启动hbase</span><br><span class="line">start-hbase.sh</span><br><span class="line"># 重新进入phoenix客户端</span><br><span class="line">sqlline.py master,node1,node2</span><br></pre></td></tr></table></figure><h3 id="2、创建索引"><a href="#2、创建索引" class="headerlink" title="2、创建索引"></a>2、创建索引</h3><h4 id="2-1、全局索引"><a href="#2-1、全局索引" class="headerlink" title="2.1、全局索引"></a>2.1、全局索引</h4><blockquote><p>全局索引适合读多写少的场景。如果使用全局索引，读数据基本不损耗性能，所有的性能损耗都来源于写数据。数据表的添加、删除和修改都会更新相关的索引表（数据删除了，索引表中的数据也会删除；数据增加了，索引表的数据也会增加）</p></blockquote><blockquote><p>注意: 对于全局索引在默认情况下，在查询语句中检索的列如果不在索引表中，Phoenix不会使用索引表将，除非使用hint。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">手机号 进入网格的时间 离开网格的时间 区县编码 经度 纬度 基站标识 网格编号 业务类型</span><br><span class="line"></span><br><span class="line"># 创建DIANXIN.sql</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> DIANXIN (</span><br><span class="line">     mdn <span class="type">VARCHAR</span> ,</span><br><span class="line">     start_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     end_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     county <span class="type">VARCHAR</span>,</span><br><span class="line">     x <span class="keyword">DOUBLE</span> ,</span><br><span class="line">     y  <span class="keyword">DOUBLE</span>,</span><br><span class="line">     bsid <span class="type">VARCHAR</span>,</span><br><span class="line">     grid_id  <span class="type">VARCHAR</span>,</span><br><span class="line">     biz_type <span class="type">VARCHAR</span>, </span><br><span class="line">     event_type <span class="type">VARCHAR</span> , </span><br><span class="line">     data_source <span class="type">VARCHAR</span> ,</span><br><span class="line">     <span class="keyword">CONSTRAINT</span> PK <span class="keyword">PRIMARY</span> KEY (mdn,start_date)</span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 上传数据DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 导入数据</span><br><span class="line">psql.py master,node1,node2 DIANXIN.sql DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 创建全局索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX <span class="keyword">ON</span> DIANXIN ( end_date );</span><br><span class="line"></span><br><span class="line"># 查询数据 ( 索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 （索引生效） hint</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> start_date <span class="operator">=</span> <span class="string">&#x27;20180503154614&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 取索引列，（索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 创建多列索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX1 <span class="keyword">ON</span> DIANXIN ( end_date,COUNTY );</span><br><span class="line"></span><br><span class="line"># 多条件查询 （索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date,MDN,COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 （索引生效）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX1) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 单条件  (索引未生效)</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span>  COUNTY <span class="operator">=</span> <span class="string">&#x27;8340103&#x27;</span>;</span><br><span class="line"># 单条件  (索引生效) end_date 在前</span><br><span class="line"><span class="keyword">select</span> COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 删除索引</span><br><span class="line"><span class="keyword">drop</span> index DIANXIN_INDEX <span class="keyword">on</span> DIANXIN;</span><br></pre></td></tr></table></figure><h4 id="2-2、本地索引"><a href="#2-2、本地索引" class="headerlink" title="2.2、本地索引"></a>2.2、本地索引</h4><blockquote><p>本地索引适合写多读少的场景，或者存储空间有限的场景。和全局索引一样，Phoenix也会在查询的时候自动选择是否使用本地索引。本地索引因为索引数据和原数据存储在同一台机器上，避免网络数据传输的开销，所以更适合写多的场景。由于无法提前确定数据在哪个Region上，所以在读数据的时候，需要检查每个Region上的数据从而带来一些性能损耗。</p></blockquote><blockquote><p>注意:对于本地索引，查询中无论是否指定hint或者是查询的列是否都在索引表中，都会使用索引表。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建本地索引</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">LOCAL</span> INDEX DIANXIN_LOCAL_IDEX <span class="keyword">ON</span> DIANXIN(grid_id);</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> grid_id <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2-3、覆盖索引"><a href="#2-3、覆盖索引" class="headerlink" title="2.3、覆盖索引"></a>2.3、覆盖索引</h4><blockquote><p>覆盖索引是把原数据存储在索引数据表中，这样在查询时不需要再去HBase的原表获取数据就，直接返回查询结果。</p></blockquote><blockquote><p>注意：查询是 select 的列和 where 的列都需要在索引中出现。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建覆盖索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX_COVER <span class="keyword">ON</span> DIANXIN ( x,y ) INCLUDE ( county );</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 (索引生效)</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询索引中的列 (索引生效) mdn是DIANXIN表的RowKey中的一部分</span><br><span class="line"><span class="keyword">select</span> x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"><span class="keyword">select</span> mdn,x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询条件必须放在索引中  <span class="keyword">select</span> 中的列可以放在INCLUDE （将数据保存在索引中）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> x,y,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> DIANXIN <span class="keyword">group</span> <span class="keyword">by</span> x,y;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十一、Phoenix-JDBC"><a href="#十一、Phoenix-JDBC" class="headerlink" title="十一、Phoenix JDBC"></a>十一、Phoenix JDBC</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 导入依赖</span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.15.0-HBase-1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># 建立连接</span><br><span class="line"><span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:phoenix:master,node1,node2:2181&quot;</span>);</span><br><span class="line">        <span class="type">PreparedStatement</span> <span class="variable">ps</span> <span class="operator">=</span> conn.prepareStatement(<span class="string">&quot;select /*+ INDEX(DIANXIN DIANXIN_INDEX) */ * from DIANXIN where end_date=?&quot;</span>);</span><br><span class="line">        ps.setString(<span class="number">1</span>, <span class="string">&quot;20180503212649&quot;</span>);</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> ps.executeQuery();</span><br><span class="line">        <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">mdn</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;mdn&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">start_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;start_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">end_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;end_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">x</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;x&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">y</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;y&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">county</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;county&quot;</span>);</span><br><span class="line">            System.out.println(mdn + <span class="string">&quot;\t&quot;</span> + start_date + <span class="string">&quot;\t&quot;</span> + end_date + <span class="string">&quot;\t&quot;</span> + x + <span class="string">&quot;\t&quot;</span> + y + <span class="string">&quot;\t&quot;</span> + county);</span><br><span class="line">        &#125;</span><br><span class="line">        ps.close();</span><br><span class="line">        conn.close();</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习hbase JAVA API的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Hbase-shell2</title>
    <link href="http://example.com/2022/06/11/Hbase%20Shell%202/"/>
    <id>http://example.com/2022/06/11/Hbase%20Shell%202/</id>
    <published>2022-06-10T16:00:00.000Z</published>
    <updated>2022-06-15T07:37:55.519Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Hbase-Shell-2"><a href="#一、Hbase-Shell-2" class="headerlink" title="一、Hbase Shell 2"></a>一、Hbase Shell 2</h2><h3 id="1、Region信息观察"><a href="#1、Region信息观察" class="headerlink" title="1、Region信息观察"></a>1、Region信息观察</h3><h4 id="创建表指定命名空间"><a href="#创建表指定命名空间" class="headerlink" title="创建表指定命名空间"></a>创建表指定命名空间</h4><blockquote><p>在创建表的时候可以选择创建到bigdata17这个namespace中，如何实现呢？<br>使用这种格式即可：‘命名空间名称:表名’<br>针对default这个命名空间，在使用的时候可以省略不写</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;bigdata17:t1&#x27;,&#x27;info&#x27;,&#x27;level&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/Dow6xBpHlRzQ8PG.png" alt="image-20220612212944281"></p><blockquote><p>此时使用list查看所有的表</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/CxKkf4Wui2Smh1A.png" alt="image-20220612212956679"></p><blockquote><p>如果只想查看bigdata17这个命名空间中的表，如何实现呢？<br>可以使用命令list_namespace_tables</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;n1&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/hnEFiVldA1Ksr6W.png" alt="image-20220612213004703"></p><blockquote><p>查看region中的某列簇数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase hfile -p -f /hbase/data/default/tbl_user/92994712513a45baaa12b72117dda5e5/info/d84e2013791845968917d876e2b438a5</span><br></pre></td></tr></table></figure><h4 id="1-1-查看表的所有region"><a href="#1-1-查看表的所有region" class="headerlink" title="1.1    查看表的所有region"></a>1.1    查看表的所有region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/bY5Oj38yBf4mnwL.png" alt="image-20220612213103879"></p><h4 id="1-2-强制将表切分出来一个region"><a href="#1-2-强制将表切分出来一个region" class="headerlink" title="1.2    强制将表切分出来一个region"></a>1.2    强制将表切分出来一个region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/yaqm2QU1oNlZRLE.png" alt="image-20220612213116364"></p><blockquote><p>但是在页面上可以看到三个：过一会会自动的把原来的删除</p></blockquote><p><img src="D:/bigdata%25E5%259F%25B9%25E8%25AE%25AD/Hbase/day02/Hbase%25E5%25AD%25A6%25E4%25B9%25A0%25EF%25BC%2588%25E4%25BA%258C%25EF%25BC%2589.assets/image-20220609215721140.png" alt="image-20220609215721140"></p><h4 id="1-2-查看某一行在哪个region中"><a href="#1-2-查看某一行在哪个region中" class="headerlink" title="1.2    查看某一行在哪个region中"></a>1.2    查看某一行在哪个region中</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate_region &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/GAjNmPi9SRoqJWU.png" alt="image-20220612213129838"></p><blockquote><p>可以hbase hfile -p -f xxxx 查看一下</p></blockquote><h3 id="2、预分region解决热点问题"><a href="#2、预分region解决热点问题" class="headerlink" title="2、预分region解决热点问题"></a>2、预分region解决热点问题</h3><blockquote><p>row设计的一个关键点是查询维度</p><p>(在建表的时候根据具体的查询业务  设计rowkey   预拆分)</p><p>在默认的拆分策略中 ,region的大小达到一定的阈值以后才会进行拆分,并且拆分的region在同一个regionserver中 ,只有达到负载均衡的时机时才会进行region重分配!并且开始如果有大量的数据进行插入操作,那么并发就会集中在单个RS中, 形成热点问题,所以如果有并发插入的时候尽量避免热点问题 ,应当预划分 Region的rowkeyRange范围 ,在建表的时候就指定预region范围 </p></blockquote><blockquote><p>查看命令使用(指定4个切割点，就会有5个region)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">help &#x27;create&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/onVxkTuJROsG2hE.png" alt="image-20220612213148593"></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;tb_split&#x27;,&#x27;cf&#x27;,SPLITS =&gt; [&#x27;e&#x27;,&#x27;h&#x27;,&#x27;l&#x27;,&#x27;r&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/sS8UjNJrlLAb5TQ.png" alt="image-20220612213201806"></p><blockquote><p>添加数据试试</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;c001&#x27;,&#x27;cf:name&#x27;,&#x27;first&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;f001&#x27;,&#x27;cf:name&#x27;,&#x27;second&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;z001&#x27;,&#x27;cf:name&#x27;,&#x27;last&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>hbase hfile -p –f xxxx 查看数据</p></blockquote><blockquote><p>如果没有数据，因为数据还在内存中，需要手动刷新内存到HDFS中，以HFile的形式存储</p></blockquote><h3 id="3、总结（写一个文档总结回顾）"><a href="#3、总结（写一个文档总结回顾）" class="headerlink" title="3、总结（写一个文档总结回顾）"></a>3、总结（写一个文档总结回顾）</h3><h3 id="4、日志查看"><a href="#4、日志查看" class="headerlink" title="4、日志查看"></a>4、日志查看</h3><blockquote><p>演示不启动hdfs 就启动hbase</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">日志目录：</span><br><span class="line">/usr/local/soft/hbase-1.7.1/logs</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/KIdYakN6uzUgGTb.png" alt="image-20220612213213973"></p><blockquote><p>start-all.sh发现HMaster没启动，hbase shell客户端也可以正常访问</p><p>再启动hbase就好了</p></blockquote><h3 id="5、scan进阶使用"><a href="#5、scan进阶使用" class="headerlink" title="5、scan进阶使用"></a>5、scan进阶使用</h3><blockquote><p>查看所有的命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace</span><br></pre></td></tr></table></figure><blockquote><p>查看某个命名空间下的所有表</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;default&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>修改命名空间,设置一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;set&#x27;,&#x27;author&#x27;=&gt;&#x27;wyh&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>查看命名空间属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">describe_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;unset&#x27;, NAME=&gt;&#x27;author&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drop_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>创建一张表</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">create <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;cf&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>添加数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:tid&#x27;,1</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0002&#x27;,&#x27;cf:tid&#x27;,2</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0003&#x27;,&#x27;cf:tid&#x27;,3</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;,4</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0005&#x27;,&#x27;cf:tid&#x27;,5</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:tid&#x27;,6</span><br></pre></td></tr></table></figure><blockquote><p>显示三行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid00001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/lE4SaAX3FCNtGOj.png" alt="image-20220612213223835"></p><blockquote><p>从后查三行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,REVERSED=&gt;true&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/ky7KZhD36bYxpCI.png" alt="image-20220612213231718"></p><blockquote><p>查看包含指定列的行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,COLUMNS=&gt;[&#x27;cf:name&#x27;]&#125;</span><br></pre></td></tr></table></figure><blockquote><p>简化写法：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,LIMIT=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>在已有的值后面追加值</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">append &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;123&#x27;</span><br></pre></td></tr></table></figure><h3 id="6、get进阶使用"><a href="#6、get进阶使用" class="headerlink" title="6、get进阶使用"></a>6、get进阶使用</h3><blockquote><p>简单使用，获取某一行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某个列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某一列（属性 ）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>可以新增一个列簇数据测试</p></blockquote><blockquote><p><strong>查看历史版本</strong></p><p>1、修改表可以存储多个版本</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,NAME=&gt;&#x27;cf&#x27;,VERSIONS=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>2、put四次相同rowkey和列的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu1&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu2&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu3&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu4&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>3、查看历史数据，默认是最新的</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#123;COLUMN=&gt;&#x27;cf:name&#x27;,VERSIONS=&gt;2&#125;</span><br></pre></td></tr></table></figure><blockquote><p>修改列簇的过期时间 TTL单位是秒，这个时间是与插入的时间比较，而不是现在开始60s</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,&#123;NAME=&gt;&#x27;cf2&#x27;,TTL=&gt;&#x27;60&#x27;&#125;</span><br></pre></td></tr></table></figure><h3 id="7、插入时间指定时间戳"><a href="#7、插入时间指定时间戳" class="headerlink" title="7、插入时间指定时间戳"></a>7、插入时间指定时间戳</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0007&#x27;,&#x27;cf2:job&#x27;,&#x27;bigdata17&#x27;,1654845442790</span><br></pre></td></tr></table></figure><blockquote><p>画图理解这个操作在实际生产的作用</p></blockquote><h3 id="8、delete-只能删除一个单元格，不能删除列簇"><a href="#8、delete-只能删除一个单元格，不能删除列簇" class="headerlink" title="8、delete(只能删除一个单元格，不能删除列簇)"></a>8、delete(只能删除一个单元格，不能删除列簇)</h3><blockquote><p>删除某一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">delete &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;</span><br></pre></td></tr></table></figure><h3 id="9、deleteall-删除不了某个列簇，但是可以删除多个单元格"><a href="#9、deleteall-删除不了某个列簇，但是可以删除多个单元格" class="headerlink" title="9、deleteall(删除不了某个列簇，但是可以删除多个单元格)"></a>9、deleteall(删除不了某个列簇，但是可以删除多个单元格)</h3><blockquote><p>删除一行，如果不指定类簇，删除的是一行中的所有列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除单元格</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;cf2:job&#x27;</span><br></pre></td></tr></table></figure><h3 id="10、incr和counter"><a href="#10、incr和counter" class="headerlink" title="10、incr和counter"></a>10、incr和counter</h3><blockquote><p>统计表有多少行(<strong>统计的是行键的个数</strong>)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">count &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>新建一个自增的一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br></pre></td></tr></table></figure><blockquote><p>每操作一次，自增1</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,10</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,100</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/o4DQfV6mOd5gGBY.png" alt="image-20220612213526090"></p><blockquote><p>配合counter取出数据,只能去incr字段</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_counter &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;</span><br></pre></td></tr></table></figure><h3 id="11、获取region的分割点，清除数据，快照"><a href="#11、获取region的分割点，清除数据，快照" class="headerlink" title="11、获取region的分割点，清除数据，快照"></a>11、获取region的分割点，清除数据，快照</h3><blockquote><p>获取region的分割点</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_splits &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>清除表数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">truncate &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>拍摄快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">snapshot &#x27;tb_split&#x27;,&#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>列出所有快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_table_snapshots &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>再添加一些数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;a001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>恢复快照(先禁用)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">disable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">restore_snapshot &#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">enable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><h3 id="12-修饰词"><a href="#12-修饰词" class="headerlink" title="12    修饰词"></a>12    修饰词</h3><h5 id="1、修饰词"><a href="#1、修饰词" class="headerlink" title="1、修饰词"></a>1、修饰词</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;列族名1:列名1&#x27;</span>, <span class="string">&#x27;列族名1:列名2&#x27;</span>, ...]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="2、TIMESTAMP-指定时间戳"><a href="#2、TIMESTAMP-指定时间戳" class="headerlink" title="2、TIMESTAMP 指定时间戳"></a>2、TIMESTAMP 指定时间戳</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[timestamp1, timestamp2]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[<span class="number">1551938004321</span>, <span class="number">1551938036450</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="3、VERSIONS"><a href="#3、VERSIONS" class="headerlink" title="3、VERSIONS"></a>3、VERSIONS</h5><blockquote><p>默认情况下一个列只能存储一个数据，后面如果修改数据就会将原来的覆盖掉，可以通过指定VERSIONS时HBase一列能存储多个值。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;columnFamily1&#x27;</span></span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_test&#x27;</span></span><br><span class="line"></span><br><span class="line"># 修改列族版本号</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_test&#x27;</span>, &#123; NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span> &#125;</span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value3&#x27;</span></span><br><span class="line"></span><br><span class="line"># 默认返回最新的一条数据</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,<span class="string">&#x27;columnFamily1:column1&#x27;</span></span><br><span class="line"></span><br><span class="line"># 返回<span class="number">3</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"># 返回<span class="number">2</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="4、STARTROW"><a href="#4、STARTROW" class="headerlink" title="4、STARTROW"></a>4、STARTROW</h5><blockquote><p>ROWKEY起始行。会先根据这个key定位到region，再向后扫描</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;vbirdbest&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"><a href="#5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据" class="headerlink" title="5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"></a>5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;xiaoming&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="6、LIMIT-返回的行数"><a href="#6、LIMIT-返回的行数" class="headerlink" title="6、LIMIT 返回的行数"></a>6、LIMIT 返回的行数</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> 行数&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2</span> &#125;</span><br></pre></td></tr></table></figure><h3 id="13-FILTER条件过滤器"><a href="#13-FILTER条件过滤器" class="headerlink" title="13    FILTER条件过滤器"></a>13    FILTER条件过滤器</h3><blockquote><p>过滤器之间可以使用AND、OR连接多个过滤器。</p></blockquote><h5 id="1、ValueFilter-值过滤器"><a href="#1、ValueFilter-值过滤器" class="headerlink" title="1、ValueFilter 值过滤器"></a>1、ValueFilter 值过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法：<span class="type">binary</span> 等于某个值</span><br><span class="line">scan <span class="string">&#x27;&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;binary:&#x27;)&quot;</span><br><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;substring:列值&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;binary:26&#x27;)&quot;</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;substring:6&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="2、ColumnPrefixFilter-列名前缀过滤器"><a href="#2、ColumnPrefixFilter-列名前缀过滤器" class="headerlink" title="2、ColumnPrefixFilter 列名前缀过滤器"></a>2、ColumnPrefixFilter 列名前缀过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;列名前缀&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;)&quot;</span><br><span class="line"># 通过括号、<span class="keyword">AND</span>和<span class="keyword">OR</span>的条件组合多个过滤器</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:26&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="3、rowKey字典排序"><a href="#3、rowKey字典排序" class="headerlink" title="3、rowKey字典排序"></a>3、rowKey字典排序</h5><blockquote><p>Table中的所有行都是按照row key的字典排序的</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/lHbNsQYjU8TCnMA.png" alt="image-20220612213543115"></p><h2 id="二、JAVA-API"><a href="#二、JAVA-API" class="headerlink" title="二、JAVA API"></a>二、JAVA API</h2><blockquote><p>pom文件</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">对学习hbase shell的一些知识笔记</summary>
    
    
    
    <category term="大数据" scheme="http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="Hbase" scheme="http://example.com/tags/Hbase/"/>
    
  </entry>
  
</feed>
