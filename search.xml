<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2022/08/19/SQL%E7%AC%94%E8%AF%95%E9%A2%98/"/>
      <url>/2022/08/19/SQL%E7%AC%94%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h5 id="TopN问题"><a href="#TopN问题" class="headerlink" title="TopN问题"></a>TopN问题</h5><p>需要确定使用什么排名函数，包含三种函数：row_number()、rank()、dense_rank()</p><p>每个班级的分数为前3名的学生</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score(sid string, class string, score <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> score;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：学生id、班级、分数</span></span><br><span class="line">s1 A <span class="number">89</span></span><br><span class="line">s2 C <span class="number">88</span></span><br><span class="line">s3 A <span class="number">92</span></span><br><span class="line">s4 A <span class="number">89</span></span><br><span class="line">s5 B <span class="number">90</span></span><br><span class="line">s6 B <span class="number">86</span></span><br><span class="line">s7 C <span class="number">92</span></span><br><span class="line">s8 C <span class="number">90</span></span><br><span class="line">s9 A <span class="number">85</span></span><br><span class="line">s10 C <span class="number">86</span></span><br><span class="line">s11 B <span class="number">86</span></span><br><span class="line">s12 B <span class="number">86</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> class, sid, score, <span class="built_in">dense_rank</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> class <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span>) <span class="keyword">as</span> rank</span><br><span class="line">    <span class="keyword">from</span> score</span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">where</span> t1.rank <span class="operator">&lt;</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t1.classt1.sidt1.scoret1.rank</span><br><span class="line">As3<span class="number">92</span><span class="number">1</span></span><br><span class="line">As4<span class="number">89</span><span class="number">2</span></span><br><span class="line">As1<span class="number">89</span><span class="number">2</span></span><br><span class="line">As9<span class="number">85</span><span class="number">3</span></span><br><span class="line">Bs5<span class="number">90</span><span class="number">1</span></span><br><span class="line">Bs11<span class="number">86</span><span class="number">2</span></span><br><span class="line">Bs12<span class="number">86</span><span class="number">2</span></span><br><span class="line">Bs6<span class="number">86</span><span class="number">2</span></span><br><span class="line">Cs7<span class="number">92</span><span class="number">1</span></span><br><span class="line">Cs8<span class="number">90</span><span class="number">2</span></span><br><span class="line">Cs2<span class="number">88</span><span class="number">3</span></span><br></pre></td></tr></table></figure><h5 id="行列转换问题"><a href="#行列转换问题" class="headerlink" title="行列转换问题"></a>行列转换问题</h5><p>（1）一行转换为多行</p><p>将每个电影的分类列表拆分出单个分类</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> movie(movie_name string, category string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> movie;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：电影名、分类</span></span><br><span class="line">让子弹飞 动作、年代</span><br><span class="line">长江七号 科幻</span><br><span class="line">大进军 战争</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> movie_name, category_name</span><br><span class="line"><span class="keyword">from</span> movie</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(category, <span class="string">&#x27;、&#x27;</span>)) t1 <span class="keyword">as</span> category_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">movie_namecategory_name</span><br><span class="line">让子弹飞动作</span><br><span class="line">让子弹飞年代</span><br><span class="line">长江七号科幻</span><br><span class="line">大进军战争</span><br></pre></td></tr></table></figure><p>（2）多行转换为一行</p><p>将年龄相同的姓名合并在一起</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> person(name string, age <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> person;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：姓名、年龄</span></span><br><span class="line">A <span class="number">20</span></span><br><span class="line">B <span class="number">18</span></span><br><span class="line">C <span class="number">20</span></span><br><span class="line">D <span class="number">24</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> concat_ws(<span class="string">&#x27;|&#x27;</span>, collect_set(name)) <span class="keyword">as</span> name_list, age</span><br><span class="line"><span class="keyword">from</span> person</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> age;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">name_listage</span><br><span class="line">B<span class="number">18</span></span><br><span class="line">A<span class="operator">|</span>C<span class="number">20</span></span><br><span class="line">D<span class="number">24</span></span><br></pre></td></tr></table></figure><p>将可枚举的值作为新的字段</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> game(<span class="keyword">year</span> <span class="type">int</span>, class string, score <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> game;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：年份、班级、得分</span></span><br><span class="line"><span class="number">2020</span> ClassA <span class="number">10</span></span><br><span class="line"><span class="number">2020</span> ClassB <span class="number">12</span></span><br><span class="line"><span class="number">2020</span> ClassC <span class="number">9</span></span><br><span class="line"><span class="number">2021</span> ClassA <span class="number">12</span></span><br><span class="line"><span class="number">2021</span> ClassB <span class="number">8</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">year</span>,</span><br><span class="line"><span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> class <span class="operator">=</span> <span class="string">&#x27;ClassA&#x27;</span> <span class="keyword">then</span> score <span class="keyword">end</span>) <span class="keyword">as</span> A,</span><br><span class="line"><span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> class <span class="operator">=</span> <span class="string">&#x27;ClassB&#x27;</span> <span class="keyword">then</span> score <span class="keyword">end</span>) <span class="keyword">as</span> B,</span><br><span class="line"><span class="built_in">max</span>(<span class="keyword">case</span> <span class="keyword">when</span> class <span class="operator">=</span> <span class="string">&#x27;ClassC&#x27;</span> <span class="keyword">then</span> score <span class="keyword">end</span>) <span class="keyword">as</span> C</span><br><span class="line"><span class="keyword">from</span> game</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">year</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line"><span class="keyword">year</span>abc</span><br><span class="line"><span class="number">2020</span><span class="number">10</span><span class="number">12</span><span class="number">9</span></span><br><span class="line"><span class="number">2021</span><span class="number">12</span><span class="number">8</span><span class="keyword">NULL</span></span><br></pre></td></tr></table></figure><h5 id="连续性问题"><a href="#连续性问题" class="headerlink" title="连续性问题"></a>连续性问题</h5><p>连续3天登录的用户</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> login(uid <span class="type">int</span>,dt <span class="type">date</span>, status <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> login;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、日期、是否登录</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-01</span><span class="number">0</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-02</span><span class="number">1</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-03</span><span class="number">1</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-04</span><span class="number">1</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-05</span><span class="number">1</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-06</span><span class="number">0</span></span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-07</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-01</span><span class="number">0</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-02</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-03</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-04</span><span class="number">0</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-05</span><span class="number">0</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-06</span><span class="number">1</span></span><br><span class="line"><span class="number">2</span><span class="number">2022</span><span class="number">-03</span><span class="number">-07</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-01</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-02</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-03</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-04</span><span class="number">0</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-05</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-06</span><span class="number">1</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-07</span><span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--查询用户在起始日期及其之后的连续登录次数</span></span><br><span class="line">    <span class="keyword">select</span> t1.uid, <span class="built_in">min</span>(t1.dt) <span class="keyword">as</span> start_day, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> day_count</span><br><span class="line">    <span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--按照用户分组，按照日期递增排序，计算连续登录操作的锚定日期</span></span><br><span class="line">        <span class="keyword">select</span> uid, dt, date_sub(dt, <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> uid <span class="keyword">order</span> <span class="keyword">by</span> dt <span class="keyword">asc</span>)) <span class="keyword">as</span> diff</span><br><span class="line">        <span class="keyword">from</span> login</span><br><span class="line">        <span class="keyword">where</span> status <span class="operator">=</span> <span class="number">1</span> <span class="comment">--筛选登录的日期</span></span><br><span class="line">    ) t1</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> t1.uid, t1.diff <span class="comment">--按照用户、锚定日期分组</span></span><br><span class="line">) t2</span><br><span class="line"><span class="keyword">where</span> t2.day_count <span class="operator">&gt;</span> <span class="number">2</span>; <span class="comment">--筛选出至少3次的连续登录操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t2.uidt2.start_dayt2.day_count</span><br><span class="line"><span class="number">1</span><span class="number">2022</span><span class="number">-03</span><span class="number">-02</span><span class="number">4</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-01</span><span class="number">3</span></span><br><span class="line"><span class="number">3</span><span class="number">2022</span><span class="number">-03</span><span class="number">-05</span><span class="number">3</span></span><br></pre></td></tr></table></figure><p>连续3年获得冠军的队伍</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> champion(<span class="keyword">year</span> <span class="type">int</span>, team string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> champion;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：年份、获得冠军的队伍</span></span><br><span class="line"><span class="number">2000</span> Sun</span><br><span class="line"><span class="number">2001</span> Lakers</span><br><span class="line"><span class="number">2002</span> Rockets</span><br><span class="line"><span class="number">2003</span> Rockets</span><br><span class="line"><span class="number">2004</span> Rockets</span><br><span class="line"><span class="number">2005</span> Spurs</span><br><span class="line"><span class="number">2006</span> Spurs</span><br><span class="line"><span class="number">2007</span> Sun</span><br><span class="line"><span class="number">2008</span> Lakers</span><br><span class="line"><span class="number">2009</span> Lakers</span><br><span class="line"><span class="number">2010</span> Lakers</span><br><span class="line"><span class="number">2011</span> Lakers</span><br><span class="line"><span class="number">2012</span> Warriors</span><br><span class="line"><span class="number">2013</span> Warriors</span><br><span class="line"><span class="number">2014</span> Warriors</span><br><span class="line"><span class="number">2015</span> Heat</span><br><span class="line"><span class="number">2016</span> Warriors</span><br><span class="line"><span class="number">2017</span> Cavaliers</span><br><span class="line"><span class="number">2018</span> Warriors</span><br><span class="line"><span class="number">2019</span> Sun</span><br><span class="line"><span class="number">2020</span> Warriors</span><br><span class="line"><span class="number">2021</span> Warriors</span><br><span class="line"><span class="number">2022</span> Raptors</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--查询队伍在起始年份及其之后的连续获得冠军的次数</span></span><br><span class="line"><span class="keyword">select</span> t1.team, <span class="built_in">min</span>(t1.year) <span class="keyword">as</span> start_year, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="comment">--按照队伍分组，按照年份递增排序，计算队伍获得冠军的锚定年份</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">year</span>, team, <span class="keyword">year</span> <span class="operator">-</span> <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> team <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">year</span> <span class="keyword">asc</span>) <span class="keyword">as</span> diff</span><br><span class="line"><span class="keyword">from</span> champion</span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t1.team, t1.diff <span class="comment">--按照队伍、锚定年份分组</span></span><br><span class="line"><span class="keyword">having</span> count <span class="operator">&gt;</span> <span class="number">2</span>; <span class="comment">--筛选出至少3次的连续获得冠军</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t2.teamt2.start_yeart2.count</span><br><span class="line">Lakers<span class="number">2008</span><span class="number">4</span></span><br><span class="line">Rockets<span class="number">2002</span><span class="number">3</span></span><br><span class="line">Warriors<span class="number">2012</span><span class="number">3</span></span><br></pre></td></tr></table></figure><h5 id="间隔连续问题"><a href="#间隔连续问题" class="headerlink" title="间隔连续问题"></a>间隔连续问题</h5><p>给定每天登录游戏的所有用户，返回每个用户连续登录的最长天数，间隔一天的两次登录也可以看作连续登录</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> login(id <span class="type">int</span>, dt <span class="type">date</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> login;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、登录日期</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-02</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-03</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-04</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-05</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-05</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-07</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-07</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-09</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-09</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--按照用户id分组，查询每个用户连续登录的最长天数</span></span><br><span class="line"><span class="keyword">select</span> id, <span class="built_in">max</span>(day_count) <span class="keyword">as</span> day_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--按照用户id、flag字段分组，计算登录日期的最大值、最小值之差，表示一次连续登录的天数</span></span><br><span class="line"><span class="keyword">select</span> id, datediff(<span class="built_in">max</span>(dt), <span class="built_in">min</span>(dt)) <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> day_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--按照用户id分组，按照登录日期递增排序，判断当前登录、上次登录的日期之差是否大于2，累计求和，</span></span><br><span class="line">        <span class="comment">--使得属于连续登录的所有日期具有相同取值的flag字段</span></span><br><span class="line"><span class="keyword">select</span> id, dt,</span><br><span class="line"><span class="built_in">sum</span>(if(diff <span class="operator">&gt;</span> <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>)) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> dt <span class="keyword">asc</span>) <span class="keyword">as</span> flag</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">            <span class="comment">--查询当前登录、上次登录的日期之差diff</span></span><br><span class="line"><span class="keyword">select</span> id, dt, </span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> pre_dt <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span> datediff(dt, pre_dt) <span class="keyword">end</span> <span class="keyword">as</span> diff</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">                <span class="comment">--按照用户id分组，按照登录日期递增排序，查询当前登录日期、上次登录日期</span></span><br><span class="line"><span class="keyword">select</span> id, dt,</span><br><span class="line"><span class="built_in">lag</span>(dt) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> dt <span class="keyword">asc</span>) <span class="keyword">as</span> pre_dt</span><br><span class="line"><span class="keyword">from</span> login</span><br><span class="line">) t1</span><br><span class="line">) t2</span><br><span class="line">) t3</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> id, flag</span><br><span class="line">) t4</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">idday_count</span><br><span class="line"><span class="number">1001</span><span class="number">4</span></span><br><span class="line"><span class="number">1002</span><span class="number">9</span></span><br><span class="line"><span class="number">1003</span><span class="number">1</span></span><br></pre></td></tr></table></figure><h5 id="波峰波谷问题"><a href="#波峰波谷问题" class="headerlink" title="波峰波谷问题"></a>波峰波谷问题</h5><p>股票价格在时间点上的波峰与波谷</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> price(stock string, <span class="type">time</span> string, price <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> price;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：股票id、时间点、价格</span></span><br><span class="line">A1 <span class="number">06</span>:<span class="number">00</span> <span class="number">12</span></span><br><span class="line">A1 <span class="number">09</span>:<span class="number">00</span> <span class="number">16</span></span><br><span class="line">A1 <span class="number">12</span>:<span class="number">00</span> <span class="number">24</span></span><br><span class="line">A1 <span class="number">15</span>:<span class="number">00</span> <span class="number">17</span></span><br><span class="line">A1 <span class="number">18</span>:<span class="number">00</span> <span class="number">11</span></span><br><span class="line">A1 <span class="number">21</span>:<span class="number">00</span> <span class="number">13</span></span><br><span class="line">B1 <span class="number">06</span>:<span class="number">00</span> <span class="number">18</span></span><br><span class="line">B1 <span class="number">09</span>:<span class="number">00</span> <span class="number">12</span></span><br><span class="line">B1 <span class="number">12</span>:<span class="number">00</span> <span class="number">13</span></span><br><span class="line">B1 <span class="number">15</span>:<span class="number">00</span> <span class="number">13</span></span><br><span class="line">B1 <span class="number">18</span>:<span class="number">00</span> <span class="number">15</span></span><br><span class="line">B1 <span class="number">21</span>:<span class="number">00</span> <span class="number">17</span></span><br><span class="line">C1 <span class="number">06</span>:<span class="number">00</span> <span class="number">12</span></span><br><span class="line">C1 <span class="number">09</span>:<span class="number">00</span> <span class="number">13</span></span><br><span class="line">C1 <span class="number">12</span>:<span class="number">00</span> <span class="number">15</span></span><br><span class="line">C1 <span class="number">15</span>:<span class="number">00</span> <span class="number">17</span></span><br><span class="line">C1 <span class="number">18</span>:<span class="number">00</span> <span class="number">18</span></span><br><span class="line">C1 <span class="number">21</span>:<span class="number">00</span> <span class="number">20</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--查询波峰点</span></span><br><span class="line">    <span class="keyword">select</span> t1.stock, t1.time, t1.price, <span class="string">&#x27;top&#x27;</span> <span class="keyword">as</span> top</span><br><span class="line">    <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span> stock, <span class="type">time</span>, price,</span><br><span class="line">        <span class="comment">--按照股票分组，按照时间点递增排序</span></span><br><span class="line">        <span class="built_in">lag</span>(price) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> stock <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> previous, <span class="comment">--前面时间点的价格</span></span><br><span class="line">        <span class="built_in">lead</span>(price) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> stock <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> next <span class="comment">--后面时间点的价格</span></span><br><span class="line">        <span class="keyword">from</span> price</span><br><span class="line">    ) t1</span><br><span class="line">    <span class="keyword">where</span> t1.price <span class="operator">&gt;</span> t1.previous <span class="keyword">and</span> t1.price <span class="operator">&gt;</span> t1.next <span class="comment">--筛选出波峰点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">union</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">--查询波谷点</span></span><br><span class="line">    <span class="keyword">select</span> t2.stock, t2.time, t2.price, <span class="string">&#x27;down&#x27;</span> <span class="keyword">as</span> top</span><br><span class="line">    <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span> stock, <span class="type">time</span>, price,</span><br><span class="line">        <span class="built_in">lag</span>(price) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> stock <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> previous,</span><br><span class="line">        <span class="built_in">lead</span>(price) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> stock <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> next</span><br><span class="line">        <span class="keyword">from</span> price</span><br><span class="line">    ) t2</span><br><span class="line">    <span class="keyword">where</span> t2.price <span class="operator">&lt;</span> t2.previous <span class="keyword">and</span> t2.price <span class="operator">&lt;</span> t2.next <span class="comment">--筛选出波谷点</span></span><br><span class="line">) t3;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t3.stockt3.timet3.pricet3.top</span><br><span class="line">A1<span class="number">12</span>:<span class="number">00</span><span class="number">24</span>top</span><br><span class="line">A1<span class="number">18</span>:<span class="number">00</span><span class="number">11</span>down</span><br><span class="line">B1<span class="number">09</span>:<span class="number">00</span><span class="number">12</span>down</span><br></pre></td></tr></table></figure><h5 id="浏览时长问题"><a href="#浏览时长问题" class="headerlink" title="浏览时长问题"></a>浏览时长问题</h5><p>给定用户在多个时间点上的点击浏览记录，如果两次点击浏览的时间间隔不超过30个单位，则两次浏览属于相同的会话。查询用户在每次会话中的浏览时长、浏览步长，步长表示点击浏览的次数</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> click(id string, <span class="type">time</span> <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> click;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、点击浏览时间</span></span><br><span class="line">a <span class="number">1001</span></span><br><span class="line">a <span class="number">1005</span></span><br><span class="line">a <span class="number">1020</span></span><br><span class="line">a <span class="number">1048</span></span><br><span class="line">a <span class="number">1078</span></span><br><span class="line">a <span class="number">1230</span></span><br><span class="line">a <span class="number">1245</span></span><br><span class="line">a <span class="number">1270</span></span><br><span class="line">a <span class="number">1282</span></span><br><span class="line">b <span class="number">1101</span></span><br><span class="line">b <span class="number">1132</span></span><br><span class="line">b <span class="number">1156</span></span><br><span class="line">b <span class="number">1180</span></span><br><span class="line">b <span class="number">1200</span></span><br><span class="line">b <span class="number">1230</span></span><br><span class="line">b <span class="number">1345</span></span><br><span class="line">b <span class="number">1370</span></span><br><span class="line">b <span class="number">1400</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--查询用户在每个会话中的起始时间点、点击浏览次数、浏览时长</span></span><br><span class="line"><span class="keyword">select</span> id, <span class="built_in">min</span>(<span class="type">time</span>) <span class="keyword">as</span> start_time, <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">as</span> count, <span class="built_in">max</span>(<span class="type">time</span>) <span class="operator">-</span> <span class="built_in">min</span>(<span class="type">time</span>) <span class="keyword">as</span> total_time</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--分组排序后，从上到下计算value列的累加和。如果求和结果相同，则表示属于相同的会话</span></span><br><span class="line">    <span class="keyword">select</span> t2.id, t2.time, <span class="built_in">sum</span>(t2.value) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> stage</span><br><span class="line">    <span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--如果与前一次点击的时间之差超过30，则value列为1，否则为0</span></span><br><span class="line">        <span class="comment">--value列为1表示这次点击属于一个新的会话，为0表示这次点击与前一次属于相同的会话</span></span><br><span class="line">        <span class="keyword">select</span> id, <span class="type">time</span>, diff, <span class="keyword">case</span> <span class="keyword">when</span> nvl(diff, <span class="number">9999</span>) <span class="operator">&gt;</span> <span class="number">30</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span> <span class="keyword">value</span></span><br><span class="line">        <span class="keyword">from</span> (</span><br><span class="line">            <span class="comment">--按照用户id分组，按照点击浏览时间递增排序，计算前后两次点击的时间之差</span></span><br><span class="line">            <span class="keyword">select</span> id, <span class="type">time</span>, <span class="type">time</span> <span class="operator">-</span> <span class="built_in">lag</span>(<span class="type">time</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> <span class="type">time</span> <span class="keyword">asc</span>) <span class="keyword">as</span> diff</span><br><span class="line">            <span class="keyword">from</span> click</span><br><span class="line">        ) t1</span><br><span class="line">    ) t2</span><br><span class="line">) t3</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> id, stage;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">idstart_timecounttotal_time</span><br><span class="line">a<span class="number">1001</span><span class="number">5</span><span class="number">77</span></span><br><span class="line">a<span class="number">1230</span><span class="number">4</span><span class="number">52</span></span><br><span class="line">b<span class="number">1101</span><span class="number">1</span><span class="number">0</span></span><br><span class="line">b<span class="number">1132</span><span class="number">5</span><span class="number">98</span></span><br><span class="line">b<span class="number">1345</span><span class="number">3</span><span class="number">55</span></span><br></pre></td></tr></table></figure><h5 id="活动时长问题"><a href="#活动时长问题" class="headerlink" title="活动时长问题"></a>活动时长问题</h5><p>每个品牌具有多个打折活动，给定每个活动的开始时间、结束时间，返回每个品牌实际参与打折的天数，重复日期不计算在内</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> discount(brand <span class="type">int</span>, start_dt <span class="type">date</span>, end_dt <span class="type">date</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> discount;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：品牌id、活动开始时间、活动结束时间</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-03</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-05</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-10</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-02</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-06</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-09</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-12</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-20</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-15</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-18</span></span><br><span class="line"><span class="number">1004</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-20</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-25</span></span><br><span class="line"><span class="number">1004</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-22</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-26</span></span><br><span class="line"><span class="number">1004</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-28</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-30</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--按照品牌id分组，计算打折活动的不重复天数之和day_count</span></span><br><span class="line"><span class="keyword">select</span> brand, <span class="built_in">sum</span>(count) <span class="keyword">as</span> day_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--根据当前结束时间的最大值max_dt，计算每行打折活动可以贡献的活动天数count</span></span><br><span class="line"><span class="keyword">select</span> brand, start_dt, end_dt, max_dt,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> max_dt <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> datediff(end_dt, start_dt) <span class="operator">+</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">when</span> max_dt <span class="operator">&lt;</span> start_dt <span class="keyword">then</span> datediff(end_dt, start_dt) <span class="operator">+</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">when</span> max_dt <span class="operator">&lt;</span> end_dt <span class="keyword">then</span> datediff(end_dt, max_dt)</span><br><span class="line"><span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span> <span class="keyword">as</span> count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--按照品牌id分组，按照开始时间、结束时间递增排序，查询当前结束时间的最大值max_dt</span></span><br><span class="line"><span class="keyword">select</span> brand, start_dt, end_dt,</span><br><span class="line"><span class="built_in">max</span>(end_dt) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> brand <span class="keyword">order</span> <span class="keyword">by</span> start_dt <span class="keyword">asc</span>, end_dt <span class="keyword">asc</span> <span class="keyword">rows</span> </span><br><span class="line">                         <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="number">1</span> preceding) <span class="keyword">as</span> max_dt</span><br><span class="line"><span class="keyword">from</span> discount</span><br><span class="line">) t1</span><br><span class="line">) t2</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> brand;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">brandday_count</span><br><span class="line"><span class="number">1001</span><span class="number">9</span></span><br><span class="line"><span class="number">1002</span><span class="number">8</span></span><br><span class="line"><span class="number">1003</span><span class="number">9</span></span><br><span class="line"><span class="number">1004</span><span class="number">11</span></span><br></pre></td></tr></table></figure><h5 id="同时在线问题"><a href="#同时在线问题" class="headerlink" title="同时在线问题"></a>同时在线问题</h5><p>给定每个用户在线的开始时间、结束时间，返回一个时间段与人数，这个时间段具有最多的在线人数</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> live(id <span class="type">int</span>, start_dt <span class="type">date</span>, end_dt <span class="type">date</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> live;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、开始时间、结束时间</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-02</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-04</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-05</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-07</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-10</span></span><br><span class="line"><span class="number">1001</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-13</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-18</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-02</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-04</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-05</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-07</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-10</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-11</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-13</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-14</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-16</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-17</span></span><br><span class="line"><span class="number">1002</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-19</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-20</span></span><br><span class="line"><span class="number">1003</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-01</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-20</span></span><br><span class="line"><span class="number">1004</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-04</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1004</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-12</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-16</span></span><br><span class="line"><span class="number">1005</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-03</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-06</span></span><br><span class="line"><span class="number">1005</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-09</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-11</span></span><br><span class="line"><span class="number">1006</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-04</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-06</span></span><br><span class="line"><span class="number">1007</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-09</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-12</span></span><br><span class="line"><span class="number">1008</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-06</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1008</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-11</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-13</span></span><br><span class="line"><span class="number">1009</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-06</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="number">1009</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-18</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-19</span></span><br><span class="line"><span class="number">1010</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-11</span> <span class="number">2022</span><span class="number">-07</span><span class="number">-14</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="keyword">select</span> dt, online</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> dt, </span><br><span class="line"><span class="built_in">sum</span>(count) <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> dt <span class="keyword">asc</span>) <span class="keyword">as</span> online</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> dt, <span class="built_in">sum</span>(<span class="keyword">value</span>) <span class="keyword">as</span> count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> id, start_dt <span class="keyword">as</span> dt, <span class="number">1</span> <span class="keyword">as</span> <span class="keyword">value</span> <span class="keyword">from</span> live</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> id, date_add(end_dt, <span class="number">1</span>) <span class="keyword">as</span> dt, <span class="number">-1</span> <span class="keyword">as</span> <span class="keyword">value</span> <span class="keyword">from</span> live</span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dt</span><br><span class="line">) t2</span><br><span class="line">) t3</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> online <span class="keyword">desc</span>, dt <span class="keyword">asc</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">dtonline</span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-04</span><span class="number">6</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-06</span><span class="number">6</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-07</span><span class="number">6</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-11</span><span class="number">6</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-13</span><span class="number">6</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-10</span><span class="number">5</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-12</span><span class="number">5</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-14</span><span class="number">5</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-09</span><span class="number">4</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-16</span><span class="number">4</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-01</span><span class="number">3</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-15</span><span class="number">3</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-17</span><span class="number">3</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-18</span><span class="number">3</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-19</span><span class="number">3</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-03</span><span class="number">2</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-20</span><span class="number">2</span></span><br><span class="line"><span class="number">2022</span><span class="number">-07</span><span class="number">-21</span><span class="number">0</span></span><br></pre></td></tr></table></figure><h5 id="区间合并问题"><a href="#区间合并问题" class="headerlink" title="区间合并问题"></a>区间合并问题</h5><p>给定多个时间段，每个时间段分为开始时间、结束时间，将相互重叠的多个时间段合并为一个区间</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> time_merge(id <span class="type">int</span>, start_time <span class="type">int</span>, end_time <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> time_merge;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：id、开始时间、结束时间</span></span><br><span class="line"><span class="number">1</span> <span class="number">12</span> <span class="number">15</span></span><br><span class="line"><span class="number">2</span> <span class="number">57</span> <span class="number">58</span></span><br><span class="line"><span class="number">3</span> <span class="number">29</span> <span class="number">32</span></span><br><span class="line"><span class="number">4</span> <span class="number">30</span> <span class="number">31</span></span><br><span class="line"><span class="number">5</span> <span class="number">17</span> <span class="number">19</span></span><br><span class="line"><span class="number">6</span> <span class="number">44</span> <span class="number">44</span></span><br><span class="line"><span class="number">7</span> <span class="number">56</span> <span class="number">57</span></span><br><span class="line"><span class="number">8</span> <span class="number">16</span> <span class="number">18</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--按照区间序号进行分组，查询每个分组的最小开始时间作为区间开始时间，最大结束时间作为区间结束时间</span></span><br><span class="line"><span class="keyword">select</span> flag, <span class="built_in">min</span>(start_time) <span class="keyword">as</span> start_time, <span class="built_in">max</span>(end_time) <span class="keyword">as</span> end_time</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--判断哪些时间段属于相同区间，flag表示时间段归属的区间序号，值相同表示属于相同区间</span></span><br><span class="line"><span class="keyword">select</span> id, start_time, end_time,</span><br><span class="line"><span class="built_in">sum</span>(count) <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> start_time <span class="keyword">asc</span>, end_time <span class="keyword">asc</span>) <span class="keyword">as</span> flag</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--根据当前结束时间的最大值max_dt进行比较，标记每个时间段是否为新的区间</span></span><br><span class="line"><span class="keyword">select</span> id, start_time, end_time,</span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> max_dt <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="number">1</span> <span class="comment">--作为一个新的区间</span></span><br><span class="line"><span class="keyword">when</span> max_dt <span class="operator">&lt;</span> start_time <span class="keyword">then</span> <span class="number">1</span> <span class="comment">--作为一个新的区间</span></span><br><span class="line"><span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span> <span class="keyword">as</span> count <span class="comment">--与前面的区间具有重叠</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">            <span class="comment">--按照开始时间、结束时间递增排序，查询当前结束时间的最大值max_dt</span></span><br><span class="line"><span class="keyword">select</span> id, start_time, end_time,</span><br><span class="line"><span class="built_in">max</span>(end_time) <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> start_time <span class="keyword">asc</span>, end_time <span class="keyword">asc</span> <span class="keyword">rows</span> </span><br><span class="line">                               <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="number">1</span> preceding) <span class="keyword">as</span> max_dt</span><br><span class="line"><span class="keyword">from</span> time_merge</span><br><span class="line">) t1</span><br><span class="line">) t2</span><br><span class="line">) t3</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> flag</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">flagstart_timeend_time</span><br><span class="line"><span class="number">1</span><span class="number">12</span><span class="number">15</span></span><br><span class="line"><span class="number">2</span><span class="number">16</span><span class="number">19</span></span><br><span class="line"><span class="number">3</span><span class="number">29</span><span class="number">32</span></span><br><span class="line"><span class="number">4</span><span class="number">44</span><span class="number">44</span></span><br><span class="line"><span class="number">5</span><span class="number">56</span><span class="number">58</span></span><br></pre></td></tr></table></figure><h5 id="共同好友问题"><a href="#共同好友问题" class="headerlink" title="共同好友问题"></a>共同好友问题</h5><p>给定每个用户的好友列表，好友关系是互相对称的，返回任意两个用户的共同好友列表</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> common_friend(id string, friends string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> common_friend;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、好友id列表</span></span><br><span class="line">A B,C,D</span><br><span class="line">B A,C,E</span><br><span class="line">C A,B,D,E,F</span><br><span class="line">D A,C,F</span><br><span class="line">E B,C</span><br><span class="line">F C,D</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--创建临时表，将好友关系分解为最细粒度</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> friend <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span> id, friend <span class="keyword">from</span> common_friend <span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(friends, <span class="string">&#x27;,&#x27;</span>)) temp <span class="keyword">as</span> friend;</span><br><span class="line"></span><br><span class="line"><span class="comment">--按照用户的两两组合进行分组，将所有的共同好友放入列表</span></span><br><span class="line"><span class="keyword">select</span> t1.ids, concat_ws(<span class="string">&#x27;,&#x27;</span>, collect_list(t1.friend)) <span class="keyword">as</span> common_friend</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--将好友关系表与自身进行连接，查询每个用户是哪两个用户的共同好友</span></span><br><span class="line"><span class="keyword">select</span> a.friend, concat(a.id, <span class="string">&#x27;,&#x27;</span>, b.id) <span class="keyword">as</span> ids</span><br><span class="line"><span class="keyword">from</span> friend a</span><br><span class="line"><span class="keyword">join</span> friend b</span><br><span class="line"><span class="keyword">on</span> a.friend <span class="operator">=</span> b.friend <span class="comment">--按照共同好友进行连接</span></span><br><span class="line"><span class="keyword">where</span> a.id <span class="operator">&lt;</span> b.id <span class="comment">--筛选出重复记录</span></span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t1.ids</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t1.idscommon_friend</span><br><span class="line">A,BC</span><br><span class="line">A,CB,D</span><br><span class="line">A,DC</span><br><span class="line">A,EB,C</span><br><span class="line">A,FC,D</span><br><span class="line">B,CA,E</span><br><span class="line">B,DA,C</span><br><span class="line">B,EC</span><br><span class="line">B,FC</span><br><span class="line">C,DA,F</span><br><span class="line">C,EB</span><br><span class="line">C,FD</span><br><span class="line">D,EC</span><br><span class="line">D,FC</span><br><span class="line">E,FC</span><br></pre></td></tr></table></figure><h5 id="可能好友问题"><a href="#可能好友问题" class="headerlink" title="可能好友问题"></a>可能好友问题</h5><p>给定每个用户的好友列表，好友关系是互相对称的，返回每个用户的可能好友。如果两个用户不是好友关系，并且两者拥有至少一个（或者两个）共同好友，则两者互相是可能好友</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> maybe_friend(id string, friends string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> maybe_friend;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、好友id列表</span></span><br><span class="line">A B,C,D</span><br><span class="line">B A,C,E</span><br><span class="line">C A,B,D,E,F</span><br><span class="line">D A,C,F</span><br><span class="line">E B,C</span><br><span class="line">F C,D</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--创建临时表，将好友关系分解为最细粒度</span></span><br><span class="line"><span class="keyword">with</span> friend <span class="keyword">as</span> (</span><br><span class="line"><span class="keyword">select</span> id, friend <span class="keyword">from</span> common_friend <span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(friends, <span class="string">&#x27;,&#x27;</span>)) temp <span class="keyword">as</span> friend)</span><br><span class="line"></span><br><span class="line"><span class="comment">--将具有至少两个共同好友的临时表与好友关系表进行连接，如果临时表的两个用户是好友关系，则在好友关系表中存在对应记录，否则不存在对应记录，</span></span><br><span class="line"><span class="comment">--表示两者是可能好友</span></span><br><span class="line"><span class="keyword">select</span> t2.id1, t2.id2</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--查询具有至少两个共同好友的任意两个用户</span></span><br><span class="line"><span class="keyword">select</span> t1.id1, t1.id2</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--将好友关系表与自身进行连接，查询任意两个用户具有的共同好友</span></span><br><span class="line"><span class="keyword">select</span> a.id <span class="keyword">as</span> id1, b.id <span class="keyword">as</span> id2, a.friend</span><br><span class="line"><span class="keyword">from</span> friend a</span><br><span class="line"><span class="keyword">join</span> friend b</span><br><span class="line"><span class="keyword">on</span> a.friend <span class="operator">=</span> b.friend</span><br><span class="line"><span class="keyword">where</span> a.id <span class="operator">&lt;</span> b.id</span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t1.id1, t1.id2</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">count</span>(t1.friend) <span class="operator">&gt;=</span> <span class="number">2</span></span><br><span class="line">) t2</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> friend</span><br><span class="line"><span class="keyword">on</span> t2.id1 <span class="operator">=</span> friend.id</span><br><span class="line"><span class="keyword">and</span> t2.id2 <span class="operator">=</span> friend.friend</span><br><span class="line"><span class="keyword">where</span> friend.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="comment">--排除真实好友，筛选可能好友</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">t2.id1t2.id2</span><br><span class="line">AE</span><br><span class="line">AF</span><br><span class="line">BD</span><br></pre></td></tr></table></figure><h5 id="推荐商品问题"><a href="#推荐商品问题" class="headerlink" title="推荐商品问题"></a>推荐商品问题</h5><p>给定一个用户购买一次商品的记录，返回每个用户可能想要购买的商品。如果其余用户与这个用户购买至少两个相同的商品，则其余用户购买、这个用户没有购买的商品，就是这个用户可能想要购买的商品</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> shop(id string, product <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> shop;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、商品id</span></span><br><span class="line">A <span class="number">1</span></span><br><span class="line">A <span class="number">2</span></span><br><span class="line">A <span class="number">1</span></span><br><span class="line">A <span class="number">3</span></span><br><span class="line">B <span class="number">2</span></span><br><span class="line">B <span class="number">3</span></span><br><span class="line">B <span class="number">4</span></span><br><span class="line">B <span class="number">5</span></span><br><span class="line">B <span class="number">2</span></span><br><span class="line">C <span class="number">1</span></span><br><span class="line">C <span class="number">2</span></span><br><span class="line">C <span class="number">1</span></span><br><span class="line">D <span class="number">1</span></span><br><span class="line">D <span class="number">3</span></span><br><span class="line">D <span class="number">6</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--sql语句</span></span><br><span class="line"><span class="comment">--按照用户、商品进行分组、去重</span></span><br><span class="line"><span class="keyword">with</span> temp <span class="keyword">as</span> (</span><br><span class="line"><span class="keyword">select</span> id, product <span class="keyword">from</span> shop <span class="keyword">group</span> <span class="keyword">by</span> id, product)</span><br><span class="line"></span><br><span class="line"><span class="comment">--将已购买与推荐购买的临时表与已购买表进行连接，如果临时表的商品已购买，则在已购买表中存在对应记录，否则不存在对应记录，表示推荐商品</span></span><br><span class="line"><span class="keyword">select</span> t4.id1 <span class="keyword">as</span> id, t4.product</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="comment">--查询每个用户已购买与推荐购买的商品</span></span><br><span class="line"><span class="keyword">select</span> t3.id1, t3.product</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">        <span class="comment">--查询每个用户、以及具有相同购买倾向的其余用户、其余用户已购买的商品</span></span><br><span class="line"><span class="keyword">select</span> t2.id1, t2.id2, temp.product</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">            <span class="comment">--查询已购买至少两个相同商品的任意两个用户</span></span><br><span class="line"><span class="keyword">select</span> t1.id1, t1.id2</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">                <span class="comment">--查询已购买相同商品的任意两个用户</span></span><br><span class="line"><span class="keyword">select</span> a.id <span class="keyword">as</span> id1, b.id <span class="keyword">as</span> id2, a.product</span><br><span class="line"><span class="keyword">from</span> temp a</span><br><span class="line"><span class="keyword">join</span> temp b</span><br><span class="line"><span class="keyword">on</span> a.product <span class="operator">=</span> b.product</span><br><span class="line"><span class="keyword">and</span> a.id <span class="operator">!=</span> b.id </span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t1.id1, t1.id2</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">count</span>(t1.product) <span class="operator">&gt;=</span> <span class="number">2</span></span><br><span class="line">) t2</span><br><span class="line"><span class="keyword">join</span> temp</span><br><span class="line"><span class="keyword">on</span> t2.id2 <span class="operator">=</span> temp.id</span><br><span class="line">) t3</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t3.id1, t3.product</span><br><span class="line">) t4</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> temp</span><br><span class="line"><span class="keyword">on</span> t4.product <span class="operator">=</span> temp.product</span><br><span class="line"><span class="keyword">and</span> t4.id1 <span class="operator">=</span> temp.id <span class="comment">--相同用户购买相同商品</span></span><br><span class="line"><span class="keyword">where</span> temp.product <span class="keyword">is</span> <span class="keyword">null</span> <span class="comment">--排除已购买商品，筛选推荐商品</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--结果</span></span><br><span class="line">idt4.product</span><br><span class="line">A<span class="number">4</span></span><br><span class="line">A<span class="number">5</span></span><br><span class="line">A<span class="number">6</span></span><br><span class="line">B<span class="number">1</span></span><br><span class="line">C<span class="number">3</span></span><br><span class="line">D<span class="number">2</span></span><br></pre></td></tr></table></figure><h5 id="登录行为分析"><a href="#登录行为分析" class="headerlink" title="登录行为分析"></a>登录行为分析</h5><p>有关的统计指标包含：访问量、活跃用户、新增用户、留存用户、流失用户、沉默用户、回流用户</p><p>含义解释：（1）活跃用户，每日登录应用的用户，（2）新增用户，在当前日期第一次登录应用的用户，（3）留存用户，在当前日期登录应用的用户，并且在之前日期登录过应用，（4）流失用户，指定时间内没有登录应用的用户，（5）沉默用户，只有第一次登录应用的用户，之后没有登录过应用，（6）回流用户，在当前日期登录应用的用户，并且在之前的指定时间内没有登录过应用</p><p>角色分配：活跃、新增 a、留存 b、留存 c、流失 d、沉默 e、回流 f</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--建表语句</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> login_action(uid string, login_date <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27; &#x27;</span>;</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/temp/sql.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> login_action;</span><br><span class="line"></span><br><span class="line"><span class="comment">--数据：用户id、登录日期</span></span><br><span class="line">d <span class="number">20220321</span></span><br><span class="line">e <span class="number">20220321</span></span><br><span class="line">f <span class="number">20220321</span></span><br><span class="line"></span><br><span class="line">a <span class="number">20220322</span></span><br><span class="line">b <span class="number">20220322</span></span><br><span class="line">d <span class="number">20220322</span></span><br><span class="line"></span><br><span class="line">a <span class="number">20220323</span></span><br><span class="line">b <span class="number">20220323</span></span><br><span class="line">c <span class="number">20220323</span></span><br><span class="line"></span><br><span class="line">a <span class="number">20220324</span></span><br><span class="line">b <span class="number">20220324</span></span><br><span class="line">c <span class="number">20220324</span></span><br><span class="line"></span><br><span class="line">a <span class="number">20220325</span></span><br><span class="line">b <span class="number">20220325</span></span><br><span class="line">c <span class="number">20220325</span></span><br><span class="line">f <span class="number">20220325</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--活跃用户：</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--新增用户：需要一张全量的用户表，一张某日的登录行为表</span></span><br><span class="line"><span class="comment">--将日期20220321的登录用户作为初始表，表示已知的用户，然后查询日期20220322的新增用户</span></span><br><span class="line"><span class="comment">--登录行为表与全量用户表进行关联，行为表中存在、用户表中不存在的记录表示这个日期的新增用户</span></span><br><span class="line"><span class="comment">--查询出每个日期的新增用户后，需要追加到全量的用户表中</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--全量的用户表：表示用户成为新增用户的日期</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> user_add(uid string, add_date <span class="type">int</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> user_add (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> login_action <span class="keyword">where</span> login_date <span class="operator">=</span> <span class="number">20220321</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> t1.uid, t1.login_date</span><br><span class="line"><span class="keyword">from</span> login_action t1</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> user_add t2</span><br><span class="line"><span class="keyword">on</span> t1.uid <span class="operator">=</span> t2.uid</span><br><span class="line"><span class="keyword">where</span> t1.login_date <span class="operator">=</span> <span class="number">20220322</span> <span class="comment">--查询日期20220322的新增用户</span></span><br><span class="line"><span class="keyword">and</span> t2.uid <span class="keyword">is</span> <span class="keyword">null</span> <span class="comment">--查询在用户表中不存在的记录，即这个日期的新增用户</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--20220322的新增用户</span></span><br><span class="line">t1.uidt1.add_date</span><br><span class="line">a<span class="number">20220322</span></span><br><span class="line">b<span class="number">20220322</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--所有日期的新增用户</span></span><br><span class="line">user_add.uiduser_add.add_date</span><br><span class="line">d<span class="number">20220321</span></span><br><span class="line">e<span class="number">20220321</span></span><br><span class="line">f<span class="number">20220321</span></span><br><span class="line">a<span class="number">20220322</span></span><br><span class="line">b<span class="number">20220322</span></span><br><span class="line">c<span class="number">20220323</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--留存用户：需要一张全量的用户表，一张某日的登录行为表</span></span><br><span class="line"><span class="comment">--登录行为表与全量用户表进行关联，行为表中的登录日期与用户表中的登录日期之差为1天，表示1日的留存用户</span></span><br><span class="line"><span class="comment">--使用union all合并1日、2日的留存用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> t1.uid, t1.login_date, t2.add_date</span><br><span class="line"><span class="keyword">from</span> login_action t1</span><br><span class="line"><span class="keyword">join</span> user_add t2</span><br><span class="line"><span class="keyword">on</span> t1.uid <span class="operator">=</span> t2.uid</span><br><span class="line"><span class="keyword">where</span> t1.login_date <span class="operator">=</span> <span class="number">20220324</span> <span class="comment">--查询日期20220324的留存用户</span></span><br><span class="line"><span class="keyword">and</span> t2.add_date <span class="operator">=</span> (<span class="number">20220324</span> <span class="operator">-</span> <span class="number">1</span>) <span class="comment">--查询1日留存用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span> <span class="comment">--合并1日、2日留存用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> t1.uid, t1.login_date, t2.add_date</span><br><span class="line"><span class="keyword">from</span> login_action t1</span><br><span class="line"><span class="keyword">join</span> user_add t2</span><br><span class="line"><span class="keyword">on</span> t1.uid <span class="operator">=</span> t2.uid</span><br><span class="line"><span class="keyword">where</span> t1.login_date <span class="operator">=</span> <span class="number">20220324</span> <span class="comment">--查询日期20220324的留存用户</span></span><br><span class="line"><span class="keyword">and</span> t2.add_date <span class="operator">=</span> (<span class="number">20220324</span> <span class="operator">-</span> <span class="number">2</span>) <span class="comment">--查询2日留存用户</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--20220324的留存用户：1日、2日</span></span><br><span class="line">_u1.uid_u1.login_date_u1.add_date</span><br><span class="line">c<span class="number">20220324</span><span class="number">20220323</span></span><br><span class="line">b<span class="number">20220324</span><span class="number">20220322</span></span><br><span class="line">a<span class="number">20220324</span><span class="number">20220322</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--流失用户：需要一张全量的登录行为表</span></span><br><span class="line"><span class="comment">--查询每个用户的登录日期的最大值，与当前日期之差超过2日，表示流失用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> uid, <span class="built_in">max</span>(login_date) <span class="keyword">as</span> last_login</span><br><span class="line"><span class="keyword">from</span> login_action</span><br><span class="line"><span class="keyword">where</span> login_date <span class="operator">&lt;=</span> <span class="number">20220325</span> <span class="comment">--查询日期20220325的流失用户</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> uid</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">max</span>(login_date) <span class="operator">&lt;</span> (<span class="number">20220325</span> <span class="operator">-</span> <span class="number">2</span>) <span class="comment">--超过2日表示流失用户</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--20220325的流失用户</span></span><br><span class="line">uidlast_login</span><br><span class="line">d<span class="number">20220322</span></span><br><span class="line">e<span class="number">20220321</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--沉默用户：需要一张全量的登录行为表</span></span><br><span class="line"><span class="comment">--查询每个用户的登录日期的数量，只有一次登录操作，表示沉默用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> uid, <span class="built_in">max</span>(login_date) <span class="keyword">as</span> once_login</span><br><span class="line"><span class="keyword">from</span> login_action</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> uid</span><br><span class="line"><span class="keyword">having</span> <span class="built_in">count</span>(login_date) <span class="operator">=</span> <span class="number">1</span> <span class="comment">--只有一次登录操作的用户表示沉默用户</span></span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--20220325的沉默用户</span></span><br><span class="line">uidonce_login</span><br><span class="line">e<span class="number">20220321</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--回流用户：需要一张全量的登录行为表</span></span><br><span class="line"><span class="comment">--日期20220325的活跃用户，如果在之前的日期为流失用户，则在日期20220325为回流用户</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> t1.uid, t1.login_date, t2.last_login</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> uid, login_date</span><br><span class="line">    <span class="keyword">from</span> login_action</span><br><span class="line">    <span class="keyword">where</span> login_date <span class="operator">=</span> <span class="number">20220325</span> <span class="comment">--查询20220325的活跃用户</span></span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">join</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">select</span> uid, <span class="built_in">max</span>(login_date) <span class="keyword">as</span> last_login</span><br><span class="line">    <span class="keyword">from</span> login_action</span><br><span class="line">    <span class="keyword">where</span> login_date <span class="operator">&lt;</span> <span class="number">20220325</span> <span class="comment">--查询20220325之前的流失用户</span></span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> uid</span><br><span class="line">    <span class="keyword">having</span> <span class="built_in">max</span>(login_date) <span class="operator">&lt;</span> (<span class="number">20220325</span> <span class="operator">-</span> <span class="number">2</span>)</span><br><span class="line">) t2</span><br><span class="line"><span class="keyword">on</span> t1.uid <span class="operator">=</span> t2.uid</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line"><span class="comment">--20220325的h用户</span></span><br><span class="line">t1.uidt1.login_datet2.last_login</span><br><span class="line">f<span class="number">20220325</span><span class="number">20220321</span></span><br></pre></td></tr></table></figure><h5 id="购买行为分析"><a href="#购买行为分析" class="headerlink" title="购买行为分析"></a>购买行为分析</h5><p>有关的统计指标包含：点击量、下单数、支付数</p><h5 id="点击行为分析"><a href="#点击行为分析" class="headerlink" title="点击行为分析"></a>点击行为分析</h5><p><strong>JSON解析</strong></p><p>解析嵌套Json字符串</p><p>get_json_object()方法</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>DolphinScheduler搭建</title>
      <link href="/2022/08/02/DolphinScheduler%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/08/02/DolphinScheduler%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="DolphinScheduler搭建"><a href="#DolphinScheduler搭建" class="headerlink" title="DolphinScheduler搭建"></a>DolphinScheduler搭建</h2><h4 id="1-上传解压"><a href="#1-上传解压" class="headerlink" title="1 上传解压"></a>1 上传解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf DolphinScheduler-bin.tar.</span><br></pre></td></tr></table></figure><h4 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2 修改配置文件"></a>2 修改配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd conf</span><br></pre></td></tr></table></figure><h5 id="2-1-修改mysql链接配置"><a href="#2-1-修改mysql链接配置" class="headerlink" title="2.1 修改mysql链接配置"></a>2.1 修改mysql链接配置</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim datasource.properties</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改一下配置</span></span><br><span class="line">spring.datasource.driver-class-name=com.mysql.jdbc.Driver</span><br><span class="line">spring.datasource.url=jdbc:mysql://node1:3306/dolphinscheduler?characterEncoding=UTF-8&amp;allowMultiQueries=<span class="literal">true</span></span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=123456</span><br></pre></td></tr></table></figure><h5 id="2-2-修改安装配置"><a href="#2-2-修改安装配置" class="headerlink" title="2.2 修改安装配置"></a>2.2 修改安装配置</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim config/install_config.conf</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql地址</span></span><br><span class="line">dbhost=<span class="string">&quot;master:3306&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql用户名</span></span><br><span class="line">username=<span class="string">&quot;root&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据库名</span></span><br><span class="line">dbname=<span class="string">&quot;dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mysql密码</span></span><br><span class="line">password=<span class="string">&quot;123456&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper链接地址</span></span><br><span class="line">zkQuorum=<span class="string">&quot;master:2181&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dolphinscheduler安装路径</span></span><br><span class="line">installPath=<span class="string">&quot;/usr/local/soft/dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装用户</span></span><br><span class="line">deployUser=<span class="string">&quot;root&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置邮箱服务器，需要开启邮箱smtp服务</span></span><br><span class="line">mailServerHost=<span class="string">&quot;smtp.163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 端口号</span></span><br><span class="line">mailServerPort=<span class="string">&quot;25&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 邮箱地址</span></span><br><span class="line">mailSender=<span class="string">&quot;mllib_fiy@163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户名和邮箱地址一致</span></span><br><span class="line">mailUser=<span class="string">&quot;mllib_fiy@163.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 邮箱密码</span></span><br><span class="line">mailPassword=<span class="string">&quot;PQUFLTJBDEASRRSX&quot;</span></span><br><span class="line"></span><br><span class="line">starttlsEnable=<span class="string">&quot;false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hdfs访问地址</span></span><br><span class="line">defaultFS=<span class="string">&quot;hdfs://master:9000&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dolphinscheduler上传到hdfs路径</span></span><br><span class="line">resourceUploadPath=<span class="string">&quot;/dolphinscheduler&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传文件使用的用户名</span></span><br><span class="line">hdfsRootUser=<span class="string">&quot;root&quot;</span></span><br></pre></td></tr></table></figure><h5 id="2-3-修改环境变量"><a href="#2-3-修改环境变量" class="headerlink" title="2.3 修改环境变量"></a>2.3 修改环境变量</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim env/dolphinscheduler_env.sh</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/local/soft/hadoop-2.7.6/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME2=/usr/local/soft/spark-2.4.5</span><br><span class="line"><span class="built_in">export</span> DATAX_HOME=/usr/local/soft/datax/bin/datax.py</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$SPARK_HOME2</span>/bin:<span class="variable">$PYTHON_HOME</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span>:<span class="variable">$FLINK_HOME</span>/bin:<span class="variable">$DATAX_HOME</span>:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h4 id="3-初始化数据库"><a href="#3-初始化数据库" class="headerlink" title="3 初始化数据库"></a>3 初始化数据库</h4><h5 id="3-1-进入mysql创建dolphinscheduler数据库"><a href="#3-1-进入mysql创建dolphinscheduler数据库" class="headerlink" title="3.1 进入mysql创建dolphinscheduler数据库"></a>3.1 进入mysql创建dolphinscheduler数据库</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p123456</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE dolphinscheduler <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br></pre></td></tr></table></figure><h5 id="3-2-执行脚本创建表"><a href="#3-2-执行脚本创建表" class="headerlink" title="3.2 执行脚本创建表"></a>3.2 执行脚本创建表</h5><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/soft/DolphinScheduler-bin/script</span><br><span class="line">sh create-dolphinscheduler.sh</span><br></pre></td></tr></table></figure><h5 id="3-3-启动zk-如果是多节点，每一节点中都需要启动"><a href="#3-3-启动zk-如果是多节点，每一节点中都需要启动" class="headerlink" title="3.3 启动zk  如果是多节点，每一节点中都需要启动"></a>3.3 启动zk  如果是多节点，每一节点中都需要启动</h5><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><h4 id="4-一键部署"><a href="#4-一键部署" class="headerlink" title="4 一键部署"></a>4 一键部署</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sh install.sh</span><br></pre></td></tr></table></figure><p>安装好之后可以到&#x2F;usr&#x2F;local&#x2F;soft&#x2F;dolphinscheduler&#x2F;log查看日志</p><h4 id="5-访问dolphinscheduler"><a href="#5-访问dolphinscheduler" class="headerlink" title="5 访问dolphinscheduler"></a>5 访问dolphinscheduler</h4><p>用户名：admin ， 密码：dolphinscheduler123</p><p><a href="http://192.168.129.201:12345/dolphinscheduler">http://192.168.129.201:12345/dolphinscheduler</a></p><h4 id="6-使用dolphinscheduler"><a href="#6-使用dolphinscheduler" class="headerlink" title="6 使用dolphinscheduler"></a>6 使用dolphinscheduler</h4><p>1 创建root租户–用于执行脚本的用户（权限）<br>2 将租户赋权给admin用户<br>3 创建项目<br>4 创建流程</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DolphinScheduler </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark参数优化</title>
      <link href="/2022/07/31/spark%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
      <url>/2022/07/31/spark%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h3 id="spark参数优化"><a href="#spark参数优化" class="headerlink" title="spark参数优化"></a>spark参数优化</h3><h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">--num-executors<span class="comment"># executor的数量</span></span><br><span class="line">--executor-memory<span class="comment"># 每一个executor的内存</span></span><br><span class="line">--executor-cores<span class="comment"># 每一个executor的核心数</span></span><br><span class="line">--driver-memory<span class="comment"># Driver的内存1G-2G(保存广播变量)</span></span><br><span class="line">--spark.storage.memoryFraction<span class="comment"># 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle</span></span><br><span class="line">--spark.shuffle.memoryFraction<span class="comment"># 用户shuffle的内存占比默认0.2</span></span><br></pre></td></tr></table></figure><p>总的内存&#x3D;num-executors<em>executor-memory<br>总的核数&#x3D;num-executors</em>executor-cores</p><h4 id="spark-on-yarn-资源设置标准"><a href="#spark-on-yarn-资源设置标准" class="headerlink" title="spark on yarn 资源设置标准"></a>spark on yarn 资源设置标准</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、单个任务总的内存和总的核数一般做多在yarn总资源的1/3到1/2之间</span><br><span class="line">比如公司集群有10太服务器</span><br><span class="line">单台服务器内存是128G,核数是40</span><br><span class="line">yarn总的内存=10*128G=1280G*0.8=960G   需要预留一般分内存给系统进程</span><br><span class="line">yarn总的核数=40*10=400</span><br><span class="line"></span><br><span class="line">提交单个spark任务资源上线</span><br><span class="line">总的内存=960G *(1/3| 1/2) = 300G-500G</span><br><span class="line">总的核数=400 * (1/3| 1/2) = 120 - 200</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2 在上线内再按照需要处理的数据量来合理指定资源，最理想的情况是一个task对应一个core</span><br><span class="line"></span><br><span class="line">2.1 数据量比较小 比如10G</span><br><span class="line">10G = 80个block = rdd80分区 = 80个task</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最理想资源指定,剩余资源充足</span></span><br><span class="line">--num-executors=40</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"><span class="comment"># 资源里面最优的方式,剩余资源不是很充足时</span></span><br><span class="line">--num-executors=20</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"></span><br><span class="line">2.2 数据量比较大时 比如80G</span><br><span class="line">80G = 640block = 640分区 = 640task</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最理想资源指定,剩余资源充足, 如果剩余资源不够，还需要减少指定的资源</span></span><br><span class="line">--num-executors=100</span><br><span class="line">--executor-memory=4G</span><br><span class="line">--executor-cores=2</span><br><span class="line"></span><br><span class="line">--spark.locality.wait: spark task<span class="comment"># 再executor中执行前的等待时间 默认3秒</span></span><br><span class="line">--spark.yarn.executor.memoryOverhead<span class="comment"># 堆外内存 默认等于堆内存的10%</span></span><br><span class="line">--spark.network.timeout<span class="comment"># spark网络链接的超时时间 默认120s</span></span><br></pre></td></tr></table></figure><h4 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">spark-submit </span><br><span class="line">--master yarn-cluster</span><br><span class="line">--num-executors = 50</span><br><span class="line">--executor-memory = 4G</span><br><span class="line">--executor-cores = 2</span><br><span class="line">--driver-memory = 2G</span><br><span class="line">--conf spark.storage.memoryFraction=0.4</span><br><span class="line">--conf spark.shuffle.memoryFraction=0.4</span><br><span class="line">--conf spark.locality.wait=10s</span><br><span class="line">--conf spark.shuffle.file.buffer=64kb</span><br><span class="line">--conf spark.yarn.executor.memoryOverhead=1024</span><br><span class="line">--conf spark.network.timeout=200s</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka代码</title>
      <link href="/2022/07/25/kafka%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/07/25/kafka%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h4 id="1、kafkaProducer"><a href="#1、kafkaProducer" class="headerlink" title="1、kafkaProducer"></a>1、kafkaProducer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1kafkaProducer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、向kafka中生产数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;test_topic2&quot;</span>, <span class="string">&quot;java&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//发送数据到kafka中</span></span><br><span class="line">    producer.send(record)</span><br><span class="line">    producer.flush()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、KafkaConsumer"><a href="#2、KafkaConsumer" class="headerlink" title="2、KafkaConsumer"></a>2、KafkaConsumer</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.&#123;<span class="type">ConsumerRecord</span>, <span class="type">ConsumerRecords</span>, <span class="type">KafkaConsumer</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"><span class="keyword">import</span> java.&#123;lang, util&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3KafkaConsumer</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建消费者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key 和value 反序列化的类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * earliest</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费</span></span><br><span class="line"><span class="comment">     * latest  默认</span></span><br><span class="line"><span class="comment">     * 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产认值生的该分区下的数据</span></span><br><span class="line"><span class="comment">     * none</span></span><br><span class="line"><span class="comment">     * topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    properties.setProperty(<span class="string">&quot;auto.offset.reset&quot;</span>, <span class="string">&quot;earliest&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者组</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;asdasd&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> consumer = <span class="keyword">new</span> <span class="type">KafkaConsumer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、订阅一个topic,可以一次订阅多个topic</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    topics.add(<span class="string">&quot;student&quot;</span>)</span><br><span class="line">    consumer.subscribe(topics)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      println(<span class="string">&quot;正在消费&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 消费数据, 需要这一个超时时间</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">val</span> consumerRecords: <span class="type">ConsumerRecords</span>[<span class="type">String</span>, <span class="type">String</span>] = consumer</span><br><span class="line">        .poll(<span class="type">Duration</span>.ofSeconds(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//解析数据</span></span><br><span class="line">      <span class="keyword">val</span> records: lang.<span class="type">Iterable</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = consumerRecords</span><br><span class="line">        .records(<span class="string">&quot;student&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> iterRecord: util.<span class="type">Iterator</span>[<span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>]] = records.iterator()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (iterRecord.hasNext) &#123;</span><br><span class="line">        <span class="comment">//获取一行数据</span></span><br><span class="line">        <span class="keyword">val</span> record: <span class="type">ConsumerRecord</span>[<span class="type">String</span>, <span class="type">String</span>] = iterRecord.next()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> topic: <span class="type">String</span> = record.topic() <span class="comment">//topic</span></span><br><span class="line">        <span class="keyword">val</span> offset: <span class="type">Long</span> = record.offset() <span class="comment">//数据偏移量</span></span><br><span class="line">        <span class="keyword">val</span> key: <span class="type">String</span> = record.key() <span class="comment">//数据的key ,默认没有指定的情况下时null</span></span><br><span class="line">        <span class="keyword">val</span> value: <span class="type">String</span> = record.value() <span class="comment">//保存的数据</span></span><br><span class="line">        <span class="keyword">val</span> ts: <span class="type">Long</span> = record.timestamp() <span class="comment">//时间戳，默认时存入的时间</span></span><br><span class="line"></span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$topic</span>\t<span class="subst">$offset</span>\t<span class="subst">$key</span>\t<span class="subst">$value</span>\t<span class="subst">$ts</span>&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关闭链接</span></span><br><span class="line">    consumer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、StudnetToKafka"><a href="#3、StudnetToKafka" class="headerlink" title="3、StudnetToKafka"></a>3、StudnetToKafka</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.&#123;<span class="type">KafkaProducer</span>, <span class="type">ProducerRecord</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2StudnetToKafka</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建生产者</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> properties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//指定kafka broker地址</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;master:9092,node2:9092,node2:9092&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置key 和value的序列化类</span></span><br><span class="line">    properties.setProperty(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line">    properties.setProperty(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>[<span class="type">String</span>, <span class="type">String</span>](properties)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取学生表将数据批量写入kafka中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (student &lt;- studentList) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">&quot;student&quot;</span>, student)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//发送数据到kafka中</span></span><br><span class="line">      producer.send(record)</span><br><span class="line">      producer.flush()</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    producer.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、统计车流量-练习"><a href="#4、统计车流量-练习" class="headerlink" title="4、统计车流量-练习"></a>4、统计车流量-练习</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.&#123;<span class="type">SerializableTimestampAssigner</span>, <span class="type">WatermarkStrategy</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.<span class="type">SimpleStringSchema</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.<span class="type">KafkaSource</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.kafka.source.enumerator.initializer.<span class="type">OffsetsInitializer</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.&#123;<span class="type">RichSinkFunction</span>, <span class="type">SinkFunction</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingEventTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>&#125;</span><br><span class="line"><span class="keyword">import</span> java.time.<span class="type">Duration</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Cars</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    env.setParallelism(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、从kafka中读取卡口过车数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">KafkaSource</span>[<span class="type">String</span>] = <span class="type">KafkaSource</span></span><br><span class="line">      .builder[<span class="type">String</span>]</span><br><span class="line">      .setBootstrapServers(<span class="string">&quot;master:9092,node1:9092,node2:9092&quot;</span>) <span class="comment">//kafka集群broker列表</span></span><br><span class="line">      .setTopics(<span class="string">&quot;cars&quot;</span>) <span class="comment">//指定topic</span></span><br><span class="line">      .setGroupId(<span class="string">&quot;asdasdasd&quot;</span>) <span class="comment">//指定消费者组，一条数据在一个组内只被消费一次</span></span><br><span class="line">      .setStartingOffsets(<span class="type">OffsetsInitializer</span>.latest()) <span class="comment">//读取数据的位置，earliest：读取所有的数据，latest：读取最新的数据</span></span><br><span class="line">      .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="type">SimpleStringSchema</span>()) <span class="comment">//反序列的类</span></span><br><span class="line">      .build</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用kafka source</span></span><br><span class="line">    <span class="keyword">val</span> carsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.fromSource(source, <span class="type">WatermarkStrategy</span>.noWatermarks(), <span class="string">&quot;Kafka Source&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式数据，将卡口编号和时间字段取出来</span></span><br><span class="line"><span class="comment">     * fastJson</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> cardAndTimeDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = carsDS.map(line =&gt; &#123;</span><br><span class="line">      <span class="comment">//将字符串转换成json对象</span></span><br><span class="line">      <span class="keyword">val</span> jsonObj: <span class="type">JSONObject</span> = <span class="type">JSON</span>.parseObject(line)</span><br><span class="line">      <span class="comment">//使用字段名获取字段值</span></span><br><span class="line">      <span class="comment">//卡口编号</span></span><br><span class="line">      <span class="keyword">val</span> card: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;card&quot;</span>)</span><br><span class="line">      <span class="comment">//事件时间，事件时间要求时毫秒级别</span></span><br><span class="line">      <span class="keyword">val</span> time: <span class="type">Long</span> = jsonObj.getLong(<span class="string">&quot;time&quot;</span>) * <span class="number">1000</span></span><br><span class="line">      (card, time)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 设置时间字段和水位线</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> assDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] = cardAndTimeDS.assignTimestampsAndWatermarks(</span><br><span class="line">      <span class="type">WatermarkStrategy</span></span><br><span class="line">        <span class="comment">//设置水位线的生成策略，前移5秒</span></span><br><span class="line">        .forBoundedOutOfOrderness(<span class="type">Duration</span>.ofSeconds(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">//设置时间字段</span></span><br><span class="line">        .withTimestampAssigner(<span class="keyword">new</span> <span class="type">SerializableTimestampAssigner</span>[(<span class="type">Long</span>, <span class="type">Long</span>)] &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTimestamp</span></span>(element: (<span class="type">Long</span>, <span class="type">Long</span>), recordTimestamp: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">            <span class="comment">//时间字段</span></span><br><span class="line">            element._2</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计车流量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = assDS.map(kv =&gt; (kv._1, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照卡口分组</span></span><br><span class="line">    <span class="keyword">val</span> keyBYDS: <span class="type">KeyedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>] = kvDS.keyBy(_._1)</span><br><span class="line">    <span class="comment">//开窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>), <span class="type">Long</span>, <span class="type">TimeWindow</span>] = keyBYDS</span><br><span class="line">      .window(<span class="type">SlidingEventTimeWindows</span>.of(<span class="type">Time</span>.minutes(<span class="number">15</span>), <span class="type">Time</span>.minutes(<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//统计车流量</span></span><br><span class="line">    <span class="keyword">val</span> flowDS: <span class="type">DataStream</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将统计的结果保存到mysql中</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    flowDS.addSink(<span class="keyword">new</span> <span class="type">RichSinkFunction</span>[(<span class="type">Long</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">//插入数据</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">invoke</span></span>(value: (<span class="type">Long</span>, <span class="type">Int</span>), context: <span class="type">SinkFunction</span>.<span class="type">Context</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;数据写入mysql&quot;</span>)</span><br><span class="line">        stat.setLong(<span class="number">1</span>, value._1)</span><br><span class="line">        stat.setInt(<span class="number">2</span>, value._2)</span><br><span class="line"></span><br><span class="line">        stat.execute()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> con: <span class="type">Connection</span> = _</span><br><span class="line">      <span class="keyword">var</span> stat: <span class="type">PreparedStatement</span> = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//创建链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">//1、加载驱动</span></span><br><span class="line">        <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">        <span class="comment">//创建链接</span></span><br><span class="line">        con = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master:3306/bigdata&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">        <span class="comment">//编写插入数据的sql</span></span><br><span class="line">        <span class="comment">//replace :如果不存在插入，如果存在就替换，需要在表中设置主键</span></span><br><span class="line">        stat = con.prepareStatement(<span class="string">&quot;replace into card_flow(card,flow) values(?,?)&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//关闭链接</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        stat.close()</span><br><span class="line">        con.close()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka搭建</title>
      <link href="/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/07/25/Kafka%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="搭建Kafka"><a href="#搭建Kafka" class="headerlink" title="搭建Kafka"></a>搭建Kafka</h2><h3 id="1、上传解压修改环境变量"><a href="#1、上传解压修改环境变量" class="headerlink" title="1、上传解压修改环境变量"></a>1、上传解压修改环境变量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压</span></span><br><span class="line">tar -xvf kafka_2.11-1.0.0.tgz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">export KAFKA_HOME=/usr/local/soft/kafka_2.11-1.0.0</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、修改配置文件"><a href="#2、修改配置文件" class="headerlink" title="2、修改配置文件"></a>2、修改配置文件</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">broker.id</span>=<span class="string">0 每一个节点broker.id 要不一样</span></span><br><span class="line"><span class="attr">zookeeper.connect</span>=<span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="attr">log.dirs</span>=<span class="string">/usr/local/soft/kafka_2.11-1.0.0/data   数据存放的位置</span></span><br></pre></td></tr></table></figure><h3 id="3、将kafka文件同步到node1-node2"><a href="#3、将kafka文件同步到node1-node2" class="headerlink" title="3、将kafka文件同步到node1,node2"></a>3、将kafka文件同步到node1,node2</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步kafka文件</span></span><br><span class="line">scp -r kafka_2.11-1.0.0/ node1:`pwd`</span><br><span class="line">scp -r kafka_2.11-1.0.0/ node2:`pwd`</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将master中的而环境变量同步到node1和node2中</span></span><br><span class="line">scp /etc/profile node1:/etc/</span><br><span class="line">scp /etc/profile node2:/etc/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 在ndoe1和node2中执行<span class="built_in">source</span></span></span><br><span class="line">source /etc/profile</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="4、修改node1和node2中的broker-id"><a href="#4、修改node1和node2中的broker-id" class="headerlink" title="4、修改node1和node2中的broker.id"></a>4、修改node1和node2中的broker.id</h3><p>vim config&#x2F;server.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># node1</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">1</span></span><br><span class="line"><span class="comment"># node2</span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="string">2</span></span><br></pre></td></tr></table></figure><h3 id="5、启动kafka"><a href="#5、启动kafka" class="headerlink" title="5、启动kafka"></a>5、启动kafka</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、需要先启动zookeeper,  kafka使用zk保存元数据</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要在每隔节点中执行启动的命令</span></span><br><span class="line">zkServer.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动的状态</span></span><br><span class="line">zkServer.sh status</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、启动kafka，每个节点中都要启动（去中心化的架构）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-daemon后台启动</span></span><br><span class="line">kafka-server-start.sh -daemon /usr/local/soft/kafka_2.11-1.0.0/config/server.properties</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用kafka"><a href="#使用kafka" class="headerlink" title="使用kafka"></a>使用kafka</h3><h3 id="1、创建topic"><a href="#1、创建topic" class="headerlink" title="1、创建topic"></a>1、创建topic</h3><blockquote><p>在生产和消费数据时，如果topic不存在会自动创建一个分区为1，副本为1的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--replication-factor  ---每一个分区的副本数量, 同一个分区的副本不能放在同一个节点，副本的数量不能大于kafak集群节点的数量</span><br><span class="line">--partition   --分区数，  根据数据量设置</span><br><span class="line">--zookeeper zk的地址，将topic的元数据保存在zookeeper中</span><br><span class="line"></span><br><span class="line">kafka-topics.sh --create --zookeeper master:2181,node1:2181,node2:2181 --replication-factor 3 --partitions 3 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="2、查看topic描述信息"><a href="#2、查看topic描述信息" class="headerlink" title="2、查看topic描述信息"></a>2、查看topic描述信息</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --describe  --zookeeper master:2181,node1:2181,node2:2181 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="3、获取所有topic"><a href="#3、获取所有topic" class="headerlink" title="3、获取所有topic"></a>3、获取所有topic</h3><blockquote><p>__consumer_offsetsL kafka用于保存消费偏移量的topic</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br></pre></td></tr></table></figure><h3 id="4、创建控制台生产者"><a href="#4、创建控制台生产者" class="headerlink" title="4、创建控制台生产者"></a>4、创建控制台生产者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list master:9092,node1:9092,node2:9092 --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="5、创建控制台消费者"><a href="#5、创建控制台消费者" class="headerlink" title="5、创建控制台消费者"></a>5、创建控制台消费者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> --from-beginning   从头消费，如果不在执行消费的新的数据</span><br><span class="line">kafka-console-consumer.sh --bootstrap-server  master:9092,node1:9092,node2:9092 --from-beginning --topic test_topic2</span><br></pre></td></tr></table></figure><h3 id="kafka数据保存的方式"><a href="#kafka数据保存的方式" class="headerlink" title="kafka数据保存的方式"></a>kafka数据保存的方式</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、保存的文件</span></span><br><span class="line">/usr/local/soft/kafka_2.11-1.0.0/data</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、每一个分区每一个副本对应一个目录</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3、每一个分区目录中可以有多个文件， 文件时滚动生成的</span></span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000000001.log</span><br><span class="line">00000000000000000002.log</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4、滚动生成文件的策略</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5、文件删除的策略，默认时7天，以文件为单位删除</span></span><br><span class="line">log.retention.hours=168</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink之Join</title>
      <link href="/2022/07/24/flink%E4%B9%8BJoin/"/>
      <url>/2022/07/24/flink%E4%B9%8BJoin/</url>
      
        <content type="html"><![CDATA[<h2 id="Flink-Join"><a href="#Flink-Join" class="headerlink" title="Flink Join"></a>Flink Join</h2><p>flink可以维护PB级别的状态</p><h4 id="1、Regular-Joins"><a href="#1、Regular-Joins" class="headerlink" title="1、Regular  Joins"></a>1、Regular  Joins</h4><blockquote><p>可以一直关联上另一张表的历史数据，flink会将两张表的数据一直保存在状态中</p><p>优点：可以保证两张表的数据一直可以关联上，数据不是同时到达的也可以关联上</p><p>缺点：两个表的数据一直缓存在状态中，状态会越来越大，每checkpoint的所需要的时间也会越来越长，最后会导致flink出现反压，如果checkpoint多次超时失败，会导致flink任务失败</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建学生表流表，数据再kafka中</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_join (</span><br><span class="line"> id String,</span><br><span class="line"> name String,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> gender STRING,</span><br><span class="line"> clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">--- inner join</span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- left outer join</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">left</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- full outer join </span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span> </span><br><span class="line">student_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">full</span> <span class="keyword">join</span> </span><br><span class="line">score_join <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span> a.id<span class="operator">=</span>b.s_id</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100002</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student_join</span></span><br><span class="line"></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"><span class="number">1500100002</span>,吕金鹏,<span class="number">24</span>,男,文科七班</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2、Interval-Joins"><a href="#2、Interval-Joins" class="headerlink" title="2、Interval Joins"></a>2、Interval Joins</h4><blockquote><p>在一定时间范围内进行关联，这样flink只需要在状态中保存一段时间的数据，不需要保存所有的数据</p><p>优点：状态不会太大</p><p>缺点：如果时间设置的不合理会导致数据关联不上</p><p>前提是两个表有一个时间字段</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建学生表流表，数据再kafka中</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_join_proc (</span><br><span class="line"> id String,</span><br><span class="line"> name String,</span><br><span class="line"> age <span class="type">int</span>,</span><br><span class="line"> gender STRING,</span><br><span class="line"> clazz STRING,</span><br><span class="line"> stu_time <span class="keyword">as</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join_proc (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span>,</span><br><span class="line"> sco_time <span class="keyword">as</span> PROCTIME()</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Interval Joins</span></span><br><span class="line"><span class="keyword">select</span> a.id,a.name,b.sco <span class="keyword">from</span></span><br><span class="line">student_join_proc <span class="keyword">as</span> a, score_join_proc <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">where</span> a.id<span class="operator">=</span>b.s_id </span><br><span class="line"><span class="keyword">and</span> a.stu_time <span class="keyword">BETWEEN</span> b.sco_time <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;10&#x27;</span> <span class="keyword">SECOND</span> <span class="keyword">AND</span> b.sco_time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100002</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student_join</span></span><br><span class="line"></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"><span class="number">1500100002</span>,吕金鹏,<span class="number">24</span>,男,文科七班</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="3、Temporal-Joins"><a href="#3、Temporal-Joins" class="headerlink" title="3、Temporal Joins"></a>3、Temporal Joins</h4><blockquote><p>流表关联版本表（拉链表），关联版本表对应版本数据，不需要将两个表的数据一直保存在状态</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 订单表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orders (</span><br><span class="line">    order_id    STRING, <span class="comment">-- 订单编号</span></span><br><span class="line">    price       <span class="type">DECIMAL</span>(<span class="number">32</span>,<span class="number">2</span>), <span class="comment">--订单的价格</span></span><br><span class="line">    currency    STRING, <span class="comment">-- 汇率表主键</span></span><br><span class="line">    order_time  <span class="type">TIMESTAMP</span>(<span class="number">3</span>), <span class="comment">-- 订单发生的事件</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> order_time <span class="keyword">AS</span> order_time <span class="comment">-- 设置事件时间和水位线</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;orders&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">--汇率表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> currency_rates (</span><br><span class="line">    currency STRING, <span class="comment">-- 汇率表主键</span></span><br><span class="line">    conversion_rate <span class="type">DECIMAL</span>(<span class="number">32</span>, <span class="number">2</span>), <span class="comment">-- 汇率</span></span><br><span class="line">    update_time <span class="type">TIMESTAMP</span>(<span class="number">3</span>) METADATA <span class="keyword">FROM</span> <span class="string">&#x27;value.ingestion-timestamp&#x27;</span> VIRTUAL, <span class="comment">--汇率更新时间</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> update_time <span class="keyword">AS</span> update_time,<span class="comment">--时间字段和水位线</span></span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY(currency) <span class="keyword">NOT</span> ENFORCED<span class="comment">--设置主键</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;test.currency_rates&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;canal-json&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;canal-json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Temporal Joins</span></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">     order_id,</span><br><span class="line">     price,</span><br><span class="line">     orders.currency,</span><br><span class="line">     conversion_rate,</span><br><span class="line">     order_time</span><br><span class="line"><span class="keyword">FROM</span> orders</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> currency_rates <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> orders.order_time</span><br><span class="line"><span class="keyword">ON</span> orders.currency <span class="operator">=</span> currency_rates.currency;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 订单表数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic orders</span></span><br><span class="line"></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">08</span>:<span class="number">20</span></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">15</span>:<span class="number">55</span></span><br><span class="line"><span class="number">001</span>,<span class="number">1000.0</span>,<span class="number">1001</span>,<span class="number">2022</span><span class="number">-08</span><span class="number">-02</span> <span class="number">11</span>:<span class="number">20</span>:<span class="number">55</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="4、Lookup-Join"><a href="#4、Lookup-Join" class="headerlink" title="4、Lookup Join"></a>4、Lookup Join</h4><blockquote><p>用于流表关联维表</p><p>关联方式：当流表每来一条数据时，都会通过关联的字段到维表底层数据库中去查询数据</p><p>如果每一条数据都需要去查询数据库，吞吐量会比较低，可以在flink中设置数据缓存，需要设置两个参数，一个是缓存大小，还有缓存过期时间</p><p>查数据时先查询缓存，如果缓存中直接返回，如果缓存中没有再去查询数据库，并将查询的结果放在缓存中</p><p>会出现缓存穿透和缓存雪崩</p><p>什么是缓存穿透呢？缓存穿透问题在一定程度上与缓存命中率有关。如果我们的缓存设计的不合理，缓存的命中率非常低，那么，数据访问的绝大部分压力都会集中在后端数据库层面。</p><p>如果在某一时刻缓存集中失效，或者缓存系统出现故障，所有的并发流量就会直接到达数据库。数据存储层的调用量就会暴增，用不了多长时间，数据库就会被大流量压垮，这种级联式的服务故障，就叫作缓存雪崩。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建一个jdbc维表  -- 有界流</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_mysql (</span><br><span class="line">  id <span class="type">BIGINT</span>,</span><br><span class="line">  name STRING,</span><br><span class="line">  age <span class="type">BIGINT</span>,</span><br><span class="line">  gender STRING,</span><br><span class="line">  clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;students&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;lookup.cache.max-rows&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;100&#x27;</span> ,<span class="comment">-- 开启缓存,指定缓存数据量,可以提高关联性能</span></span><br><span class="line">   <span class="string">&#x27;lookup.cache.ttl&#x27;</span>  <span class="operator">=</span> <span class="string">&#x27;30s&#x27;</span> <span class="comment">-- 缓存过期时间，一般会按照维表更新频率设置</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 分数表  -- 无界流</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> score_join (</span><br><span class="line"> s_id String,</span><br><span class="line"> c_id String,</span><br><span class="line"> sco <span class="type">int</span>,</span><br><span class="line"> pro_time <span class="keyword">as</span> PROCTIME() <span class="comment">-- Lookup Join关联方式，流表需要有一个时间字段</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;score_join&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;asdasdasd&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">b.id,b.name,b.age,a.sco</span><br><span class="line"><span class="keyword">FROM</span> score_join <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> student_mysql <span class="keyword">FOR</span> <span class="built_in">SYSTEM_TIME</span> <span class="keyword">AS</span> <span class="keyword">OF</span> a.pro_time <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">ON</span> <span class="built_in">cast</span>(a.s_id  <span class="keyword">as</span>  <span class="type">BIGINT</span>)<span class="operator">=</span> b.id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建生产者向两个topic中生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic score_join</span></span><br><span class="line"><span class="number">1500100003</span>,<span class="number">1000001</span>,<span class="number">98</span></span><br><span class="line"><span class="number">1500100004</span>,<span class="number">1000002</span>,<span class="number">5</span></span><br><span class="line"><span class="number">1500100001</span>,<span class="number">1000003</span>,<span class="number">0</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FLink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Canal搭建</title>
      <link href="/2022/07/21/canal%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/07/21/canal%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="开启mysql-binlog"><a href="#开启mysql-binlog" class="headerlink" title="开启mysql binlog"></a>开启mysql binlog</h2><blockquote><p>默认没有开启</p><p>开启binlog之后mysql的性能会手动影响</p></blockquote><h3 id="1、修改mysql配置文件-x2F-etc-x2F-my-cnf"><a href="#1、修改mysql配置文件-x2F-etc-x2F-my-cnf" class="headerlink" title="1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf"></a>1、修改mysql配置文件&#x2F;etc&#x2F;my.cnf</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果配置文件不存在，复制一个过来</span></span><br><span class="line">cp /usr/share/mysql/my-medium.cnf /etc/my.cnf</span><br><span class="line"></span><br><span class="line">vim /etc/my.cnf </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在配置文件中增加二配置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要将配置放在[mysqld]后面</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开binlog</span></span><br><span class="line">log-bin=mysql-bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">选择ROW(行)模式</span></span><br><span class="line">binlog-format=ROW</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置MySQL replaction需要定义，不要和canal的slaveId重复</span></span><br><span class="line">server_id=1</span><br></pre></td></tr></table></figure><h3 id="2、重启mysql"><a href="#2、重启mysql" class="headerlink" title="2、重启mysql"></a>2、重启mysql</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service mysqld restart</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看mysql binlog文件</span></span><br><span class="line">cd /var/lib/mysql</span><br><span class="line">mysql-bin.000001</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">改了配置文件之后，重启MySQL，使用命令查看是否打开binlog模式：</span></span><br><span class="line">mysql -uroot -p123456</span><br><span class="line">show variables like &#x27;log_bin&#x27;;</span><br></pre></td></tr></table></figure><h2 id="搭建Canal"><a href="#搭建Canal" class="headerlink" title="搭建Canal"></a>搭建Canal</h2><h3 id="2、上传解压，上传到soft目录"><a href="#2、上传解压，上传到soft目录" class="headerlink" title="2、上传解压，上传到soft目录"></a>2、上传解压，上传到soft目录</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建解压目录</span></span><br><span class="line">mkdir canal</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压到指定目录</span></span><br><span class="line">tar -xvf canal.deployer-1.1.4.tar.gz -C canal</span><br></pre></td></tr></table></figure><h3 id="3、修改配置文件conf-x2F-example-x2F-instance-properties"><a href="#3、修改配置文件conf-x2F-example-x2F-instance-properties" class="headerlink" title="3、修改配置文件conf&#x2F;example&#x2F;instance.properties"></a>3、修改配置文件conf&#x2F;example&#x2F;instance.properties</h3><p>vim conf&#x2F;example&#x2F;instance.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql 地址</span></span><br><span class="line"><span class="attr">canal.instance.master.address</span>=<span class="string">master:3306</span></span><br><span class="line"><span class="comment"># mysql用户名</span></span><br><span class="line"><span class="attr">canal.instance.dbUsername</span>=<span class="string">root</span></span><br><span class="line"><span class="comment"># mysql密码</span></span><br><span class="line"><span class="attr">canal.instance.dbPassword</span>=<span class="string">123456</span></span><br><span class="line"><span class="comment"># 数据写入kafka 的topic名称, 所有的数据写入同一个topic</span></span><br><span class="line"><span class="attr">canal.mq.topic</span>=<span class="string">example</span></span><br><span class="line"><span class="comment"># 为每一个表自动创建一个topic</span></span><br><span class="line"><span class="comment"># 监控bigdata数据库，不同的表发送到表名的topic上, topic命令方式bigdata.student</span></span><br><span class="line"><span class="attr">canal.mq.dynamicTopic</span>=<span class="string">bigdata\\..*</span></span><br></pre></td></tr></table></figure><h3 id="4、修改配置文件conf-x2F-canal-properties"><a href="#4、修改配置文件conf-x2F-canal-properties" class="headerlink" title="4、修改配置文件conf&#x2F;canal.properties"></a>4、修改配置文件conf&#x2F;canal.properties</h3><p>vim conf&#x2F;canal.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># zk地址 </span></span><br><span class="line"><span class="attr">canal.zkServers</span> = <span class="string">master:2181,node1:2181,node2:2181</span></span><br><span class="line"><span class="comment"># 数据保存到kafka</span></span><br><span class="line"><span class="attr">canal.serverMode</span> = <span class="string">kafka</span></span><br><span class="line"><span class="comment"># kafka集群地址</span></span><br><span class="line"><span class="attr">canal.mq.servers</span> = <span class="string">master:9092,node1:9092,node2:9092</span></span><br></pre></td></tr></table></figure><h3 id="5、启动canal"><a href="#5、启动canal" class="headerlink" title="5、启动canal"></a>5、启动canal</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/canal/bin/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动canal</span></span><br><span class="line">./startup.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看启动日志</span></span><br><span class="line">cd /usr/local/soft/canal/logs</span><br><span class="line">cat canal/*</span><br><span class="line">cat example/*</span><br></pre></td></tr></table></figure><h3 id="5、测试"><a href="#5、测试" class="headerlink" title="5、测试"></a>5、测试</h3><p>在test数据库创建一个订单表，并且执行几个简单的DML：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 登录mysql</span></span><br><span class="line">mysql <span class="operator">-</span>uroot <span class="operator">-</span>p123456</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 切换数据库</span></span><br><span class="line">use `bigdata`;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `<span class="keyword">order</span>`</span><br><span class="line">(</span><br><span class="line">    id          <span class="type">BIGINT</span> <span class="keyword">UNIQUE</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT COMMENT <span class="string">&#x27;主键&#x27;</span>,</span><br><span class="line">    order_id    <span class="type">VARCHAR</span>(<span class="number">64</span>)   COMMENT <span class="string">&#x27;订单ID&#x27;</span>,</span><br><span class="line">    amount      <span class="type">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>) COMMENT <span class="string">&#x27;订单金额&#x27;</span>,</span><br><span class="line">    create_time DATETIME       COMMENT <span class="string">&#x27;创建时间&#x27;</span>,</span><br><span class="line">    <span class="keyword">UNIQUE</span> uniq_order_id (`order_id`)</span><br><span class="line">) COMMENT <span class="string">&#x27;订单表&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> `<span class="keyword">order</span>`(order_id, amount) <span class="keyword">VALUES</span> (<span class="string">&#x27;10087&#x27;</span>, <span class="number">999</span>);</span><br><span class="line"><span class="keyword">UPDATE</span> `<span class="keyword">order</span>` <span class="keyword">SET</span> amount <span class="operator">=</span> <span class="number">99</span> <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"><span class="keyword">DELETE</span>  <span class="keyword">FROM</span> `<span class="keyword">order</span>` <span class="keyword">WHERE</span> order_id <span class="operator">=</span> <span class="string">&#x27;10087&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="6、可以利用Kafka的kafka-console-consumer消费数据"><a href="#6、可以利用Kafka的kafka-console-consumer消费数据" class="headerlink" title="6、可以利用Kafka的kafka-console-consumer消费数据"></a>6、可以利用Kafka的kafka-console-consumer消费数据</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看是否自动创建topic</span></span><br><span class="line">kafka-topics.sh --list  --zookeeper  master:2181,node1:2181,node2:2181</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">消费数据</span></span><br><span class="line">kafka-console-consumer.sh --bootstrap-server master:9092,node1:9092,node2:9092 --from-beginning --topic bigdata.order</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark优化</title>
      <link href="/2022/07/20/spark%E4%BC%98%E5%8C%96/"/>
      <url>/2022/07/20/spark%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="spark优化"><a href="#spark优化" class="headerlink" title="spark优化"></a>spark优化</h1><h2 id="一、代码优化"><a href="#一、代码优化" class="headerlink" title="一、代码优化"></a>一、代码优化</h2><h3 id="1、多次使用的rdd-df-table进行缓存"><a href="#1、多次使用的rdd-df-table进行缓存" class="headerlink" title="**1、多次使用的rdd df table进行缓存 ***"></a>**1、多次使用的rdd df table进行缓存 ***</h3><ul><li><p>缓存级别</p><ul><li>数据量不大时可以使用MEMORY_ONLY</li><li>数据量超过了内存的限制 MEMORy_AND_DISK_SER</li></ul></li></ul><h3 id="2、使用高性能的算子"><a href="#2、使用高性能的算子" class="headerlink" title="**2、使用高性能的算子 ***"></a>**2、使用高性能的算子 ***</h3><ul><li><p>reduceByKey</p><ul><li>会再map端做预聚合</li></ul></li><li><p>aggregateByKey</p></li><li><p>mapPartition</p></li><li><p>foreachPartition</p><ul><li>主要用于将数据保存到外部数据库时</li><li>只需要为每一个分区创建一个网络链接</li></ul></li><li><p>coalesce</p><ul><li>如果代码产生了很多的小文件，可以再保存数据的时候合并小文件</li></ul></li></ul><h3 id="3、map-join"><a href="#3、map-join" class="headerlink" title="**3、map join ***"></a>**3、map join ***</h3><ul><li>当一个大表join小表的时候，可以将小表广播，在map端进行关联</li><li>小表不能超过1G</li></ul><h3 id="4、Kryo"><a href="#4、Kryo" class="headerlink" title="4、Kryo"></a>4、Kryo</h3><h3 id="5、优化数据结构"><a href="#5、优化数据结构" class="headerlink" title="5、优化数据结构"></a>5、优化数据结构</h3><ul><li>1、尽量使用字符串代替对象</li><li>2、尽量使用基本数据类型代替字符串</li><li>3、尽量使用数组代替集合</li></ul><h3 id="6、使用高性能的fastUtil库"><a href="#6、使用高性能的fastUtil库" class="headerlink" title="6、使用高性能的fastUtil库"></a>6、使用高性能的fastUtil库</h3><h2 id="二、参数优化"><a href="#二、参数优化" class="headerlink" title="二、参数优化"></a>二、参数优化</h2><h3 id="–num-executors-executor的数量"><a href="#–num-executors-executor的数量" class="headerlink" title="–num-executors executor的数量"></a><strong>–num-executors executor的数量</strong></h3><h3 id="–executor-memory-每一个executor的内存"><a href="#–executor-memory-每一个executor的内存" class="headerlink" title="–executor-memory 每一个executor的内存"></a><strong>–executor-memory 每一个executor的内存</strong></h3><h3 id="–executor-cores-每一个executor的核心数"><a href="#–executor-cores-每一个executor的核心数" class="headerlink" title="–executor-cores  每一个executor的核心数"></a><strong>–executor-cores  每一个executor的核心数</strong></h3><h3 id="–driver-memory-Driver的内存1G-2G-保存广播变量"><a href="#–driver-memory-Driver的内存1G-2G-保存广播变量" class="headerlink" title="–driver-memory  Driver的内存1G-2G(保存广播变量)"></a>–driver-memory  Driver的内存1G-2G(保存广播变量)</h3><h3 id="–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle"><a href="#–spark-storage-memoryFraction-用于缓存的内存占比默认时0-6-如果代码中没有用到缓存-可以将内存分配给shuffle" class="headerlink" title="–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle"></a>–spark.storage.memoryFraction 用于缓存的内存占比默认时0.6,如果代码中没有用到缓存 可以将内存分配给shuffle</h3><h3 id="–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2"><a href="#–spark-shuffle-memoryFraction-用户shuffle的内存占比默认0-2" class="headerlink" title="–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2"></a>–spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2</h3><h3 id="–spark-locality-wait-数据本地化等待时间"><a href="#–spark-locality-wait-数据本地化等待时间" class="headerlink" title="–spark.locality.wait 数据本地化等待时间"></a>–spark.locality.wait 数据本地化等待时间</h3><h3 id="–spark-yarn-executor-memoryOverhead堆外内存"><a href="#–spark-yarn-executor-memoryOverhead堆外内存" class="headerlink" title="–spark.yarn.executor.memoryOverhead堆外内存"></a>–spark.yarn.executor.memoryOverhead堆外内存</h3><h3 id="–spark-network-timeout-网络链接的超时时间"><a href="#–spark-network-timeout-网络链接的超时时间" class="headerlink" title="–spark.network.timeout 网络链接的超时时间"></a>–spark.network.timeout 网络链接的超时时间</h3><h2 id="三、数据倾斜"><a href="#三、数据倾斜" class="headerlink" title="三、数据倾斜"></a>三、数据倾斜</h2><h3 id="1、将数据倾斜提前带hive"><a href="#1、将数据倾斜提前带hive" class="headerlink" title="1、将数据倾斜提前带hive"></a><strong>1、将数据倾斜提前带hive</strong></h3><ul><li>hive比spark稳定</li></ul><h3 id="2、过滤少量导致倾斜的key"><a href="#2、过滤少量导致倾斜的key" class="headerlink" title="2、过滤少量导致倾斜的key"></a><strong>2、过滤少量导致倾斜的key</strong></h3><ul><li>key对业务不重要</li></ul><h3 id="3、提高shuffle的并行度"><a href="#3、提高shuffle的并行度" class="headerlink" title="3、提高shuffle的并行度"></a><strong>3、提高shuffle的并行度</strong></h3><ul><li>可以减少每一个reduce中分到的数据量，可以缓解数据倾斜</li></ul><h3 id="4、双重聚合"><a href="#4、双重聚合" class="headerlink" title="4、双重聚合"></a><strong>4、双重聚合</strong></h3><ul><li>先增加随机前缀聚合一次，再去掉前缀聚合一次</li></ul><h3 id="5、map-join"><a href="#5、map-join" class="headerlink" title="**5、map join **"></a>**5、map join **</h3><ul><li>适合大表关联小表，大表部分数据分布不均</li><li>mapjoin 不会产生shuffle,就不会导致数据倾斜</li></ul><h3 id="6、采样倾斜的key并拆分jon"><a href="#6、采样倾斜的key并拆分jon" class="headerlink" title="6、采样倾斜的key并拆分jon"></a><strong>6、采样倾斜的key并拆分jon</strong></h3><ul><li>当大表关联大表，有一个表部分key数据分布不均</li><li>把倾斜的数据单独拿出来使用mapjoin进行关联，避免了数据倾斜</li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FLink代码</title>
      <link href="/2022/07/19/FLink%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/07/19/FLink%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h4 id="1、flink编写WordCount"><a href="#1、flink编写WordCount" class="headerlink" title="1、flink编写WordCount"></a>1、flink编写WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建flink环境</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">//设置flink任务的并行度</span></span><br><span class="line">    <span class="comment">//默认和电脑的核数有关</span></span><br><span class="line">    env.setParallelism(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//数据从上游发送到下游的超时时间</span></span><br><span class="line">    <span class="comment">//默认是200毫秒</span></span><br><span class="line">    env.setBufferTimeout(<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、读取数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计单词的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//将一行转换成多行</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//转换成kv格式</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照单词进行分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//d对value进行汇总</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = groupByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、查看结果</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动flink程序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、map"><a href="#2、map" class="headerlink" title="2、map"></a>2、map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * map方法，每一条数据执行一次，传进来一条返回一条</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ： 一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">map</span></span>(value: <span class="type">String</span>): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">4</span>)</span><br><span class="line">        (clazz, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    kvDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3、Java-API"><a href="#3、Java-API" class="headerlink" title="3、Java API"></a>3、Java API</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">MapFunction</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.<span class="type">Tuple2</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">DataStreamSource</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.<span class="type">SingleOutputStreamOperator</span>;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.<span class="type">StreamExecutionEnvironment</span>;</span><br><span class="line"></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Demo2JavaApi</span> </span>&#123;</span><br><span class="line">    public static void main(<span class="type">String</span>[] args) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">        <span class="comment">//创建flink环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> env = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="type">DataStreamSource</span>&lt;<span class="type">String</span>&gt; studentDS = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//java 代码</span></span><br><span class="line">        <span class="type">SingleOutputStreamOperator</span>&lt;<span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt; kvDS = studentDS.map(<span class="keyword">new</span> <span class="type">MapFunction</span>&lt;<span class="type">String</span>, <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            public <span class="type">Tuple2</span>&lt;<span class="type">String</span>, <span class="type">Integer</span>&gt; map(<span class="type">String</span> value) <span class="keyword">throws</span> <span class="type">Exception</span> &#123;</span><br><span class="line">                <span class="type">String</span> clazz = value.split(<span class="string">&quot;,&quot;</span>)[<span class="number">4</span>];</span><br><span class="line">                <span class="keyword">return</span> <span class="type">Tuple2</span>.of(clazz, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        kvDS.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4、FlatMapFuncation"><a href="#4、FlatMapFuncation" class="headerlink" title="4、FlatMapFuncation"></a>4、FlatMapFuncation</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FlatMapFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3FlatMapFuncation</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(<span class="keyword">new</span> <span class="type">FlatMapFunction</span>[<span class="type">String</span>, <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * flatMap： 一条数据执行一次，传入一条数据可以返回多条数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @param out   ：用于将数据发送到下游</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>(value: <span class="type">String</span>, out: <span class="type">Collector</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = value.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">          <span class="comment">//将数据发送到下游</span></span><br><span class="line">          out.collect(word)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    wordsDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Filter"><a href="#5、Filter" class="headerlink" title="5、Filter"></a>5、Filter</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">FilterFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala.&#123;<span class="type">DataStream</span>, <span class="type">StreamExecutionEnvironment</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4Filter</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.readTextFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> filterDS: <span class="type">DataStream</span>[<span class="type">String</span>] = studentDS.filter(<span class="keyword">new</span> <span class="type">FilterFunction</span>[<span class="type">String</span>] &#123;</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 传如一条数据返回一个布尔值，返回true保留数据，返回false过滤数据</span></span><br><span class="line"><span class="comment">       *</span></span><br><span class="line"><span class="comment">       * @param value ：一行数据</span></span><br><span class="line"><span class="comment">       * @return</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(value: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> gender: <span class="type">String</span> = value.split(<span class="string">&quot;,&quot;</span>)(<span class="number">3</span>)</span><br><span class="line">        <span class="string">&quot;女&quot;</span>.equals(gender)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    filterDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、KeyBy"><a href="#6、KeyBy" class="headerlink" title="6、KeyBy"></a>6、KeyBy</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.<span class="type">KeySelector</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5KeyBy</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(<span class="keyword">new</span> <span class="type">KeySelector</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getKey</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>)): <span class="type">String</span> = &#123;</span><br><span class="line">        value._1</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//key之后进行聚合计算</span></span><br><span class="line">    <span class="keyword">val</span> sumDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    sumDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Reduce"><a href="#7、Reduce" class="headerlink" title="7、Reduce"></a>7、Reduce</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">ReduceFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6Reduce</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再分组之后进行聚合计算</span></span><br><span class="line">    <span class="comment">//val reduceDS: DataStream[(String, Int)] = keyByDS.reduce((kv1, kv2) =&gt; (kv1._1, kv1._2 + kv2._2))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//java api</span></span><br><span class="line">    <span class="keyword">val</span> reduceDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = keyByDS.reduce(<span class="keyword">new</span> <span class="type">ReduceFunction</span>[(<span class="type">String</span>, <span class="type">Int</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(kv1: (<span class="type">String</span>, <span class="type">Int</span>), kv2: (<span class="type">String</span>, <span class="type">Int</span>)): (<span class="type">String</span>, <span class="type">Int</span>) = &#123;</span><br><span class="line">        (kv1._1, kv1._2 + kv2._2)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    reduceDS.print()</span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Window"><a href="#8、Window" class="headerlink" title="8、Window"></a>8、Window</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.<span class="type">SlidingProcessingTimeWindows</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.<span class="type">Time</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.<span class="type">TimeWindow</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesDS: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordsDS: <span class="type">DataStream</span>[<span class="type">String</span>] = linesDS.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> kvDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = wordsDS.map((_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计最近10秒单词的数量，每个5秒统计一次</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = kvDS.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//滑动窗口</span></span><br><span class="line">    <span class="keyword">val</span> windowDS: <span class="type">WindowedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>, <span class="type">TimeWindow</span>] = keyByDS</span><br><span class="line">      .window(<span class="type">SlidingProcessingTimeWindows</span>.of(<span class="type">Time</span>.seconds(<span class="number">10</span>), <span class="type">Time</span>.seconds(<span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//再开窗之后进行集合计算</span></span><br><span class="line">    <span class="keyword">val</span> countDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = windowDS.sum(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    countDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、Union"><a href="#9、Union" class="headerlink" title="9、Union"></a>9、Union</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Union</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建flink环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ds1: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">    <span class="keyword">val</span> ds2: <span class="type">DataStream</span>[<span class="type">Int</span>] = env.fromCollection(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//两个ds的类型要一致</span></span><br><span class="line">    <span class="keyword">val</span> unionDS: <span class="type">DataStream</span>[<span class="type">Int</span>] = ds1.union(ds2)</span><br><span class="line"></span><br><span class="line">    unionDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FLink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink状态和checkPoint</title>
      <link href="/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/"/>
      <url>/2022/07/19/Flink%E7%8A%B6%E6%80%81%E5%92%8CcheckPoint/</url>
      
        <content type="html"><![CDATA[<h4 id="1、实时计算每一个班级的平均年龄"><a href="#1、实时计算每一个班级的平均年龄" class="headerlink" title="1、实时计算每一个班级的平均年龄"></a>1、实时计算每一个班级的平均年龄</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.<span class="type">RuntimeContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.&#123;<span class="type">ValueState</span>, <span class="type">ValueStateDescriptor</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.<span class="type">KeyedProcessFunction</span></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.scala._</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.<span class="type">Collector</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo14AvgAge</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//创建环境</span></span><br><span class="line">    <span class="keyword">val</span> env: <span class="type">StreamExecutionEnvironment</span> = <span class="type">StreamExecutionEnvironment</span>.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取socket的数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">DataStream</span>[<span class="type">String</span>] = env.socketTextStream(<span class="string">&quot;master&quot;</span>, <span class="number">8888</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> clazzAndAge: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = lines.map(line =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> splits: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = splits(<span class="number">4</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Int</span> = splits(<span class="number">2</span>).toInt</span><br><span class="line">      (clazz, age)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照班级分组</span></span><br><span class="line">    <span class="keyword">val</span> keyByDS: <span class="type">KeyedStream</span>[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">String</span>] = clazzAndAge.keyBy(_._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 计算平均年龄</span></span><br><span class="line"><span class="comment">     * flink的状态可以在任务算子中使用，map，filter，process都可以（Rich）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> resultDS: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Double</span>)] = keyByDS.process(<span class="keyword">new</span> <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(parameters: <span class="type">Configuration</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 定义两个状态来保存总人数和总年龄</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">val</span> context: <span class="type">RuntimeContext</span> = getRuntimeContext</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总人数的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumNumDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumNum&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment">//总年龄的状态描述对象</span></span><br><span class="line">        <span class="keyword">val</span> sumAgeDesc = <span class="keyword">new</span> <span class="type">ValueStateDescriptor</span>[<span class="type">Int</span>](<span class="string">&quot;sumAge&quot;</span>, classOf[<span class="type">Int</span>])</span><br><span class="line"></span><br><span class="line">        sumNumState = context.getState(sumNumDesc)</span><br><span class="line"></span><br><span class="line">        sumAgeState = context.getState(sumAgeDesc)</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总人数的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumNumState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存总年龄的状态</span></span><br><span class="line">      <span class="keyword">var</span> sumAgeState: <span class="type">ValueState</span>[<span class="type">Int</span>] = _</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">processElement</span></span>(value: (<span class="type">String</span>, <span class="type">Int</span>),</span><br><span class="line">                                  ctx: <span class="type">KeyedProcessFunction</span>[<span class="type">String</span>, (<span class="type">String</span>, <span class="type">Int</span>), (<span class="type">String</span>, <span class="type">Double</span>)]#<span class="type">Context</span>,</span><br><span class="line">                                  out: <span class="type">Collector</span>[(<span class="type">String</span>, <span class="type">Double</span>)]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> clazz: <span class="type">String</span> = value._1</span><br><span class="line">        <span class="keyword">val</span> age: <span class="type">Int</span> = value._2</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1、获取之前的总人数和总的年龄</span></span><br><span class="line">        <span class="keyword">var</span> sumNum: <span class="type">Int</span> = sumNumState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumNum += <span class="number">1</span></span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumNumState.update(sumNum)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> sumAge: <span class="type">Int</span> = sumAgeState.value()</span><br><span class="line">        <span class="comment">//人数累加</span></span><br><span class="line">        sumAge += age</span><br><span class="line">        <span class="comment">//更新状态</span></span><br><span class="line">        sumAgeState.update(sumAge)</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算平均年龄</span></span><br><span class="line">        <span class="keyword">val</span> avgAge: <span class="type">Double</span> = sumAge / sumNum.toDouble</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将数据发送到下游</span></span><br><span class="line"></span><br><span class="line">        out.collect((clazz, avgAge))</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    resultDS.print()</span><br><span class="line"></span><br><span class="line">    env.execute()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2、状态"><a href="#2、状态" class="headerlink" title="2、状态"></a>2、状态</h4><ol><li><p>flink用于保存之前计算结果的机制</p></li><li><p>flink会为每一个key保存一个状态</p></li><li><p>常用的sum（需要保存之前的计算结果）  window（需要保存一段时间内的数据）内部都是有状态的</p></li><li><p>flink也提供了几种查用的状态类</p><ol><li><strong>valueState: 单值状态</strong>，为每一个key保存一个值，可以是任何类型，必须可以序列化</li><li><strong>mapState: kv格式的状态</strong>，为每一个key保存一个kv格式的状态</li><li><strong>listState: 集合状态</strong>，为每一个key保存一个集合状态，集合中可以保存多个元素</li><li><strong>reducingState&#x2F;AggregatingState:聚合状态</strong>，为每一个key保存一个值，再定义状态时需要一个聚合函数</li></ol></li><li><p>flink的状态和普通变量的区别</p><ol><li>普通变量是保存再flink的内存中的，如果flink任务执行失败，变量的数据会丢失</li><li>flink的状态是一个特殊的变量，状态中的数据会被checkpoint持久化到hdfs中, 如果任务执行失败，重启任务，可以恢复状态</li></ol></li><li><p>状态后端，用于保存状态的位置</p><ol><li><p>HashMapStateBackend： </p><ol><li><p>将flink的状态先保存TaskManager的内存中，在触发checkpoint的时候将taskmanager中的状态再持久化到hdfs中</p></li><li><p>可以直接使用</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">HashMapStateBackend</span>())</span><br></pre></td></tr></table></figure></li></ol></li><li><p>EmbeddedRocksDBStateBackend：</p><ol><li><p>RocksDS是一个本地的轻量级的数据库，数据在磁盘上</p></li><li><p>再启动lfink任务的时候会在每一个taskManager所在的节点启动一个rocksDB进程</p></li><li><p>flink的状态会先保存在rocksDb数据库中，当触发checkpoint的时候将数据库中的状态持久化到hdfs中</p></li><li><p>可以支持增量快照</p></li><li><p>使用rocksDb状态后端需要带入依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-statebackend-rocksdb<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>使用方式</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br></pre></td></tr></table></figure></li></ol></li></ol></li></ol><h4 id="3、checkpoint"><a href="#3、checkpoint" class="headerlink" title="3、checkpoint"></a>3、checkpoint</h4><ol><li><p>checkpoint是flink用于持久化flink状态的机制</p></li><li><p>flink会定时将flink计算的状态持久化到hdfs中</p></li><li><p>开启checkpint的方法</p><ol><li><p>在代码中开启- 每一个代码单独开启，优先级最高</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 每 1000ms 开始一次 checkpoint</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>)</span><br><span class="line"><span class="comment">// 高级选项：</span></span><br><span class="line"><span class="comment">// 设置模式为精确一次 (这是默认值)</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)</span><br><span class="line"><span class="comment">// 确认 checkpoints 之间的时间会进行 500 ms</span></span><br><span class="line">env.getCheckpointConfig.setMinPauseBetweenCheckpoints(<span class="number">500</span>)</span><br><span class="line"><span class="comment">// Checkpoint 必须在一分钟内完成，否则就会被抛弃</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointTimeout(<span class="number">60000</span>)</span><br><span class="line"><span class="comment">// 允许两个连续的 checkpoint 错误</span></span><br><span class="line">env.getCheckpointConfig.setTolerableCheckpointFailureNumber(<span class="number">2</span>)</span><br><span class="line"><span class="comment">// 同一时间只允许一个 checkpoint 进行</span></span><br><span class="line">env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// 使用 externalized checkpoints，这样 checkpoint 在作业取消后仍就会被保留</span></span><br><span class="line"><span class="comment">//RETAIN_ON_CANCELLATION: 当任务取消时保留checkpoint</span></span><br><span class="line">env.getCheckpointConfig.setExternalizedCheckpointCleanup(</span><br><span class="line">ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)</span><br><span class="line"><span class="comment">//指定状态后端</span></span><br><span class="line"><span class="comment">//EmbeddedRocksDBStateBackend eocksDb状态后端</span></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> <span class="title class_">EmbeddedRocksDBStateBackend</span>(<span class="literal">true</span>))</span><br><span class="line"><span class="comment">//将状态保存到hdfs中，在触发checkpoint的时候将状态持久化到hdfs中</span></span><br><span class="line">env.getCheckpointConfig.setCheckpointStorage(<span class="string">&quot;hdfs://master:9000/flink/checkpoint&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>在flink的集群的配置文件中同意开启– flink新版才有</p><p>vim  flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">execution.checkpointing.interval:</span> <span class="string">3min</span></span><br><span class="line"><span class="attr">execution.checkpointing.externalized-checkpoint-retention:</span> <span class="string">RETAIN_ON_CANCELLATION</span></span><br><span class="line"><span class="attr">execution.checkpointing.max-concurrent-checkpoints:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">execution.checkpointing.min-pause:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">execution.checkpointing.mode:</span> <span class="string">EXACTLY_ONCE</span></span><br><span class="line"><span class="attr">execution.checkpointing.timeout:</span> <span class="string">10min</span></span><br><span class="line"><span class="attr">execution.checkpointing.tolerable-failed-checkpoints:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://master:9000/flink/checkpoint</span></span><br></pre></td></tr></table></figure></li><li><p>从checkpoint恢复任务</p></li><li><p>可以在网页中指定checkpint的路径恢复,路径需要带上前缀hdfs:&#x2F;&#x2F;master:9000</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35</span><br></pre></td></tr></table></figure></li><li><p>也可以在命令行中重新提交任务，指定恢复任务的位置, 需要先上传jar包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-s 恢复任务的位置</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0005  -c com.hzh.flink.core.Demo15RocksDB -s hdfs://master:9000/flink/checkpoint/11edbec21742ceddebbb90f3e49f24b4/chk-35 flink-1.0.jar</span><br></pre></td></tr></table></figure></li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FLink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink SQL</title>
      <link href="/2022/07/19/flink%20SQL/"/>
      <url>/2022/07/19/flink%20SQL/</url>
      
        <content type="html"><![CDATA[<h2 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h2><h3 id="1、连接器"><a href="#1、连接器" class="headerlink" title="1、连接器"></a>1、连接器</h3><h4 id="1、DataGen"><a href="#1、DataGen" class="headerlink" title="1、DataGen"></a>1、DataGen</h4><blockquote><p>用于生成随机数据的工具</p><p>只能用于source表</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line"> id STRING,</span><br><span class="line"> name STRING,</span><br><span class="line"> age <span class="type">INT</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- ts AS localtimestamp, : localtimestamp获取当前时间戳，</span></span><br></pre></td></tr></table></figure><h4 id="2、Print"><a href="#2、Print" class="headerlink" title="2、Print"></a>2、Print</h4><blockquote><p>print用于打印连续查询的结果的表</p><p>print只能用于sink表</p></blockquote><ul><li>基于已有的表结构创建print表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- LIKE： 基于已有的表创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><ul><li>打印数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="operator">|</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> datagen</span><br></pre></td></tr></table></figure><ul><li>手动设置字段</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table (</span><br><span class="line"> age <span class="type">INT</span>,</span><br><span class="line"> num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>统计年龄额人数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> age_num</span><br><span class="line"><span class="keyword">select</span> age ,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> datagen</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> age</span><br></pre></td></tr></table></figure><h4 id="3、BlackHole"><a href="#3、BlackHole" class="headerlink" title="3、BlackHole"></a>3、BlackHole</h4><blockquote><p>用于flink性能测试</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> blackhole_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;blackhole&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> datagen (EXCLUDING <span class="keyword">ALL</span>)</span><br></pre></td></tr></table></figure><h4 id="4、Kafka"><a href="#4、Kafka" class="headerlink" title="4、Kafka"></a>4、Kafka</h4><ul><li>kafka依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>csv依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-csv<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>kafka source</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>参选介绍</p><p>scan.startup.mode：<br>    earliest-offset: 读取所有的数据<br>    latest-offset：读取最新的数据，只能读取到任务启动之后生产的数据<br>    group-offsets（默认值）： 基于以消费者组读取数据，如果消费者组不存在读取最新的数据<br>    timestamp ：指定时间戳读取数据<br>    specific-offsets：指定偏移量读取数据<br>format：<br>    csv: 文本格式，指定字段时需要按照顺序映射，flink sql会自动解析</p><ul><li>kafka sink， 使用flink向kafka中写数据存在两种情况，<ul><li>将append only流写入kafka</li></ul></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_nan&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;\t&#x27;</span> <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 非聚合类的连续查询返回的动态表是一个append only表，可以可以写入到kafka中</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span></span><br><span class="line">student_kafka_source</span><br><span class="line"><span class="keyword">where</span> gender <span class="operator">=</span><span class="string">&#x27;男&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic student_nan</span></span><br></pre></td></tr></table></figure><ul><li>更新的流写入kafka</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建kafka source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建 kafka sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> gender_num_sink (</span><br><span class="line">    gender STRING,</span><br><span class="line">num <span class="type">BIGINT</span>,</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (gender) <span class="keyword">NOT</span> ENFORCED<span class="comment">-- 设置唯一主键</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;upsert-kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;gender_num&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;key.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;value.format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="comment">-- 将更新的流写入kafka</span></span><br><span class="line"><span class="comment">-- 已唯一的主键作为kafka中key</span></span><br><span class="line"><span class="comment">-- 已数据作为kafkavalue</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> gender_num_sink</span><br><span class="line"><span class="keyword">select</span> gender,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num</span><br><span class="line"><span class="keyword">from</span> student_kafka</span><br><span class="line"><span class="keyword">where</span> gender <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> gender</span><br><span class="line"></span><br><span class="line"><span class="comment">--使用控制台查看数据</span></span><br><span class="line"> kafka<span class="operator">-</span>console<span class="operator">-</span>consumer.sh <span class="comment">--bootstrap-server  master:9092,node2:9092,node2:9092 --from-beginning --topic gender_num</span></span><br></pre></td></tr></table></figure><ul><li><p>提交到集群运行需要先将kafka依赖包上传到flink  lib目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink-sql-connector-kafka-1.15.0.jar</span><br></pre></td></tr></table></figure></li></ul><h4 id="5、JDBC"><a href="#5、JDBC" class="headerlink" title="5、JDBC"></a>5、JDBC</h4><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>jdbc source   — 有界流</p><blockquote><p>jdbc 字段按照名称和类型进行映射的，flink sql中表的字段和类型必须和数据库中保持一致</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建jdbc source表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_mysql (</span><br><span class="line">  id <span class="type">BIGINT</span>,</span><br><span class="line">  name STRING,</span><br><span class="line">  age <span class="type">BIGINT</span>,</span><br><span class="line">  gender STRING,</span><br><span class="line">  clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;students&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建print sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_mysql (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_mysql</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>jdbc sink</p><blockquote><p>实时读取kafka中学生表的数据，实时统计每个班级学生的人数，将统计的结果保存到mysql中</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- flink sql kafka source表  学生表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.group.id&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;testGroup&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;earliest-offset&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;csv.field-delimiter&#x27;</span><span class="operator">=</span><span class="string">&#x27;,&#x27;</span>, <span class="comment">-- csv格式数据的分隔符</span></span><br><span class="line">  <span class="string">&#x27;csv.ignore-parse-errors&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span>, <span class="comment">-- 如果出现脏数据据,补null</span></span><br><span class="line">  <span class="string">&#x27;csv.allow-comments&#x27;</span><span class="operator">=</span><span class="string">&#x27;true&#x27;</span><span class="comment">--跳过#注释行</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 在mysql中创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `clazz_num` (</span><br><span class="line">  `clazz` <span class="type">varchar</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `num` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`clazz`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- flink sql  jdbc sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> clazz_num_mysql (</span><br><span class="line">  clazz STRING,</span><br><span class="line">  num <span class="type">BIGINT</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (clazz) <span class="keyword">NOT</span> ENFORCED <span class="comment">-- 按照主键更新数据</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;url&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;jdbc:mysql://master:3306/bigdata?useUnicode=true&amp;characterEncoding=UTF-8&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;table-name&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;clazz_num&#x27;</span>, <span class="comment">-- 需要手动到数据库中创建表</span></span><br><span class="line">   <span class="string">&#x27;username&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;root&#x27;</span>,</span><br><span class="line">   <span class="string">&#x27;password&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;123456&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 以下查询返回的是一个更新流，flinksql会自动按照主键更新数据</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> clazz_num_mysql</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span> </span><br><span class="line">student_kafka</span><br><span class="line"><span class="keyword">where</span> clazz <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 生产数据</span></span><br><span class="line">kafka<span class="operator">-</span>console<span class="operator">-</span>producer.sh <span class="comment">--broker-list master:9092,node1:9092,node2:9092 --topic student</span></span><br><span class="line"><span class="number">1500100001</span>,施笑槐,<span class="number">22</span>,女,文科六班</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>将包含jdbc代码提交到集群运行</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、将flink-connector-jdbc-1.15.0.jar依赖上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、将mysql-connector-java-5.1.49.jar mysql 驱动上传到flink lib目录下</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果是使用yarn-session模式徐娅偶先重启yarn-session</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭</span></span><br><span class="line">yarm application -kill application_1658546198162_0005</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">yarn-session-.sh -d</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将代码打包上传到服务器提交任务</span></span><br><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1658546198162_0007  -c com.shujia.flink.sql.Demo9JDBCSink  flink-1.0.jar</span><br></pre></td></tr></table></figure><h4 id="7、FIleSystem"><a href="#7、FIleSystem" class="headerlink" title="7、FIleSystem"></a>7、FIleSystem</h4><blockquote><p>本地文件，hdfs  其它的文件系统</p></blockquote><ul><li><p>读取文件  </p><blockquote><p>可以使用batch模式处理数据</p></blockquote></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 文件 source</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file (</span><br><span class="line">    id STRINg,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.txt&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;csv&#x27;</span>                     <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 读取csv格式字段需要按照顺序映射</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--print sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line">(</span><br><span class="line">    clazz STRING,</span><br><span class="line">    num <span class="type">BIGINT</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> clazz,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> num <span class="keyword">from</span></span><br><span class="line">student_file</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> clazz</span><br></pre></td></tr></table></figure><ul><li>写入文件</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建source 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> datagen (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    ts <span class="keyword">AS</span> <span class="built_in">localtimestamp</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line"> <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;datagen&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;rows-per-second&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;500&#x27;</span>, <span class="comment">-- 每秒生成的数据行数据</span></span><br><span class="line"> <span class="string">&#x27;fields.id.length&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;5&#x27;</span>, <span class="comment">--字段长度限制</span></span><br><span class="line"> <span class="string">&#x27;fields.name.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.gender.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;1&#x27;</span>,   </span><br><span class="line"> <span class="string">&#x27;fields.clazz.length&#x27;</span><span class="operator">=</span><span class="string">&#x27;5&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;fields.age.min&#x27;</span> <span class="operator">=</span><span class="string">&#x27;1&#x27;</span>, <span class="comment">-- 最小值</span></span><br><span class="line"> <span class="string">&#x27;fields.age.max&#x27;</span><span class="operator">=</span><span class="string">&#x27;100&#x27;</span> <span class="comment">-- 最大值</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 创建file sink表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> file_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING,</span><br><span class="line">    `<span class="keyword">day</span>` STRING,</span><br><span class="line">    `<span class="keyword">hour</span>` STRING</span><br><span class="line">) PARTITIONED <span class="keyword">BY</span> (`<span class="keyword">day</span>`,`<span class="keyword">hour</span>`) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span><span class="operator">=</span><span class="string">&#x27;filesystem&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;path&#x27;</span><span class="operator">=</span><span class="string">&#x27;data/flink_sink&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span><span class="operator">=</span><span class="string">&#x27;csv&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;sink.rolling-policy.file-size&#x27;</span> <span class="operator">=</span><span class="string">&#x27;100kb&#x27;</span><span class="comment">--滚动生成新的文件的大小，默认128M</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> file_sink</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">id,name,age,gender,clazz,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;yyyy-MM-dd&#x27;</span>) <span class="keyword">as</span> `<span class="keyword">day</span>`,</span><br><span class="line">DATE_FORMAT(ts, <span class="string">&#x27;HH&#x27;</span>)  <span class="keyword">as</span> `<span class="keyword">hour</span>`</span><br><span class="line"><span class="keyword">from</span> </span><br><span class="line">datagen</span><br></pre></td></tr></table></figure><h3 id="2、format"><a href="#2、format" class="headerlink" title="2、format"></a>2、format</h3><h4 id="1、json"><a href="#1、json" class="headerlink" title="1、json"></a>1、json</h4><blockquote><p>json格式表结构按照字段名和类型进行映射</p></blockquote><ul><li>增加依赖</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>读取json格式的数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- sink 表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> print_table </span><br><span class="line"><span class="keyword">WITH</span> (<span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;print&#x27;</span>)</span><br><span class="line"><span class="keyword">LIKE</span> student_file_json (EXCLUDING <span class="keyword">ALL</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> print_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><ul><li>将数据保存为json格式</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- source 表 </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_file_json (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">)  <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;filesystem&#x27;</span>,           <span class="comment">-- 必选：指定连接器类型</span></span><br><span class="line">  <span class="string">&#x27;path&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;data/students.json&#x27;</span>,  <span class="comment">-- 必选：指定路径</span></span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> ,                    <span class="comment">-- 必选：文件系统连接器指定 format</span></span><br><span class="line">  <span class="string">&#x27;json.ignore-parse-errors&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- kafka sink </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student_kafka_sink (</span><br><span class="line">    id STRING,</span><br><span class="line">    name STRING,</span><br><span class="line">    age <span class="type">INT</span>,</span><br><span class="line">    gender STRING,</span><br><span class="line">    clazz STRING</span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">  <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>,<span class="comment">-- 只支持追加的流</span></span><br><span class="line">  <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;student_flink_json&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;master:9092,node1:9092,node2:9092&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 执行sql</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_kafka_sink</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student_file_json</span><br></pre></td></tr></table></figure><h3 id="3、练习"><a href="#3、练习" class="headerlink" title="3、练习"></a>3、练习</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 1、使用flink sql 统计每个城市总的车流量</span></span><br><span class="line"><span class="comment">-- 2、source 使用文件sourcecars_sample.json</span></span><br><span class="line"><span class="comment">-- 3、将统计好的结果保存到mysql中，mysql中只保留最新的结果</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FLink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FLink集群搭建</title>
      <link href="/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/07/18/FLink%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="FLink集群搭建"><a href="#FLink集群搭建" class="headerlink" title="FLink集群搭建"></a>FLink集群搭建</h1><h2 id="独立集群"><a href="#独立集群" class="headerlink" title="独立集群"></a>独立集群</h2><blockquote><p>独立集群不需要依赖任何框架，独立运行</p></blockquote><p>1、上传解压配置环境变量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf flink-1.15.0-bin-scala_2.12.tgz </span><br><span class="line"></span><br><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><p>2、修改配置文件</p><p>vim conf&#x2F;flink-conf.yaml</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">jobmanager.rpc.address:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">jobmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.bind-host:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">rest.bind-address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">taskmanager.numberOfTaskSlots:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>vim conf&#x2F;masters</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master:8081</span><br></pre></td></tr></table></figure><p>vim workers</p><p>分布式写node1,node2（伪分布式只写master）</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><p>3、将flink文件同步到另外两个节点中</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r flink-1.15.0/ node1:`pwd`</span><br><span class="line">scp -r flink-1.15.0/ node2:`pwd`</span><br></pre></td></tr></table></figure><p>4、需要修改node1和node2中的配置文件</p><p>vim flink-conf.yaml</p><p>node1节点改成node1,node2的节点改成node2</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">taskmanager.host:</span> <span class="string">node1/node2</span></span><br></pre></td></tr></table></figure><p>5、启动flink的独立集群</p><p>在master中启动集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-cluster.sh</span><br><span class="line"></span><br><span class="line">关闭</span><br><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>6、访问flink的页面</p><p><a href="http://master:8081/">http://master:8081</a></p><h2 id="flink-提交任务的方式"><a href="#flink-提交任务的方式" class="headerlink" title="flink 提交任务的方式"></a>flink 提交任务的方式</h2><p>1、将项目打包在网页上提交</p><p>2、将jar包上传到集群使用flink命令提交</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink run -c com.shujia.core.Demo1WordCount flink-1.0.jar</span><br></pre></td></tr></table></figure><h2 id="FLINK-on-YARN"><a href="#FLINK-on-YARN" class="headerlink" title="FLINK on YARN"></a>FLINK on YARN</h2><blockquote><p>将flink的任务提交到yarn上运行</p></blockquote><p>1、可以先关闭flink的独立集群</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stop-cluster.sh</span><br></pre></td></tr></table></figure><p>2、配置HADOOP_CLASSPATH</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加</span></span><br><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>3、启动hadoop</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h2 id="提交任务到yarn上运行"><a href="#提交任务到yarn上运行" class="headerlink" title="提交任务到yarn上运行"></a>提交任务到yarn上运行</h2><h3 id="1、Application-Mode"><a href="#1、Application-Mode" class="headerlink" title="1、Application Mode"></a>1、Application Mode</h3><p>Application Mode模式主要时为了让flink可以在K8S上运行</p><blockquote><p>为每一个flink任务在yarn上启动一个集群，提交任务的main运行在jobmanager,  数据流程图在jobmanager中构建</p><p>每一个任务启动一个jobmanager</p></blockquote><p>将项目打包上传到服务器</p><p>提交任务</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">flink run-application -t yarn-application -c com.shujia.flink.core.Demo2Submit  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-application -Dyarn.application.id=application_1654846044068_0002</span><br></pre></td></tr></table></figure><p>关闭任务</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-application -Dyarn.application.id=application_1654846044068_0002 52b325d666be767b24698f459bb5dda9</span><br></pre></td></tr></table></figure><h3 id="2、Per-Job-Cluster-Mode"><a href="#2、Per-Job-Cluster-Mode" class="headerlink" title="2、Per-Job Cluster Mode"></a>2、Per-Job Cluster Mode</h3><blockquote><p>为每一个flink任务在yarn上启动一个集群, 在本地构建数据流程图，再将数据流程图提交到jobmanager中运行</p><p>每一个任务启动一个jobmanager</p></blockquote><p>提交任务</p><p>–detached: 客户端提交成功之后会退出</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-per-job --detached -c com.shujia.flink.core.Demo2Submit   flink-1.0.jar</span><br></pre></td></tr></table></figure><p>查看任务列表</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink list -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003</span><br></pre></td></tr></table></figure><p>取消任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink cancel -t yarn-per-job -Dyarn.application.id=application_1654846044068_0003 86d6973d3d79a7040bfdf75b7cad88d0</span><br></pre></td></tr></table></figure><h3 id="3、Session-Mode"><a href="#3、Session-Mode" class="headerlink" title="3、Session Mode"></a>3、Session Mode</h3><blockquote><p>先再yarn中启动一个flink的集群，再通过命令将任务提交到这个集群中运行</p><p>所有的任务共享同一个jobmanager</p></blockquote><p>启动yarn session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn-session.sh -d</span><br></pre></td></tr></table></figure><p>提交任务- 可以提交多个任务，多个任务共享同一个jobmanager</p><p>1、可以在网页中提交任务</p><p>2、可以通过命令行提交任务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flink run -t yarn-session -Dyarn.application.id=application_1654852007237_0008  -c com.shujia.core.Demo12ValueState  flink-1.0.jar</span><br></pre></td></tr></table></figure><p>退出yarn-session</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -kill application_1654846044068_0004</span><br></pre></td></tr></table></figure><p>Application Mode:  每一个任务启动一个集群，任何和任务之前互不影响，在jobmanager中构建JobGraph </p><p>Per-Job Cluster Mode：每一个任务启动一个集群，任何和任务之前互不影响，在本地构建JobGraph 再将JobGraph 提交到jobmanager中运行</p><p>Session Mode: 通过sessIon模式提交的任务共用同一个集群（同一个jobmanager），如果有一个任务执行出了问题，可能会影响其它任务，一般Session 用来测试使用，因为占用的资源要少一点, 在提交任务时在动态申请taskmanager</p><p>在集群中读取kafka的数据</p><p>java.lang.ClassNotFoundException: org.apache.flink.connector.kafka.source.KafkaSource</p><p>需要将flink-sql-connector-kafka-1.15.0.jar 包上传到flink的lib目录下</p><h2 id="yarn-资源不足问题"><a href="#yarn-资源不足问题" class="headerlink" title="yarn 资源不足问题"></a>yarn 资源不足问题</h2><p>修改yarn-site.xml文件</p><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>16384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">将配置文件同步到另外两个节点</span><br><span class="line">scp yarn-site.xml node1:`pwd`</span><br><span class="line">scp yarn-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line">重启yarn</span><br><span class="line">stop-yarn.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FLink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark-SQL</title>
      <link href="/2022/07/15/Spark-Sql/"/>
      <url>/2022/07/15/Spark-Sql/</url>
      
        <content type="html"><![CDATA[<h5 id="1、sparkWordCount"><a href="#1、sparkWordCount" class="headerlink" title="1、sparkWordCount"></a>1、sparkWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo1WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    linesDF.printSchema() <span class="comment">//打印表结构</span></span><br><span class="line">    linesDF.show() <span class="comment">//打印数据</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、将DataFrame注册成一个视图，才能写sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    linesDF.createOrReplaceTempView(<span class="string">&quot;lines&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、写Spark的SQl来统计单词的数量</span></span><br><span class="line"><span class="comment">     * sparkSQl的语法完全兼容hive sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">DataFrame</span> = spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |select word,count(1) as c from</span></span><br><span class="line"><span class="string">        |(select explode(split(line,&#x27;,&#x27;)) as word</span></span><br><span class="line"><span class="string">        |from</span></span><br><span class="line"><span class="string">        |lines) as a</span></span><br><span class="line"><span class="string">        |group by word</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、将数据保存到本地</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    result</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)<span class="comment">//指定文件类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;,&quot;</span>)<span class="comment">//数据分隔符</span></span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)<span class="comment">//覆盖数据</span></span><br><span class="line">      .save(<span class="string">&quot;data/wc1&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2、WslWordCount"><a href="#2、WslWordCount" class="headerlink" title="2、WslWordCount"></a>2、WslWordCount</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo2DSLWC</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;sql&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、读取数据构建DataFrame，DF相当于一张表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> linesDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定读取数据的文件格式</span></span><br><span class="line">      .schema(<span class="string">&quot;line STRING&quot;</span>) <span class="comment">//指定字段名和字段类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;\t&quot;</span>) <span class="comment">//指定分隔符，csv格式默认逗号分隔</span></span><br><span class="line">      .load(<span class="string">&quot;data/words.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL:类sql api，介于代码和SQL之间的一种写法</span></span><br><span class="line"><span class="comment">     * 在写DSL之前需要导入sparkSql的函数和隐式转换</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//$&quot;line&quot; 获取列对象</span></span><br><span class="line">    linesDF</span><br><span class="line">      <span class="comment">//将一行中的多个单词拆分成多行</span></span><br><span class="line">      .select(explode(split($<span class="string">&quot;line&quot;</span>, <span class="string">&quot;,&quot;</span>)) as <span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//按照单词分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;word&quot;</span>)</span><br><span class="line">      <span class="comment">//统计单词的数量</span></span><br><span class="line">      .agg(count($<span class="string">&quot;word&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保存数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/wc2&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3、DslAPI"><a href="#3、DslAPI" class="headerlink" title="3、DslAPI"></a>3、DslAPI</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo3DSLAPI</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、创建spark连接</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> session: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;Demo3DslAPI&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partition&quot;</span>,<span class="number">1</span>) <span class="comment">//指定在shuffle之后的分区数，默认是200，类似hive中设置reduce的数量</span></span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL API</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取一个json格式文件,spark会自动识别json中的列名</span></span><br><span class="line">    <span class="keyword">val</span> dataFrame: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>) <span class="comment">//指定读取数据的格式为json</span></span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    dataFrame.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * show：查看df中数据，相当于rdd的action算子，会触发任务的执行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    dataFrame.show()</span><br><span class="line">    <span class="comment">//指定打印多少行</span></span><br><span class="line">    dataFrame.show(<span class="number">20</span>)</span><br><span class="line">    <span class="comment">//完整打印每一列的数据</span></span><br><span class="line">    dataFrame.show(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * select:选择数据，和sql中的select用法基本一致</span></span><br><span class="line"><span class="comment">     * dsl中select 不能使用聚合函数需要在agg中使用聚合函数</span></span><br><span class="line"><span class="comment">     * select相当于rdd中的转换算子</span></span><br><span class="line"><span class="comment">     * selectExpr可以传一个sql的表达式</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame.select(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age&quot;</span>)</span><br><span class="line">    dataFrame.selectExpr(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;age+1 as age&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//需要导入spark sql的函数才能在DSl中使用函数</span></span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line">    <span class="keyword">import</span> session.implicits._</span><br><span class="line">    <span class="comment">//使用列对象的方式</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;name&quot;</span>, $<span class="string">&quot;age&quot;</span> + <span class="number">1</span> as <span class="string">&quot;age&quot;</span>).show()</span><br><span class="line">    <span class="comment">//在sql中使用spark函数</span></span><br><span class="line">    dataFrame.select($<span class="string">&quot;id&quot;</span>, substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) as <span class="string">&quot;zz&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * where：过滤数据 也相当于一个转换算子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//字符串的sql表达式</span></span><br><span class="line">    dataFrame.where(<span class="string">&quot;gender = &#x27;女&#x27; and age = 23&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用列对象</span></span><br><span class="line">    dataFrame.where($<span class="string">&quot;gender&quot;</span> =!= <span class="string">&quot;男&quot;</span> and $<span class="string">&quot;age&quot;</span> === <span class="number">22</span>).show()</span><br><span class="line">    <span class="comment">//这个里面只能用函数不能写scala代码</span></span><br><span class="line">    dataFrame.where(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) === <span class="string">&quot;文科&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * groupBy agg ：分组聚合要一起使用不能单独使用</span></span><br><span class="line"><span class="comment">     * 分组聚合之后返回的DF只包含分组字段和聚合字段</span></span><br><span class="line"><span class="comment">     * 分组不能在select中聚合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>, floor(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age1&quot;</span>, ceil(avg($<span class="string">&quot;age&quot;</span>)) as <span class="string">&quot;avg_age2&quot;</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * orderBy : 排序</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    dataFrame</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .orderBy($<span class="string">&quot;num&quot;</span>.desc)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * join:表关联</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = session</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,cid STRING,Sco DOUBLE&quot;</span>) <span class="comment">//指定列名</span></span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//关联字段名不一样时</span></span><br><span class="line">    <span class="comment">//    scoreDF.join(dataFrame,$&quot;id&quot;===$&quot;sid&quot;,&quot;inner&quot;).show()</span></span><br><span class="line">    <span class="comment">//关联字段名一样时,直接写&quot;id&quot;</span></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = scoreDF.join(dataFrame, <span class="string">&quot;id&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开窗函数</span></span><br><span class="line"><span class="comment">     * 统计每个班级总分前十的学生</span></span><br><span class="line"><span class="comment">     * withColumn():在DF的基础上增加新的列</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF</span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>,$<span class="string">&quot;clazz&quot;</span>)<span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)<span class="comment">//计算总分</span></span><br><span class="line">      <span class="comment">//简写，在前面的基础上增加列</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>,row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      .where($<span class="string">&quot;r&quot;</span>&lt;=<span class="number">10</span>)</span><br><span class="line">      .show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    joinDF.createOrReplaceTempView(<span class="string">&quot;student_score&quot;</span>)</span><br><span class="line"></span><br><span class="line">    session.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select * from (</span></span><br><span class="line"><span class="string">        |select id as sid,clazz,sumSco,row_number() over(partition by clazz order by sumSco desc) as r from (</span></span><br><span class="line"><span class="string">        |select id,clazz,sum(sco) as  sumSco</span></span><br><span class="line"><span class="string">        |from student_score</span></span><br><span class="line"><span class="string">        |group by id,clazz</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |) as b</span></span><br><span class="line"><span class="string">        |where r&lt;=10</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、DataSource"><a href="#4、DataSource" class="headerlink" title="4、DataSource"></a>4、DataSource</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo4DataSource</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;source&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * csv格式的数据</span></span><br><span class="line"><span class="comment">     * 选哟指定表结构，分隔符（默认时逗号），文件路径</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> csvDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING, clazz STRING&quot;</span>) <span class="comment">//指定列名和类的类型</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    csvDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将数据保持为csv格式</span></span><br><span class="line">    csvDF</span><br><span class="line">      .groupBy($<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;clazz&quot;</span>) as <span class="string">&quot;num&quot;</span>)</span><br><span class="line">      .write <span class="comment">//保持数据</span></span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>) <span class="comment">//指定保持数据的格式</span></span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/clazz_num1&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * json格式</span></span><br><span class="line"><span class="comment">     * spark 会自动将json中字段名和字段类型解析出来</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * json格式比csv格式占用的空间更大，在大数据场景下不适用json</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取json格式的数据</span></span><br><span class="line">    <span class="keyword">val</span> jsonDF: <span class="type">DataFrame</span> = spark.read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    jsonDF.show()</span><br><span class="line">    <span class="comment">//将数据保存为json格式</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .groupBy($<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      .agg(count($<span class="string">&quot;gender&quot;</span>) as <span class="string">&quot;c&quot;</span>)</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/gender_num&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * parquet: 带表结构的压缩格式</span></span><br><span class="line"><span class="comment">     * 压缩：时间换空间</span></span><br><span class="line"><span class="comment">     * 压缩比取决于《信息熵》</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、将数据保存为parquet</span></span><br><span class="line">    jsonDF</span><br><span class="line">      .write</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .save(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取parquet</span></span><br><span class="line"><span class="comment">     * parquet格式的数据自带了表结构，不需要手动指定</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> parquetDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students&quot;</span>)</span><br><span class="line"></span><br><span class="line">    parquetDF.printSchema()</span><br><span class="line">    parquetDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 读取JDBC中的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> jdbcDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://master:3306&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;bigdata.students&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line">      .load()</span><br><span class="line"></span><br><span class="line">    jdbcDF.printSchema()</span><br><span class="line">    jdbcDF.show()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="5、RDDToDF"><a href="#5、RDDToDF" class="headerlink" title="5、RDDToDF"></a>5、RDDToDF</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo5RDDToDF</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取sparkContext，使用rdd ppi</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> sc: <span class="type">SparkContext</span> = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studnetRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = linesRDD</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">          (id, name, age, gender, clazz)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将rdd转换成DF</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = studnetRDD.toDF(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;name&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;gender&quot;</span>, <span class="string">&quot;clazz&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line">    studentDF.show()</span><br><span class="line"></span><br><span class="line">    spark</span><br><span class="line">      .read</span><br><span class="line">      .json()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="6、DFToRDD"><a href="#6、DFToRDD" class="headerlink" title="6、DFToRDD"></a>6、DFToRDD</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo6DFToRDD</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;rdd&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;json&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">    studentDF.printSchema()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将DF转换成RDD</span></span><br><span class="line">    <span class="keyword">val</span> studentRDD: <span class="type">RDD</span>[<span class="type">Row</span>] = studentDF.rdd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> stuRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map((row: <span class="type">Row</span>) =&gt; &#123;</span><br><span class="line">      <span class="comment">//通过列名获取数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = row.getAs[<span class="type">Long</span>](<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = row.getAs[<span class="type">String</span>](<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      (id, name, age, gender, clazz)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//stuRDD.foreach(println)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> caseRDD: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">Long</span>, <span class="type">String</span>, <span class="type">String</span>)] = studentRDD.map &#123;</span><br><span class="line">      <span class="comment">//需要注意字段顺序</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Row</span>(age: <span class="type">Long</span>, clazz: <span class="type">String</span>, gender: <span class="type">String</span>, id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    caseRDD.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="7、开窗"><a href="#7、开窗" class="headerlink" title="7、开窗"></a>7、开窗</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo7Window</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 窗口函数</span></span><br><span class="line"><span class="comment">     * row_number</span></span><br><span class="line"><span class="comment">     * rank</span></span><br><span class="line"><span class="comment">     * sum</span></span><br><span class="line"><span class="comment">     * count</span></span><br><span class="line"><span class="comment">     * avg</span></span><br><span class="line"><span class="comment">     * max</span></span><br><span class="line"><span class="comment">     * min</span></span><br><span class="line"><span class="comment">     * lag 取当前行前面</span></span><br><span class="line"><span class="comment">     * lead： 取当前行后面的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;window&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//学生表</span></span><br><span class="line">    <span class="keyword">val</span> studentDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;id STRING,name STRING,age INT,gender STRING,clazz STRING&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoreDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;sid STRING,cid STRING,sco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//科目表</span></span><br><span class="line">    <span class="keyword">val</span> subjectDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;cid STRING,cname STRING,ssco DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/subject.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> joinDF: <span class="type">DataFrame</span> = studentDF.join(scoreDF, $<span class="string">&quot;id&quot;</span> === $<span class="string">&quot;sid&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计总分年级排名前十学生各科的分数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * sum over 由两种用法</span></span><br><span class="line"><span class="comment">     * 1、之分区不拍戏----总和</span></span><br><span class="line"><span class="comment">     * 2、分区也排序-----累计求和</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//按总分排名</span></span><br><span class="line">      .orderBy($<span class="string">&quot;sumSco&quot;</span>.desc)</span><br><span class="line">      <span class="comment">//取top</span></span><br><span class="line">      .limit(<span class="number">60</span>)</span><br><span class="line">    <span class="comment">//.show(60)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、统计每科都及格的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreDF</span><br><span class="line">      <span class="comment">//关联科目表</span></span><br><span class="line">      .join(subjectDF, <span class="string">&quot;cid&quot;</span>)</span><br><span class="line">      <span class="comment">//1过滤不及格的分数</span></span><br><span class="line">      .where($<span class="string">&quot;sco&quot;</span> &gt;= $<span class="string">&quot;ssco&quot;</span> * <span class="number">0.6</span>)</span><br><span class="line">      <span class="comment">//统计每个学生几个的科目数</span></span><br><span class="line">      .withColumn(<span class="string">&quot;jige&quot;</span>, count($<span class="string">&quot;sid&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;sid&quot;</span>))</span><br><span class="line">      <span class="comment">//取出都及格的学生</span></span><br><span class="line">      .where($<span class="string">&quot;jige&quot;</span> === <span class="number">6</span>)</span><br><span class="line">    <span class="comment">//.show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、统计总分大于年级平均分的学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;sumSco&quot;</span>, sum($<span class="string">&quot;sco&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;id&quot;</span>))</span><br><span class="line">      <span class="comment">//计算年级平均分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;avgSco&quot;</span>, avg($<span class="string">&quot;sumSco&quot;</span>) over <span class="type">Window</span>.partitionBy(substring($<span class="string">&quot;clazz&quot;</span>, <span class="number">0</span>, <span class="number">2</span>)))</span><br><span class="line">      .where($<span class="string">&quot;sumSco&quot;</span> &gt; $<span class="string">&quot;avgSco&quot;</span>)</span><br><span class="line">    <span class="comment">//.show(1000)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计每个班级每个名次分数差</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * lag:取当前行前面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     * lead 取当前行后面的数据，需要分区和排序</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    joinDF</span><br><span class="line">      <span class="comment">//按照学号和班级分组</span></span><br><span class="line">      .groupBy($<span class="string">&quot;id&quot;</span>, $<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      <span class="comment">//计算总分</span></span><br><span class="line">      .agg(sum($<span class="string">&quot;sco&quot;</span>) as <span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      <span class="comment">//增加排名</span></span><br><span class="line">      .withColumn(<span class="string">&quot;r&quot;</span>, row_number() over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//取前一个名次的总分</span></span><br><span class="line">      .withColumn(<span class="string">&quot;headSumSco&quot;</span>, lag($<span class="string">&quot;sumSco&quot;</span>, <span class="number">1</span>, <span class="number">750</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;clazz&quot;</span>).orderBy($<span class="string">&quot;sumSco&quot;</span>.desc))</span><br><span class="line">      <span class="comment">//计算分数差</span></span><br><span class="line">      .withColumn(<span class="string">&quot;cha&quot;</span>, $<span class="string">&quot;headSumSco&quot;</span> - $<span class="string">&quot;sumSco&quot;</span>)</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="8、练习"><a href="#8、练习" class="headerlink" title="8、练习"></a>8、练习</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Column</span>, <span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8Burks</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">      .builder()</span><br><span class="line">      .appName(<span class="string">&quot;burk&quot;</span>)</span><br><span class="line">      .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">      .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="number">1</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">    <span class="comment">//读取数据</span></span><br><span class="line">    <span class="keyword">val</span> burksDF: <span class="type">DataFrame</span> = spark</span><br><span class="line">      .read</span><br><span class="line">      .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">      .option(<span class="string">&quot;sep&quot;</span>, <span class="string">&quot;,&quot;</span>)</span><br><span class="line">      .schema(<span class="string">&quot;burk STRING,year STRING,tsl01 DOUBLE,tsl02 DOUBLE,tsl03 DOUBLE,tsl04 DOUBLE,tsl05 DOUBLE,tsl06 DOUBLE,tsl07 DOUBLE,tsl08 DOUBLE,tsl09 DOUBLE,tsl10 DOUBLE,tsl11 DOUBLE,tsl12 DOUBLE&quot;</span>)</span><br><span class="line">      .load(<span class="string">&quot;data/burks.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    burksDF.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、统计每个公司每年按月累计收入  行转列 --&gt; sum窗口函数</span></span><br><span class="line"><span class="comment">     * 输出结果</span></span><br><span class="line"><span class="comment">     * 公司代码,年度,月份,当月收入,累计收入</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * sql</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    burksDF.createOrReplaceTempView(<span class="string">&quot;burks&quot;</span>)</span><br><span class="line"></span><br><span class="line">    spark.sql(</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |select</span></span><br><span class="line"><span class="string">        |burk,year,month,plc,</span></span><br><span class="line"><span class="string">        |sum(plc) over(partition by burk,year order by month) as leiji</span></span><br><span class="line"><span class="string">        | from (</span></span><br><span class="line"><span class="string">        |select burk,year,month,plc</span></span><br><span class="line"><span class="string">        |from burks</span></span><br><span class="line"><span class="string">        |lateral view explode(map(1,tsl01,2,tsl02,3,tsl03,4,tsl04,5,tsl05,6,tsl06,7,tsl07,8,tsl08,9,tsl09,10,tsl10,11,tsl11,12,tsl12)) T as month,plc</span></span><br><span class="line"><span class="string">        |) as a</span></span><br><span class="line"><span class="string">        |</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin)</span><br><span class="line">    <span class="comment">// .show(100)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * DSL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> m: <span class="type">Column</span> = map(</span><br><span class="line">      expr(<span class="string">&quot;1&quot;</span>), $<span class="string">&quot;tsl01&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;2&quot;</span>), $<span class="string">&quot;tsl02&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;3&quot;</span>), $<span class="string">&quot;tsl03&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;4&quot;</span>), $<span class="string">&quot;tsl04&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;5&quot;</span>), $<span class="string">&quot;tsl05&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;6&quot;</span>), $<span class="string">&quot;tsl06&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;7&quot;</span>), $<span class="string">&quot;tsl07&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;8&quot;</span>), $<span class="string">&quot;tsl08&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;9&quot;</span>), $<span class="string">&quot;tsl09&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;10&quot;</span>), $<span class="string">&quot;tsl10&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;11&quot;</span>), $<span class="string">&quot;tsl11&quot;</span>,</span><br><span class="line">      expr(<span class="string">&quot;12&quot;</span>), $<span class="string">&quot;tsl12&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    burksDF</span><br><span class="line">      <span class="comment">//一行转换成多行</span></span><br><span class="line">      .select($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>, explode(m) as <span class="type">Array</span>(<span class="string">&quot;month&quot;</span>, <span class="string">&quot;plc&quot;</span>))</span><br><span class="line">      <span class="comment">//计算按月累计</span></span><br><span class="line">      .withColumn(<span class="string">&quot;leiji&quot;</span>, sum($<span class="string">&quot;plc&quot;</span>) over <span class="type">Window</span>.partitionBy($<span class="string">&quot;burk&quot;</span>, $<span class="string">&quot;year&quot;</span>).orderBy($<span class="string">&quot;month&quot;</span>))</span><br><span class="line">      .show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="9、Spark-Sql"><a href="#9、Spark-Sql" class="headerlink" title="9、Spark Sql"></a>9、Spark Sql</h5><p><strong>spark-sql  写代码方式</strong></p><h6 id="1、idea里面将代码编写好打包上传到集群中运行，上线使用"><a href="#1、idea里面将代码编写好打包上传到集群中运行，上线使用" class="headerlink" title="1、idea里面将代码编写好打包上传到集群中运行，上线使用"></a>1、idea里面将代码编写好打包上传到集群中运行，上线使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--conf spark.sql.shuffle.partitions=1 -- 设置spark sqlshuffle之后分区数据马，和代码里面设置是一样的，代码中优先级高</span><br><span class="line">spark-submit提交</span><br><span class="line">spark-submit --master yarn-client --class com.shujia.spark.sql.Demo9Submit --conf spark.sql.shuffle.partitions=1 spark-1.0.jar </span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用"><a href="#2、spark-shell-repl-里面使用sqlContext-测试使用，简单任务使用" class="headerlink" title="2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用"></a>2、spark shell  (repl) 里面使用sqlContext     测试使用，简单任务使用</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark-shell --master yarn-client</span><br><span class="line">不能使用yarn-cluster Driver必须再本地启动</span><br></pre></td></tr></table></figure><h6 id="3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql"><a href="#3、spark-sql-spark-sql-–master-yarn-client-不能使用yarn-cluster-和hive的命令行一样，直接写sql" class="headerlink" title="3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql"></a>3、spark-sql    spark-sql –master yarn-client   不能使用yarn-cluster    和hive的命令行一样，直接写sql</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在spark-sql时完全兼容hive sql的</span><br><span class="line">spark-sql底层使用的时spark进行计算的</span><br><span class="line">hive 底层使用的是MR进行计算的</span><br></pre></td></tr></table></figure><h5 id="10、spark-sql整合hive"><a href="#10、spark-sql整合hive" class="headerlink" title="10、spark sql整合hive"></a>10、spark sql整合hive</h5><blockquote><p>在spark sql中使用hive的元数据</p><p>spark sql是使用spark进行计算的，hive使用MR进行计算的</p></blockquote><h6 id="1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"><a href="#1、在hive的hive-site-xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务" class="headerlink" title="1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务"></a>1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务</h6><p>cd &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hive-1.2.1&#x2F;conf&#x2F;</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://master:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h6 id="2、启动hive元数据服务-将hvie的元数据暴露给第三方使用"><a href="#2、启动hive元数据服务-将hvie的元数据暴露给第三方使用" class="headerlink" title="2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用"></a>2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup  hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="3、将hive-site-xml-复制到spark-conf目录下"><a href="#3、将hive-site-xml-复制到spark-conf目录下" class="headerlink" title="3、将hive-site.xml  复制到spark conf目录下"></a>3、将hive-site.xml  复制到spark conf目录下</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp hive-site.xml /usr/local/soft/spark-2.4.5/conf/</span><br></pre></td></tr></table></figure><h6 id="4、-将mysql-驱动包复制到spark-jars目录下"><a href="#4、-将mysql-驱动包复制到spark-jars目录下" class="headerlink" title="4、 将mysql 驱动包复制到spark jars目录下"></a>4、 将mysql 驱动包复制到spark jars目录下</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/hive-1.2.1/lib</span><br><span class="line">cp mysql-connector-java-5.1.49.jar /usr/local/soft/spark-2.4.5/jars/</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="5、整合好之后在spark-sql-里面就可以使用hive的表了"><a href="#5、整合好之后在spark-sql-里面就可以使用hive的表了" class="headerlink" title="5、整合好之后在spark-sql 里面就可以使用hive的表了"></a>5、整合好之后在spark-sql 里面就可以使用hive的表了</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">模式是<span class="built_in">local</span>模式</span></span><br><span class="line">spark-sql -conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用yarn-client模式</span></span><br><span class="line">spark-sql --master yarn-client  --conf  spark.sql.shuffle.partitions=2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">在spark-sql中设置运行参数</span></span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-e"><a href="#spark-sql-e" class="headerlink" title="spark-sql -e"></a>spark-sql -e</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 执行一条sql语句，执行完，自动退出</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>e &quot;select * from student&quot;</span><br></pre></td></tr></table></figure><h6 id="spark-sql-f"><a href="#spark-sql-f" class="headerlink" title="spark-sql -f"></a>spark-sql -f</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">vim a.sql</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student</span><br><span class="line"><span class="comment">-- 执行一个sql文件</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span> <span class="operator">-</span>f a.sql</span><br></pre></td></tr></table></figure><h6 id="当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表"><a href="#当spark-sql-和hive整合好之后再代码中也可以直接使用hive的表" class="headerlink" title="当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表"></a>当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表</h6><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span></span><br><span class="line">.builder()</span><br><span class="line">.appName(<span class="string">&quot;onhive&quot;</span>)</span><br><span class="line">.enableHiveSupport() <span class="comment">//开启hive的元数据支持，在代码中读取hive的元数据</span></span><br><span class="line">.getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">//读取hie的表</span></span><br><span class="line"><span class="keyword">val</span> studentDF = spark.talbe(<span class="string">&quot;studnet&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//写好的代码不能再本地运行， 需要打包上传到集群运行</span></span><br></pre></td></tr></table></figure><h6 id="spark-sql和hvie的建表语句一样"><a href="#spark-sql和hvie的建表语句一样" class="headerlink" title="spark sql和hvie的建表语句一样"></a>spark sql和hvie的建表语句一样</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student</span><br><span class="line">(</span><br><span class="line">id  string,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span>,</span><br><span class="line">gender string,</span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/student/&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score</span><br><span class="line">(</span><br><span class="line">student_id  string,</span><br><span class="line">cource_id string,</span><br><span class="line">sco <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">STORED <span class="keyword">AS</span> textfile</span><br><span class="line">location <span class="string">&#x27;/data/score/&#x27;</span>;</span><br></pre></td></tr></table></figure><h6 id="禁用集群spark日志"><a href="#禁用集群spark日志" class="headerlink" title="禁用集群spark日志"></a>禁用集群spark日志</h6><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/conf</span><br><span class="line">mv log4j.properties.template log4j.properties</span><br><span class="line">vim log4j.properties</span><br><span class="line">修改配置</span><br><span class="line">log4j.rootCategory=ERROR, console</span><br></pre></td></tr></table></figure><h5 id="11、spark-sql和hive区别"><a href="#11、spark-sql和hive区别" class="headerlink" title="11、spark sql和hive区别"></a>11、spark sql和hive区别</h5><h6 id="1、spark-sql缓存"><a href="#1、spark-sql缓存" class="headerlink" title="1、spark sql缓存"></a>1、spark sql缓存</h6><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 进入spark sql命令行</span></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span></span><br><span class="line"><span class="comment">-- 可以通过一个网址访问spark任务</span></span><br><span class="line">http:<span class="operator">/</span><span class="operator">/</span>master:<span class="number">4040</span></span><br><span class="line"><span class="comment">-- 设置并行度</span></span><br><span class="line"><span class="keyword">set</span> spark.sql.shuffle.partitions<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再spark-sql中对同一个表进行多次查询的时候可以将表缓存起来</span></span><br><span class="line">cache <span class="keyword">table</span> student;</span><br><span class="line"><span class="comment">-- 删除缓存</span></span><br><span class="line">uncache <span class="keyword">table</span> student;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 再代码中也可以缓存DF</span></span><br><span class="line"> studentDF.persist(StorageLevel.MEMORY_ONLY)</span><br></pre></td></tr></table></figure><h6 id="2、spark-sql-mapjoin-—-广播变量"><a href="#2、spark-sql-mapjoin-—-广播变量" class="headerlink" title="2、spark sql mapjoin    — 广播变量"></a>2、spark sql mapjoin    — 广播变量</h6><h5 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><h5 id="MapJoin"><a href="#MapJoin" class="headerlink" title="MapJoin"></a>MapJoin</h5><blockquote><p>当一个大表关联小表的时候可以将小表加载到内存中进行关联—- 广播变量</p><p>在map端进行表关联，不会产生shuffle</p></blockquote> <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+broadcast(a)  */</span> <span class="operator">*</span> <span class="keyword">from</span> </span><br><span class="line">student <span class="keyword">as</span> a</span><br><span class="line"><span class="keyword">join</span> </span><br><span class="line">score <span class="keyword">as</span> b</span><br><span class="line"><span class="keyword">on</span></span><br><span class="line">a.id<span class="operator">=</span>b.student_id</span><br></pre></td></tr></table></figure><blockquote><p>&#x2F;*+broadcast(a)  *&#x2F;   HINT:给sql加提示的语法</p></blockquote><h5 id="12、Spaark-JDBC"><a href="#12、Spaark-JDBC" class="headerlink" title="12、Spaark JDBC"></a>12、Spaark JDBC</h5><h6 id="1、开启hive的元数据服务"><a href="#1、开启hive的元数据服务" class="headerlink" title="1、开启hive的元数据服务"></a>1、开启hive的元数据服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup hive --service metastore &gt;&gt; metastore.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h6 id="2、开启spark-jdbc-服务"><a href="#2、开启spark-jdbc-服务" class="headerlink" title="2、开启spark jdbc  服务"></a>2、开启spark jdbc  服务</h6><blockquote><p>saprkjdbc服务使用的就是hive的jdbc服务</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/sbin/</span><br><span class="line">./start-thriftserver.sh --master yarn-client</span><br></pre></td></tr></table></figure><h6 id="3、使用命令链接spark-sql-jdbc服务"><a href="#3、使用命令链接spark-sql-jdbc服务" class="headerlink" title="3、使用命令链接spark sql  jdbc服务"></a>3、使用命令链接spark sql  jdbc服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/bin/</span><br><span class="line">./beeline </span><br><span class="line">输入</span><br><span class="line">!connect jdbc:hive2://master:10000</span><br><span class="line"></span><br><span class="line">设置sparkshuffle并行度</span><br><span class="line">set spark.sql.shuffle.partitions=2;</span><br></pre></td></tr></table></figure><h6 id="4、使用scala代码远程链接spark-sql-jdbc服务"><a href="#4、使用scala代码远程链接spark-sql-jdbc服务" class="headerlink" title="4、使用scala代码远程链接spark sql jdbc服务"></a>4、使用scala代码远程链接spark sql jdbc服务</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">-- 1、在maven增加增加jdbc驱动</span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">-- 2、编写java jdbc代码</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark搭建</title>
      <link href="/2022/07/12/spark%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/07/12/spark%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h3 id="Spark搭建"><a href="#Spark搭建" class="headerlink" title="Spark搭建"></a>Spark搭建</h3><h4 id="一、standalone模式"><a href="#一、standalone模式" class="headerlink" title="一、standalone模式"></a>一、standalone模式</h4><h5 id="1、上传解压，配置环境变量-配置bin目录"><a href="#1、上传解压，配置环境变量-配置bin目录" class="headerlink" title="1、上传解压，配置环境变量 配置bin目录"></a>1、上传解压，配置环境变量 配置bin目录</h5><p>解压</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf spark-2.4.5-bin-hadoop2.7.tgz </span><br></pre></td></tr></table></figure><p>重命名</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv spark-2.4.5-bin-hadoop2.7 spark-2.4.5</span><br></pre></td></tr></table></figure><p>配置环境变量<br><img src="https://s2.loli.net/2022/07/13/JhzWDHme6kwMncb.png" alt="image-20220713092425892"></p><h5 id="2、修改配置文件-conf"><a href="#2、修改配置文件-conf" class="headerlink" title="2、修改配置文件(conf)"></a>2、修改配置文件(conf)</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export SPARK_MASTER_IP=master</span><br><span class="line">export SPARK_MASTER_PORT=7077</span><br><span class="line"></span><br><span class="line">export SPARK_WORKER_CORES=2</span><br><span class="line">export SPARK_WORKER_INSTANCES=1</span><br><span class="line">export SPARK_WORKER_MEMORY=2g</span><br><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><p>master相当于RM  worker相当于NM</p><p>增加从节点配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim slaves</span><br><span class="line">增加从节点</span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><h5 id="3、复制到其它节点"><a href="#3、复制到其它节点" class="headerlink" title="3、复制到其它节点"></a>3、复制到其它节点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r spark-2.4.5 node1:`pwd`</span><br><span class="line">scp -r spark-2.4.5 node2:`pwd`</span><br></pre></td></tr></table></figure><h5 id="4、在主节点执行启动命令"><a href="#4、在主节点执行启动命令" class="headerlink" title="4、在主节点执行启动命令"></a>4、在主节点执行启动命令</h5><p>​    启动集群，在master中执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./sbin/start-all.sh</span><br></pre></td></tr></table></figure><figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">http://master:8080/  访问spark ui</span><br></pre></td></tr></table></figure><h5 id="5、两种spark提交任务的方式"><a href="#5、两种spark提交任务的方式" class="headerlink" title="5、两种spark提交任务的方式"></a>5、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><p>（1）standalone client模式 日志在本地输出，一般用于上线前测试(bin&#x2F;下执行)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512m --total-executor-cores 1 spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）standalone cluster模式，上线使用，不会再本地打印日志</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 --executor-memory 512M --total-executor-cores 1 --deploy-mode cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码"><a href="#6、spark-shell-spark-提供的一个交互式的命令行，可以直接写代码" class="headerlink" title="6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码"></a>6、spark-shell   spark 提供的一个交互式的命令行，可以直接写代码</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-shell master spark://master:7077</span><br></pre></td></tr></table></figure><h4 id="二、spark整合yarn"><a href="#二、spark整合yarn" class="headerlink" title="二、spark整合yarn"></a>二、spark整合yarn</h4><p>​        在公司一般不适用standalone模式，因为公司一般已经有yarn，不需要搞两个资源管理框架</p><p>首先停止spark集群，在spark sbin目录下执行  .&#x2F;stop-all.sh，也要保证hadoop也是关闭的</p><p>spark整合yarn只需要在一个节点整合, 可以删除node1 和node2中所有的spark 文件（也可以不删除）</p><h5 id="1、增加hadoop-配置文件地址"><a href="#1、增加hadoop-配置文件地址" class="headerlink" title="1、增加hadoop 配置文件地址"></a>1、增加hadoop 配置文件地址</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim spark-env.sh</span><br><span class="line">增加配置</span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/soft/hadoop-2.7.6/etc/hadoop</span><br></pre></td></tr></table></figure><h5 id="2、往yarn提交任务需要增加两个配置-yarn-site-xml"><a href="#2、往yarn提交任务需要增加两个配置-yarn-site-xml" class="headerlink" title="2、往yarn提交任务需要增加两个配置  yarn-site.xml"></a>2、往yarn提交任务需要增加两个配置  yarn-site.xml</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/usr/local/soft/hadoop-2.7.6/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>增加配置</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="3、同步到其他节点，重启yarn"><a href="#3、同步到其他节点，重启yarn" class="headerlink" title="3、同步到其他节点，重启yarn"></a>3、同步到其他节点，重启yarn</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r yarn-site.xml node1:`pwd`</span><br><span class="line">scp -r yarn-site.xml node2:`pwd`</span><br></pre></td></tr></table></figure><p>启动yarn</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h5 id="4、两种spark提交任务的方式"><a href="#4、两种spark提交任务的方式" class="headerlink" title="4、两种spark提交任务的方式"></a>4、两种spark提交任务的方式</h5><p>需要进入到spark-examples_2.11-2.4.5.jar 包所在的目录下执行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/spark-2.4.5/examples/jars</span><br></pre></td></tr></table></figure><p>（1）spark on yarn client模式，日志在本地输出，一般用于上线前测试</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-client spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><p>（2）spark on yarn cluster模式，上线使用，不会再本地打印日志减少io</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster spark-examples_2.11-2.4.5.jar 100</span><br></pre></td></tr></table></figure><h5 id="5、获取yarn程序执行日志-执行成功之后才能获取到"><a href="#5、获取yarn程序执行日志-执行成功之后才能获取到" class="headerlink" title="5、获取yarn程序执行日志  执行成功之后才能获取到"></a>5、获取yarn程序执行日志  执行成功之后才能获取到</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yarn logs -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><h5 id="6、杀掉进行的任务"><a href="#6、杀掉进行的任务" class="headerlink" title="6、杀掉进行的任务"></a>6、杀掉进行的任务</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn application -applicationId application_1560967444524_0003</span><br></pre></td></tr></table></figure><p>hdfs web ui<br><a href="http://node1:50070/">http://node1:50070</a></p><p>yarn ui<br><a href="http://node1:8088/">http://node1:8088</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark代码</title>
      <link href="/2022/07/11/spark%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/07/11/spark%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h5 id="1、编写wordcount-（standalone模式）"><a href="#1、编写wordcount-（standalone模式）" class="headerlink" title="1、编写wordcount    （standalone模式）"></a>1、编写wordcount    （standalone模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  建立连接</span></span><br><span class="line"><span class="comment">     *  提交到集群运行需要注释setMaster</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo18SparkSubmit&quot;</span>)</span><br><span class="line"><span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> valuesRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.parallelize(<span class="type">List</span>(<span class="string">&quot;java,java,hadoop&quot;</span>, <span class="string">&quot;spark,scala,java&quot;</span>, <span class="string">&quot;hadoop,hadoop,scala&quot;</span>)) </span><br><span class="line">    valuesRDD.flatMap(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_+_) <span class="comment">//按key聚合</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master spark://master:7077 spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="2、编写wordcount-（on-yarn模式）"><a href="#2、编写wordcount-（on-yarn模式）" class="headerlink" title="2、编写wordcount    （on yarn模式）"></a>2、编写wordcount    （on yarn模式）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 建立连接，注释掉setMaster一行</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line"></span><br><span class="line">    conf.setAppName(<span class="string">&quot;submit on yarn&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    conf.setMaster(&quot;local&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">Configuration</span>()</span><br><span class="line">    <span class="keyword">val</span> fileSystem: <span class="type">FileSystem</span> = <span class="type">FileSystem</span>.get(conf)</span><br><span class="line">    <span class="keyword">if</span> (fileSystem.exists(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>))) &#123;</span><br><span class="line">      fileSystem.delete(<span class="keyword">new</span> <span class="type">Path</span>(<span class="string">&quot;path&quot;</span>), <span class="literal">true</span>)<span class="comment">//若存在，删除目标路径</span></span><br><span class="line"></span><br><span class="line">    sc.textFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs的输入路径</span></span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map &#123;</span><br><span class="line">        word: <span class="type">String</span> =&gt;</span><br><span class="line">          (word, <span class="number">1</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      .reduceByKey(_ + _)</span><br><span class="line">      .map &#123;</span><br><span class="line">        <span class="keyword">case</span> (word: <span class="type">String</span>, count: <span class="type">Int</span>) =&gt;</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$word</span>\t<span class="subst">$count</span>&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">      .saveAsTextFile(<span class="string">&quot;path&quot;</span>) <span class="comment">//path:hdfs输出目录，保证目标路径不存在</span></span><br><span class="line">    </span><br><span class="line">       <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将本地的代码打成jar包提交到集群运行</span></span><br><span class="line"><span class="comment">     * spark-submit --class 主类名称 --master yarn-client spark-1.0.jar</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h5 id="3、用spark代码实现PI的计算"><a href="#3、用spark代码实现PI的计算" class="headerlink" title="3、用spark代码实现PI的计算"></a>3、用spark代码实现PI的计算</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20PI</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 创建spark环境</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo20PI&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">//生成一个大集合</span></span><br><span class="line">    <span class="keyword">val</span> list: <span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="number">0</span> to <span class="number">100000</span></span><br><span class="line">    <span class="comment">//构建一个很大的RDD</span></span><br><span class="line">    <span class="keyword">val</span> rdd: <span class="type">RDD</span>[<span class="type">Int</span>] = sc.parallelize(list)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//随机生成正方形内的点</span></span><br><span class="line">    <span class="keyword">val</span> squareRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = rdd.map(i =&gt; &#123;</span><br><span class="line">      <span class="comment">//随机生成x和y，范围是[-1,1]</span></span><br><span class="line">      <span class="keyword">val</span> x: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> y: <span class="type">Double</span> = <span class="type">Random</span>.nextDouble() * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">      (x, y)</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="comment">//取出圆内的点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> circleRDD: <span class="type">RDD</span>[(<span class="type">Double</span>, <span class="type">Double</span>)] = squareRDD.filter &#123;</span><br><span class="line">      <span class="keyword">case</span> (x, y) =&gt;</span><br><span class="line">        x * x + y * y &lt; <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">PI</span>: <span class="type">Double</span> = <span class="number">4.0</span> * circleRDD.count() / squareRDD.count()</span><br><span class="line"></span><br><span class="line">    println(<span class="type">PI</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="4、spark代码的坑（引出累加器）"><a href="#4、spark代码的坑（引出累加器）" class="headerlink" title="4、spark代码的坑（引出累加器）"></a>4、spark代码的坑（引出累加器）</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">  count += <span class="number">1</span></span><br><span class="line">  println(count)</span><br><span class="line">&#125;)</span><br><span class="line">  println (<span class="string">s&quot;count:<span class="subst">$&#123;count&#125;</span>&quot;</span>) <span class="comment">//不要这么写</span></span><br></pre></td></tr></table></figure><p>在spark编程中算子内的代码会被封装成Task发送到<strong>Executor</strong>中去执行，而算子外的代码运行在driver端，Executor和Driver属于不同的JVM，所以当在算子内修改算子外的一个普通变量时不会生效，当算子内使用算子外的一个普通变量时，这个变量会以变量副本的形式发送给Executor中去。</p><p><strong>累加器</strong></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、定义一个累加器</span></span><br><span class="line">   <span class="keyword">val</span> accumulator: <span class="type">LongAccumulator</span> = sc.longAccumulator</span><br><span class="line"></span><br><span class="line">   studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="comment">//2、对累加器进行累加</span></span><br><span class="line">     accumulator.add(<span class="number">1</span>)</span><br><span class="line">   &#125;)</span><br><span class="line">   <span class="comment">//3、再从Driver端读取累加结果</span></span><br><span class="line">   println(<span class="string">s&quot;accumulator:<span class="subst">$&#123;accumulator.value&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>累加器原理</strong></p><p>1、现在每一个task中局部做累加</p><p>2、当job执行完成之后，将多个累加结果汇总到Driver端合并成一个结果</p><p><strong>累加器使用的限制</strong></p><p>1、只能在Driver端定义累加器</p><p>2、只能在Executor端进行累加</p><p>3、只能在Driver端读取结果</p><p>在spark写代码的过程中，rdd不能嵌套使用，在算子内不能使用rdd</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">       println(stu)</span><br><span class="line">     &#125;)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><p>在算子内 不能使用SparkContext，算子会被封装成一个Task，而Task不能被序列化（Task需要网络传输）</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">studentRDD.foreach(stu=&gt;&#123;</span><br><span class="line">     <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line">     scoreRDD.foreach(println)</span><br><span class="line">   &#125;)</span><br></pre></td></tr></table></figure><h5 id="5、广播变量"><a href="#5、广播变量" class="headerlink" title="5、广播变量"></a>5、广播变量</h5><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Broadcast</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="string">&quot;Demo23Broadcast&quot;</span>)</span><br><span class="line">    conf.setMaster(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 广播变量</span></span><br><span class="line"><span class="comment">     * 当算子内使用算子外的一个比较大的变量时，可以将这个变量广播出去，可以减少变量的副本数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">      <span class="comment">//读取学生表，以学号作为key构建一个map集合</span></span><br><span class="line">    <span class="keyword">val</span> studentMap: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">      .getLines()</span><br><span class="line">      .toList</span><br><span class="line">      .map(stu =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> id: <span class="type">String</span> = stu.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">        (id, stu)</span><br><span class="line">      &#125;)</span><br><span class="line">      .toMap</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scoreRDD: <span class="type">RDD</span>[<span class="type">String</span>] = sc.textFile(<span class="string">&quot;data/score.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关联学生表和分数表</span></span><br><span class="line"><span class="comment">     * 循环分数表，使用学号到学生表的map集合中查询学生的信息</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    scoreRDD.map(sco=&gt;&#123;</span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = sco.split(<span class="string">&quot;,&quot;</span>)(<span class="number">0</span>)</span><br><span class="line">      <span class="comment">//使用学号到学生表中获取学生的信息</span></span><br><span class="line">      <span class="keyword">val</span> studentInfo: <span class="type">String</span> = studentMap.getOrElse(id, <span class="string">&quot;默认值&quot;</span>)</span><br><span class="line">      (sco,studentInfo)</span><br><span class="line">    &#125;)</span><br><span class="line">      .foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在使用算子内使用算子外的一个普通变量时，普通变量会以变量副本的形式封装到Task中，将Task发送到Executor中执行。</p><p>如果rdd有10个分区，则会产生10个Task，汇总产生10个变量副本</p><p>广播变量的使用（在spark中常用于<strong>mapJoin</strong>）</p><p>1、在Driver端定义广播变量</p><p>2、到Executor使用广播变量</p><p>如果不使用广播变量，每一个task都需要携带一个变量副本每增加网络IO，增加副本数</p><p>使用广播每一个Executor中的一个变量副本</p><p>正常情况时task的数量远小于Executor的数量</p><p>mapJoin不产生shuffle，性能比reduceJoin好</p><p>mapJoin只适合小表关联大表（小表的数据量不超1G）</p><p><img src="https://s2.loli.net/2022/07/14/tSmhnvJM327pbxF.png" alt="blockmanasger"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark概述</title>
      <link href="/2022/07/10/spark%E6%A6%82%E8%BF%B0/"/>
      <url>/2022/07/10/spark%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://s2.loli.net/2022/07/13/v6e4yxQ98YuOZKD.png" alt="屏幕截图 2022-07-13 095014"></p><p>MapReduce执行流程</p><p><img src="https://s2.loli.net/2022/07/13/b91AKcnLVuo3UvE.png" alt="mr执行流程"></p><p>RDD基础</p><p><img src="https://s2.loli.net/2022/07/13/9pGtPZL3gwcxoq4.png" alt="image-20220713095434515"></p><p>reduceByKey和groupByKey的区别</p><p><img src="https://s2.loli.net/2022/07/13/eGU2wRthNzT9Fbq.png" alt="reduceByKey金额groupByKey的区别"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala概述及使用</title>
      <link href="/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2022/07/06/scala%E6%A6%82%E8%BF%B0%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3 id="1、scala介绍"><a href="#1、scala介绍" class="headerlink" title="1、scala介绍"></a>1、scala介绍</h3><p>Scala 是 Scalable Language 的简写，是一门多范式的编程语言</p><p>联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计Scala。</p><p>Scala是把函数式编程思想和面向对象编程思想结合的一种编程语言。</p><p>大数据计算引擎Spark由Scala编写</p><h3 id="2、Scala特点"><a href="#2、Scala特点" class="headerlink" title="2、Scala特点"></a>2、Scala特点</h3><p><strong>多范式</strong>：面向对象，函数式编程</p><p><strong>兼容JAVA</strong>：类库调用，互操作</p><p><strong>语法简洁</strong>：代码行短，类型推断，抽象控制</p><p><strong>静态类型化</strong>：可检验，安全重构</p><p><strong>支持并发控制</strong>：强计算能力，自定义其他控制结构</p><p>在面向对象编程中，我们把对象传来传去，那在函数式编程中，我们要做的是把函数传来传去，而这个，说成术语，我们把他叫做高阶函数。</p><p>在函数式编程中，函数是基本单位，，他几乎被用作一切，包括最简单的计算，甚至连变量都被计算所取代。在函数式编程中，变量只是一个名称，而不是一个存储单元，这是函数式编程与传统的命令式编程最典型的不同之处。</p><h3 id="3、scala和java的联系"><a href="#3、scala和java的联系" class="headerlink" title="3、scala和java的联系"></a>3、scala和java的联系</h3><p><img src="https://s2.loli.net/2022/07/13/4ahsL5tkqSGlf2m.png" alt="屏幕截图 2022-07-13 102038"></p><h3 id="4、环境准备及代码编写"><a href="#4、环境准备及代码编写" class="headerlink" title="4、环境准备及代码编写"></a>4、环境准备及代码编写</h3><h4 id="1、在idea中增加scala插件"><a href="#1、在idea中增加scala插件" class="headerlink" title="1、在idea中增加scala插件"></a>1、在idea中增加scala插件</h4><p><img src="https://s2.loli.net/2022/07/13/DogYxlEBcjnZVKy.png" alt="image-20220713102325386"></p><h4 id="2、新建一个maven项目，在pom中增加Scala和java的编译插件"><a href="#2、新建一个maven项目，在pom中增加Scala和java的编译插件" class="headerlink" title="2、新建一个maven项目，在pom中增加Scala和java的编译插件"></a>2、新建一个maven项目，在pom中增加Scala和java的编译插件</h4><h5 id="（1）在pom文件中增加依赖"><a href="#（1）在pom文件中增加依赖" class="headerlink" title="（1）在pom文件中增加依赖"></a>（1）在pom文件中增加依赖</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-compiler<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-reflect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="（2）在pom中增加Scala和java的编译插件"><a href="#（2）在pom中增加Scala和java的编译插件" class="headerlink" title="（2）在pom中增加Scala和java的编译插件"></a>（2）在pom中增加Scala和java的编译插件</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Scala Compiler --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-scala-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.15.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>testCompile<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="3、scala样例类"><a href="#3、scala样例类" class="headerlink" title="3、scala样例类"></a>3、scala样例类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo8CaseClass</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> user1 = <span class="keyword">new</span> <span class="type">User</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;张三&quot;</span>)</span><br><span class="line">    <span class="comment">//直接通过属性获取值</span></span><br><span class="line">    println(user1.id)</span><br><span class="line">    println(user1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//样例类可以不适用new创建对象</span></span><br><span class="line">    <span class="keyword">val</span> user2: <span class="type">User</span> = <span class="type">User</span>(<span class="string">&quot;002&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="number">24</span>)</span><br><span class="line">    println(user2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//修改属性,需要在属性上增加var</span></span><br><span class="line">    user2.name = <span class="string">&quot;王五&quot;</span></span><br><span class="line">    println(user2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 样例类</span></span><br><span class="line"><span class="comment"> * scala会在编译的时候给样例类动态增加新的方法，属性，toString，序列化</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * age: Int = 0: 参数默认值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span>(<span class="params">id: <span class="type">String</span>,var name: <span class="type">String</span>, age: <span class="type">Int</span> = 0</span>)</span></span><br></pre></td></tr></table></figure><h4 id="4、List"><a href="#4、List" class="headerlink" title="4、List"></a>4、List</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo15List</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合</span></span><br><span class="line"><span class="comment">     * 1、List: 有序，不唯一</span></span><br><span class="line"><span class="comment">     * 2、Set ：无序，唯一</span></span><br><span class="line"><span class="comment">     * 3、Map: kv格式   key是唯一的</span></span><br><span class="line"><span class="comment">     * 4、Tuple: 元组，固定长度集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * List集合</span></span><br><span class="line"><span class="comment">     * scal的集合比java的集合好用-多了很多的方法</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//不可变的List</span></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标获取数据</span></span><br><span class="line">    println(list(<span class="number">3</span>))</span><br><span class="line">    <span class="comment">//获取第一个元素</span></span><br><span class="line">    println(list.head)</span><br><span class="line">    <span class="comment">//获取最后一个元素</span></span><br><span class="line">    println(list.last)</span><br><span class="line">    <span class="comment">//获取不包含第一个元素的所有的元素</span></span><br><span class="line">    println(list.tail)</span><br><span class="line">    <span class="comment">//将集合中的元素拼接成一个字符串</span></span><br><span class="line">    println(list.mkString(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment">//反转，返回一个新的List</span></span><br><span class="line">    println(list.reverse)</span><br><span class="line">    <span class="comment">//取前n个元素</span></span><br><span class="line">    println(list.take(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//取后n个元素</span></span><br><span class="line">    println(list.takeRight(<span class="number">4</span>))</span><br><span class="line">    <span class="comment">//去重</span></span><br><span class="line">    println(list.distinct)</span><br><span class="line">    <span class="comment">//求和，集合元素的类型必须是可以求和的类型</span></span><br><span class="line">    println(list.sum)</span><br><span class="line">    <span class="comment">//取最大值</span></span><br><span class="line">    println(list.max)</span><br><span class="line">    <span class="comment">//最小值</span></span><br><span class="line">    println(list.min)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * foreach: 循环集合，将集合中的元素一个一个传递给后面的函数，foreach没有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">var</span> sum = <span class="number">0</span></span><br><span class="line">    <span class="comment">//循环统计总和</span></span><br><span class="line">    list.foreach((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      sum += i</span><br><span class="line">    &#125;)</span><br><span class="line">    println(sum)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个元素加一（处理集合中的元素）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- list) &#123;</span><br><span class="line">      <span class="keyword">val</span> j = i * <span class="number">2</span></span><br><span class="line">      println(j)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map:循环集合将集合中的元素一个一个传递给后面的函数，函数的返回值会构建出一个新的集合</span></span><br><span class="line"><span class="comment">     * i代表的是集合中所有的元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mapList: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    println(mapList)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理集合中的元素，偶数加1，奇数乘以2</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list2: <span class="type">List</span>[<span class="type">Int</span>] = list.map((i: <span class="type">Int</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        i * <span class="number">2</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        i + <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    println(list2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 取出集合中奇数</span></span><br><span class="line"><span class="comment">     * Filter: 循环集合，将集合中的元素一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 如果函数返回true保留数据，如果函数返回false过滤数据</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> jishuList: <span class="type">List</span>[<span class="type">Int</span>] = list.filter((i: <span class="type">Int</span>) =&gt; i % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line">    println(jishuList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将一行中的多个单词拆分出来，一个单纯一行</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> linesList = <span class="type">List</span>(<span class="string">&quot;java,spark,hadoop&quot;</span>, <span class="string">&quot;datax,scala,java&quot;</span>, <span class="string">&quot;hadoop,hive,sqoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (line &lt;- linesList) &#123;</span><br><span class="line">      <span class="keyword">val</span> split: <span class="type">Array</span>[<span class="type">String</span>] = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">      <span class="keyword">for</span> (word &lt;- split) &#123;</span><br><span class="line">        println(word)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * flatMap: 循环集合中的元素，将袁术一个一个传递给后面的函数</span></span><br><span class="line"><span class="comment">     * 函数返回一个集合，flatMap会将返回的集合拆分出来构建成一个新的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> wordsList: <span class="type">List</span>[<span class="type">String</span>] = linesList.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    wordsList.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 多集合排序</span></span><br><span class="line"><span class="comment">     * sortBy: 需要指定一个排序的字段，默认是升序</span></span><br><span class="line"><span class="comment">     * sortWith: 指定一个排序的比较规则</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> list3: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">32</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortByList = list3.sortBy((i: <span class="type">Int</span>) =&gt; -i)</span><br><span class="line">    println(sortByList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sortWithList = list3.sortWith((x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x &gt; y)</span><br><span class="line">    println(sortWithList)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * groupBy: 分组，需要指定一个分组的字段</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> words = <span class="type">List</span>(<span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;java&quot;</span>, <span class="string">&quot;spark&quot;</span>, <span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    groupByList.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 以下所有的方法都是返回新的集合，不会修改原始的集合</span></span><br><span class="line"><span class="comment">     * 同时以下这些方法在set集合中也有，除了sort</span></span><br><span class="line"><span class="comment">     * foreach:遍历数据</span></span><br><span class="line"><span class="comment">     * map：一条一条处理数据</span></span><br><span class="line"><span class="comment">     * filter：过滤数据</span></span><br><span class="line"><span class="comment">     * flatMap:将一行转换成多行</span></span><br><span class="line"><span class="comment">     * sortBy：排序</span></span><br><span class="line"><span class="comment">     * groupBy：分组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5、Set"><a href="#5、Set" class="headerlink" title="5、Set"></a>5、Set</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo16Set</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Set集合，无序，唯一</span></span><br><span class="line"><span class="comment">     * set集合比List集合少了排序的方法，其它的方法基本一致</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> set = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line">    println(set)</span><br><span class="line">    println(set.mkString(<span class="string">&quot;\t&quot;</span>))</span><br><span class="line">    set.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> s1 = <span class="type">Set</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">val</span> s2 = <span class="type">Set</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    println(s1 &amp; s2)<span class="comment">//交集</span></span><br><span class="line">    println(s1 | s2)<span class="comment">//并集</span></span><br><span class="line">    println(s1 &amp;~ s2)<span class="comment">//差集</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 集合之前的转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line">    println(list)</span><br><span class="line">    <span class="keyword">val</span> listSet = list.toSet</span><br><span class="line">    println(listSet)</span><br><span class="line">    println(listSet.toList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="6、Mutable"><a href="#6、Mutable" class="headerlink" title="6、Mutable"></a>6、Mutable</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo17Mutable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变集合</span></span><br><span class="line"><span class="comment">     * ListBuffer:List有的方法ListBuffer都有，只是ListBuffer是可以改变的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> listBuffer = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    listBuffer.+=(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    listBuffer += <span class="string">&quot;spark&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;hadoop&quot;</span></span><br><span class="line">    listBuffer += <span class="string">&quot;flume&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    listBuffer -= <span class="string">&quot;java&quot;</span></span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用下标删除钠元素</span></span><br><span class="line">    listBuffer.remove(<span class="number">1</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//批量插入元素</span></span><br><span class="line">    listBuffer ++= <span class="type">List</span>(<span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>, <span class="string">&quot;asd&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//更新元素</span></span><br><span class="line">    listBuffer.update(<span class="number">1</span>, <span class="string">&quot;shujia&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过下标插入元素</span></span><br><span class="line">    listBuffer.insert(<span class="number">2</span>, <span class="string">&quot;大数据&quot;</span>)</span><br><span class="line">    println(listBuffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变Set</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashSet = <span class="keyword">new</span> mutable.<span class="type">HashSet</span>[<span class="type">Int</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//增加元素</span></span><br><span class="line">    hashSet += <span class="number">1</span></span><br><span class="line">    hashSet += <span class="number">2</span></span><br><span class="line">    hashSet += <span class="number">3</span></span><br><span class="line">    hashSet += <span class="number">4</span></span><br><span class="line">    hashSet += <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    println(hashSet)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashSet -= <span class="number">1</span></span><br><span class="line">    println(hashSet)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="7、Tuple"><a href="#7、Tuple" class="headerlink" title="7、Tuple"></a>7、Tuple</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo18Tuple</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 元组：固定长度集合</span></span><br><span class="line"><span class="comment">     * 可以通过下划线加上下标获取数据, 可以避免下标越界异常</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 元组最多只能存22个元素</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//val tuple = Tuple6(1, 2, 3, 4, 5, 6)</span></span><br><span class="line">    <span class="comment">//简写</span></span><br><span class="line">    <span class="keyword">val</span> tuple = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    println(tuple._6)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8、Map"><a href="#8、Map" class="headerlink" title="8、Map"></a>8、Map</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.mutable</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo19Map</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map：kv格式的集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = <span class="type">Map</span>((<span class="string">&quot;001&quot;</span>, <span class="number">23</span>), (<span class="string">&quot;002&quot;</span>, <span class="number">24</span>), <span class="string">&quot;003&quot;</span> -&gt; <span class="number">25</span>)</span><br><span class="line">    println(map)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以通过key获取value</span></span><br><span class="line">    <span class="keyword">val</span> value = map(<span class="string">&quot;001&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果key不存在返回默认值</span></span><br><span class="line">    <span class="keyword">val</span> age = map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="number">0</span>)</span><br><span class="line">    println(age)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 给每个人的年龄加一</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * map集合的map方法，函数的参数是一个二元组,</span></span><br><span class="line"><span class="comment">     * 返回一个新的map</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> addAge: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = map.map((kv: (<span class="type">String</span>, <span class="type">Int</span>)) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> id = kv._1</span><br><span class="line">      <span class="keyword">val</span> age = kv._2</span><br><span class="line">      (id, age + <span class="number">1</span>)</span><br><span class="line">    &#125;)</span><br><span class="line">    println(addAge)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取所有的key和value</span></span><br><span class="line">    println(map.keys)</span><br><span class="line">    println(map.values)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 可变map集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> hashMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">String</span>]()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//插入元素</span></span><br><span class="line">    hashMap += <span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;王五&quot;</span></span><br><span class="line"></span><br><span class="line">    println(hashMap)</span><br><span class="line">    <span class="comment">//如果key存在自动覆盖</span></span><br><span class="line">    hashMap += <span class="string">&quot;003&quot;</span> -&gt; <span class="string">&quot;赵六&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//删除元素</span></span><br><span class="line">    hashMap.remove(<span class="string">&quot;003&quot;</span>)</span><br><span class="line">    hashMap -= <span class="string">&quot;002&quot;</span></span><br><span class="line">    println(hashMap)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="9、WordCount"><a href="#9、WordCount" class="headerlink" title="9、WordCount"></a>9、WordCount</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo20WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 统计单纯的数量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//链式调用</span></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/words.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将一行中的多个单纯展开，变成一个单词一行</span></span><br><span class="line">    <span class="keyword">val</span> words: <span class="type">List</span>[<span class="type">String</span>] = lines.flatMap((line: <span class="type">String</span>) =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、按照单词分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>]] = words.groupBy((word: <span class="type">String</span>) =&gt; word)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、统计单词的数量</span></span><br><span class="line">    <span class="keyword">val</span> wordCount: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupBy.map((kv: (<span class="type">String</span>, <span class="type">List</span>[<span class="type">String</span>])) =&gt; &#123;</span><br><span class="line">      <span class="comment">//分组单词</span></span><br><span class="line">      <span class="keyword">val</span> word: <span class="type">String</span> = kv._1</span><br><span class="line">      <span class="comment">//组内所有的单词</span></span><br><span class="line">      <span class="keyword">val</span> values: <span class="type">List</span>[<span class="type">String</span>] = kv._2</span><br><span class="line">      <span class="comment">//计算单词的数量</span></span><br><span class="line">      <span class="keyword">val</span> count = values.length</span><br><span class="line">      <span class="comment">//返回单词和单词的数量</span></span><br><span class="line">      (word, count)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印结果</span></span><br><span class="line">    wordCount.foreach(println)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">&quot;=&quot;</span> * <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 简写</span></span><br><span class="line"><span class="comment">     * 链式调用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="type">Source</span></span><br><span class="line">      .fromFile(<span class="string">&quot;data/words.txt&quot;</span>)<span class="comment">//读取文件</span></span><br><span class="line">      .getLines()<span class="comment">//获取所有行</span></span><br><span class="line">      .toList<span class="comment">//转换成集合</span></span><br><span class="line">      .flatMap(_.split(<span class="string">&quot;,&quot;</span>))<span class="comment">//将数据展开</span></span><br><span class="line">      .groupBy(w =&gt; w)<span class="comment">//安装单词分组</span></span><br><span class="line">      .map(kv =&gt; (kv._1, kv._2.length))<span class="comment">//统计单词的数量</span></span><br><span class="line">      .foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="10、统计学生的总分"><a href="#10、统计学生的总分" class="headerlink" title="10、统计学生的总分"></a>10、统计学生的总分</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo23Case</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数表</span></span><br><span class="line">    <span class="keyword">val</span> scoresList: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、安装逗号拆分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoLost: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoresList.map(sco =&gt; sco.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> filterList: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoLost.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * case 也可以匹配数组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = filterList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _: <span class="type">String</span>, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupByList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 当需要处理的集合中的数据格式是一个很复杂的元组时，使用case语法，代码的可读性会更高</span></span><br><span class="line"><span class="comment">     * 以函数作为参数的另一种写法</span></span><br><span class="line"><span class="comment">     * 没有使用的变量可以使用下划线占位</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sumScoList: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Int</span>] = groupByList.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, scores: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//取出分数</span></span><br><span class="line">        <span class="keyword">val</span> scos: <span class="type">List</span>[<span class="type">Int</span>] = scores.map &#123; <span class="keyword">case</span> (_: <span class="type">String</span>, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line">        <span class="keyword">val</span> sumSco: <span class="type">Int</span> = scos.sum</span><br><span class="line">        (id, sumSco)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sumScoList.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="11、scala连接Mysql（JDBC）"><a href="#11、scala连接Mysql（JDBC）" class="headerlink" title="11、scala连接Mysql（JDBC）"></a>11、scala连接Mysql（JDBC）</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.&#123;<span class="type">Connection</span>, <span class="type">DriverManager</span>, <span class="type">PreparedStatement</span>, <span class="type">ResultSet</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo24Jdbc</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 在scala语法中链接数据库</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//需要先在pom中增加mysql驱动的依赖</span></span><br><span class="line">    <span class="comment">//1、加载驱动</span></span><br><span class="line">    <span class="type">Class</span>.forName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">    <span class="comment">//2、建立数据库链接</span></span><br><span class="line">    <span class="keyword">val</span> con: <span class="type">Connection</span> = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:mysql://master/test?useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;123456&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、编写sql查询数据</span></span><br><span class="line">    <span class="keyword">val</span> stat: <span class="type">PreparedStatement</span> = con.prepareStatement(<span class="string">&quot;select * from students where clazz=?&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、给参数赋值</span></span><br><span class="line">    stat.setString(<span class="number">1</span>, <span class="string">&quot;文科六班&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、执行查询</span></span><br><span class="line">    <span class="keyword">val</span> resultSet: <span class="type">ResultSet</span> = stat.executeQuery()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//6、解析数据</span></span><br><span class="line">    <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">      <span class="comment">//通过列名取出数据</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> name: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: <span class="type">Long</span> = resultSet.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> gender: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;gender&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> clazz: <span class="type">String</span> = resultSet.getString(<span class="string">&quot;clazz&quot;</span>)</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$gender</span>\t<span class="subst">$clazz</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//7、关闭连接</span></span><br><span class="line">    stat.close()</span><br><span class="line">    con.close()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="12、scala解析Json数据"><a href="#12、scala解析Json数据" class="headerlink" title="12、scala解析Json数据"></a>12、scala解析Json数据</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.&#123;<span class="type">JSON</span>, <span class="type">JSONArray</span>, <span class="type">JSONObject</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo25JSON</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 第三方解析json工具  fastJson  Gson</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取文件</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/users.json&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、将读到的数据拼接成一个字符串</span></span><br><span class="line">    <span class="keyword">val</span> jsonStr: <span class="type">String</span> = lines.mkString(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    println(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 使用FastJson解析json格式的数据</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> userArray: <span class="type">JSONArray</span> = <span class="type">JSON</span>.parseArray(jsonStr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (index &lt; userArray.size()) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过下标获取每一个用户</span></span><br><span class="line">      <span class="keyword">val</span> userObject: <span class="type">JSONObject</span> = userArray.getJSONObject(index)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//通过列名获取列值</span></span><br><span class="line">      <span class="keyword">val</span> id: <span class="type">String</span> = userObject.getString(<span class="string">&quot;id&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> nane: <span class="type">String</span> = userObject.getString(<span class="string">&quot;name&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> age: lang.<span class="type">Long</span> = userObject.getLong(<span class="string">&quot;age&quot;</span>)</span><br><span class="line"></span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$nane</span>\t<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      index += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="13、scala和java中的集合相互转换"><a href="#13、scala和java中的集合相互转换" class="headerlink" title="13、scala和java中的集合相互转换"></a>13、scala和java中的集合相互转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.scala</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo26ScalaOnJava</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//java中的集合</span></span><br><span class="line">    <span class="keyword">val</span> arrayList = <span class="keyword">new</span> util.<span class="type">ArrayList</span>[<span class="type">String</span>]()</span><br><span class="line">    arrayList.add(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hadoop&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;hive&quot;</span>)</span><br><span class="line">    arrayList.add(<span class="string">&quot;scala&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * java 集合转换成scala集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//下划线相当于java中的*</span></span><br><span class="line">    <span class="comment">//导入隐式转换(动态给对象增加新的方法)</span></span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConverters</span>._</span><br><span class="line">    <span class="keyword">import</span> scala.collection.<span class="type">JavaConversions</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scalaList: <span class="type">List</span>[<span class="type">String</span>] = arrayList.asScala.toList</span><br><span class="line"></span><br><span class="line">    println(scalaList)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * scala集合转换成java集合</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> javaList: util.<span class="type">List</span>[<span class="type">Int</span>] = list.asJava</span><br><span class="line"></span><br><span class="line">    println(javaList)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="14、Match"><a href="#14、Match" class="headerlink" title="14、Match"></a>14、Match</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo27Match</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * java中的模式匹配可以匹配基本数据类型，字符串，枚举</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * scala的模式匹配，可以匹配基本数据类型，字符串，对象，元组，数组，匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1、匹配基本数据类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 模式匹配只有一个能匹配成功</span></span><br><span class="line"><span class="comment">     * 下划线代表其其它情况</span></span><br><span class="line"><span class="comment">     * 在写代码是需要考虑到所有的情况</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> i = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    i <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">10</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是10&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">20</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是20&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="number">100</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;i的值是100&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">&quot;其他&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 2、匹配字符串</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> str: <span class="type">String</span> = <span class="string">&quot;java&quot;</span></span><br><span class="line"></span><br><span class="line">    str <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;java&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;java&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&quot;spark&quot;</span> =&gt;</span><br><span class="line">        println(<span class="string">&quot;spark&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; println(<span class="string">&quot;其它&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 3、匹配元组</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> t: (<span class="type">String</span>, <span class="type">Int</span>, <span class="type">String</span>) = (<span class="string">&quot;张三&quot;</span>, <span class="number">23</span>, <span class="string">&quot;001&quot;</span>)</span><br><span class="line"></span><br><span class="line">    t <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//替代下划线</span></span><br><span class="line">    <span class="keyword">val</span> (name: <span class="type">String</span>, age: <span class="type">Int</span>, id: <span class="type">String</span>) = t</span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$name</span>\t<span class="subst">$age</span>\t<span class="subst">$id</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、匹配数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> array: <span class="type">Array</span>[<span class="type">Any</span>] = <span class="type">Array</span>(<span class="string">&quot;001&quot;</span>, <span class="string">&quot;李四&quot;</span>)</span><br><span class="line"></span><br><span class="line">    array <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">Int</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>\4<span class="subst">$age</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>) =&gt;</span><br><span class="line">        println(<span class="string">s&quot;<span class="subst">$id</span>\t<span class="subst">$name</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 5、匹配类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> obj: <span class="type">Any</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    obj <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> i: <span class="type">Int</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Int类型：<span class="subst">$i</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">String</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个String类型:<span class="subst">$s</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> d: <span class="type">Double</span> =&gt;</span><br><span class="line">        println(<span class="string">s&quot;obj是一个Double类型:<span class="subst">$d</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        println(<span class="string">s&quot;其它类型：<span class="subst">$obj</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配可以有返回值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i1: <span class="type">Int</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> ty: <span class="type">String</span> = i1 % <span class="number">2</span> <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">&quot;奇数&quot;</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span> =&gt; <span class="string">&quot;偶数&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(ty)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配在map集合的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> map = <span class="type">Map</span>(<span class="string">&quot;001&quot;</span> -&gt; <span class="string">&quot;张三&quot;</span>, <span class="string">&quot;002&quot;</span> -&gt; <span class="string">&quot;李四&quot;</span>)</span><br><span class="line">    println(map.getOrElse(<span class="string">&quot;006&quot;</span>, <span class="string">&quot;默认值&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Option：是一个可选的取值有有两个取值</span></span><br><span class="line"><span class="comment">     * Some ：有值</span></span><br><span class="line"><span class="comment">     * None: 没有值</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> value: <span class="type">Option</span>[<span class="type">String</span>] = map.get(<span class="string">&quot;005&quot;</span>)</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> mvalue: <span class="type">String</span> = map.get(<span class="string">&quot;003&quot;</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(v) =&gt; v</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="string">&quot;默认值&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(mvalue)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模式匹配结合函数的使用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照逗号分割数据</span></span><br><span class="line">    <span class="keyword">val</span> arrays: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//匹配取出数据</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)] = arrays.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, name: <span class="type">String</span>, age: <span class="type">String</span>, gender: <span class="type">String</span>, clazz: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, name, age, gender, clazz)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="15、隐式转换"><a href="#15、隐式转换" class="headerlink" title="15、隐式转换"></a>15、隐式转换</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo28Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换  -- 隐式类型转换  -- 可以动态可以对象增加新的方法</span></span><br><span class="line"><span class="comment">     * 1、隐式转换变量</span></span><br><span class="line"><span class="comment">     * 2、隐式转换方法: 可以隐式将方法的参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     * 3、隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//        val s:String = &quot;100&quot;</span></span><br><span class="line">    <span class="comment">//        val i: Int = s.toInt</span></span><br><span class="line">    <span class="comment">//        println(i)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fun</span></span>(i: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(i * i)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">100</span>)</span><br><span class="line">    <span class="comment">//显示类型转换</span></span><br><span class="line">    <span class="comment">//fun(&quot;100&quot;.toInt)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义一个隐式转换方法</span></span><br><span class="line"><span class="comment">     * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 隐式转换的方法和方法名无关,和参数类型返回值类有关</span></span><br><span class="line"><span class="comment">     * 同一个作用域中只能存储一个相同类型的隐式转换</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//将String 转换成Int的隐式转换的方法</span></span><br><span class="line">    <span class="comment">//当前作用域中所有的String都可以当成Int类使用</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">strToInt</span></span>(s: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;strToInt被调用&quot;</span>)</span><br><span class="line">      <span class="type">Integer</span>.parseInt(s)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="string">&quot;200&quot;</span>)</span><br><span class="line">    <span class="comment">//等同于</span></span><br><span class="line">    fun(strToInt(<span class="string">&quot;200&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">douToInt</span></span>(d: <span class="type">Double</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;douToInt被调用&quot;</span>)</span><br><span class="line">      d.toInt</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fun(<span class="number">3.14</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 应用</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//导入隐式转换</span></span><br><span class="line">    <span class="keyword">import</span> com.shujia.scala.<span class="type">Test</span>._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> studentPsPath: <span class="type">String</span> = <span class="string">&quot;data/students.txt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> students: <span class="type">List</span>[<span class="type">String</span>] = studentPsPath.getLines().toList</span><br><span class="line"></span><br><span class="line">    students.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.getLines().toList</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换</span></span><br><span class="line"><span class="comment">   * 可以将参数类型转换成返回值类型</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">implicit</span> <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(path: <span class="type">String</span>): <span class="type">BufferedSource</span> = &#123;</span><br><span class="line">    <span class="type">Source</span>.fromFile(path)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="16、隐式转换类"><a href="#16、隐式转换类" class="headerlink" title="16、隐式转换类"></a>16、隐式转换类</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo29Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换类</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> read = <span class="keyword">new</span> <span class="type">Read</span>(<span class="string">&quot;data/students.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = read.read()</span><br><span class="line">    println(lines)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//使用隐式转换</span></span><br><span class="line">    <span class="comment">//相当于String被隐式转换成了Read类型</span></span><br><span class="line">    <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">String</span>] = <span class="string">&quot;data/score.txt&quot;</span>.read()</span><br><span class="line">    println(scores)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 隐式转换类：可以隐式的将类的构造函数参数类型转换成当前类的类型</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">implicit</span> <span class="class"><span class="keyword">class</span> <span class="title">Read</span>(<span class="params">path: <span class="type">String</span></span>) </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(): <span class="type">List</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">      <span class="comment">//读取文件</span></span><br><span class="line">      <span class="type">Source</span>.fromFile(path).getLines().toList</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="17、隐式转换变量"><a href="#17、隐式转换变量" class="headerlink" title="17、隐式转换变量"></a>17、隐式转换变量</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.io.&#123;<span class="type">BufferedSource</span>, <span class="type">Codec</span>, <span class="type">Source</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo30Implicit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 隐式转换变量</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span></span>(x: <span class="type">Int</span>)(<span class="keyword">implicit</span> y: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      x + y</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> i: <span class="type">Int</span> = add(<span class="number">100</span>)(<span class="number">200</span>)</span><br><span class="line">    println(i)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义一个隐式转换变量</span></span><br><span class="line">    <span class="keyword">implicit</span> <span class="keyword">val</span> a: <span class="type">Int</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用方法时，会自动使用当前作用域同类型的隐式转换变量填补上发方法的隐式转换参数</span></span><br><span class="line">    <span class="keyword">val</span> j: <span class="type">Int</span> = add(<span class="number">200</span>)</span><br><span class="line">    println(j)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//隐式转换变量的应用</span></span><br><span class="line">    <span class="keyword">val</span> source: <span class="type">BufferedSource</span> = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/students.txt&quot;</span>)(<span class="type">Codec</span>(<span class="string">&quot;Utf-8&quot;</span>))</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="18、统计偏科最严重的前100名学生"><a href="#18、统计偏科最严重的前100名学生" class="headerlink" title="18、统计偏科最严重的前100名学生"></a>18、统计偏科最严重的前100名学生</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scala.collection.immutable</span><br><span class="line"><span class="keyword">import</span> scala.io.<span class="type">Source</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Demo31Student</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 4、统计偏科最严重的前100名学生</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 偏科评估的标准： 方差</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//1、读取分数</span></span><br><span class="line">    <span class="keyword">val</span> lines: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">Source</span>.fromFile(<span class="string">&quot;data/score.txt&quot;</span>).getLines().toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2、切分数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreArr: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = lines.map(line =&gt; line.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3、过滤脏数据</span></span><br><span class="line">    <span class="keyword">val</span> scoreFilter: <span class="type">List</span>[<span class="type">Array</span>[<span class="type">String</span>]] = scoreArr.filter(arr =&gt; arr.length == <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4、取出学号和分数</span></span><br><span class="line">    <span class="keyword">val</span> idAndScore: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = scoreFilter.map &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Array</span>(id: <span class="type">String</span>, _, sco: <span class="type">String</span>) =&gt;</span><br><span class="line">        (id, sco.toInt)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5、按照学号分组</span></span><br><span class="line">    <span class="keyword">val</span> groupBy: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = idAndScore.groupBy(kv =&gt; kv._1)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算方差</span></span><br><span class="line">    <span class="keyword">val</span> std: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = groupBy.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id: <span class="type">String</span>, list: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]) =&gt;</span><br><span class="line">        <span class="comment">//一个学生所有的分数</span></span><br><span class="line">        <span class="keyword">val</span> scores: <span class="type">List</span>[<span class="type">Int</span>] = list.map &#123; <span class="keyword">case</span> (_, sco: <span class="type">Int</span>) =&gt; sco &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 计算方差</span></span><br><span class="line"><span class="comment">         * 1、计算总数</span></span><br><span class="line"><span class="comment">         * 2、计算平均值</span></span><br><span class="line"><span class="comment">         * 3、计算方差</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//科目数</span></span><br><span class="line">        <span class="keyword">val</span> <span class="type">N</span>: <span class="type">Double</span> = scores.length.toDouble</span><br><span class="line">        <span class="comment">//平均数</span></span><br><span class="line">        <span class="keyword">val</span> avg: <span class="type">Double</span> = scores.sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算方差</span></span><br><span class="line">        <span class="keyword">val</span> std: <span class="type">Double</span> = scores.map((sco: <span class="type">Int</span>) =&gt; (sco - avg) * (sco - avg)).sum / <span class="type">N</span></span><br><span class="line"></span><br><span class="line">        (id, std, list)</span><br><span class="line">    &#125;.toList</span><br><span class="line"></span><br><span class="line">    <span class="comment">//按照方差排序，取前100</span></span><br><span class="line">    <span class="keyword">val</span> sortByStd: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = std.sortBy(kv =&gt; -kv._2)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//取前100</span></span><br><span class="line">    <span class="keyword">val</span> top10: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Double</span>, <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)])] = sortByStd.take(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    top10.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sqoop</title>
      <link href="/2022/06/16/Sqoop/"/>
      <url>/2022/06/16/Sqoop/</url>
      
        <content type="html"><![CDATA[<h3 id="SQOOP安装"><a href="#SQOOP安装" class="headerlink" title="SQOOP安装"></a>SQOOP安装</h3><h4 id="1、上传并解压"><a href="#1、上传并解压" class="headerlink" title="1、上传并解压"></a>1、上传并解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /usr/local/soft/</span><br></pre></td></tr></table></figure><h4 id="2、修改文件夹名字"><a href="#2、修改文件夹名字" class="headerlink" title="2、修改文件夹名字"></a>2、修改文件夹名字</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop-1.4.6</span><br></pre></td></tr></table></figure><h4 id="3、修改配置文件"><a href="#3、修改配置文件" class="headerlink" title="3、修改配置文件"></a>3、修改配置文件</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 切换到sqoop配置文件目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/conf</span><br><span class="line"><span class="comment"># 复制配置文件并重命名</span></span><br><span class="line"><span class="built_in">cp</span> sqoop-env-template.sh sqoop-env.sh</span><br><span class="line"><span class="comment"># vim sqoop-env.sh 编辑配置文件，并加入以下内容</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/usr/local/soft/hadoop-2.7.6/share/hadoop/mapreduce</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/local/soft/hbase-1.4.6</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/soft/hive-1.2.1</span><br><span class="line"><span class="built_in">export</span> ZOOCFGDIR=/usr/local/soft/zookeeper-3.4.6/conf</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到bin目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/soft/sqoop-1.4.6/bin</span><br><span class="line"><span class="comment"># vim configure-sqoop 修改配置文件，注释掉没用的内容（就是为了去掉警告信息）</span></span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/wQgeExBmpyDju1t.png" alt="image.png" style="zoom:50%;" /><h4 id="4、修改环境变量"><a href="#4、修改环境变量" class="headerlink" title="4、修改环境变量"></a>4、修改环境变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将sqoop的目录加入环境变量</span></span><br></pre></td></tr></table></figure><h4 id="5、添加MySQL连接驱动"><a href="#5、添加MySQL连接驱动" class="headerlink" title="5、添加MySQL连接驱动"></a>5、添加MySQL连接驱动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从HIVE中复制MySQL连接驱动到<span class="variable">$SQOOP_HOME</span>/lib</span></span><br><span class="line">cp /usr/local/soft/hive-1.2.1/lib/mysql-connector-java-5.1.49.jar /usr/local/soft/sqoop-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="6、测试"><a href="#6、测试" class="headerlink" title="6、测试"></a>6、测试</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打印sqoop版本</span></span><br><span class="line">sqoop version</span><br></pre></td></tr></table></figure><img src="https://s2.loli.net/2022/06/20/6N1HJzVD7i9P3r5.png" alt="image.png" style="zoom:50%;" /><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试MySQL连通性</span></span><br><span class="line">sqoop list-databases -connect jdbc:mysql://master:3306/ -username root -password 123456</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/fos2dlvrMLQm4wa.png" alt="image-20220620200744244"></p><h3 id="准备MySQL数据"><a href="#准备MySQL数据" class="headerlink" title="准备MySQL数据"></a>准备MySQL数据</h3><h4 id="登录MySQL数据库"><a href="#登录MySQL数据库" class="headerlink" title="登录MySQL数据库"></a>登录MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p123456;</span><br></pre></td></tr></table></figure><h4 id="创建student数据库"><a href="#创建student数据库" class="headerlink" title="创建student数据库"></a>创建student数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create database student;</span><br></pre></td></tr></table></figure><h4 id="切换数据库并导入数据"><a href="#切换数据库并导入数据" class="headerlink" title="切换数据库并导入数据"></a>切换数据库并导入数据</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mysql shell中执行</span></span><br><span class="line">use student;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/student.sql;</span><br><span class="line">source /usr/local/soft/bigdata17/scrips/score.sql;</span><br></pre></td></tr></table></figure><h4 id="另外一种导入数据的方式"><a href="#另外一种导入数据的方式" class="headerlink" title="另外一种导入数据的方式"></a>另外一种导入数据的方式</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">linux shell中执行</span></span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/student.sql</span><br><span class="line">mysql -u root -p123456 student&lt;/usr/local/soft/bigdata17/scrips/score.sql</span><br></pre></td></tr></table></figure><h4 id="使用Navicat运行SQL文件"><a href="#使用Navicat运行SQL文件" class="headerlink" title="使用Navicat运行SQL文件"></a>使用Navicat运行SQL文件</h4><blockquote><p>也可以通过Navicat导入</p></blockquote><h4 id="导出MySQL数据库"><a href="#导出MySQL数据库" class="headerlink" title="导出MySQL数据库"></a>导出MySQL数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqldump -u root -p123456 数据库名&gt;任意一个文件名.sql</span><br></pre></td></tr></table></figure><h3 id="SQOOP–import"><a href="#SQOOP–import" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h3><blockquote><p>从传统的关系型数据库导入HDFS、HIVE、HBASE……</p></blockquote><h4 id="MySQLToHDFS"><a href="#MySQLToHDFS" class="headerlink" title="MySQLToHDFS"></a>MySQLToHDFS</h4><h5 id="编写脚本，保存为MySQLToHDFS-conf"><a href="#编写脚本，保存为MySQLToHDFS-conf" class="headerlink" title="编写脚本，保存为MySQLToHDFS.conf"></a>编写脚本，保存为MySQLToHDFS.conf</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop执行脚本有两种方式：</span><br><span class="line">第一种方式：直接在命令行窗口中直接输入脚本；</span><br><span class="line">第二种方式是将命令封装成一个脚本文件，然后使用另一个命令执行</span><br><span class="line"></span><br><span class="line">第一种方式：</span><br><span class="line">sqoop import \</span><br><span class="line">--append \</span><br><span class="line">--connect jdbc:mysql://master:3306/test \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table student \</span><br><span class="line">--m 4 \</span><br><span class="line">--split-by age \</span><br><span class="line">--target-dir /shujia/bigdata17/student1/ \</span><br><span class="line">--fields-terminated-by &#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">第二种方式：</span><br><span class="line">import</span><br><span class="line">--append</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/test</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">4</span><br><span class="line">--split-by</span><br><span class="line">age</span><br><span class="line">--target-dir</span><br><span class="line">/shujia/bigdata17/student21/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本"><a href="#执行脚本" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHDFS.conf</span><br></pre></td></tr></table></figure><h5 id="注意事项："><a href="#注意事项：" class="headerlink" title="注意事项："></a>注意事项：</h5><p>1、–m 表示指定生成多少个Map任务，不是越多越好，因为MySQL Server的承载能力有限</p><p>2、当指定的Map任务数&gt;1，那么需要结合<code>--split-by</code>参数，指定分割键，以确定每个map任务到底读取哪一部分数据，最好指定数值型的列，最好指定主键（或者分布均匀的列&#x3D;&gt;避免每个map任务处理的数据量差别过大）</p><p>3、如果指定的分割键数据分布不均，可能导致数据倾斜问题</p><p>4、分割的键最好指定数值型的，而且字段的类型为int、bigint这样的数值型</p><p>5、编写脚本的时候，注意：例如：<code>--username</code>参数，参数值不能和参数名同一行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--username root  // 错误的</span><br><span class="line"></span><br><span class="line">// 应该分成两行</span><br><span class="line">--username</span><br><span class="line">root</span><br></pre></td></tr></table></figure><p>6、运行的时候会报错<strong>InterruptedException</strong>，hadoop2.7.6自带的问题，忽略即可</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">21/01/25 14:32:32 WARN hdfs.DFSClient: Caught exception </span><br><span class="line">java.lang.InterruptedException</span><br><span class="line">at java.lang.Object.wait(Native Method)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1252)</span><br><span class="line">at java.lang.Thread.join(Thread.java:1326)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:716)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:476)</span><br><span class="line">at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:652)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>7、实际上sqoop在读取mysql数据的时候，用的是JDBC的方式，所以当数据量大的时候，效率不是很高</p><p>8、sqoop底层通过MapReduce完成数据导入导出，只需要Map任务，不许需要Reduce任务  part-m-00000</p><p>9、每个Map任务会生成一个文件</p><h4 id="MySQLToHive"><a href="#MySQLToHive" class="headerlink" title="MySQLToHive"></a>MySQLToHive</h4><blockquote><p>先会将MySQL的数据导出来并在HDFS上找个目录临时存放，默认为：&#x2F;user&#x2F;用户名&#x2F;表名</p><p>然后再将数据加载到Hive中，加载完成后，会将临时存放的目录删除</p></blockquote><h5 id="编写脚本，并保存为MySQLToHive-conf文件"><a href="#编写脚本，并保存为MySQLToHive-conf文件" class="headerlink" title="编写脚本，并保存为MySQLToHive.conf文件"></a>编写脚本，并保存为MySQLToHive.conf文件</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">score</span><br><span class="line">--m</span><br><span class="line">3</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore</span><br><span class="line"></span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h5 id="执行脚本-1"><a href="#执行脚本-1" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHive.conf</span><br></pre></td></tr></table></figure><h5 id="–direct"><a href="#–direct" class="headerlink" title="–direct"></a>–direct</h5><blockquote><p>加上这个参数，可以在导出MySQL数据的时候，使用MySQL提供的导出工具mysqldump，加快导出速度，提高效率</p></blockquote><p>需要将master上的&#x2F;usr&#x2F;bin&#x2F;mysqldump分发至 node1、node2的&#x2F;usr&#x2F;bin目录下</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp /usr/bin/mysqldump node1:/usr/bin/</span><br><span class="line">scp /usr/bin/mysqldump node2:/usr/bin/</span><br></pre></td></tr></table></figure><h5 id="–e参数的使用"><a href="#–e参数的使用" class="headerlink" title="–e参数的使用"></a>–e参数的使用</h5><blockquote><p>sqoop在导入数据时，可以使用–e搭配sql来指定查询条件，并且还需在sql中添加$CONDITIONS，来实现并行运行mr的功能。</p><p>只要有–e+sql，就需要加$CONDITIONS，哪怕只有一个maptask。</p></blockquote><blockquote><p>sqoop通过继承hadoop的并行性来执行高效的数据传输。 为了帮助sqoop将查询拆分为多个可以并行传输的块，需要在查询的where子句中包含$conditions占位符。 sqoop将自动用生成的条件替换这个占位符，这些条件指定每个任务应该传输哪个数据片。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--m</span><br><span class="line">2</span><br><span class="line">--split-by</span><br><span class="line">student_id</span><br><span class="line">--e</span><br><span class="line">&quot;select * from score where student_id=1500100001 and $CONDITIONS&quot;</span><br><span class="line">--target-dir</span><br><span class="line">/testE</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">sqooptest</span><br><span class="line">--hive-table</span><br><span class="line">mysqltoscore3</span><br><span class="line">--direct</span><br></pre></td></tr></table></figure><h4 id="MySQLToHBase"><a href="#MySQLToHBase" class="headerlink" title="MySQLToHBase"></a>MySQLToHBase</h4><h5 id="编写脚本，并保存为MySQLToHBase-conf"><a href="#编写脚本，并保存为MySQLToHBase-conf" class="headerlink" title="编写脚本，并保存为MySQLToHBase.conf"></a>编写脚本，并保存为MySQLToHBase.conf</h5><blockquote><p>sqoop1.4.6 只支持 HBase1.0.1 之前的版本的自动创建 HBase 表的功能</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id</span><br><span class="line">--m</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h5 id="在HBase中创建student表"><a href="#在HBase中创建student表" class="headerlink" title="在HBase中创建student表"></a>在HBase中创建student表</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create &#x27;studentsq&#x27;,&#x27;cf1&#x27;</span><br></pre></td></tr></table></figure><h5 id="执行脚本-2"><a href="#执行脚本-2" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file MySQLToHBase.conf</span><br></pre></td></tr></table></figure><h4 id="SQOOP–import-1"><a href="#SQOOP–import-1" class="headerlink" title="SQOOP–import"></a>SQOOP–import</h4><h4 id="HDFSToMySQL"><a href="#HDFSToMySQL" class="headerlink" title="HDFSToMySQL"></a>HDFSToMySQL</h4><h5 id="编写脚本，并保存为HDFSToMySQL-conf"><a href="#编写脚本，并保存为HDFSToMySQL-conf" class="headerlink" title="编写脚本，并保存为HDFSToMySQL.conf"></a>编写脚本，并保存为HDFSToMySQL.conf</h5><blockquote><p><strong>在往关系型数据库中导出的时候我们要先在关系型数据库中创建好库以及表，这些sqoop不会帮我们完成。</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student?useUnicode=true&amp;characterEncoding=UTF-8</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br></pre></td></tr></table></figure><h5 id="先清空MySQL-student表中的数据，不然会造成主键冲突"><a href="#先清空MySQL-student表中的数据，不然会造成主键冲突" class="headerlink" title="先清空MySQL student表中的数据，不然会造成主键冲突"></a>先清空MySQL student表中的数据，不然会造成主键冲突</h5><h5 id="执行脚本-3"><a href="#执行脚本-3" class="headerlink" title="执行脚本"></a>执行脚本</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop --options-file HDFSToMySQL.conf</span><br></pre></td></tr></table></figure><h4 id="查看sqoop-help"><a href="#查看sqoop-help" class="headerlink" title="查看sqoop help"></a>查看sqoop help</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sqoop help</span><br><span class="line"></span><br><span class="line">21/04/26 15:50:36 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">usage: sqoop COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  codegen            Generate code to interact with database records</span><br><span class="line">  create-hive-table  Import a table definition into Hive</span><br><span class="line">  eval               Evaluate a SQL statement and display the results</span><br><span class="line">  export             Export an HDFS directory to a database table</span><br><span class="line">  help               List available commands</span><br><span class="line">  import             Import a table from a database to HDFS</span><br><span class="line">  import-all-tables  Import tables from a database to HDFS</span><br><span class="line">  import-mainframe   Import datasets from a mainframe server to HDFS</span><br><span class="line">  job                Work with saved jobs</span><br><span class="line">  list-databases     List available databases on a server</span><br><span class="line">  list-tables        List available tables in a database</span><br><span class="line">  merge              Merge results of incremental imports</span><br><span class="line">  metastore          Run a standalone Sqoop metastore</span><br><span class="line">  version            Display version information</span><br><span class="line"></span><br><span class="line">See &#x27;sqoop help COMMAND&#x27; for information on a specific command.</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看import的详细帮助</span><br><span class="line">sqoop import --help</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、并行度不能太高，就是 -m</span><br><span class="line">2、如果没有主键的时候，-m 不是1的时候就要指定分割字段，不然会报错，如果有主键的时候，-m 不是1 可以不去指定分割字段，默认是主键，不指定 -m 的时候，Sqoop会默认是分4个map任务。</span><br></pre></td></tr></table></figure><h4 id="Sqoop-在从HDFS中导出到关系型数据库时的一些问题"><a href="#Sqoop-在从HDFS中导出到关系型数据库时的一些问题" class="headerlink" title="Sqoop 在从HDFS中导出到关系型数据库时的一些问题"></a>Sqoop 在从HDFS中导出到关系型数据库时的一些问题</h4><h5 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a><strong>问题一：</strong></h5><p>在上传过程中遇到这种问题：</p><p><strong>ERROR tool.ExportTool: Encountered IOException running export job: java.io.IOException: No columns to generate for ClassWriter</strong></p><p><img src="https://s2.loli.net/2022/06/20/746cVG2nRzkPTsd.png" alt="image-20220620213336190"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">驱动版本的过低导致的，其实在尝试这个方法的时候我们可以先进行这样：加一行命令，--driver com.mysql.jdbc.Driver \  然后问题解决！！！</span><br><span class="line"></span><br><span class="line">如果添加命令之后还没有解决就把jar包换成高点版本的。</span><br></pre></td></tr></table></figure><h5 id="问题二："><a href="#问题二：" class="headerlink" title="问题二："></a><strong>问题二：</strong></h5><p><strong>依旧是导出的时候，会报错，但是我们很神奇的发现，也有部分数据导入了。这也就是下一个问题。</strong></p><p><strong>Caused by: java.lang.NumberFormatException: For input string: “null”</strong></p><p><img src="https://s2.loli.net/2022/06/20/ZDp6kQ5V2UOghCl.png" alt="image-20220620213402824"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">解决方式：因为数据有存在null值得导致的</span><br><span class="line"></span><br><span class="line">在命令中加入一行（方式一中的修改方式，方式二也就是转换一下格式）：--input-null-string &#x27;\\N&#x27; \  </span><br><span class="line"></span><br><span class="line">--input-null-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure><h5 id="问题三："><a href="#问题三：" class="headerlink" title="问题三：**"></a>问题三：**</h5><p><strong>java.lang.RuntimeException: Can’t parse input data: ‘1998&#x2F;5&#x2F;11’</strong></p><p><img src="https://s2.loli.net/2022/06/20/nRyQel6fvAr9UXT.png" alt="image-20220620213425310"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">出现像这样的问题，大多是因为HDFS上的数据与关系型数据库创建表的字段类型不匹配导致的。仔细对比修改后，就不会有这个报错啦！！</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/20/8QFgr9AG4wRyZSH.png" alt="image-20220620230831268"></p><p>数据有问题有个@符号，虽然报错但是也能导出数据</p><h3 id="增量同步数据"><a href="#增量同步数据" class="headerlink" title="增量同步数据"></a>增量同步数据</h3><p>我们之前导入的都是全量导入，一次性全部导入，但是实际开发并不是这样，例如web端进行用户注册，mysql就增加了一条数据，但是HDFS中的数据并没有进行更新，但是又再全部导入一次又完全没有必要。</p><p>所以，sqoop提供了增量导入的方法。</p><p>1、数据准备：</p><p><img src="https://s2.loli.net/2022/06/20/tHPlkEISReUA4Ya.png" alt="image-20220620213457114"></p><p>2、将其先用全量导入到HDFS(hive)中去</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br></pre></td></tr></table></figure><p>3、先在mysql中添加一条数据，在使用命令进行追加</p><p>4、根据时间进行大量追加（不去重）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">前面的案例中，hive本身的数据也是存储在HDFS上的，所以我今后要做增量操作的时候，需要指定HDFS上的路径</span></span><br><span class="line">import</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--incremental </span><br><span class="line">append</span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>结果：但是我们发现有两个重复的字段</p><p><img src="https://s2.loli.net/2022/06/20/vPN8seuwOUkgYqR.png" alt="img"></p><p>5、往往开发中需要进行去重操作：sqoop提供了一个方法进行去重，内部是先开一个map任务将数据导入进来，然后再开一个map任务根据指定的字段进行合并去重</p><p>结果：</p><p><img src="https://s2.loli.net/2022/06/20/7tW4nmR5OUes3MP.png" alt="img"></p><blockquote><p> <strong>之前有重复的也进行合并去重操作，最后生成一个结果。</strong></p></blockquote><blockquote><p>总结：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">–check-column</span><br><span class="line">用来指定一些列，这些列在增量导入时用来检查这些数据是否作为增量数据进行导入，和关系型数据库中的自增字段及时间戳类似. </span><br><span class="line">注意:这些被指定的列的类型不能使任意字符类型，如char、varchar等类型都是不可以的，同时–check-column可以去指定多个列</span><br><span class="line">–incremental</span><br><span class="line">用来指定增量导入的模式，两种模式分别为Append和Lastmodified</span><br><span class="line">–last-value</span><br><span class="line">指定上一次导入中检查列指定字段最大值</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">RDBMS--&gt;</span><span class="language-bash">HDFS     import</span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">RDBMS    <span class="built_in">export</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">Mysql---&gt;</span><span class="language-bash">HDFS(hive)</span></span><br><span class="line">要知道你要数据的来源和数据的目的地</span><br><span class="line">mysql:</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://master:3306/student</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">student</span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"></span><br><span class="line">hive:</span><br><span class="line">1)</span><br><span class="line">--hive-import</span><br><span class="line">--hive-overwrite</span><br><span class="line">--create-hive-table  (如果表不存在，自动创建，如果存在，报错，就不需要这个参数)</span><br><span class="line">--hive-database</span><br><span class="line">testsqoop</span><br><span class="line">--hive-table</span><br><span class="line">from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">2)</span><br><span class="line">--target-dir</span><br><span class="line">/user/hive/warehouse/sqooptest.db/from_mysql_student</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增量需要添加的参数=================================================</span></span><br><span class="line">--incremental </span><br><span class="line">append </span><br><span class="line">--check-column</span><br><span class="line">id</span><br><span class="line">--last-value</span><br><span class="line">3</span><br><span class="line">（或者是）------------------------------------------------------------</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;\t&#x27;</span><br><span class="line">--check-column （hive的列名）</span><br><span class="line">last_mod</span><br><span class="line">--incremental</span><br><span class="line">lastmodified</span><br><span class="line">--last-value</span><br><span class="line">&quot;2022-06-18 16:40:09&quot;</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line">========================================================================</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果需要去重，请先搞清楚根据什么去重，否则结果可能不是你想要的</span></span><br><span class="line">--merge-key</span><br><span class="line">name   （这里是根据姓名去重，你可以改成自己的去重列名）</span><br><span class="line"></span><br><span class="line">hbase:（因为我们的hbase版本是1.4.6，而sqoop1.4.6不支持hbase1.0.1以后的自动创建表，所以我们在做同步到hbase的时候，需要手动先将表创建好）</span><br><span class="line">--hbase-table</span><br><span class="line">studentsq</span><br><span class="line">--column-family</span><br><span class="line">cf1</span><br><span class="line">--hbase-row-key</span><br><span class="line">id  (mysql中的列名)</span><br><span class="line">--m</span><br><span class="line">1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">HDFS---&gt;</span><span class="language-bash">mysql</span></span><br><span class="line"></span><br><span class="line">hdfs:</span><br><span class="line">--columns</span><br><span class="line">id,name,age,gender,clazz</span><br><span class="line">--export-dir</span><br><span class="line">/shujia/bigdata17/sqoopinput/</span><br><span class="line">--fields-terminated-by</span><br><span class="line">&#x27;,&#x27;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果数据分割出来的字段值有空值，需要添加以下参数（面试可能会面到）</span></span><br><span class="line">--null-string </span><br><span class="line">&#x27;\\N&#x27; </span><br><span class="line">--null-non-string </span><br><span class="line">&#x27;\\N&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sqoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase高级操作</title>
      <link href="/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/"/>
      <url>/2022/06/13/Hbase%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="一、HBase的读写流程"><a href="#一、HBase的读写流程" class="headerlink" title="一、HBase的读写流程"></a>一、HBase的读写流程</h2><p><img src="https://s2.loli.net/2022/06/15/tel8cnYuW4o6EiI.png" alt="image-20220615154028494"></p><h3 id="1-1-HBase读流程"><a href="#1-1-HBase读流程" class="headerlink" title="1.1    HBase读流程"></a>1.1    HBase读流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Hbase读取数据的流程：</span><br><span class="line">1）是由客户端发起读取数据的请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取一个hbase:meta表位置信息，被哪一个regionserver所管理着</span><br><span class="line">     hbase:meta表：hbase的元数据表，在这个表中存储了自定义表相关的元数据，包括表名，表有哪些列簇，表有哪些reguion,每个region存储的位置，每个region被哪个regionserver所管理，这个表也是存储在某一个region上的，并且这个meta表只会被一个regionserver所管理。这个表的位置信息只有zookeeper知道。</span><br><span class="line">3）连接这个meta表对应的regionserver,从meta表中获取当前你要读取的这个表对应的regionsever是谁。</span><br><span class="line">     当一个表多个region怎么办呢？</span><br><span class="line">     如果我们获取数据是以get的方式，只会返回一个regionserver</span><br><span class="line">     如果我们获取数据是以scan的方式，会将所有的region对应的regionserver的地址全部返回。</span><br><span class="line">4）连接要读取表的对应的regionserver,从regionserver上的开始读取数据：</span><br><span class="line">       读取顺序：memstore--&gt;blockcache--&gt;storefile--&gt;Hfile中</span><br><span class="line">       注意：如果是scan操作，就不仅仅去blockcache了，而是所有都会去找。</span><br></pre></td></tr></table></figure><h3 id="1-2-HBase写流程"><a href="#1-2-HBase写流程" class="headerlink" title="1.2    HBase写流程"></a>1.2    HBase写流程</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--------------------------1-4步是客户端写入数据的流程-----------------</span><br><span class="line"></span><br><span class="line">Hbase的写入数据流程：</span><br><span class="line">1）由客户端发起写数据请求，首先会与zookeeper建立连接</span><br><span class="line">2）从zookeeper中获取hbase:meta表被哪一个regionserver所管理</span><br><span class="line">3）连接hbase:meta表中获取对应的regionserver地址 (从meta表中获取当前要写入数据的表对应的region所管理的regionserver) 只会返回一个regionserver地址</span><br><span class="line">4）与要写入数据的regionserver建立连接，然后开始写入数据，将数据首先会写入到HLog，然后将数据写入到对应store模块中的memstore中</span><br><span class="line">（可能会写多个），当这两个地方都写入完成之后，表示数据写入完成。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-------------------------后面的步骤是服务器内部的操作-----------------</span><br><span class="line">异步操作</span><br><span class="line">5）随着客户端不断地写入数据，memstore中的数据会越来多，当内存中的数据达到阈值（128M/1h）的时候，放入到blockchache中，生成新的memstore接收用户过来的数据，然后当blockcache的大小达到一定阈值（0.85）的时候，开始触发flush机制，将数据最终刷新到HDFS中形成小的Hfile文件。</span><br><span class="line"></span><br><span class="line">6）随着不断地刷新，storefile不断地在HDFS上生成小HFIle文件，当小的HFile文件达到阈值的时候（3个及3个以上）,就会触发Compaction机制，将小的HFile合并成一个大的HFile.</span><br><span class="line"></span><br><span class="line">7）随着不断地合并，大的HFile文件会越来越大，当达到一定阈值（最终10G）的时候，会触发分裂机制（split）,将大的HFile文件进行一分为二，同时管理这个大的HFile的region也会被一分为二，形成两个新的region和两个新的HFile文件，一对一的进行管理，将原来旧的region和分裂之前大的HFile文件慢慢地就会下线处理。</span><br></pre></td></tr></table></figure><h2 id="二、Region的分裂策略"><a href="#二、Region的分裂策略" class="headerlink" title="二、Region的分裂策略"></a>二、Region的分裂策略</h2><blockquote><p>region中存储的是一张表的数据，当region中的数据条数过多的时候，会直接影响查询效率。当region过大的时候，region会被拆分为两个region，HMaster会将分裂的region分配到不同的regionserver上，这样可以让请求分散到不同的RegionServer上，已达到负载均衡 , 这也是HBase的一个优点 。</p></blockquote><ul><li><p>ConstantSizeRegionSplitPolicy</p><blockquote><p>0.94版本前，HBase region的默认切分策略 </p></blockquote><p>当region中最大的store大小超过某个阈值(hbase.hregion.max.filesize&#x3D;10G)之后就会触发切分，一个region等分为2个region。</p><p>但是在生产线上这种切分策略却有相当大的弊端（切分策略对于大表和小表没有明显的区分）：</p><ul><li>阈值(hbase.hregion.max.filesize)设置较大对大表比较友好，但是小表就有可能不会触发分裂，极端情况下可能就1个，形成热点，这对业务来说并不是什么好事。</li><li>如果设置较小则对小表友好，但一个大表就会在整个集群产生大量的region，这对于集群的管理、资源使用、failover来说都不是一件好事。</li></ul></li><li><p>IncreasingToUpperBoundRegionSplitPolicy</p><blockquote><p>0.94版本~2.0版本默认切分策略 </p></blockquote><p>​        总体看和ConstantSizeRegionSplitPolicy思路相同，一个region中最大的store大小大于设置阈值就会触发切分。<br>但是这个阈值并不像ConstantSizeRegionSplitPolicy是一个固定的值，而是会在一定条件下不断调整，调整规则和region所属表在当前regionserver上的region个数有关系.</p><p>region split阈值的计算公式是：</p><ul><li><p>设regioncount：是region所属表在当前regionserver上的region的个数</p></li><li><p>阈值 &#x3D; regioncount^3 * 128M * 2，当然阈值并不会无限增长，最大不超过MaxRegionFileSize（10G),当region中最大的store的大小达到该阈值的时候进行region split</p></li></ul><p>例如：</p><ul><li>第一次split阈值 &#x3D; 1^3 * 256 &#x3D; 256MB</li><li>第二次split阈值 &#x3D; 2^3 * 256 &#x3D; 2048MB</li><li>第三次split阈值 &#x3D; 3^3 * 256 &#x3D; 6912MB</li><li>第四次split阈值 &#x3D; 4^3 * 256 &#x3D; 16384MB &gt; 10GB，因此取较小的值10GB</li><li>后面每次split的size都是10GB了</li></ul><p><strong>特点</strong></p><ul><li>相比ConstantSizeRegionSplitPolicy，可以自适应大表、小表；</li><li>在集群规模比较大的情况下，对大表的表现比较优秀</li><li>对小表不友好，小表可能产生大量的小region，分散在各regionserver上</li><li>小表达不到多次切分条件，导致每个split都很小，所以分散在各个regionServer上</li></ul></li><li><p>SteppingSplitPolicy</p><blockquote><p>2.0版本默认切分策略</p></blockquote><p>​    相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些<br>​    region切分的阈值依然和待分裂region所属表在当前regionserver上的region个数有关系</p><ul><li>如果region个数等于1，切分阈值为flush size 128M * 2</li><li>否则为MaxRegionFileSize。</li></ul><blockquote><p>这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小region，而是适可而止。</p></blockquote></li><li><p>KeyPrefixRegionSplitPolicy</p><blockquote><p>根据rowKey的前缀对数据进行分区，这里是指定rowKey的前多少位作为前缀，比如rowKey都是16位的，指定前5位是前缀，那么前5位相同的rowKey在相同的region中。</p></blockquote></li><li><p>DelimitedKeyPrefixRegionSplitPolicy</p><blockquote><p>保证相同前缀的数据在同一个region中，例如rowKey的格式为：userid_eventtype_eventid，指定的delimiter为 _ ，则split的的时候会确保userid相同的数据在同一个region中。<br>按照分隔符进行切分，而KeyPrefixRegionSplitPolicy是按照指定位数切分。</p></blockquote></li><li><p>BusyRegionSplitPolicy</p><blockquote><p>按照一定的策略判断Region是不是Busy状态，如果是即进行切分</p><p>如果你的系统常常会出现热点Region，而你对性能有很高的追求，那么这种策略可能会比较适合你。它会通过拆分热点Region来缓解热点Region的压力，但是根据热点来拆分Region也会带来很多不确定性因素，因为你也不知道下一个被拆分的Region是哪个。</p></blockquote></li><li><p>DisabledRegionSplitPolicy</p><blockquote><p>不启用自动拆分, 需要指定手动拆分</p></blockquote></li></ul><h2 id="三、Compaction操作"><a href="#三、Compaction操作" class="headerlink" title="三、Compaction操作"></a>三、Compaction操作</h2><h4 id="Minor-Compaction："><a href="#Minor-Compaction：" class="headerlink" title="Minor Compaction："></a>Minor Compaction：</h4><ul><li>指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次 Minor Compaction 的结果是更少并且更大的StoreFile。</li></ul><h4 id="Major-Compaction："><a href="#Major-Compaction：" class="headerlink" title="Major Compaction："></a>Major Compaction：</h4><ul><li>指将<strong>所有的StoreFile</strong>合并成一个StoreFile，这个过程会清理三类没有意义的数据：<strong>被删除的数据</strong>、<strong>TTL过期数据</strong>、<strong>版本号超过设定版本号的数据</strong>。另外，一般情况下，major compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发major compaction功能，改为手动在业务低峰期触发。</li></ul><blockquote><p>参考文档：<a href="https://cloud.tencent.com/developer/article/1488439">https://cloud.tencent.com/developer/article/1488439</a></p></blockquote><h2 id="四、面对百亿数据，HBase为什么查询速度依然非常快？"><a href="#四、面对百亿数据，HBase为什么查询速度依然非常快？" class="headerlink" title="四、面对百亿数据，HBase为什么查询速度依然非常快？"></a>四、面对百亿数据，HBase为什么查询速度依然非常快？</h2><p>HBase适合存储PB级别的海量数据（百亿千亿量级条记录），如果根据记录主键Rowkey来查询，能在几十到百毫秒内返回数据。</p><p><strong>那么HBase是如何做到的呢？</strong></p><p>下面，简单阐述一下数据的查询思路和过程。</p><h2 id="查询过程"><a href="#查询过程" class="headerlink" title="查询过程"></a>查询过程</h2><h5 id="第1步："><a href="#第1步：" class="headerlink" title="第1步："></a>第1步：</h5><p>项目有100亿业务数据，存储在一个HBase集群上（由多个服务器数据节点构成），每个数据节点上有若干个Region（区域），每个Region实际上就是HBase中一批数据的集合（一段连续范围rowkey的数据）。</p><p>我们现在开始根据主键RowKey来查询对应的记录，通过meta表可以帮我们迅速定位到该记录所在的数据节点，以及数据节点中的Region，目前我们有100亿条记录，占空间10TB。所有记录被切分成5000个Region，那么现在，每个Region就是2G。</p><p><strong>由于记录在1个Region中，所以现在我们只要查询这2G的记录文件，就能找到对应记录。</strong></p><h5 id="第2步："><a href="#第2步：" class="headerlink" title="第2步："></a>第2步：</h5><p>由于HBase存储数据是按照列族存储的。比如一条记录有400个字段，前100个字段是人员信息相关，这是一个列簇（列的集合）；中间100个字段是公司信息相关，是一个列簇。另外100个字段是人员交易信息相关，也是一个列簇；最后还有100个字段是其他信息，也是一个列簇</p><p>这四个列簇是分开存储的，这时，假设2G的Region文件中，分为4个列族，那么每个列族就是500M。</p><p><strong>到这里，我们只需要遍历这500M的列簇就可以找到对应的记录。</strong></p><h5 id="第3步："><a href="#第3步：" class="headerlink" title="第3步："></a>第3步：</h5><p>如果要查询的记录在其中1个列族上，1个列族在HDFS中会包含1个或者多个HFile。</p><p>如果一个HFile一般的大小为100M，那么该列族包含5个HFile在磁盘上或内存中。</p><p>由于HBase的内存进而磁盘中的数据是排好序的，要查询的记录有可能在最前面，也有可能在最后面，按平均来算，<strong>我们只需遍历2.5个HFile共250M，即可找到对应的记录。</strong></p><h5 id="第4步："><a href="#第4步：" class="headerlink" title="第4步："></a>第4步：</h5><p>每个HFile中，是以键值对(key&#x2F;value)方式存储，只要遍历文件中的key位置并判断符合条件即可</p><p>一般key是有限的长度，假设key&#x2F;value比是1:24，<strong>最终只需要10M的数据量，就可获取的对应的记录。</strong></p><p>如果数据在机械磁盘上，按其访问速度100M&#x2F;S，只需0.1秒即可查到。</p><p>如果是SSD的话，0.01秒即可查到。</p><p>当然，扫描HFile时还可以通过布隆过滤器快速定位到对应的HFile，以及HBase是有内存缓存机制的，如果数据在内存中，效率会更高。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>正因为以上大致的查询思路，保证了HBase即使随着数据量的剧增，也不会导致查询性能的下降。</p><p>同时，HBase是一个面向列存储的数据库（列簇机制），当表字段非常多时，可以把其中一些字段独立出来放在一部分机器上，而另外一些字段放到另一部分机器上，分散存储，分散列查询。</p><p>正由于这样复杂的存储结构和分布式的存储方式，保证了HBase海量数据下的查询效率。</p><h2 id="五、HBase与Hive的集成"><a href="#五、HBase与Hive的集成" class="headerlink" title="五、HBase与Hive的集成"></a>五、HBase与Hive的集成</h2><blockquote><p>HBase与Hive的对比</p></blockquote><p><strong>hive:</strong></p><p>数据仓库：Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p><p>用于数据分析、清洗：Hive适用于离线的数据分析和清洗，延迟较高。</p><p>基于HDFS、MapReduce：Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</p><p><strong>HBase</strong></p><p>数据库：是一种面向列族存储的非关系型数据库。</p><p>用于存储结构化和非结构化的数据：适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p><p>基于HDFS：数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</p><p>延迟较低，接入在线业务使用：面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p><blockquote><p>在<code>hive-site.xml</code>中添加zookeeper的属性</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102,hadoop103,hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.client.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><h2 id="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"><a href="#HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表" class="headerlink" title="HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表"></a>HBase中已经存储了某一张表，在Hive中创建一个外部表来关联HBase中的这张表</h2></blockquote><blockquote><p>建立外部表的字段名要和hbase中的列名一致</p><p>前提是hbase中已经有表了</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> students_hbase</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">name string,</span><br><span class="line">age string,</span><br><span class="line">gender string, </span><br><span class="line">clazz string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:name,</span><br><span class="line">info:age,</span><br><span class="line">info:gender,</span><br><span class="line">info:clazz</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:students&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> score_hbase2</span><br><span class="line">(</span><br><span class="line">id string,</span><br><span class="line">score_dan string</span><br><span class="line">)</span><br><span class="line">stored <span class="keyword">by</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">with</span> serdeproperties (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;</span><br><span class="line">:key,</span><br><span class="line">info:score_dan</span><br><span class="line">&quot;)</span><br><span class="line">tblproperties(&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;default:score&quot;);</span><br></pre></td></tr></table></figure><blockquote><p>关联后就可以使用Hive函数进行一些分析操作了</p></blockquote><h2 id="六、Phoenix"><a href="#六、Phoenix" class="headerlink" title="六、Phoenix"></a>六、Phoenix</h2><blockquote><p>Hbase适合存储大量的对关系运算要求低的NOSQL数据，受Hbase 设计上的限制不能直接使用原生的API执行在关系数据库中普遍使用的条件判断和聚合等操作。Hbase很优秀，一些团队寻求在Hbase之上提供一种更面向普通开发人员的操作方式，Apache Phoenix即是。</p></blockquote><blockquote><p>Phoenix 基于Hbase给面向业务的开发人员提供了以标准SQL的方式对Hbase进行查询操作，并支持标准SQL中大部分特性:条件运算,分组，分页，等高级查询语法。</p></blockquote><h3 id="1、Phoenix搭建"><a href="#1、Phoenix搭建" class="headerlink" title="1、Phoenix搭建"></a>1、Phoenix搭建</h3><p><strong>Phoenix 4.15    HBase 1.4.6    hadoop 2.7.6</strong></p><h4 id="1、关闭hbase集群，在master中执行"><a href="#1、关闭hbase集群，在master中执行" class="headerlink" title="1、关闭hbase集群，在master中执行"></a>1、关闭hbase集群，在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="2、上传解压配置环境变量"><a href="#2、上传解压配置环境变量" class="headerlink" title="2、上传解压配置环境变量"></a>2、上传解压配置环境变量</h4><p>解压</p><p><code>tar -xvf apache-phoenix-4.15.0-HBase-1.4-bin.tar.gz -C /usr/local/soft/</code></p><p>改名</p><p><code>mv apache-phoenix-4.15.0-HBase-1.4-bin phoenix-4.15.0</code></p><h4 id="3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下"><a href="#3、将phoenix-4-15-0-HBase-1-4-server-jar复制到所有节点的hbase-lib目录下" class="headerlink" title="3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下"></a>3、将phoenix-4.15.0-HBase-1.4-server.jar复制到所有节点的hbase lib目录下</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar master:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node1:/usr/local/soft/hbase-1.4.6/lib/</span><br><span class="line"></span><br><span class="line">scp /usr/local/soft/phoenix-4.15.0/phoenix-4.15.0-HBase-1.4-server.jar node2:/usr/local/soft/hbase-1.4.6/lib/</span><br></pre></td></tr></table></figure><h4 id="4、启动hbase-，-在master中执行"><a href="#4、启动hbase-，-在master中执行" class="headerlink" title="4、启动hbase ， 在master中执行"></a>4、启动hbase ， 在master中执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h4 id="5、配置环境变量"><a href="#5、配置环境变量" class="headerlink" title="5、配置环境变量"></a>5、配置环境变量</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><h3 id="2、Phoenix使用"><a href="#2、Phoenix使用" class="headerlink" title="2、Phoenix使用"></a>2、Phoenix使用</h3><h4 id="1、连接sqlline"><a href="#1、连接sqlline" class="headerlink" title="1、连接sqlline"></a>1、连接sqlline</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sqlline.py master,node1,node2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">出现即已连接成功</span></span><br><span class="line">163/163 (100%) Done</span><br><span class="line">Done</span><br><span class="line">sqlline version 1.5.0</span><br><span class="line">0: jdbc:phoenix:master,node1,node2&gt; </span><br></pre></td></tr></table></figure><h4 id="2、常用命令"><a href="#2、常用命令" class="headerlink" title="2、常用命令"></a>2、常用命令</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="number">1</span>、创建表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> student (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> name <span class="type">VARCHAR</span>,</span><br><span class="line"> age <span class="type">BIGINT</span>, </span><br><span class="line"> gender <span class="type">VARCHAR</span> ,</span><br><span class="line"> clazz <span class="type">VARCHAR</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>、显示所有表</span><br><span class="line"> <span class="operator">!</span><span class="keyword">table</span></span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、插入数据</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100004&#x27;</span>,<span class="string">&#x27;葛德曜&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100005&#x27;</span>,<span class="string">&#x27;宣谷芹&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科六班&#x27;</span>);</span><br><span class="line">upsert <span class="keyword">into</span> STUDENT <span class="keyword">values</span>(<span class="string">&#x27;1500100006&#x27;</span>,<span class="string">&#x27;羿彦昌&#x27;</span>,<span class="number">24</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、查询数据,支持大部分<span class="keyword">sql</span>语法，</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT ;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> age<span class="operator">=</span><span class="number">24</span>;</span><br><span class="line"><span class="keyword">select</span> gender ,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> STUDENT <span class="keyword">group</span> <span class="keyword">by</span> gender;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student <span class="keyword">order</span> <span class="keyword">by</span> gender;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、删除数据</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> STUDENT <span class="keyword">where</span> id<span class="operator">=</span><span class="string">&#x27;1500100004&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>、删除表</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> STUDENT;</span><br><span class="line"> </span><br><span class="line"># <span class="number">7</span>、退出命令行</span><br><span class="line"><span class="operator">!</span>quit</span><br><span class="line"></span><br><span class="line">更多语法参照官网</span><br><span class="line">https:<span class="operator">/</span><span class="operator">/</span>phoenix.apache.org<span class="operator">/</span><span class="keyword">language</span><span class="operator">/</span>index.html#upsert_select</span><br></pre></td></tr></table></figure><h4 id="3、phoenix表映射"><a href="#3、phoenix表映射" class="headerlink" title="3、phoenix表映射"></a>3、phoenix表映射</h4><blockquote><p> 默认情况下，直接在hbase中创建的表，通过phoenix是查看不到的</p></blockquote><blockquote><p>如果需要在phoenix中操作直接在hbase中创建的表，则需要在phoenix中进行表的映射。映射方式有两种：视图映射和表映射</p></blockquote><h5 id="3-1、视图映射"><a href="#3-1、视图映射" class="headerlink" title="3.1、视图映射"></a>3.1、视图映射</h5><blockquote><p> Phoenix创建的视图是只读的，所以只能用来做查询，无法通过视图对源数据进行修改等操作</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># hbase shell 进入hbase命令行</span><br><span class="line">hbase shell </span><br><span class="line"></span><br><span class="line"># 创建hbase表</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;company&#x27;</span> </span><br><span class="line"></span><br><span class="line"># 插入数据</span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:firstname&#x27;</span>,<span class="string">&#x27;zhangsan1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;name:lastname&#x27;</span>,<span class="string">&#x27;zhangsan2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:name&#x27;</span>,<span class="string">&#x27;数加&#x27;</span></span><br><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;001&#x27;</span>,<span class="string">&#x27;company:address&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span></span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> TEST <span class="keyword">values</span>(<span class="string">&#x27;002&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"># 在phoenix创建视图， <span class="keyword">primary</span> key 对应到hbase中的rowkey</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> &quot;test&quot;(</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">view</span> &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 在phoenix查询数据，表名通过双引号引起来</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> &quot;test&quot;;</span><br><span class="line"></span><br><span class="line"># 删除视图</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">view</span> &quot;test&quot;;</span><br></pre></td></tr></table></figure><h5 id="3-2、表映射"><a href="#3-2、表映射" class="headerlink" title="3.2、表映射"></a>3.2、表映射</h5><p>使用Apache Phoenix创建对HBase的表映射，有两类：</p><p>1） 当HBase中已经存在表时，可以以类似创建视图的方式创建关联表，只需要将create view改为create table即可。</p><p>2）当HBase中不存在表时，可以直接使用create table指令创建需要的表，并且在创建指令中可以根据需要对HBase表结构进行显示的说明。</p><p>第1）种情况下，如在之前的基础上已经存在了test表，则表映射的语句如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> &quot;test&quot; (</span><br><span class="line">empid <span class="type">varchar</span> <span class="keyword">primary</span> key,</span><br><span class="line">&quot;name&quot;.&quot;firstname&quot; <span class="type">varchar</span>,</span><br><span class="line">&quot;name&quot;.&quot;lastname&quot;<span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;name&quot;  <span class="type">varchar</span>,</span><br><span class="line">&quot;company&quot;.&quot;address&quot; <span class="type">varchar</span></span><br><span class="line">)column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span>  &quot;test&quot;  <span class="keyword">values</span>(<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;xiaoxiao&#x27;</span>,<span class="string">&#x27;数加&#x27;</span>,<span class="string">&#x27;合肥&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;students&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;name&quot; <span class="type">VARCHAR</span>,</span><br><span class="line"> &quot;info&quot;.&quot;age&quot; <span class="type">VARCHAR</span>, </span><br><span class="line"> &quot;info&quot;.&quot;gender&quot; <span class="type">VARCHAR</span> ,</span><br><span class="line"> &quot;info&quot;.&quot;clazz&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">upsert <span class="keyword">into</span> &quot;students&quot; <span class="keyword">values</span>(<span class="string">&#x27;150011000100&#x27;</span>,<span class="string">&#x27;xiaohu&#x27;</span>,<span class="string">&#x27;24&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;理科三班&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span>  &quot;score&quot; (</span><br><span class="line"> id <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY, </span><br><span class="line"> &quot;info&quot;.&quot;score_dan&quot; <span class="type">VARCHAR</span></span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>使用create table创建的关联表，如果对表进行了修改，源数据也会改变，同时如果关联表被删除，源表也会被删除。但是视图就不会，如果删除视图，源数据不会发生改变。</p><h2 id="七、bulkLoad实现批量导入"><a href="#七、bulkLoad实现批量导入" class="headerlink" title="七、bulkLoad实现批量导入"></a>七、bulkLoad实现批量导入</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ol><li><p>如果我们一次性入库hbase巨量数据，处理速度慢不说，还特别占用Region资源， 一个比较高效便捷的方法就是使用 “Bulk Loading”方法，即HBase提供的HFileOutputFormat类。</p></li><li><p>它是利用hbase的数据信息按照特定格式存储在hdfs内这一原理，直接生成这种hdfs内存储的数据格式文件，然后上传至合适位置，即完成巨量数据快速入库的办法。配合mapreduce完成，高效便捷，而且不占用region资源，增添负载。</p></li></ol><h3 id="限制："><a href="#限制：" class="headerlink" title="限制："></a>限制：</h3><ol><li>仅适合初次数据导入，即表内数据为空，或者每次入库表内都无数据的情况。</li><li>HBase集群与Hadoop集群为同一集群，即HBase所基于的HDFS为生成HFile的MR的集群</li></ol><h3 id="代码编写："><a href="#代码编写：" class="headerlink" title="代码编写："></a>代码编写：</h3><blockquote><p>提前在Hbase中创建好表</p><p>生成Hfile基本流程：</p><ol><li><p>设置Mapper的输出KV类型：     </p><p>K： ImmutableBytesWritable（代表行键）</p><p>V： KeyValue  （代表cell）</p></li></ol><p>​    2.  开发Mapper</p><p>​        读取你的原始数据，按你的需求做处理</p><p>​        输出rowkey作为K，输出一些KeyValue（Put）作为V</p><p>​    3.  配置job参数</p><p>​        a. Zookeeper的连接地址</p><p>​        b. 配置输出的OutputFormat为HFileOutputFormat2，并为其设置参数</p><p>​    4.  提交job</p><p>​            导入HFile到RegionServer的流程</p><p>​                构建一个表描述对象</p><p>​            构建一个region定位工具</p><p>​            然后用LoadIncrementalHFiles来doBulkload操作</p></blockquote><blockquote><p>pom文件：</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-bigdata17<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.shujia<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>had-hbase-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-server<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- compiler插件, 设定JDK版本 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">showWarnings</span>&gt;</span>true<span class="tag">&lt;/<span class="name">showWarnings</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">&lt;!-- 带依赖jar 插件--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>电信数据</p></blockquote><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br></pre></td></tr></table></figure><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><ol><li><p>最终输出结果，无论是map还是reduce，输出部分key和value的类型必须是： &lt;ImmutableBytesWritable, KeyValue&gt;或者&lt;ImmutableBytesWritable, Put&gt;。</p></li><li><p>最终输出部分，Value类型是KeyValue 或Put，对应的Sorter分别是KeyValueSortReducer或PutSortReducer。</p></li><li><p>MR例子中HFileOutputFormat2.configureIncrementalLoad(job, dianxin_bulk, regionLocator);自动对job进行配置。SimpleTotalOrderPartitioner是需要先对key进行整体排序，然后划分到每个reduce中，保证每一个reducer中的的key最小最大值区间范围，是不会有交集的。因为入库到HBase的时候，作为一个整体的Region，key是绝对有序的。</p></li><li><p>MR例子中最后生成HFile存储在HDFS上，输出路径下的子目录是各个列族。如果对HFile进行入库HBase，相当于move HFile到HBase的Region中，HFile子目录的列族内容没有了，但不能直接使用mv命令移动，因为直接移动不能更新HBase的元数据。</p></li><li><p>HFile入库到HBase通过HBase中 LoadIncrementalHFiles的doBulkLoad方法，对生成的HFile文件入库</p></li></ol><h2 id="八、HBase中rowkey的设计（重点）"><a href="#八、HBase中rowkey的设计（重点）" class="headerlink" title="八、HBase中rowkey的设计（重点）"></a>八、HBase中rowkey的设计（重点）</h2><p><strong>HBase的RowKey设计</strong></p><p>HBase是三维有序存储的，通过rowkey（行键），column key（column family和qualifier）和TimeStamp（时间戳）这个三个维度可以对HBase中的数据进行快速定位。</p><p>HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有两种方式：</p><p> 通过get方式，指定rowkey获取唯一一条记录</p><p> 通过scan方式，设置startRow和stopRow参数进行范围匹配</p><p> 全表扫描，即直接扫描整张表中所有行记录</p><p><strong>rowkey长度原则</strong></p><p>rowkey是一个二进制码流，可以是任意字符串，最大长度 <em>64kb</em> ，实际应用中一般为10-100bytes，以 byte[] 形式保存，一般设计成定长。</p><p>建议越短越好，不要超过16个字节，原因如下：</p><p> 数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w&#x3D;10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；</p><p> MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。</p><p> 目前操作系统都是64位系统，内存8字节对齐，控制在16个字节，8字节的整数倍利用了操作系统的最佳特性。</p><p><strong>rowkey散列原则</strong></p><p>如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程序随机生成，低位放时间字段，这样将提高数据均衡分布在每个RegionServer，以实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载会集中在个别的RegionServer上，造成热点问题，会降低查询效率。</p><p><strong>rowkey唯一原则</strong></p><p>必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。</p><p><strong>什么是热点</strong></p><p>HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的行存取在临近位置，便于scan。然而糟糕的rowkey设计是热点的源头。 热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。大量访问会使热点region所在的单个机器超出自身承受能力，引起性能下降甚至region不可用，这也会影响同一个RegionServer上的其他region，由于主机无法服务其他region的请求。 设计良好的数据访问模式以使集群被充分，均衡的利用。</p><p>为了避免写热点，设计rowkey使得不同行在同一个region，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。</p><p>下面是一些常见的避免热点的方法以及它们的优缺点：</p><p><strong>加盐</strong></p><p>这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。</p><p><strong>哈希</strong></p><p>哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据</p><p><strong>反转</strong></p><p>第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。</p><p>反转rowkey的例子以手机号为rowkey，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那样比较固定开头导致热点问题</p><p><strong>时间戳反转</strong></p><p>一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 [key]reverse_timestamp , [key] 的最新值可以通过scan [key]获得[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。</p><p>比如需要保存一个用户的操作记录，按照操作时间倒序排序，在设计rowkey的时候，可以这样设计</p><p>[userId反转]Long.Max_Value - timestamp，在查询用户的所有操作记录数据的时候，直接指定反转后的userId，startRow是[userId反转]000000000000,stopRow是[userId反转]Long.Max_Value - timestamp</p><p>如果需要查询某段时间的操作记录，startRow是[user反转]Long.Max_Value - 起始时间，stopRow是[userId反转]Long.Max_Value - 结束时间</p><p>其他一些建议</p><p> 尽量减少行和列的大小在HBase中，value永远和它的key一起传输的。当具体的值在系统间传输时，它的rowkey，列名，时间戳也会一起传输。如果你的rowkey和列名很大，甚至可以和具体的值相比较，那么你将会遇到一些有趣的问题。HBase storefiles中的索引（有助于随机访问）最终占据了HBase分配的大量内存，因为具体的值和它的key很大。可以增加block大小使得storefiles索引再更大的时间间隔增加，或者修改表的模式以减小rowkey和列名的大小。压缩也有助于更大的索引。</p><p> 列族尽可能越短越好，最好是一个字符</p><p> 冗长的属性名虽然可读性好，但是更短的属性名存储在HBase中会更好</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 原数据：以时间戳_user_id作为rowkey</span><br><span class="line"># 时间戳高位变化不大，太连续，最终可能会导致热点问题</span><br><span class="line">1638584124_user_id</span><br><span class="line">1638584135_user_id</span><br><span class="line">1638584146_user_id</span><br><span class="line">1638584157_user_id</span><br><span class="line">1638584168_user_id</span><br><span class="line">1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 解决方案：加盐、反转、哈希</span><br><span class="line"></span><br><span class="line"># 加盐</span><br><span class="line"># 加上随即前缀，随机的打散</span><br><span class="line"># 该过程无法预测 前缀时随机的</span><br><span class="line">00_1638584124_user_id</span><br><span class="line">05_1638584135_user_id</span><br><span class="line">03_1638584146_user_id</span><br><span class="line">04_1638584157_user_id</span><br><span class="line">02_1638584168_user_id</span><br><span class="line">06_1638584179_user_id</span><br><span class="line"></span><br><span class="line"># 反转</span><br><span class="line"># 适用于高位变化不大，低位变化大的rowkey</span><br><span class="line">4214858361_user_id</span><br><span class="line">5314858361_user_id</span><br><span class="line">6414858361_user_id</span><br><span class="line">7514858361_user_id</span><br><span class="line">8614858361_user_id</span><br><span class="line">9714858361_user_id</span><br><span class="line"></span><br><span class="line"># 散列 md5、sha1、sha256......</span><br><span class="line">25531D7065AE158AAB6FA53379523979_user_id</span><br><span class="line">60F9A0072C0BD06C92D768DACF2DFDC3_user_id</span><br><span class="line">D2EFD883A6C0198DA3AF4FD8F82DEB57_user_id</span><br><span class="line">A9A4C265D61E0801D163927DE1299C79_user_id</span><br><span class="line">3F41251355E092D7D8A50130441B58A5_user_id</span><br><span class="line">5E6043C773DA4CF991B389D200B77379_user_id</span><br><span class="line"></span><br><span class="line"># 时间戳&quot;反转&quot;</span><br><span class="line"># rowkey：时间戳_user_id</span><br><span class="line"># rowkey是字典升序的，那么越新的记录会被排在最后面，不容易被获取到</span><br><span class="line"># 需求：让最新的记录排在最前面</span><br><span class="line"></span><br><span class="line"># 大数：9999999999</span><br><span class="line"># 大数-小数</span><br><span class="line"></span><br><span class="line">1638584124_user_id =&gt; 8361415875_user_id</span><br><span class="line">1638584135_user_id =&gt; 8361415864_user_id</span><br><span class="line">1638584146_user_id =&gt; 8361415853_user_id</span><br><span class="line">1638584157_user_id =&gt; 8361415842_user_id</span><br><span class="line">1638584168_user_id =&gt; 8361415831_user_id</span><br><span class="line">1638584179_user_id =&gt; 8361415820_user_id</span><br><span class="line"></span><br><span class="line">1638586193_user_id =&gt; 8361413806_user_id</span><br></pre></td></tr></table></figure><h3 id="合理设计rowkey实战（电信）"><a href="#合理设计rowkey实战（电信）" class="headerlink" title="合理设计rowkey实战（电信）"></a>合理设计rowkey实战（电信）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">手机号,网格编号,城市编号,区县编号,停留时间,进入时间,离开时间,时间分区</span><br><span class="line">D55433A437AEC8D8D3DB2BCA56E9E64392A9D93C,117210031795040,83401,8340104,301,20180503190539,20180503233517,20180503</span><br><span class="line"></span><br><span class="line">将用户位置数据保存到hbase</span><br><span class="line">    查询需求</span><br><span class="line">        1、通过手机号查询用户最近10条位置记录</span><br><span class="line"></span><br><span class="line">        2、获取用户某一天在一个城市中的所有位置</span><br><span class="line"></span><br><span class="line">    怎么设计hbase表</span><br><span class="line">        1、rowkey</span><br><span class="line">        2、时间戳</span><br></pre></td></tr></table></figure><h2 id="九、二级索引"><a href="#九、二级索引" class="headerlink" title="九、二级索引"></a>九、二级索引</h2><blockquote><p><strong>二级索引的本质就是建立各列值与行键之间的映射关系</strong></p></blockquote><p><strong>Hbase的局限性：</strong></p><p>　　HBase本身只提供基于行键和全表扫描的查询，而行键索引单一，对于多维度的查询困难。</p><p><strong>所以我们引进一个二级索引的概念</strong></p><h3 id="常见的二级索引："><a href="#常见的二级索引：" class="headerlink" title="常见的二级索引："></a><strong>常见的二级索引：</strong></h3><p>HBase的一级索引就是rowkey，我们只能通过rowkey进行检索。如果我们相对hbase里面列族的列列进行一些组合查询，就需要采用HBase的二级索引方案来进行多条件的查询。 </p><p>  　　1. MapReduce方案<br>  　　2. ITHBASE（Indexed-Transanctional HBase）方案<br>  　　3. IHBASE（Index HBase）方案<br>  　　4. Hbase Coprocessor(协处理器)方案<br>  　　5. Solr+hbase方案  redis+hbase 方案</p><p>  　　6. CCIndex（complementalclustering index）方案</p><h3 id="二级索引的种类"><a href="#二级索引的种类" class="headerlink" title="二级索引的种类"></a><strong>二级索引的种类</strong></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">　　1、创建单列索引</span><br><span class="line"></span><br><span class="line">　　2、同时创建多个单列索引</span><br><span class="line"></span><br><span class="line">　　3、创建联合索引（最多同时支持3个列）</span><br><span class="line"></span><br><span class="line">　　4、只根据rowkey创建索引</span><br></pre></td></tr></table></figure><p><strong>单表建立二级索引</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.首先disable ‘表名’</span><br><span class="line">2.然后修改表</span><br><span class="line"></span><br><span class="line">alter &#x27;LogTable&#x27;,METHOD=&gt;&#x27;table_att&#x27;,&#x27;coprocessor&#x27;=&gt;&#x27;hdfs:///写好的Hbase协处理器（coprocessor）的jar包名|类的绝对路径名|1001&#x27;</span><br><span class="line"></span><br><span class="line">3. enable &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><strong>二级索引的设计思路</strong></p><p><img src="https://s2.loli.net/2022/06/15/74rQAdRhWFzasxm.png" alt="image-20220615155157645"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">二级索引的本质就是建立各列值与行键之间的映射关系</span><br><span class="line"></span><br><span class="line">如上图，当要对F:C1这列建立索引时，只需要建立F:C1各列值到其对应行键的映射关系，如C11-&gt;RK1等，这样就完成了对F:C1列值的二级索引的构建，当要查询符合F:C1=C11对应的F:C2的列值时（即根据C1=C11来查询C2的值,图1青色部分）</span><br><span class="line"></span><br><span class="line">其查询步骤如下：</span><br><span class="line"></span><br><span class="line">1. 根据C1=C11到索引数据中查找其对应的RK，查询得到其对应的RK=RK1</span><br><span class="line"></span><br><span class="line">2. 得到RK1后就自然能根据RK1来查询C2的值了 这是构建二级索引大概思路，其他组合查询的联合索引的建立也类似。</span><br></pre></td></tr></table></figure><h3 id="Mapreduce的方式创建二级索引"><a href="#Mapreduce的方式创建二级索引" class="headerlink" title="Mapreduce的方式创建二级索引"></a><strong>Mapreduce的方式创建二级索引</strong></h3><p>使用整合MapReduce的方式创建hbase索引。主要的流程如下：</p><p>1.1扫描输入表，使用hbase继承类TableMapper</p><p>1.2获取rowkey和指定字段名称和字段值</p><p>1.3创建Put实例， value&#x3D;” “, rowkey&#x3D;班级，column&#x3D;学号</p><p>1.4使用IdentityTableReducer将数据写入索引表</p><h4 id="案例："><a href="#案例：" class="headerlink" title="案例："></a>案例：</h4><blockquote><p><strong>1、在hbase中创建索引表 student_index</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;student_index&#x27;</span>,<span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>2、编写mapreduce代码</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Mutation;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  编写整个mapreduce程序建立索引表</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexMapper</span> <span class="keyword">extends</span> <span class="title class_">TableMapper</span>&lt;Text, NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(ImmutableBytesWritable key, Result value, Mapper&lt;ImmutableBytesWritable, Result, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(key.get());</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(value.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">key1</span> <span class="operator">=</span> id+<span class="string">&quot;_&quot;</span>+clazz;</span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(key1),NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * reduce端获取map端传过来的key</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IndexReduce</span> <span class="keyword">extends</span> <span class="title class_">TableReducer</span>&lt;Text,NullWritable,NullWritable&gt;&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Reducer&lt;Text, NullWritable, NullWritable, Mutation&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        String[] strings = key.toString().split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> strings[<span class="number">0</span>];</span><br><span class="line">        <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> strings[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//索引表也是属于hbase的表，需要使用put实例添加数据</span></span><br><span class="line">        <span class="type">Put</span> <span class="variable">put</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(clazz.getBytes());</span><br><span class="line">        put.add(<span class="string">&quot;info&quot;</span>.getBytes(),id.getBytes(),<span class="string">&quot;&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        context.write(NullWritable.get(),put);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndex</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        job.setJobName(<span class="string">&quot;建立学生索引表&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(HbaseIndex.class);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.addFamily(<span class="string">&quot;info&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定对哪张表建立索引，以及指定需要建索引的列所属的列簇</span></span><br><span class="line">        TableMapReduceUtil.initTableMapperJob(<span class="string">&quot;students&quot;</span>,scan,IndexMapper.class,Text.class,NullWritable.class,job);</span><br><span class="line">        TableMapReduceUtil.initTableReducerJob(<span class="string">&quot;student_index&quot;</span>,IndexReduce.class,job);</span><br><span class="line"></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>3、打成jar包上传到hadoop中运行</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop jar had-hbase-demo-1.0-SNAPSHOT-jar-with-dependencies.jar com.shujia.hbaseapi.hbaseindexdemo.HbaseIndex</span><br></pre></td></tr></table></figure><blockquote><p><strong>4、编写查询代码，测试结果（先查询索引表，在查数据）</strong></p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.hbaseapi.hbaseindexdemo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.Cell;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.CellUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.CompareFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SubstringComparator;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"><span class="keyword">import</span> org.junit.After;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseIndexToStudents</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> HConnection conn;</span><br><span class="line">    <span class="keyword">private</span> HBaseAdmin hAdmin;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">connect</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//1、获取Hadoop的相关配置环境</span></span><br><span class="line">            <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//2、获取zookeeper的配置</span></span><br><span class="line">            conf.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;master:2181,node1:2181,node2:2181&quot;</span>);</span><br><span class="line">            <span class="comment">//获取与Hbase的连接，这个连接是将来可以用户获取hbase表的</span></span><br><span class="line">            conn = HConnectionManager.createConnection(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//将来我们要对表做DDL相关操作，而对表的操作在hbase架构中是有HMaster</span></span><br><span class="line">            hAdmin = <span class="keyword">new</span> <span class="title class_">HBaseAdmin</span>(conf);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;建立连接成功:&quot;</span> + conn + <span class="string">&quot;, HMaster获取成功：&quot;</span> + hAdmin);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过索引表进行查询数据</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * 需求：获取理科二班所有的学生信息，不适用过滤器，使用索引表查询</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">scanData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//创建一个集合存放查询到的学号</span></span><br><span class="line">            ArrayList&lt;Get&gt; gets = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取到索引表</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">student_index</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;student_index&quot;</span>);</span><br><span class="line">            <span class="comment">//创建Get实例</span></span><br><span class="line">            <span class="type">Get</span> <span class="variable">get</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(<span class="string">&quot;理科二班&quot;</span>.getBytes());</span><br><span class="line">            <span class="type">Result</span> <span class="variable">result</span> <span class="operator">=</span> student_index.get(get);</span><br><span class="line">            List&lt;Cell&gt; cells = result.listCells();</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">                <span class="comment">//每一个单元格的列名</span></span><br><span class="line">                <span class="type">byte</span>[] bytes = CellUtil.cloneQualifier(cell);</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(bytes);</span><br><span class="line"></span><br><span class="line">                <span class="type">Get</span> <span class="variable">get1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(id.getBytes());</span><br><span class="line">                <span class="comment">//将学号添加到集合中</span></span><br><span class="line">                gets.add(get1);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            Result[] results = students.get(gets);</span><br><span class="line">            <span class="keyword">for</span> (Result result1 : results) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(result1.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(result1.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            <span class="comment">//获取真正的学生数据表 students</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">            <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;理科二班&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(), CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            scan.setFilter(singleColumnValueFilter);</span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">            <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;, 姓名：&quot;</span> + name + <span class="string">&quot;, 年龄：&quot;</span> + age + <span class="string">&quot;, 性别：&quot;</span> + gender + <span class="string">&quot;, 班级：&quot;</span> + clazz);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="type">long</span> <span class="variable">endtime</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">            System.out.println(<span class="string">&quot;=========================================&quot;</span>);</span><br><span class="line">            System.out.println((endtime - start) + <span class="string">&quot;毫秒&quot;</span>);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (conn != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                conn.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;conn连接已经关闭.....&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (hAdmin != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                hAdmin.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;HMaster已经关闭......&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十、Phoenix二级索引"><a href="#十、Phoenix二级索引" class="headerlink" title="十、Phoenix二级索引"></a>十、Phoenix二级索引</h2><blockquote><p>对于Hbase，如果想精确定位到某行记录，唯一的办法就是通过rowkey查询。如果不通过rowkey查找数据，就必须逐行比较每一行的值，对于较大的表，全表扫描的代价是不可接受的。</p></blockquote><h3 id="1、开启索引支持"><a href="#1、开启索引支持" class="headerlink" title="1、开启索引支持"></a>1、开启索引支持</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 关闭hbase集群</span><br><span class="line">stop-hbase.sh</span><br><span class="line"></span><br><span class="line"># 在/usr/local/soft/hbase-1.4.6/conf/hbase-site.xml中增加如下配置</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.wal.codec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 同步到所有节点</span><br><span class="line">scp hbase-site.xml node1:`pwd`</span><br><span class="line">scp hbase-site.xml node2:`pwd`</span><br><span class="line"></span><br><span class="line"># 修改phoenix目录下的bin目录中的hbase-site.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.client.scanner.timeout.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>phoenix.query.timeoutMs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"># 启动hbase</span><br><span class="line">start-hbase.sh</span><br><span class="line"># 重新进入phoenix客户端</span><br><span class="line">sqlline.py master,node1,node2</span><br></pre></td></tr></table></figure><h3 id="2、创建索引"><a href="#2、创建索引" class="headerlink" title="2、创建索引"></a>2、创建索引</h3><h4 id="2-1、全局索引"><a href="#2-1、全局索引" class="headerlink" title="2.1、全局索引"></a>2.1、全局索引</h4><blockquote><p>全局索引适合读多写少的场景。如果使用全局索引，读数据基本不损耗性能，所有的性能损耗都来源于写数据。数据表的添加、删除和修改都会更新相关的索引表（数据删除了，索引表中的数据也会删除；数据增加了，索引表的数据也会增加）</p></blockquote><blockquote><p>注意: 对于全局索引在默认情况下，在查询语句中检索的列如果不在索引表中，Phoenix不会使用索引表将，除非使用hint。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">手机号 进入网格的时间 离开网格的时间 区县编码 经度 纬度 基站标识 网格编号 业务类型</span><br><span class="line"></span><br><span class="line"># 创建DIANXIN.sql</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> DIANXIN (</span><br><span class="line">     mdn <span class="type">VARCHAR</span> ,</span><br><span class="line">     start_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     end_date <span class="type">VARCHAR</span> ,</span><br><span class="line">     county <span class="type">VARCHAR</span>,</span><br><span class="line">     x <span class="keyword">DOUBLE</span> ,</span><br><span class="line">     y  <span class="keyword">DOUBLE</span>,</span><br><span class="line">     bsid <span class="type">VARCHAR</span>,</span><br><span class="line">     grid_id  <span class="type">VARCHAR</span>,</span><br><span class="line">     biz_type <span class="type">VARCHAR</span>, </span><br><span class="line">     event_type <span class="type">VARCHAR</span> , </span><br><span class="line">     data_source <span class="type">VARCHAR</span> ,</span><br><span class="line">     <span class="keyword">CONSTRAINT</span> PK <span class="keyword">PRIMARY</span> KEY (mdn,start_date)</span><br><span class="line">) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"># 上传数据DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 导入数据</span><br><span class="line">psql.py master,node1,node2 DIANXIN.sql DIANXIN.csv</span><br><span class="line"></span><br><span class="line"># 创建全局索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX <span class="keyword">ON</span> DIANXIN ( end_date );</span><br><span class="line"></span><br><span class="line"># 查询数据 ( 索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 （索引生效） hint</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX) */</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> start_date <span class="operator">=</span> <span class="string">&#x27;20180503154614&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 取索引列，（索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 创建多列索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX1 <span class="keyword">ON</span> DIANXIN ( end_date,COUNTY );</span><br><span class="line"></span><br><span class="line"># 多条件查询 （索引生效）</span><br><span class="line"><span class="keyword">select</span> end_date,MDN,COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span>  <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>  <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 查询所有列 （索引生效）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX1) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span> <span class="keyword">and</span> COUNTY <span class="operator">=</span> <span class="string">&#x27;8340104&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 单条件  (索引未生效)</span><br><span class="line"><span class="keyword">select</span> end_date <span class="keyword">from</span> DIANXIN <span class="keyword">where</span>  COUNTY <span class="operator">=</span> <span class="string">&#x27;8340103&#x27;</span>;</span><br><span class="line"># 单条件  (索引生效) end_date 在前</span><br><span class="line"><span class="keyword">select</span> COUNTY <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> end_date <span class="operator">=</span> <span class="string">&#x27;20180503154014&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 删除索引</span><br><span class="line"><span class="keyword">drop</span> index DIANXIN_INDEX <span class="keyword">on</span> DIANXIN;</span><br></pre></td></tr></table></figure><h4 id="2-2、本地索引"><a href="#2-2、本地索引" class="headerlink" title="2.2、本地索引"></a>2.2、本地索引</h4><blockquote><p>本地索引适合写多读少的场景，或者存储空间有限的场景。和全局索引一样，Phoenix也会在查询的时候自动选择是否使用本地索引。本地索引因为索引数据和原数据存储在同一台机器上，避免网络数据传输的开销，所以更适合写多的场景。由于无法提前确定数据在哪个Region上，所以在读数据的时候，需要检查每个Region上的数据从而带来一些性能损耗。</p></blockquote><blockquote><p>注意:对于本地索引，查询中无论是否指定hint或者是查询的列是否都在索引表中，都会使用索引表。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建本地索引</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">LOCAL</span> INDEX DIANXIN_LOCAL_IDEX <span class="keyword">ON</span> DIANXIN(grid_id);</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> grid_id <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 索引生效</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dianxin <span class="keyword">where</span> grid_id<span class="operator">=</span><span class="string">&#x27;117285031820040&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2-3、覆盖索引"><a href="#2-3、覆盖索引" class="headerlink" title="2.3、覆盖索引"></a>2.3、覆盖索引</h4><blockquote><p>覆盖索引是把原数据存储在索引数据表中，这样在查询时不需要再去HBase的原表获取数据就，直接返回查询结果。</p></blockquote><blockquote><p>注意：查询是 select 的列和 where 的列都需要在索引中出现。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建覆盖索引</span><br><span class="line"><span class="keyword">CREATE</span> INDEX DIANXIN_INDEX_COVER <span class="keyword">ON</span> DIANXIN ( x,y ) INCLUDE ( county );</span><br><span class="line"></span><br><span class="line"># 查询所有列 (索引未生效)</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 强制使用索引 (索引生效)</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> <span class="operator">*</span> <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询索引中的列 (索引生效) mdn是DIANXIN表的RowKey中的一部分</span><br><span class="line"><span class="keyword">select</span> x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"><span class="keyword">select</span> mdn,x,y,county <span class="keyword">from</span> DIANXIN <span class="keyword">where</span> x<span class="operator">=</span><span class="number">117.288</span> <span class="keyword">and</span> y <span class="operator">=</span><span class="number">31.822</span>;</span><br><span class="line"></span><br><span class="line"># 查询条件必须放在索引中  <span class="keyword">select</span> 中的列可以放在INCLUDE （将数据保存在索引中）</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+ INDEX(DIANXIN DIANXIN_INDEX_COVER) */</span> x,y,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> DIANXIN <span class="keyword">group</span> <span class="keyword">by</span> x,y;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="十一、Phoenix-JDBC"><a href="#十一、Phoenix-JDBC" class="headerlink" title="十一、Phoenix JDBC"></a>十一、Phoenix JDBC</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># 导入依赖</span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.15.0-HBase-1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.lmax<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>disruptor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"># 建立连接</span><br><span class="line"><span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:phoenix:master,node1,node2:2181&quot;</span>);</span><br><span class="line">        <span class="type">PreparedStatement</span> <span class="variable">ps</span> <span class="operator">=</span> conn.prepareStatement(<span class="string">&quot;select /*+ INDEX(DIANXIN DIANXIN_INDEX) */ * from DIANXIN where end_date=?&quot;</span>);</span><br><span class="line">        ps.setString(<span class="number">1</span>, <span class="string">&quot;20180503212649&quot;</span>);</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> ps.executeQuery();</span><br><span class="line">        <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">mdn</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;mdn&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">start_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;start_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">end_date</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;end_date&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">x</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;x&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">y</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;y&quot;</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">county</span> <span class="operator">=</span> rs.getString(<span class="string">&quot;county&quot;</span>);</span><br><span class="line">            System.out.println(mdn + <span class="string">&quot;\t&quot;</span> + start_date + <span class="string">&quot;\t&quot;</span> + end_date + <span class="string">&quot;\t&quot;</span> + x + <span class="string">&quot;\t&quot;</span> + y + <span class="string">&quot;\t&quot;</span> + county);</span><br><span class="line">        &#125;</span><br><span class="line">        ps.close();</span><br><span class="line">        conn.close();</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase-shell2</title>
      <link href="/2022/06/11/Hbase%20Shell%202/"/>
      <url>/2022/06/11/Hbase%20Shell%202/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Hbase-Shell-2"><a href="#一、Hbase-Shell-2" class="headerlink" title="一、Hbase Shell 2"></a>一、Hbase Shell 2</h2><h3 id="1、Region信息观察"><a href="#1、Region信息观察" class="headerlink" title="1、Region信息观察"></a>1、Region信息观察</h3><h4 id="创建表指定命名空间"><a href="#创建表指定命名空间" class="headerlink" title="创建表指定命名空间"></a>创建表指定命名空间</h4><blockquote><p>在创建表的时候可以选择创建到bigdata17这个namespace中，如何实现呢？<br>使用这种格式即可：‘命名空间名称:表名’<br>针对default这个命名空间，在使用的时候可以省略不写</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;bigdata17:t1&#x27;,&#x27;info&#x27;,&#x27;level&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/Dow6xBpHlRzQ8PG.png" alt="image-20220612212944281"></p><blockquote><p>此时使用list查看所有的表</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/CxKkf4Wui2Smh1A.png" alt="image-20220612212956679"></p><blockquote><p>如果只想查看bigdata17这个命名空间中的表，如何实现呢？<br>可以使用命令list_namespace_tables</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;n1&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/hnEFiVldA1Ksr6W.png" alt="image-20220612213004703"></p><blockquote><p>查看region中的某列簇数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase hfile -p -f /hbase/data/default/tbl_user/92994712513a45baaa12b72117dda5e5/info/d84e2013791845968917d876e2b438a5</span><br></pre></td></tr></table></figure><h4 id="1-1-查看表的所有region"><a href="#1-1-查看表的所有region" class="headerlink" title="1.1    查看表的所有region"></a>1.1    查看表的所有region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/bY5Oj38yBf4mnwL.png" alt="image-20220612213103879"></p><h4 id="1-2-强制将表切分出来一个region"><a href="#1-2-强制将表切分出来一个region" class="headerlink" title="1.2    强制将表切分出来一个region"></a>1.2    强制将表切分出来一个region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">split &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/yaqm2QU1oNlZRLE.png" alt="image-20220612213116364"></p><blockquote><p>但是在页面上可以看到三个：过一会会自动的把原来的删除</p></blockquote><p><img src="D:/bigdata%25E5%259F%25B9%25E8%25AE%25AD/Hbase/day02/Hbase%25E5%25AD%25A6%25E4%25B9%25A0%25EF%25BC%2588%25E4%25BA%258C%25EF%25BC%2589.assets/image-20220609215721140.png" alt="image-20220609215721140"></p><h4 id="1-2-查看某一行在哪个region中"><a href="#1-2-查看某一行在哪个region中" class="headerlink" title="1.2    查看某一行在哪个region中"></a>1.2    查看某一行在哪个region中</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate_region &#x27;表名&#x27;,&#x27;行键&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/GAjNmPi9SRoqJWU.png" alt="image-20220612213129838"></p><blockquote><p>可以hbase hfile -p -f xxxx 查看一下</p></blockquote><h3 id="2、预分region解决热点问题"><a href="#2、预分region解决热点问题" class="headerlink" title="2、预分region解决热点问题"></a>2、预分region解决热点问题</h3><blockquote><p>row设计的一个关键点是查询维度</p><p>(在建表的时候根据具体的查询业务  设计rowkey   预拆分)</p><p>在默认的拆分策略中 ,region的大小达到一定的阈值以后才会进行拆分,并且拆分的region在同一个regionserver中 ,只有达到负载均衡的时机时才会进行region重分配!并且开始如果有大量的数据进行插入操作,那么并发就会集中在单个RS中, 形成热点问题,所以如果有并发插入的时候尽量避免热点问题 ,应当预划分 Region的rowkeyRange范围 ,在建表的时候就指定预region范围 </p></blockquote><blockquote><p>查看命令使用(指定4个切割点，就会有5个region)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">help &#x27;create&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/onVxkTuJROsG2hE.png" alt="image-20220612213148593"></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create &#x27;tb_split&#x27;,&#x27;cf&#x27;,SPLITS =&gt; [&#x27;e&#x27;,&#x27;h&#x27;,&#x27;l&#x27;,&#x27;r&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_regions &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/sS8UjNJrlLAb5TQ.png" alt="image-20220612213201806"></p><blockquote><p>添加数据试试</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;c001&#x27;,&#x27;cf:name&#x27;,&#x27;first&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;f001&#x27;,&#x27;cf:name&#x27;,&#x27;second&#x27;</span><br><span class="line">put &#x27;tb_split&#x27;,&#x27;z001&#x27;,&#x27;cf:name&#x27;,&#x27;last&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>hbase hfile -p –f xxxx 查看数据</p></blockquote><blockquote><p>如果没有数据，因为数据还在内存中，需要手动刷新内存到HDFS中，以HFile的形式存储</p></blockquote><h3 id="3、总结（写一个文档总结回顾）"><a href="#3、总结（写一个文档总结回顾）" class="headerlink" title="3、总结（写一个文档总结回顾）"></a>3、总结（写一个文档总结回顾）</h3><h3 id="4、日志查看"><a href="#4、日志查看" class="headerlink" title="4、日志查看"></a>4、日志查看</h3><blockquote><p>演示不启动hdfs 就启动hbase</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">日志目录：</span><br><span class="line">/usr/local/soft/hbase-1.7.1/logs</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/KIdYakN6uzUgGTb.png" alt="image-20220612213213973"></p><blockquote><p>start-all.sh发现HMaster没启动，hbase shell客户端也可以正常访问</p><p>再启动hbase就好了</p></blockquote><h3 id="5、scan进阶使用"><a href="#5、scan进阶使用" class="headerlink" title="5、scan进阶使用"></a>5、scan进阶使用</h3><blockquote><p>查看所有的命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace</span><br></pre></td></tr></table></figure><blockquote><p>查看某个命名空间下的所有表</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_namespace_tables &#x27;default&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>修改命名空间,设置一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;set&#x27;,&#x27;author&#x27;=&gt;&#x27;wyh&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>查看命名空间属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">describe_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个属性</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter_namespace &#x27;bigdata17&#x27;,&#123;METHOD=&gt;&#x27;unset&#x27;, NAME=&gt;&#x27;author&#x27;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>删除一个命名空间</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drop_namespace &#x27;bigdata17&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>创建一张表</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">create <span class="string">&#x27;teacher&#x27;</span>,<span class="string">&#x27;cf&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>添加数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:tid&#x27;,1</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0002&#x27;,&#x27;cf:tid&#x27;,2</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0003&#x27;,&#x27;cf:tid&#x27;,3</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;,4</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0005&#x27;,&#x27;cf:tid&#x27;,5</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:tid&#x27;,6</span><br></pre></td></tr></table></figure><blockquote><p>显示三行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid00001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/lE4SaAX3FCNtGOj.png" alt="image-20220612213223835"></p><blockquote><p>从后查三行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,REVERSED=&gt;true&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/ky7KZhD36bYxpCI.png" alt="image-20220612213231718"></p><blockquote><p>查看包含指定列的行</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,&#123;LIMIT=&gt;3,COLUMNS=&gt;[&#x27;cf:name&#x27;]&#125;</span><br></pre></td></tr></table></figure><blockquote><p>简化写法：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scan &#x27;teacher&#x27;,LIMIT=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>在已有的值后面追加值</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">append &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;123&#x27;</span><br></pre></td></tr></table></figure><h3 id="6、get进阶使用"><a href="#6、get进阶使用" class="headerlink" title="6、get进阶使用"></a>6、get进阶使用</h3><blockquote><p>简单使用，获取某一行数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某个列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>获取某一行的某一列（属性 ）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>可以新增一个列簇数据测试</p></blockquote><blockquote><p><strong>查看历史版本</strong></p><p>1、修改表可以存储多个版本</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,NAME=&gt;&#x27;cf&#x27;,VERSIONS=&gt;3</span><br></pre></td></tr></table></figure><blockquote><p>2、put四次相同rowkey和列的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu1&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu2&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu3&#x27;</span><br><span class="line">put &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:name&#x27;,&#x27;xiaohu4&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>3、查看历史数据，默认是最新的</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#123;COLUMN=&gt;&#x27;cf:name&#x27;,VERSIONS=&gt;2&#125;</span><br></pre></td></tr></table></figure><blockquote><p>修改列簇的过期时间 TTL单位是秒，这个时间是与插入的时间比较，而不是现在开始60s</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">alter &#x27;teacher&#x27;,&#123;NAME=&gt;&#x27;cf2&#x27;,TTL=&gt;&#x27;60&#x27;&#125;</span><br></pre></td></tr></table></figure><h3 id="7、插入时间指定时间戳"><a href="#7、插入时间指定时间戳" class="headerlink" title="7、插入时间指定时间戳"></a>7、插入时间指定时间戳</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;teacher&#x27;,&#x27;tid0007&#x27;,&#x27;cf2:job&#x27;,&#x27;bigdata17&#x27;,1654845442790</span><br></pre></td></tr></table></figure><blockquote><p>画图理解这个操作在实际生产的作用</p></blockquote><h3 id="8、delete-只能删除一个单元格，不能删除列簇"><a href="#8、delete-只能删除一个单元格，不能删除列簇" class="headerlink" title="8、delete(只能删除一个单元格，不能删除列簇)"></a>8、delete(只能删除一个单元格，不能删除列簇)</h3><blockquote><p>删除某一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">delete &#x27;teacher&#x27;,&#x27;tid0004&#x27;,&#x27;cf:tid&#x27;</span><br></pre></td></tr></table></figure><h3 id="9、deleteall-删除不了某个列簇，但是可以删除多个单元格"><a href="#9、deleteall-删除不了某个列簇，但是可以删除多个单元格" class="headerlink" title="9、deleteall(删除不了某个列簇，但是可以删除多个单元格)"></a>9、deleteall(删除不了某个列簇，但是可以删除多个单元格)</h3><blockquote><p>删除一行，如果不指定类簇，删除的是一行中的所有列簇</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>删除单元格</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deleteall &#x27;teacher&#x27;,&#x27;tid0006&#x27;,&#x27;cf:name&#x27;,&#x27;cf2:job&#x27;</span><br></pre></td></tr></table></figure><h3 id="10、incr和counter"><a href="#10、incr和counter" class="headerlink" title="10、incr和counter"></a>10、incr和counter</h3><blockquote><p>统计表有多少行(<strong>统计的是行键的个数</strong>)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">count &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>新建一个自增的一列</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br></pre></td></tr></table></figure><blockquote><p>每操作一次，自增1</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,1</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,10</span><br><span class="line">incr &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;,100</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/o4DQfV6mOd5gGBY.png" alt="image-20220612213526090"></p><blockquote><p>配合counter取出数据,只能去incr字段</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_counter &#x27;teacher&#x27;,&#x27;tid0001&#x27;,&#x27;cf:cnt&#x27;</span><br></pre></td></tr></table></figure><h3 id="11、获取region的分割点，清除数据，快照"><a href="#11、获取region的分割点，清除数据，快照" class="headerlink" title="11、获取region的分割点，清除数据，快照"></a>11、获取region的分割点，清除数据，快照</h3><blockquote><p>获取region的分割点</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get_splits &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>清除表数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">truncate &#x27;teacher&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>拍摄快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">snapshot &#x27;tb_split&#x27;,&#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>列出所有快照</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">list_table_snapshots &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>再添加一些数据</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">put &#x27;tb_split&#x27;,&#x27;a001&#x27;,&#x27;cf:name&#x27;,&#x27;wyh&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>恢复快照(先禁用)</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">disable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">restore_snapshot &#x27;tb_split_20220610&#x27;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">enable &#x27;tb_split&#x27;</span><br></pre></td></tr></table></figure><h3 id="12-修饰词"><a href="#12-修饰词" class="headerlink" title="12    修饰词"></a>12    修饰词</h3><h5 id="1、修饰词"><a href="#1、修饰词" class="headerlink" title="1、修饰词"></a>1、修饰词</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;列族名1:列名1&#x27;</span>, <span class="string">&#x27;列族名1:列名2&#x27;</span>, ...]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="2、TIMESTAMP-指定时间戳"><a href="#2、TIMESTAMP-指定时间戳" class="headerlink" title="2、TIMESTAMP 指定时间戳"></a>2、TIMESTAMP 指定时间戳</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[timestamp1, timestamp2]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[<span class="number">1551938004321</span>, <span class="number">1551938036450</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="3、VERSIONS"><a href="#3、VERSIONS" class="headerlink" title="3、VERSIONS"></a>3、VERSIONS</h5><blockquote><p>默认情况下一个列只能存储一个数据，后面如果修改数据就会将原来的覆盖掉，可以通过指定VERSIONS时HBase一列能存储多个值。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;columnFamily1&#x27;</span></span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_test&#x27;</span></span><br><span class="line"></span><br><span class="line"># 修改列族版本号</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_test&#x27;</span>, &#123; NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span> &#125;</span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value3&#x27;</span></span><br><span class="line"></span><br><span class="line"># 默认返回最新的一条数据</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,<span class="string">&#x27;columnFamily1:column1&#x27;</span></span><br><span class="line"></span><br><span class="line"># 返回<span class="number">3</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"># 返回<span class="number">2</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="4、STARTROW"><a href="#4、STARTROW" class="headerlink" title="4、STARTROW"></a>4、STARTROW</h5><blockquote><p>ROWKEY起始行。会先根据这个key定位到region，再向后扫描</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;vbirdbest&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"><a href="#5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据" class="headerlink" title="5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"></a>5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;xiaoming&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="6、LIMIT-返回的行数"><a href="#6、LIMIT-返回的行数" class="headerlink" title="6、LIMIT 返回的行数"></a>6、LIMIT 返回的行数</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> 行数&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2</span> &#125;</span><br></pre></td></tr></table></figure><h3 id="13-FILTER条件过滤器"><a href="#13-FILTER条件过滤器" class="headerlink" title="13    FILTER条件过滤器"></a>13    FILTER条件过滤器</h3><blockquote><p>过滤器之间可以使用AND、OR连接多个过滤器。</p></blockquote><h5 id="1、ValueFilter-值过滤器"><a href="#1、ValueFilter-值过滤器" class="headerlink" title="1、ValueFilter 值过滤器"></a>1、ValueFilter 值过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法：<span class="type">binary</span> 等于某个值</span><br><span class="line">scan <span class="string">&#x27;&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;binary:&#x27;)&quot;</span><br><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;substring:列值&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;binary:26&#x27;)&quot;</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;substring:6&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="2、ColumnPrefixFilter-列名前缀过滤器"><a href="#2、ColumnPrefixFilter-列名前缀过滤器" class="headerlink" title="2、ColumnPrefixFilter 列名前缀过滤器"></a>2、ColumnPrefixFilter 列名前缀过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;列名前缀&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;)&quot;</span><br><span class="line"># 通过括号、<span class="keyword">AND</span>和<span class="keyword">OR</span>的条件组合多个过滤器</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:26&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="3、rowKey字典排序"><a href="#3、rowKey字典排序" class="headerlink" title="3、rowKey字典排序"></a>3、rowKey字典排序</h5><blockquote><p>Table中的所有行都是按照row key的字典排序的</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/lHbNsQYjU8TCnMA.png" alt="image-20220612213543115"></p><h2 id="二、JAVA-API"><a href="#二、JAVA-API" class="headerlink" title="二、JAVA API"></a>二、JAVA API</h2><blockquote><p>pom文件</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase过滤器</title>
      <link href="/2022/06/11/Hbase%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
      <url>/2022/06/11/Hbase%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Hbase过滤器"><a href="#Hbase过滤器" class="headerlink" title="Hbase过滤器"></a>Hbase过滤器</h2><blockquote><p>HBase 的基本 API，包括增、删、改、查等。<br>增、删都是相对简单的操作，与传统的 RDBMS 相比，这里的查询操作略显苍白，只能根据特性的行键进行查询（Get）或者根据行键的范围来查询（Scan）。<br>HBase 不仅提供了这些简单的查询，而且提供了更加高级的过滤器（Filter）来查询。</p><p>过滤器可以根据列族、列、版本等更多的条件来对数据进行过滤，</p><p>基于 HBase 本身提供的三维有序（行键，列，版本有序），这些过滤器可以高效地完成查询过滤的任务，带有过滤器条件的 RPC 查询请求会把过滤器分发到各个 RegionServer（这是一个服务端过滤器），这样也可以降低网络传输的压力。</p><p>使用过滤器至少需要两类参数：</p><p><strong>一类是抽象的操作符，另一类是比较器</strong></p></blockquote><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><ul><li>过滤器的作用是在<strong>服务端</strong>判断数据是否满足条件，然后只将满足条件的数据返回给<strong>客户端</strong></li><li>过滤器的类型很多，但是可以分为三大类：<ul><li>比较过滤器：可应用于rowkey、列簇、列、列值过滤器</li><li>专用过滤器：只能适用于特定的过滤器</li><li>包装过滤器：包装过滤器就是通过包装其他过滤器以实现某些拓展的功能。</li></ul></li></ul><h4 id="比较过滤器"><a href="#比较过滤器" class="headerlink" title="比较过滤器"></a>比较过滤器</h4><blockquote><p>所有比较过滤器均继承自 <code>CompareFilter</code>。创建一个比较过滤器需要两个参数，分别是<strong>比较运算符</strong>和<strong>比较器实例</strong>。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">CompareFilter</span><span class="params">(<span class="keyword">final</span> CompareOp compareOp,<span class="keyword">final</span> ByteArrayComparable comparator)</span> &#123;</span><br><span class="line">   <span class="built_in">this</span>.compareOp = compareOp;</span><br><span class="line">   <span class="built_in">this</span>.comparator = comparator;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h5 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h5><ul><li><p>LESS  &lt;</p></li><li><p>LESS_OR_EQUAL &lt;&#x3D;</p></li><li><p>EQUAL &#x3D;</p></li><li><p>NOT_EQUAL &lt;&gt;</p></li><li><p>GREATER_OR_EQUAL &gt;&#x3D;</p></li><li><p>GREATER &gt;</p></li><li><p>NO_OP 排除所有</p></li></ul><h5 id="常见的六大比较过滤器"><a href="#常见的六大比较过滤器" class="headerlink" title="常见的六大比较过滤器"></a>常见的六大比较过滤器</h5><h6 id="BinaryComparator"><a href="#BinaryComparator" class="headerlink" title="BinaryComparator"></a>BinaryComparator</h6><blockquote><p>按字节索引顺序比较指定字节数组，采用Bytes.compareTo(byte[])</p></blockquote><h6 id="BinaryPrefixComparator"><a href="#BinaryPrefixComparator" class="headerlink" title="BinaryPrefixComparator"></a>BinaryPrefixComparator</h6><blockquote><p>通BinaryComparator，只是比较左端前缀的数据是否相同</p></blockquote><h6 id="NullComparator"><a href="#NullComparator" class="headerlink" title="NullComparator"></a>NullComparator</h6><blockquote><p>判断给定的是否为空</p></blockquote><h6 id="BitComparator"><a href="#BitComparator" class="headerlink" title="BitComparator"></a>BitComparator</h6><blockquote><p>按位比较</p></blockquote><h6 id="RegexStringComparator"><a href="#RegexStringComparator" class="headerlink" title="RegexStringComparator"></a>RegexStringComparator</h6><blockquote><p>提供一个正则的比较器，仅支持 EQUAL 和非EQUAL</p></blockquote><h6 id="SubstringComparator"><a href="#SubstringComparator" class="headerlink" title="SubstringComparator"></a>SubstringComparator</h6><blockquote><p>判断提供的子串是否出现在中</p></blockquote><h5 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h5><h6 id="rowKey过滤器：RowFilter-行键过滤器"><a href="#rowKey过滤器：RowFilter-行键过滤器" class="headerlink" title="rowKey过滤器：RowFilter  行键过滤器"></a>rowKey过滤器：RowFilter  行键过滤器</h6><blockquote><p>通过RowFilter与BinaryComparator过滤比rowKey 1500100010小的所有值出来</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  行键过滤器</span></span><br><span class="line"><span class="comment">     *  通过RowFilter与BinaryComparator过滤比rowKey 1500100010小的所有值出来</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">RowFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;1500100010&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建一个行键过滤器的对象</span></span><br><span class="line">            <span class="type">RowFilter</span> <span class="variable">rowFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.LESS, binaryComparator);</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(rowFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            print(scanner);</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *      专门用来打印数据的方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(ResultScanner scanner)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line"><span class="comment">//                List&lt;Cell&gt; cells = rs.listCells();</span></span><br><span class="line"><span class="comment">//                System.out.print(&quot;id:&quot; + id);</span></span><br><span class="line"><span class="comment">//                System.out.print(&quot;\t&quot;);</span></span><br><span class="line"><span class="comment">//                for (Cell cell : cells) &#123;</span></span><br><span class="line"><span class="comment">////                String s = Bytes.toString(cell.getValue());</span></span><br><span class="line"><span class="comment">//                    String col = Bytes.toString(CellUtil.cloneQualifier(cell));</span></span><br><span class="line"><span class="comment">//                    String s = Bytes.toString(CellUtil.cloneValue(cell));</span></span><br><span class="line"><span class="comment">//                    System.out.print(col + &quot;:&quot; + s);</span></span><br><span class="line"><span class="comment">//                    System.out.print(&quot;\t&quot;);</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//                System.out.println();</span></span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">            System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;,姓名：&quot;</span> + name + <span class="string">&quot;,年龄：&quot;</span> + age + <span class="string">&quot;,性别：&quot;</span> + gender + <span class="string">&quot;,班级：&quot;</span> + clazz);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h6 id="列簇过滤器：FamilyFilter"><a href="#列簇过滤器：FamilyFilter" class="headerlink" title="列簇过滤器：FamilyFilter"></a>列簇过滤器：FamilyFilter</h6><blockquote><p>通过FamilyFilter与SubstringComparator查询列簇名包含in的所有列簇下面的数据</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *      列簇过滤器案例1：通过FamilyFilter与SubstringComparator查询列簇名包含in的所有列簇下面的数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FamilyFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个比较器对象</span></span><br><span class="line">        <span class="comment">//只要列簇名中包含了in，就把该列簇下的所有列查询出来</span></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;in&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列簇过滤器</span></span><br><span class="line">        <span class="type">FamilyFilter</span> <span class="variable">familyFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FamilyFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(familyFilter);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取数据</span></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>通过FamilyFilter与 BinaryPrefixComparator 过滤出列簇以i开头的列簇下的所有数据</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列簇过滤器案例2：通过FamilyFilter与 BinaryPrefixComparator 过滤出列簇以i开头的列簇下的所有数据</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FamilyFilter2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建前缀比较器</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;i&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列簇过滤器</span></span><br><span class="line">        <span class="type">FamilyFilter</span> <span class="variable">familyFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FamilyFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(familyFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="列过滤器：QualifierFilter"><a href="#列过滤器：QualifierFilter" class="headerlink" title="列过滤器：QualifierFilter"></a>列过滤器：QualifierFilter</h6><blockquote><p>通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列过滤器案例1：通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">QualifierFilter1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建包含比较器</span></span><br><span class="line">        <span class="comment">//age</span></span><br><span class="line">        <span class="comment">//gender</span></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;ge&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个列过滤器</span></span><br><span class="line">        <span class="type">QualifierFilter</span> <span class="variable">qualifierFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QualifierFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(qualifierFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出列的名字中 包含 “am” 所有的列 及列的值</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 列过滤器案例2：通过QualifierFilter与SubstringComparator查询列名包含ge的列的值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">QualifierFilter2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;am&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列过滤器</span></span><br><span class="line">        <span class="type">QualifierFilter</span> <span class="variable">qualifierFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QualifierFilter</span>(CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(qualifierFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="列值过滤器：ValueFilter"><a href="#列值过滤器：ValueFilter" class="headerlink" title="列值过滤器：ValueFilter"></a>列值过滤器：ValueFilter</h6><blockquote><p>通过ValueFilter与BinaryPrefixComparator过滤出所有的cell中值以 “张” 开头的学生</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 列值过滤器案例1:通过ValueFilter与BinaryPrefixComparator过滤出所有的cell中值以 &quot;张&quot; 开头的学生</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">ValueFilter1</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建前缀比较器</span></span><br><span class="line">            <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;张&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建列值过滤器的对象</span></span><br><span class="line">            <span class="type">ValueFilter</span> <span class="variable">valueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(valueFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//因为ResultScanner类继承了迭代器</span></span><br><span class="line">            <span class="comment">//使用增强for循环遍历</span></span><br><span class="line"><span class="comment">//            for (Result rs : scanner) &#123;</span></span><br><span class="line"><span class="comment">//                String id = Bytes.toString(rs.getRow());</span></span><br><span class="line"><span class="comment">//                System.out.println(&quot;当前行的rowkey为：&quot; + id);</span></span><br><span class="line"><span class="comment">//                //继续增强for循环得到每一行中的每一个单元格（列）</span></span><br><span class="line"><span class="comment">//                //获取一行中的所有单元格</span></span><br><span class="line"><span class="comment">//                for (Cell cell : rs.listCells()) &#123;</span></span><br><span class="line"><span class="comment">//                    //获取该单元格属于的列簇</span></span><br><span class="line"><span class="comment">//                    String family = Bytes.toString(CellUtil.cloneFamily(cell));</span></span><br><span class="line"><span class="comment">//                    //获取该单元格的列名</span></span><br><span class="line"><span class="comment">//                    String colName = Bytes.toString(CellUtil.cloneQualifier(cell));</span></span><br><span class="line"><span class="comment">//                    //获取该单元格的列值</span></span><br><span class="line"><span class="comment">//                    String value = Bytes.toString(CellUtil.cloneValue(cell));</span></span><br><span class="line"><span class="comment">//                    System.out.println(family + &quot;:&quot; + colName + &quot;的值为：&quot; + value);</span></span><br><span class="line"><span class="comment">//                &#125;</span></span><br><span class="line"><span class="comment">//            &#125;</span></span><br><span class="line"></span><br><span class="line">            print(scanner);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出文科的学生，只会返回以文科开头的数据列，其他列的数据不符合条件，不会返回</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *      列值过滤器案例2：&gt; 过滤出文科的学生，只会返回以文科开头的数据列，其他列的数据不符合条件，不会返回</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">ValueFilter12</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建正则比较器</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建列值过滤器</span></span><br><span class="line">        <span class="type">ValueFilter</span> <span class="variable">valueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareFilter.CompareOp.EQUAL, regexStringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(valueFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="专用过滤器"><a href="#专用过滤器" class="headerlink" title="专用过滤器"></a>专用过滤器</h4><h6 id="单列值过滤器：SingleColumnValueFilter"><a href="#单列值过滤器：SingleColumnValueFilter" class="headerlink" title="单列值过滤器：SingleColumnValueFilter"></a>单列值过滤器：SingleColumnValueFilter</h6><blockquote><p>SingleColumnValueFilter会返回满足条件的cell所在行的所有cell的值（即会返回一行数据）</p><p>通过SingleColumnValueFilter与查询文科班所有学生信息</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 单列值过滤器</span></span><br><span class="line"><span class="comment">     * SingleColumnValueFilter会返回满足条件的cell所在行的所有cell的值（即会返回一行数据）</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 通过SingleColumnValueFilter与查询文科班所有学生信息</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">SingleColumnValueFilter</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取表的实例</span></span><br><span class="line">            <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建一个正则比较器</span></span><br><span class="line">            <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//创建单列值过滤器对象</span></span><br><span class="line">            <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(</span><br><span class="line">                    <span class="string">&quot;info&quot;</span>.getBytes(),</span><br><span class="line">                    <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                    CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                    regexStringComparator</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">            scan.setFilter(singleColumnValueFilter);</span><br><span class="line"></span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 专门用来打印数据的方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">print</span><span class="params">(ResultScanner scanner)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((rs = scanner.next()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">            List&lt;Cell&gt; cells = rs.listCells();</span><br><span class="line">            System.out.print(<span class="string">&quot;id:&quot;</span> + id);</span><br><span class="line">            System.out.print(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line"><span class="comment">//                String s = Bytes.toString(cell.getValue());</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">col</span> <span class="operator">=</span> Bytes.toString(CellUtil.cloneQualifier(cell));</span><br><span class="line">                <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> Bytes.toString(CellUtil.cloneValue(cell));</span><br><span class="line">                System.out.print(col + <span class="string">&quot;:&quot;</span> + s);</span><br><span class="line">                System.out.print(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println();</span><br><span class="line"></span><br><span class="line"><span class="comment">//            String name = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;name&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String age = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;age&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String gender = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;gender&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            String clazz = Bytes.toString(rs.getValue(&quot;info&quot;.getBytes(), &quot;clazz&quot;.getBytes()));</span></span><br><span class="line"><span class="comment">//            System.out.println(&quot;学号：&quot; + id + &quot;,姓名：&quot; + name + &quot;,年龄：&quot; + age + &quot;,性别：&quot; + gender + &quot;,班级：&quot; + clazz);</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h6 id="列值排除过滤器：SingleColumnValueExcludeFilter"><a href="#列值排除过滤器：SingleColumnValueExcludeFilter" class="headerlink" title="列值排除过滤器：SingleColumnValueExcludeFilter"></a>列值排除过滤器：SingleColumnValueExcludeFilter</h6><blockquote><p>与SingleColumnValueFilter相反，会排除掉指定的列，其他的列全部返回</p><p>通过SingleColumnValueExcludeFilter与BinaryComparator查询文科一班所有学生信息，最终不返回clazz列</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列值排除过滤器</span></span><br><span class="line"><span class="comment"> * 与SingleColumnValueFilter相反，会排除掉指定的列，其他的列全部返回</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 通过SingleColumnValueExcludeFilter与BinaryComparator查询文科一班所有学生信息，最终不返回clazz列</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">SingleColumnValueExcludeFilter</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个二进制比较器</span></span><br><span class="line">        <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;文科一班&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建一个列值排除过滤器</span></span><br><span class="line">        <span class="type">SingleColumnValueExcludeFilter</span> <span class="variable">singleColumnValueExcludeFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueExcludeFilter</span>(</span><br><span class="line">                <span class="string">&quot;info&quot;</span>.getBytes(),</span><br><span class="line">                <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                binaryComparator</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(singleColumnValueExcludeFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="rowkey前缀过滤器：PrefixFilter"><a href="#rowkey前缀过滤器：PrefixFilter" class="headerlink" title="rowkey前缀过滤器：PrefixFilter"></a>rowkey前缀过滤器：PrefixFilter</h6><blockquote><p>通过PrefixFilter查询以150010008开头的所有前缀的rowkey</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * rowkey前缀过滤器</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 通过PrefixFilter查询以150010008开头的所有前缀的rowkey</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">PrefixFilter</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建rowkey前缀过滤器</span></span><br><span class="line">        <span class="type">PrefixFilter</span> <span class="variable">prefixFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PrefixFilter</span>(<span class="string">&quot;150010008&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        scan.setFilter(prefixFilter);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="分页过滤器PageFilter"><a href="#分页过滤器PageFilter" class="headerlink" title="分页过滤器PageFilter"></a>分页过滤器PageFilter</h6><blockquote><p>通过PageFilter查询三页的数据，每页10条</p><p>使用PageFilter分页效率比较低，每次都需要扫描前面的数据，直到扫描到所需要查的数据</p><p>可设计一个合理的rowkey来实现分页需求</p></blockquote><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 注意事项：</span></span><br><span class="line">客户端进行分页查询，需要传递 startRow(起始 RowKey)，知道起始 startRow 后，就可以返回对应的 pageSize 行数据。这里唯一的问题就是，对于第一次查询，显然 startRow 就是表格的第一行数据，但是之后第二次、第三次查询我们并不知道 startRow，只能知道上一次查询的最后一条数据的 RowKey（简单称之为 lastRow）。</span><br><span class="line"></span><br><span class="line">我们不能将 lastRow 作为新一次查询的 startRow 传入，因为 scan 的查询区间是[startRow，endRow) ，即前开后闭区间，这样 startRow 在新的查询也会被返回，这条数据就重复了。</span><br><span class="line"></span><br><span class="line">同时在不使用第三方数据库存储 RowKey 的情况下，我们是无法通过知道 lastRow 的下一个 RowKey 的，因为 RowKey 的设计可能是连续的也有可能是不连续的。</span><br><span class="line"></span><br><span class="line">由于 Hbase 的 RowKey 是按照字典序进行排序的。这种情况下，就可以在 lastRow 后面加上 0 ，作为 startRow 传入，因为按照字典序的规则，某个值加上 0 后的新值，在字典序上一定是这个值的下一个值，对于 HBase 来说下一个 RowKey 在字典序上一定也是等于或者大于这个新值的。</span><br><span class="line"></span><br><span class="line">所以最后传入 lastRow+0，如果等于这个值的 RowKey 存在就从这个值开始 scan,否则从字典序的下一个 RowKey 开始 scan。</span><br><span class="line"></span><br><span class="line">25 个字母以及数字字符，字典排序如下:</span><br><span class="line"></span><br><span class="line">&#x27;0&#x27; &lt; &#x27;1&#x27; &lt; &#x27;2&#x27; &lt; ... &lt; &#x27;9&#x27; &lt; &#x27;a&#x27; &lt; &#x27;b&#x27; &lt; ... &lt; &#x27;z&#x27;</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是在多台 Regin Services 上执行分页过滤的时候，由于并行执行的过滤器不能共享它们的状态和边界，所以有可能每个过滤器都会在完成扫描前获取了 PageCount 行的结果，这种情况下会返回比分页条数更多的数据，分页过滤器就有失效的可能。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 分页过滤器</span></span><br><span class="line"><span class="comment"> * 通过PageFilter查询三页的数据，每页10条</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">PageFilter</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line">        <span class="comment">//定义要查询的页数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">pageNum</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line">        <span class="comment">//定义每页的条数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">pageSize</span> <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一开始的行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">current_page_start_row</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= pageNum; i++) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;====================当前是第&quot;</span> + i + <span class="string">&quot;页===========================&quot;</span>);</span><br><span class="line">            <span class="comment">//创建一个分页过滤器</span></span><br><span class="line">            <span class="type">PageFilter</span> <span class="variable">pageFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PageFilter</span>(pageSize);</span><br><span class="line">            scan.setFilter(pageFilter);</span><br><span class="line">            <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">            <span class="keyword">for</span> (Result rs : scanner) &#123;</span><br><span class="line">                current_page_start_row = Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="comment">//告诉扫描器是从哪一行开始获取数据</span></span><br><span class="line">                scan.withStartRow((current_page_start_row + <span class="number">0</span>).getBytes());</span><br><span class="line">                <span class="type">PageFilter</span> <span class="variable">pageFilter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PageFilter</span>(pageSize);</span><br><span class="line">                scan.setFilter(pageFilter1);</span><br><span class="line">                <span class="comment">//获取id</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">                <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(<span class="string">&quot;学号：&quot;</span> + id + <span class="string">&quot;,姓名：&quot;</span> + name + <span class="string">&quot;,年龄：&quot;</span> + age + <span class="string">&quot;,性别：&quot;</span> + gender + <span class="string">&quot;,班级：&quot;</span> + clazz);</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="包装过滤器"><a href="#包装过滤器" class="headerlink" title="包装过滤器"></a>包装过滤器</h4><h6 id="SkipFilter过滤器"><a href="#SkipFilter过滤器" class="headerlink" title="SkipFilter过滤器"></a>SkipFilter过滤器</h6><blockquote><p>SkipFilter包装一个过滤器，当被包装的过滤器遇到一个需要过滤的 KeyValue 实例时，则拓展过滤整行数据。下面是一个使用示例：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义 ValueFilter 过滤器</span></span><br><span class="line"><span class="type">Filter</span> <span class="variable">filter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ValueFilter</span>(CompareOperator.NOT_EQUAL,</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(Bytes.toBytes(<span class="string">&quot;xxx&quot;</span>)));</span><br><span class="line"><span class="comment">// 使用 SkipFilter 进行包装</span></span><br><span class="line"><span class="type">Filter</span> <span class="variable">filter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SkipFilter</span>(filter1);</span><br></pre></td></tr></table></figure><h6 id="WhileMatchFilter过滤器"><a href="#WhileMatchFilter过滤器" class="headerlink" title="WhileMatchFilter过滤器"></a>WhileMatchFilter过滤器</h6><blockquote><p>WhileMatchFilter 包装一个过滤器，当被包装的过滤器遇到一个需要过滤的 KeyValue 实例时，WhileMatchFilter 则结束本次扫描，返回已经扫描到的结果。下面是其使用示例：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">baoZhuang1</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Filter</span> <span class="variable">filter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.NOT_EQUAL,<span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;1500100009&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//不做包装</span></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(filter1);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner1</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs</span> <span class="operator">=</span> scanner1.next();</span><br><span class="line">        <span class="keyword">while</span> (rs != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs.getRow());</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">            System.out.println(id + <span class="string">&quot;\t&quot;</span> + name + <span class="string">&quot;\t&quot;</span> + age + <span class="string">&quot;\t&quot;</span> + gender + <span class="string">&quot;\t&quot;</span> + clazz + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            rs = scanner1.next();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;--------------------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用 WhileMatchFilter 进行包装</span></span><br><span class="line">        <span class="type">Filter</span> <span class="variable">filter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WhileMatchFilter</span>(filter1);</span><br><span class="line">        scan.setFilter(filter2);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        <span class="type">Result</span> <span class="variable">rs2</span> <span class="operator">=</span> scanner.next();</span><br><span class="line">        <span class="keyword">while</span> (rs2 != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> Bytes.toString(rs2.getRow());</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">age</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes()));</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> Bytes.toString(rs2.getValue(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes()));</span><br><span class="line"></span><br><span class="line">            System.out.println(id + <span class="string">&quot;\t&quot;</span> + name + <span class="string">&quot;\t&quot;</span> + age + <span class="string">&quot;\t&quot;</span> + gender + <span class="string">&quot;\t&quot;</span> + clazz + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            rs2 = scanner.next();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="多过滤器综合查询"><a href="#多过滤器综合查询" class="headerlink" title="多过滤器综合查询"></a>多过滤器综合查询</h4><p>以上都是讲解单个过滤器的作用，当需要多个过滤器共同作用于一次查询的时候，就需要使用 <code>FilterList</code>。<code>FilterList</code> 支持通过构造器或者 <code>addFilter</code> 方法传入多个过滤器。</p><blockquote><p>通过运用4种比较器过滤出姓于，年纪大于23岁，性别为女，且是理科的学生。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 需求：1 通过运用4种比较器过滤出姓于，年纪大于23岁，性别为女，且是理科的学生。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 正则比较器   RegexStringComparator</span></span><br><span class="line"><span class="comment"> * 包含比较器   SubstringComparator</span></span><br><span class="line"><span class="comment"> * 二进制前缀比较器   BinaryPrefixComparator</span></span><br><span class="line"><span class="comment"> * 二进制比较器      BinaryComparator</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">FilterData1</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *  第一个过滤器，过滤出是理科开头的班级</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^理科.*&quot;</span>);</span><br><span class="line">        <span class="comment">//单列值过滤器</span></span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, regexStringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第二个过滤器，过滤出性别是女生的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="type">SubstringComparator</span> <span class="variable">substringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SubstringComparator</span>(<span class="string">&quot;女&quot;</span>);</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;gender&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, substringComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第三个过滤器，过滤出年龄大于23岁的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryComparator</span> <span class="variable">binaryComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryComparator</span>(<span class="string">&quot;20&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;age&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.GREATER, binaryComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 第四个过滤器，过滤出姓于的学生</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;于&quot;</span>.getBytes());</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;name&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//要想实现多个需求同时过滤，就需要创建多个过滤器，添加到一个过滤器列表中</span></span><br><span class="line">        <span class="comment">//然后将过滤器列表传给扫描器scan</span></span><br><span class="line">        <span class="type">FilterList</span> <span class="variable">filterList</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FilterList</span>();</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter1);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter2);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter3);</span><br><span class="line"></span><br><span class="line">        scan.setFilter(filterList);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line"></span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>过滤出学号是以15001001开头的文科学生</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 过滤出学号是以15001001开头的文科学生</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">filterData2</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//获取表的实例</span></span><br><span class="line">        <span class="type">HTableInterface</span> <span class="variable">students</span> <span class="operator">=</span> conn.getTable(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         *  创建第一个过滤器，过滤是以15001001开头的rowkey</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">BinaryPrefixComparator</span> <span class="variable">binaryPrefixComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BinaryPrefixComparator</span>(<span class="string">&quot;15001001&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//创建行键过滤器</span></span><br><span class="line">        <span class="type">RowFilter</span> <span class="variable">rowFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RowFilter</span>(CompareFilter.CompareOp.EQUAL, binaryPrefixComparator);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 创建第二个过滤器，过滤出文科的学生</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">RegexStringComparator</span> <span class="variable">regexStringComparator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexStringComparator</span>(<span class="string">&quot;^文科.*&quot;</span>);</span><br><span class="line">        <span class="type">SingleColumnValueFilter</span> <span class="variable">singleColumnValueFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingleColumnValueFilter</span>(<span class="string">&quot;info&quot;</span>.getBytes(), <span class="string">&quot;clazz&quot;</span>.getBytes(),</span><br><span class="line">                CompareFilter.CompareOp.EQUAL,</span><br><span class="line">                regexStringComparator);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">FilterList</span> <span class="variable">filterList</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FilterList</span>();</span><br><span class="line">        filterList.addFilter(rowFilter);</span><br><span class="line">        filterList.addFilter(singleColumnValueFilter);</span><br><span class="line"></span><br><span class="line">        <span class="type">Scan</span> <span class="variable">scan</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">        scan.setFilter(filterList);</span><br><span class="line">        <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> students.getScanner(scan);</span><br><span class="line">        print2(scanner);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>作业：查询文科一班学生总分排名前10的学生（输出：学号，姓名，班级，总分）结果写到hbase</p></blockquote><h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><blockquote><p>本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉你 “<strong>某样东西一定不存在或者可能存在</strong>”。</p><p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。</p><p>实际上，布隆过滤器广泛应用于<strong>网页黑名单系统</strong>、<strong>垃圾邮件过滤系统</strong>、<strong>爬虫网址判重系统</strong>等，Google 著名的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的 IO 次数，Google Chrome 浏览器使用了布隆过滤器加速安全浏览服务。</p><p>在很多 Key-Value 系统中也使用了布隆过滤器来加快查询过程，如 Hbase，Accumulo，Leveldb，一般而言，Value 保存在磁盘中，访问磁盘需要花费大量时间，然而使用布隆过滤器可以快速判断某个 Key 对应的 Value 是否存在，因此可以避免很多不必要的磁盘 IO 操作。</p><p>通过一个 Hash 函数将一个元素映射成一个位阵列（Bit Array）中的一个点。这样一来，我们只要看看这个点是不是 1 就知道可以集合中有没有它了。这就是布隆过滤器的基本思想。</p></blockquote><h5 id="运用场景"><a href="#运用场景" class="headerlink" title="运用场景"></a>运用场景</h5><blockquote><p>1、目前有 10 亿数量的自然数，乱序排列，需要对其排序。限制条件在 32 位机器上面完成，内存限制为 2G。如何完成？</p><p>2、如何快速在亿级黑名单中快速定位 URL 地址是否在黑名单中？(每条 URL 平均 64 字节)</p><p>3、需要进行用户登陆行为分析，来确定用户的活跃情况？</p><p>4、网络爬虫-如何判断 URL 是否被爬过？</p><p>5、快速定位用户属性（黑名单、白名单等）？</p><p>6、数据存储在磁盘中，如何避免大量的无效 IO？</p><p>7、判断一个元素在亿级数据中是否存在？</p><p>8、缓存穿透。</p></blockquote><h5 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h5><blockquote><p>假设我们有个集合 A，A 中有 n 个元素。利用<strong>k个哈希散列</strong>函数，将A中的每个元素<strong>映射</strong>到一个长度为 a 位的数组 B中的不同位置上，这些位置上的二进制数均设置为 1。如果待检查的元素，经过这 k个哈希散列函数的映射后，发现其 k 个位置上的二进制数<strong>全部为 1</strong>，这个元素很可能属于集合A，反之，<strong>一定不属于集合A</strong>。</p><p>比如我们有 3 个 URL <code>&#123;URL1,URL2,URL3&#125;</code>，通过一个hash 函数把它们映射到一个长度为 16 的数组上，如下：</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/qAcJ4GLkDvZgjzt.png" alt="image-20220612214242813"></p><p>若当前哈希函数为 <code>Hash1()</code>，通过哈希运算映射到数组中，假设<code>Hash1(URL1) = 3</code>，<code>Hash1(URL2) = 6</code>，<code>Hash1(URL3) = 6</code>，如下：</p><p><img src="https://s2.loli.net/2022/06/12/NAO6aL8KT2isjZG.png" alt="image-20220612214254594"></p><blockquote><p>因此，如果我们需要判断<code>URL1</code>是否在这个集合中，则通过<code>Hash(urL1)</code>计算出其下标，并得到其值若为 1 则说明存在。</p><p>由于 Hash 存在哈希冲突，如上面<code>URL2,URL3</code>都定位到一个位置上，假设 Hash 函数是良好的，如果我们的数组长度为 m 个点，那么如果我们想将冲突率降低到例如 <strong>1%<strong>， 这个散列表就只能容纳 <code>m/100</code> 个元素，显然空间利用率就变低了，也就是没法做到</strong>空间有效</strong>（space-efficient）。</p><p>解决方法也简单，就是使用多个 Hash 算法，如果它们有一个说元素不在集合中，那肯定就不在，如下：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hash1(URL1) = 3,Hash2(URL1) = 5,Hash3(URL1) = 6</span><br><span class="line">Hash1(URL2) = 5,Hash2(URL2) = 8,Hash3(URL2) = 14</span><br><span class="line">Hash1(URL3) = 4,Hash2(URL3) = 7,Hash3(URL3) = 10</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/2y6qDXUfvg5Ic8k.png" alt="image-20220612214308660"></p><blockquote><p>以上就是布隆过滤器做法，使用了<strong>k个哈希函数</strong>，每个字符串跟 k 个 bit 对应，从而降低了冲突的概率。</p></blockquote><h5 id="误判现象"><a href="#误判现象" class="headerlink" title="误判现象"></a>误判现象</h5><blockquote><p>上面的做法同样存在问题，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断这个值存在。比如此时来一个不存在的 <code>URL1000</code>，经过哈希计算后，发现 bit 位为下：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Hash1(URL1000) = 7,Hash2(URL1000) = 8,Hash3(URL1000) = 14</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/vkUtQ6bqMLwFj7c.png" alt="image-20220612214320802"></p><blockquote><p>但是上面这些 bit 位已经被<code>URL1,URL2,URL3</code>置为 1 了，此时程序就会判断 <code>URL1000</code> 值存在。</p><p>这就是布隆过滤器的误判现象，所以，<strong>布隆过滤器判断存在的不一定存在，但是，判断不存在的一定不存在。</strong></p><p>布隆过滤器可精确的代表一个集合，可精确判断某一元素是否在此集合中，精确程度由用户的具体设计决定，达到 100% 的正确是不可能的。但是布隆过滤器的优势在于，<strong>利用很少的空间可以达到较高的精确率</strong>。</p></blockquote><h5 id="控制粒度"><a href="#控制粒度" class="headerlink" title="控制粒度"></a>控制粒度</h5><blockquote><p><strong>a）ROW</strong><br>    根据KeyValue中的行来过滤storefile<br>    举例：假设有2个storefile文件sf1和sf2，<br>        sf1包含kv1（r1 cf：q1 v），kv2（r2 cf：q1 v）<br>        sf2包含kv3（r3 cf：q1 v），kv4（r4 cf：q1 v）<br>        若是设置了CF属性中的bloomfilter为ROW，那么得（r1）时就会过滤sf2，get（r3）就会过滤sf1<br><strong>b）ROWCOL</strong><br>    根据KeyValue中的行+限定符来过滤storefile<br>    举例：假设有2个storefile文件sf1和sf2，<br>        sf1包含kv1（r1 cf：q1 v），kv2（r2 cf：q1 v）<br>        sf2包含kv3（r1 cf：q2 v），kv4（r2 cf：q2 v）<br>        若是设置了CF属性中的布隆过滤器为ROW，不管获得（R1，Q1）仍是获得（R1，Q2），都会读取SF1 + SF2;而若是设置了CF属性中的布隆过滤器为        ROWCOL，那么GET（R1， q1）就会过滤sf2，get（r1，q2）就会过滤sf1<br><strong>c）NO</strong><br>    默认的值，默认不开启布隆过滤器</p></blockquote><h5 id="实现："><a href="#实现：" class="headerlink" title="实现："></a>实现：</h5><blockquote><p>在建立表时加入一个参数就能够了</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">//使用HTableDescriptor类创建一个表对象</span></span><br><span class="line">          <span class="type">HTableDescriptor</span> <span class="variable">students</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HTableDescriptor</span>(<span class="string">&quot;students&quot;</span>);</span><br><span class="line"></span><br><span class="line">          <span class="comment">//在创建表的时候，至少指定一个列簇</span></span><br><span class="line">          <span class="type">HColumnDescriptor</span> <span class="variable">info</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HColumnDescriptor</span>(<span class="string">&quot;info&quot;</span>);</span><br><span class="line">          info.setBloomFilterType(BloomType.ROW); <span class="comment">//&lt;===========================================</span></span><br><span class="line"></span><br><span class="line">          <span class="comment">//将列簇添加到表中</span></span><br><span class="line">          students.addFamily(info);</span><br><span class="line">          <span class="comment">//真正的执行，是由HMaster</span></span><br><span class="line">          <span class="comment">//hAdmin</span></span><br><span class="line">          hAdmin.createTable(students);</span><br><span class="line">          System.out.println(Bytes.toString(students.getName()) + <span class="string">&quot;表 创建成功。。。&quot;</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          e.printStackTrace();</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase shell1</title>
      <link href="/2022/06/10/Hbase%20Shell%201/"/>
      <url>/2022/06/10/Hbase%20Shell%201/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Hbase-Shell-1"><a href="#一、Hbase-Shell-1" class="headerlink" title="一、Hbase Shell 1"></a>一、Hbase Shell 1</h2><table><thead><tr><th>命名</th><th>描述</th><th>语法</th></tr></thead><tbody><tr><td>help ‘命名名’</td><td>查看命令的使用描述</td><td>help ‘命令名’</td></tr><tr><td>whoami</td><td>我是谁</td><td>whoami</td></tr><tr><td>version</td><td>返回hbase版本信息</td><td>version</td></tr><tr><td>status</td><td>返回hbase集群的状态信息</td><td>status</td></tr><tr><td>table_help</td><td>查看如何操作表</td><td>table_help</td></tr><tr><td><strong>create</strong></td><td>创建表</td><td>create ‘表名’, ‘列族名1’, ‘列族名2’, ‘列族名N’</td></tr><tr><td><strong>alter</strong></td><td>修改列族</td><td>添加一个列族：alter ‘表名’, ‘列族名’ <br />删除列族：alter ‘表名’, {NAME&#x3D;&gt; ‘列族名’, METHOD&#x3D;&gt; ‘delete’}</td></tr><tr><td>describe</td><td>显示表相关的详细信息</td><td>describe ‘表名’</td></tr><tr><td><strong>list</strong></td><td>列出hbase中存在的所有表</td><td>list</td></tr><tr><td>exists</td><td>测试表是否存在</td><td>exists ‘表名’</td></tr><tr><td><strong>put</strong></td><td>添加或修改的表的值</td><td>put ‘表名’, ‘行键’, ‘列族名’, ‘列值’ <br />put ‘表名’, ‘行键’, ‘列族名:列名’, ‘列值’</td></tr><tr><td><strong>scan</strong></td><td>通过对表的扫描来获取对用的值</td><td>scan ‘表名’<br/>扫描某个列族： scan ‘表名’, {COLUMN&#x3D;&gt;‘列族名’}<br/>扫描某个列族的某个列： scan ‘表名’, {COLUMN&#x3D;&gt;‘列族名:列名’}<br/>查询同一个列族的多个列： scan ‘表名’, {COLUMNS &#x3D;&gt; [ ‘列族名1:列名1’, ‘列族名1:列名2’, …]}</td></tr><tr><td><strong>get</strong></td><td>获取行或单元（cell）的值</td><td>get ‘表名’, ‘行键’ <br />get ‘表名’, ‘行键’, ‘列族名’</td></tr><tr><td>count</td><td>统计表中行的数量</td><td>count ‘表名’</td></tr><tr><td>incr</td><td>增加指定表行或列的值</td><td>incr ‘表名’, ‘行键’, ‘列族:列名’, 步长值</td></tr><tr><td>get_counter</td><td>获取计数器</td><td>get_counter ‘表名’, ‘行键’, ‘列族:列名’</td></tr><tr><td><strong>delete</strong></td><td>删除指定对象的值（可以为表，行，列对应的值，另外也可以指定时间戳的值）</td><td>删除列族的某个列： delete ‘表名’, ‘行键’, ‘列族名:列名’</td></tr><tr><td>deleteall</td><td>删除指定行的所有元素值</td><td>deleteall ‘表名’, ‘行键’</td></tr><tr><td><strong>truncate</strong></td><td>重新创建指定表</td><td>truncate ‘表名’</td></tr><tr><td><strong>enable</strong></td><td>使表有效</td><td>enable ‘表名’</td></tr><tr><td>is_enabled</td><td>是否启用</td><td>is_enabled ‘表名’</td></tr><tr><td><strong>disable</strong></td><td>使表无效</td><td>disable ‘表名’</td></tr><tr><td><strong>is_disabled</strong></td><td>是否无效</td><td>is_disabled ‘表名’</td></tr><tr><td><strong>drop</strong></td><td>删除表</td><td>drop的表必须是disable的 <br />disable ‘表名’ <br />drop ‘表名’</td></tr><tr><td>shutdown</td><td>关闭hbase集群（与exit不同）</td><td></td></tr><tr><td>tools</td><td>列出hbase所支持的工具</td><td></td></tr><tr><td><strong>exit</strong></td><td>退出hbase shell</td><td></td></tr></tbody></table><p>HBase Shell 是官方提供的一组命令，用于操作HBase。如果配置了HBase的<strong>环境变量</strong>了，就可以知己在命令行中输入hbase shell 命令进入命令行。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/SXT6AIdLqjEc7CV.png" alt="image-20220608225844374"></p><h3 id="help命令"><a href="#help命令" class="headerlink" title="help命令"></a>help命令</h3><blockquote><p>可以通过 <code>help &#39;命名名称&#39;</code>来查看<strong>命令行</strong>的具体使用，包括命令的作用和用法。<br>通过help ‘hbase’ 命名来查看hbase shell 支持的所有命令，hbase将命令进行分组，其中ddl、dml使用较多。</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/hOgVHLT9FPvBnf6.png" alt="image-20220608230009607"></p><h3 id="1-2-general-类"><a href="#1-2-general-类" class="headerlink" title="1.2    general 类"></a>1.2    general 类</h3><h4 id="1-2-1-显示集群状态status"><a href="#1-2-1-显示集群状态status" class="headerlink" title="1.2.1    显示集群状态status"></a>1.2.1    显示集群状态status</h4><p><img src="https://s2.loli.net/2022/06/12/dCGBNJEuMOrcHI8.png" alt="image-20220612211516897"></p><h4 id="1-2-2-查询数据库版本version"><a href="#1-2-2-查询数据库版本version" class="headerlink" title="1.2.2     查询数据库版本version"></a>1.2.2     查询数据库版本version</h4><p><img src="https://s2.loli.net/2022/06/12/Tgupqb7tkDCvf5J.png" alt="image-20220612211524520"></p><h4 id="1-2-3-显示当前用户与组-whoami"><a href="#1-2-3-显示当前用户与组-whoami" class="headerlink" title="1.2.3    显示当前用户与组 whoami"></a>1.2.3    显示当前用户与组 whoami</h4><p><img src="https://s2.loli.net/2022/06/12/hBgJPd16uKf98Ck.png" alt="image-20220612211550680"></p><h4 id="1-2-4-查看操作表的命令table-help"><a href="#1-2-4-查看操作表的命令table-help" class="headerlink" title="1.2.4    查看操作表的命令table_help"></a>1.2.4    查看操作表的命令table_help</h4><p><img src="https://s2.loli.net/2022/06/12/zDu9nGlk46CLEs8.png" alt="image-20220612211739667"></p><h4 id="1-2-5-退出HBase-Shell-exit"><a href="#1-2-5-退出HBase-Shell-exit" class="headerlink" title="1.2.5    退出HBase Shell exit"></a>1.2.5    退出HBase Shell exit</h4><p><img src="https://s2.loli.net/2022/06/12/DcuwQTr8WmKxkIO.png" alt="image-20220612211758289"></p><h3 id="1-3-DDL相关"><a href="#1-3-DDL相关" class="headerlink" title="1.3    DDL相关"></a>1.3    DDL相关</h3><h4 id="1-3-1-创建表create"><a href="#1-3-1-创建表create" class="headerlink" title="1.3.1. 创建表create"></a>1.3.1. 创建表create</h4><blockquote><p>注意：创建表时只需要指定列族名称，不需要指定列名。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名1&#x27;</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名2&#x27;</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名3&#x27;</span>&#125;</span><br><span class="line"># 此种方式是上上面的简写方式，使用上面方式可以为列族指定更多的属性，如VERSIONS、TTL、BLOCKCACHE、CONFIGURATION等属性</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;列族名1&#x27;</span>, <span class="string">&#x27;列族名2&#x27;</span>, <span class="string">&#x27;列族名3&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> 版本号, TTL <span class="operator">=</span><span class="operator">&gt;</span> 过期时间, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_user&#x27;</span>, <span class="string">&#x27;info&#x27;</span>, <span class="string">&#x27;detail&#x27;</span></span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;t1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1</span>, TTL <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2592000</span>, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/wUgQbz1Lpu6MKao.png" alt="image-20220612211844485"></p><h4 id="1-3-2-修改-添加、删除-表结构Schema-alter"><a href="#1-3-2-修改-添加、删除-表结构Schema-alter" class="headerlink" title="1.3.2    修改(添加、删除)表结构Schema alter"></a>1.3.2    修改(添加、删除)表结构Schema alter</h4><h5 id="1-3-2-1-添加一个列簇"><a href="#1-3-2-1-添加一个列簇" class="headerlink" title="1.3.2.1    添加一个列簇"></a>1.3.2.1    添加一个列簇</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_user&#x27;</span>, <span class="string">&#x27;address&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/sp2T48CcUBNaH6x.png" alt="image-20220612211857310"></p><h5 id="1-3-2-2-删除一个列簇"><a href="#1-3-2-2-删除一个列簇" class="headerlink" title="1.3.2.2    删除一个列簇"></a>1.3.2.2    删除一个列簇</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;表名&#x27;</span>, &#123;NAME<span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;列族名&#x27;</span>, <span class="keyword">METHOD</span><span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;delete&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_user&#x27;</span>, &#123;NAME<span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;address&#x27;</span>, <span class="keyword">METHOD</span><span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;delete&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/GVo9jqBUNhpvgnm.png" alt="image-20220612211912064"></p><h5 id="1-3-2-3-修改列族的属性"><a href="#1-3-2-3-修改列族的属性" class="headerlink" title="1.3.2.3    修改列族的属性"></a>1.3.2.3    修改列族的属性</h5><blockquote><p>可以修改列族的VERSIONS、IN_MEMORY</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 修改f1列族的版本为<span class="number">5</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line"># 修改多个列族，修改f2为内存，版本号为<span class="number">5</span></span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;f1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f2&#x27;</span>, IN_MEMORY <span class="operator">=</span><span class="operator">&gt;</span> <span class="literal">true</span>&#125;, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;f3&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line"># 也可以修改<span class="keyword">table</span><span class="operator">-</span><span class="keyword">scope</span>属性，例如MAX_FILESIZE, READONLY,MEMSTORE_FLUSHSIZE, DEFERRED_LOG_FLUSH等。</span><br><span class="line"># 例如，修改region的最大大小为<span class="number">128</span>MB：</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, MAX_FILESIZE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;134217728&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-3-获取表的描述describe"><a href="#1-3-3-获取表的描述describe" class="headerlink" title="1.3.3    获取表的描述describe"></a>1.3.3    获取表的描述describe</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/KeTgHt3YSZy8Aox.png" alt="image-20220612211927537"></p><h4 id="1-3-4-列举所有表list"><a href="#1-3-4-列举所有表list" class="headerlink" title="1.3.4    列举所有表list"></a>1.3.4    列举所有表list</h4><p><img src="https://s2.loli.net/2022/06/12/X4H17ytvEKNBbSp.png" alt="image-20220612211939477"></p><h4 id="1-3-5-表是否存在exists"><a href="#1-3-5-表是否存在exists" class="headerlink" title="1.3.5    表是否存在exists"></a>1.3.5    表是否存在exists</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法 </span><br><span class="line"><span class="keyword">exists</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">exists</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/HcSG3VxYrj7mfno.png" alt="image-20220612211957306"></p><h4 id="1-3-6-启用表enable和禁用表disable"><a href="#1-3-6-启用表enable和禁用表disable" class="headerlink" title="1.3.6    启用表enable和禁用表disable"></a>1.3.6    启用表enable和禁用表disable</h4><blockquote><p>通过enable和disable来启用&#x2F;禁用这个表,相应的可以通过is_enabled和is_disabled来检查表是否被禁用。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">enable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">is_enabled <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line">disable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line">is_disabled <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">disable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line">is_disabled <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line"></span><br><span class="line">enable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line">is_enabled <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-7-禁用满足正则表达式的所有表disable-all"><a href="#1-3-7-禁用满足正则表达式的所有表disable-all" class="headerlink" title="1.3.7    禁用满足正则表达式的所有表disable_all"></a>1.3.7    禁用满足正则表达式的所有表disable_all</h4><ul><li><code>.</code>匹配除“\n”和”\r”之外的任何单个字符</li><li><code>*</code>匹配前面的子表达式任意次</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 匹配以t开头的表名</span><br><span class="line">disable_all <span class="string">&#x27;t.*&#x27;</span></span><br><span class="line"># 匹配指定命名空间ns下的以t开头的所有表</span><br><span class="line">disable_all <span class="string">&#x27;ns:t.*&#x27;</span></span><br><span class="line"># 匹配ns命名空间下的所有表</span><br><span class="line">disable_all <span class="string">&#x27;ns:.*&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-3-8-启用满足正则表达式的所有表enable-all"><a href="#1-3-8-启用满足正则表达式的所有表enable-all" class="headerlink" title="1.3.8    启用满足正则表达式的所有表enable_all"></a>1.3.8    启用满足正则表达式的所有表enable_all</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">enable_all &#x27;t.*&#x27;</span><br><span class="line">enable_all &#x27;ns:t.*&#x27;</span><br><span class="line">enable_all &#x27;ns:.*&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-9-删除表drop"><a href="#1-3-9-删除表drop" class="headerlink" title="1.3.9    删除表drop"></a>1.3.9    删除表drop</h4><blockquote><p>需要先禁用表，然后再删除表，启用的表是不允许删除的</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">disable <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">disable <span class="string">&#x27;tbl_user&#x27;</span></span><br><span class="line"><span class="keyword">drop</span> <span class="string">&#x27;tbl_user&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>直接删除报错：</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/Ki8HoPqw1UCjSsX.png" alt="image-20220612212011296"></p><p>先禁用后删除</p><p><img src="https://s2.loli.net/2022/06/12/VP5UMTDBEg9LNop.png" alt="image-20220612212023082"></p><h4 id="1-3-10-删除满足正则表达式的所有表drop-all"><a href="#1-3-10-删除满足正则表达式的所有表drop-all" class="headerlink" title="1.3.10    删除满足正则表达式的所有表drop_all"></a>1.3.10    删除满足正则表达式的所有表drop_all</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">drop_all &#x27;t.*&#x27;</span><br><span class="line">drop_all &#x27;ns:t.*&#x27;</span><br><span class="line">drop_all &#x27;ns:.*&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-11-获取某个表赋值给一个变量-get-table"><a href="#1-3-11-获取某个表赋值给一个变量-get-table" class="headerlink" title="1.3.11    获取某个表赋值给一个变量 get_table"></a>1.3.11    获取某个表赋值给一个变量 get_table</h4><blockquote><p>通过 var &#x3D; get_table ‘表名’ 赋值给一个变量对象，然后对象.来调用，就像面向对象编程一样，通过对象.方法来调用，这种方式在操作某个表时就不必每次列举表名了。</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/YhZ5EpCQijf2d1k.png" alt="image-20220612212036726"></p><h4 id="1-3-12-获取rowKey所在的区-locate-region"><a href="#1-3-12-获取rowKey所在的区-locate-region" class="headerlink" title="1.3.12    获取rowKey所在的区 locate_region"></a>1.3.12    获取rowKey所在的区 locate_region</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">locate_region &#x27;表名&#x27;, &#x27;行键&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-3-13-显示hbase所支持的所有过滤器show-filters"><a href="#1-3-13-显示hbase所支持的所有过滤器show-filters" class="headerlink" title="1.3.13    显示hbase所支持的所有过滤器show_filters"></a>1.3.13    显示hbase所支持的所有过滤器show_filters</h4><blockquote><p>过滤器用于get和scan命令中作为筛选数据的条件，类型关系型数据库中的where的作用</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/dkL1wJREzvXOjxQ.png" alt="image-20220612212116009"></p><h3 id="1-4-namespace"><a href="#1-4-namespace" class="headerlink" title="1.4    namespace"></a>1.4    namespace</h3><blockquote><p><strong>hbase中没有数据库的概念 , 可以使用namespace来达到数据库分类别管理表的作用</strong></p></blockquote><h4 id="1-4-1-列举命名空间-list-namespace"><a href="#1-4-1-列举命名空间-list-namespace" class="headerlink" title="1.4.1    列举命名空间 list_namespace"></a>1.4.1    列举命名空间 list_namespace</h4><p><img src="https://s2.loli.net/2022/06/12/ndvMyJafYNrStip.png" alt="image-20220612212131363"></p><h4 id="1-4-2-获取命名空间描述-describe-namespace"><a href="#1-4-2-获取命名空间描述-describe-namespace" class="headerlink" title="1.4.2    获取命名空间描述 describe_namespace"></a>1.4.2    获取命名空间描述 describe_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">describe_namespace <span class="string">&#x27;default&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/fCoW9JQNq4YEgDG.png" alt="image-20220612212142303"></p><h4 id="1-4-3-查看命名空间下的所有表-list-namespace-tables"><a href="#1-4-3-查看命名空间下的所有表-list-namespace-tables" class="headerlink" title="1.4.3    查看命名空间下的所有表 list_namespace_tables"></a>1.4.3    查看命名空间下的所有表 list_namespace_tables</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">list_namespace_tables <span class="string">&#x27;default&#x27;</span></span><br><span class="line"></span><br><span class="line">list_namespace_tables <span class="string">&#x27;hbase&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/78yuhSa3n4HRfEU.png" alt="image-20220612212155514"></p><h4 id="1-4-4-创建命名空间create-namespace"><a href="#1-4-4-创建命名空间create-namespace" class="headerlink" title="1.4.4    创建命名空间create_namespace"></a>1.4.4    创建命名空间create_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">create_namespace <span class="string">&#x27;bigdata17&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-4-5-删除命名空间drop-namespace"><a href="#1-4-5-删除命名空间drop-namespace" class="headerlink" title="1.4.5    删除命名空间drop_namespace"></a>1.4.5    删除命名空间drop_namespace</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">drop_namespace <span class="string">&#x27;命名空间名称&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="1-5-DML"><a href="#1-5-DML" class="headerlink" title="1.5    DML"></a>1.5    DML</h3><h4 id="1-5-1-插入或者修改数据put"><a href="#1-5-1-插入或者修改数据put" class="headerlink" title="1.5.1    插入或者修改数据put"></a>1.5.1    插入或者修改数据put</h4><p><img src="https://s2.loli.net/2022/06/12/ItKsyROVx8p3DBg.png" alt="image-20220612212213476"></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"># 当列族中只有一个列时<span class="string">&#x27;列族名:列名&#x27;</span>使用<span class="string">&#x27;列族名&#x27;</span></span><br><span class="line">put <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span>, <span class="string">&#x27;列值&#x27;</span></span><br><span class="line">put <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名:列名&#x27;</span>, <span class="string">&#x27;列值&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"></span><br><span class="line"># 创建表</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;info&#x27;</span>, <span class="string">&#x27;detail&#x27;</span>, <span class="string">&#x27;address&#x27;</span></span><br><span class="line"></span><br><span class="line"># 第一行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;张三&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;28&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-26&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;abc@163.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-04 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;mengday&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;上海市&#x27;</span></span><br><span class="line"></span><br><span class="line"># 第二行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;李四&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;27&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-27&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;xxx@gmail.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-05 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;vbirdbest&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;北京市&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 第三行数据</span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;3&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:name&#x27;</span>, <span class="string">&#x27;王五&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>, <span class="string">&#x27;26&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:birthday&#x27;</span>, <span class="string">&#x27;1990-06-28&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:email&#x27;</span>, <span class="string">&#x27;xyz@qq.com&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;detail:create_time&#x27;</span>, <span class="string">&#x27;2019-03-06 14:26:10&#x27;</span></span><br><span class="line">put <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;address&#x27;</span>, <span class="string">&#x27;杭州市&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-2-全表扫描scan"><a href="#1-5-2-全表扫描scan" class="headerlink" title="1.5.2    全表扫描scan"></a>1.5.2    全表扫描scan</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/MnSmobUu6JAG5Qd.png" alt="image-20220612212319590"></p><blockquote><p>扫描整个列簇</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;列族名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;info&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><blockquote><p>扫描整个列簇的某个列</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;列族名:列名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;users&#x27;</span>, &#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;info:age&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="1-5-3-获取数据get"><a href="#1-5-3-获取数据get" class="headerlink" title="1.5.3     获取数据get"></a>1.5.3     获取数据get</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>根据某一行某列族的数据</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族名&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span>, <span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 创建表，c1版本为<span class="number">4</span>， 元数据mykey<span class="operator">=</span>myvalue</span><br><span class="line">hbase(main):<span class="number">009</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="string">&#x27;t1&#x27;</span>, &#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;, METADATA <span class="operator">=</span><span class="operator">&gt;</span> &#123; <span class="string">&#x27;mykey&#x27;</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;myvalue&#x27;</span> &#125;</span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">2.2810</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> Hbase::<span class="keyword">Table</span> <span class="operator">-</span> t1</span><br><span class="line"># 添加列族c2, c3</span><br><span class="line">hbase(main):<span class="number">010</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span></span><br><span class="line">Updating <span class="keyword">all</span> regions <span class="keyword">with</span> the <span class="keyword">new</span> schema...</span><br><span class="line"><span class="number">1</span><span class="operator">/</span><span class="number">1</span> regions updated.</span><br><span class="line">Done.</span><br><span class="line">Updating <span class="keyword">all</span> regions <span class="keyword">with</span> the <span class="keyword">new</span> schema...</span><br><span class="line"><span class="number">1</span><span class="operator">/</span><span class="number">1</span> regions updated.</span><br><span class="line">Done.</span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">3.8320</span> seconds</span><br><span class="line"></span><br><span class="line"># 出入数据，c1 插入<span class="number">4</span>个版本的值</span><br><span class="line">hbase(main):<span class="number">011</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v1&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.1000</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">012</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v11&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">013</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v111&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">014</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;v1111&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line"># 插入c2、c3的值</span><br><span class="line">hbase(main):<span class="number">015</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;v2&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0140</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">016</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>, <span class="string">&#x27;v3&#x27;</span></span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0210</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1的一行记录</span><br><span class="line">hbase(main):<span class="number">017</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span></span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"> c3:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819398244</span>, <span class="keyword">value</span><span class="operator">=</span>v3</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0550</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1并且 <span class="number">1552819392398</span> <span class="operator">&lt;=</span> 时间戳范围 <span class="operator">&lt;</span> <span class="number">1552819398244</span></span><br><span class="line">hbase(main):<span class="number">018</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;TIMERANGE <span class="operator">=</span><span class="operator">&gt;</span> [<span class="number">1552819392398</span>, <span class="number">1552819398244</span>]&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0090</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定列的值</span><br><span class="line">hbase(main):<span class="number">019</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0160</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定列的值，多个值使用数组表示</span><br><span class="line">hbase(main):<span class="number">020</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> [<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>]&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"> c3:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819398244</span>, <span class="keyword">value</span><span class="operator">=</span>v3</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0170</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取c1的值，获取<span class="number">4</span>个版本的值，默认是按照时间戳降续排序的</span><br><span class="line">hbase(main):<span class="number">021</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819368993</span>, <span class="keyword">value</span><span class="operator">=</span>v11</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819362975</span>, <span class="keyword">value</span><span class="operator">=</span>v1</span><br><span class="line"><span class="number">4</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取c1的<span class="number">3</span>个版本值</span><br><span class="line">hbase(main):<span class="number">027</span>:<span class="number">0</span><span class="operator">*</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                               CELL</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"> c1:                                                 <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819368993</span>, <span class="keyword">value</span><span class="operator">=</span>v11</span><br><span class="line"><span class="number">3</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0090</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取指定时间戳版本的列</span><br><span class="line">hbase(main):<span class="number">022</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, <span class="type">TIMESTAMP</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1552819376343</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0170</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">023</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, <span class="type">TIMESTAMP</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">1552819376343</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">4</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819376343</span>, <span class="keyword">value</span><span class="operator">=</span>v111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0130</span> seconds</span><br><span class="line"></span><br><span class="line"># 获取rowKey<span class="operator">=</span>r1中的值等于v2的所有列</span><br><span class="line">hbase(main):<span class="number">024</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">FILTER</span> <span class="operator">=</span><span class="operator">&gt;</span> &quot;ValueFilter(=, &#x27;binary:v2&#x27;)&quot;&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c2:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819392398</span>, <span class="keyword">value</span><span class="operator">=</span>v2</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0510</span> seconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">025</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">get</span> <span class="string">&#x27;t1&#x27;</span>, <span class="string">&#x27;r1&#x27;</span>, &#123;<span class="keyword">COLUMN</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;c1&#x27;</span>, ATTRIBUTES <span class="operator">=</span><span class="operator">&gt;</span> &#123;<span class="string">&#x27;mykey&#x27;</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;myvalue&#x27;</span>&#125;&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                                              CELL</span><br><span class="line"> c1:                                                <span class="type">timestamp</span><span class="operator">=</span><span class="number">1552819382575</span>, <span class="keyword">value</span><span class="operator">=</span>v1111</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s) <span class="keyword">in</span> <span class="number">0.0100</span> seconds</span><br></pre></td></tr></table></figure><h4 id="1-5-4-删除某个列族中的某个列delete"><a href="#1-5-4-删除某个列族中的某个列delete" class="headerlink" title="1.5.4    删除某个列族中的某个列delete"></a>1.5.4    删除某个列族中的某个列delete</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">语法</span></span><br><span class="line">delete &#x27;表名&#x27;, &#x27;行键&#x27;, &#x27;列族名:列名&#x27;</span><br><span class="line"></span><br><span class="line">delete &#x27;users&#x27;,&#x27;xiaoming&#x27;,&#x27;info:age&#x27;</span><br><span class="line"></span><br><span class="line">create &#x27;tbl_test&#x27;, &#x27;columnFamily1&#x27;</span><br><span class="line"></span><br><span class="line">put &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column1&#x27;, &#x27;value1&#x27;</span><br><span class="line">put &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column2&#x27;, &#x27;value2&#x27;</span><br><span class="line"></span><br><span class="line">delete &#x27;tbl_test&#x27;, &#x27;rowKey1&#x27;, &#x27;columnFamily1:column1&#x27;</span><br></pre></td></tr></table></figure><h4 id="1-5-5-删除某行数据deleteall"><a href="#1-5-5-删除某行数据deleteall" class="headerlink" title="1.5.5     删除某行数据deleteall"></a>1.5.5     删除某行数据deleteall</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">deleteall <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span></span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">deleteall <span class="string">&#x27;users&#x27;</span>, <span class="string">&#x27;xiaoming&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-6-清空整个表的数据truncate"><a href="#1-5-6-清空整个表的数据truncate" class="headerlink" title="1.5.6    清空整个表的数据truncate"></a>1.5.6    清空整个表的数据truncate</h4><blockquote><p>先disable表，然后再drop表，最后重新create表</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">truncate &#x27;表名&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/vpx594qBNIhoGcU.png" alt="image-20220612212401461"></p><h4 id="1-5-7-自增incr"><a href="#1-5-7-自增incr" class="headerlink" title="1.5.7    自增incr"></a>1.5.7    自增incr</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">incr <span class="string">&#x27;表名&#x27;</span>, <span class="string">&#x27;行键&#x27;</span>, <span class="string">&#x27;列族:列名&#x27;</span>, 步长值</span><br><span class="line"></span><br><span class="line"># 示例 </span><br><span class="line"># 注意：incr 可以对不存的行键操作，如果行键已经存在会报错，如果使用put修改了incr的值再使用incr也会报错</span><br><span class="line"># ERROR: org.apache.hadoop.hbase.DoNotRetryIOException: Field <span class="keyword">is</span> <span class="keyword">not</span> a long, it<span class="string">&#x27;s 2 bytes wide</span></span><br><span class="line"><span class="string">incr &#x27;</span>tbl_user<span class="string">&#x27;, &#x27;</span>xiaohong<span class="string">&#x27;, &#x27;</span>info:age<span class="string">&#x27;, 1</span></span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/12/lizvE4OsXNP9WjI.png" alt="image-20220612212416654"></p><h4 id="1-5-8-计数器get-counter"><a href="#1-5-8-计数器get-counter" class="headerlink" title="1.5.8    计数器get_counter"></a>1.5.8    计数器get_counter</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 点击量：日、周、月</span><br><span class="line"><span class="keyword">create</span> <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;daily&#x27;</span>, <span class="string">&#x27;weekly&#x27;</span>, <span class="string">&#x27;monthly&#x27;</span></span><br><span class="line">incr <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span>, <span class="number">1</span></span><br><span class="line">incr <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span>, <span class="number">1</span></span><br><span class="line">get_counter <span class="string">&#x27;counters&#x27;</span>, <span class="string">&#x27;20110101&#x27;</span>, <span class="string">&#x27;daily:hits&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="1-5-9-修饰词"><a href="#1-5-9-修饰词" class="headerlink" title="1.5.9    修饰词"></a>1.5.9    修饰词</h4><h5 id="1、修饰词"><a href="#1、修饰词" class="headerlink" title="1、修饰词"></a>1、修饰词</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;列族名1:列名1&#x27;</span>, <span class="string">&#x27;列族名1:列名2&#x27;</span>, ...]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123;COLUMNS <span class="operator">=</span><span class="operator">&gt;</span> [ <span class="string">&#x27;info:id&#x27;</span>, <span class="string">&#x27;info:age&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="2、TIMESTAMP-指定时间戳"><a href="#2、TIMESTAMP-指定时间戳" class="headerlink" title="2、TIMESTAMP 指定时间戳"></a>2、TIMESTAMP 指定时间戳</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[timestamp1, timestamp2]&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>,&#123;TIMERANGE<span class="operator">=</span><span class="operator">&gt;</span>[<span class="number">1551938004321</span>, <span class="number">1551938036450</span>]&#125;</span><br></pre></td></tr></table></figure><h5 id="3、VERSIONS"><a href="#3、VERSIONS" class="headerlink" title="3、VERSIONS"></a>3、VERSIONS</h5><blockquote><p>默认情况下一个列只能存储一个数据，后面如果修改数据就会将原来的覆盖掉，可以通过指定VERSIONS时HBase一列能存储多个值。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;columnFamily1&#x27;</span></span><br><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;tbl_test&#x27;</span></span><br><span class="line"></span><br><span class="line"># 修改列族版本号</span><br><span class="line"><span class="keyword">alter</span> <span class="string">&#x27;tbl_test&#x27;</span>, &#123; NAME<span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span> &#125;</span><br><span class="line"></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value1&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value2&#x27;</span></span><br><span class="line">put <span class="string">&#x27;tbl_test&#x27;</span>, <span class="string">&#x27;rowKey1&#x27;</span>, <span class="string">&#x27;columnFamily1:column1&#x27;</span>, <span class="string">&#x27;value3&#x27;</span></span><br><span class="line"></span><br><span class="line"># 默认返回最新的一条数据</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,<span class="string">&#x27;columnFamily1:column1&#x27;</span></span><br><span class="line"></span><br><span class="line"># 返回<span class="number">3</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"># 返回<span class="number">2</span>个</span><br><span class="line"><span class="keyword">get</span> <span class="string">&#x27;tbl_test&#x27;</span>,<span class="string">&#x27;rowKey1&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;columnFamily1:column1&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="4、STARTROW"><a href="#4、STARTROW" class="headerlink" title="4、STARTROW"></a>4、STARTROW</h5><blockquote><p>ROWKEY起始行。会先根据这个key定位到region，再向后扫描</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STARTROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;vbirdbest&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"><a href="#5、STOPROW-：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据" class="headerlink" title="5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据"></a>5、STOPROW ：截止到STOPROW行，STOPROW行之前的数据，不包括STOPROW这行数据</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;行键名&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; STOPROW <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;xiaoming&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h5 id="6、LIMIT-返回的行数"><a href="#6、LIMIT-返回的行数" class="headerlink" title="6、LIMIT 返回的行数"></a>6、LIMIT 返回的行数</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> 行数&#125;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, &#123; LIMIT <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">2</span> &#125;</span><br></pre></td></tr></table></figure><h4 id="1-5-10-FILTER条件过滤器"><a href="#1-5-10-FILTER条件过滤器" class="headerlink" title="1.5.10    FILTER条件过滤器"></a>1.5.10    FILTER条件过滤器</h4><blockquote><p>过滤器之间可以使用AND、OR连接多个过滤器。</p></blockquote><h5 id="1、ValueFilter-值过滤器"><a href="#1、ValueFilter-值过滤器" class="headerlink" title="1、ValueFilter 值过滤器"></a>1、ValueFilter 值过滤器</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 语法：<span class="type">binary</span> 等于某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;binary:列值&#x27;)&quot;</span><br><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan <span class="string">&#x27;表名&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=,&#x27;substring:列值&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;binary:26&#x27;)&quot;</span><br><span class="line">scan <span class="string">&#x27;tbl_user&#x27;</span>, <span class="keyword">FILTER</span><span class="operator">=</span><span class="operator">&gt;</span>&quot;ValueFilter(=, &#x27;substring:6&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="2、ColumnPrefixFilter-列名前缀过滤器"><a href="#2、ColumnPrefixFilter-列名前缀过滤器" class="headerlink" title="2、ColumnPrefixFilter 列名前缀过滤器"></a>2、ColumnPrefixFilter 列名前缀过滤器</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 语法 substring:包含某个值</span><br><span class="line">scan &#x27;表名&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;列名前缀&#x27;)&quot;</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">scan &#x27;tbl_user&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;birth&#x27;)&quot;</span><br><span class="line"># 通过括号、AND和OR的条件组合多个过滤器</span><br><span class="line">scan &#x27;tbl_user&#x27;, FILTER=&gt;&quot;ColumnPrefixFilter(&#x27;birth&#x27;) AND ValueFilter(=,&#x27;substring:26&#x27;)&quot;</span><br></pre></td></tr></table></figure><h5 id="3、rowKey字典排序"><a href="#3、rowKey字典排序" class="headerlink" title="3、rowKey字典排序"></a>3、rowKey字典排序</h5><blockquote><p>Table中的所有行都是按照row key的字典排序的</p></blockquote><p><img src="https://s2.loli.net/2022/06/12/lHbNsQYjU8TCnMA.png" alt="image-20220612212431834"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hbase概述及搭建</title>
      <link href="/2022/06/08/Hbase%E6%A6%82%E8%BF%B0%E5%8F%8A%E6%90%AD%E5%BB%BA/"/>
      <url>/2022/06/08/Hbase%E6%A6%82%E8%BF%B0%E5%8F%8A%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="一、了解HBase"><a href="#一、了解HBase" class="headerlink" title="一、了解HBase"></a>一、了解HBase</h2><p>官方文档：<a href="https://hbase.apache.org/book.html">https://hbase.apache.org/book.html</a></p><h3 id="1-1-HBase概述"><a href="#1-1-HBase概述" class="headerlink" title="1.1    HBase概述"></a>1.1    HBase概述</h3><blockquote><p>HBase 是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，用于存储海量的结构化或者半结构化，非结构化的数据</p><p>HBase是Hadoop的生态系统之一，是建立在Hadoop文件系统（HDFS）之上的分布式、面向列的数据库，通过利用Hadoop的文件系统提供容错能力。如果需要进行实时读写或者随机访问大规模的数据集的时候，会考虑使用HBase。</p><p>HBase作为Google Bigtable的开源实现，Google Bigtable利用GFS作为其文件存储系统类似，则HBase利用Hadoop HDFS作为其文件存储系统；Google通过运行MapReduce来处理Bigtable中的海量数据，同样，HBase利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用Chubby作为协同服务，HBase利用Zookeeper作为对应。在2010年5月，成为apache顶级项目</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/IYKfrEsFbvx2Q4A.png" alt="image-20220608204054001"></p><h3 id="1-2-HBase处理数据"><a href="#1-2-HBase处理数据" class="headerlink" title="1.2    HBase处理数据"></a>1.2    HBase处理数据</h3><blockquote><p>虽然Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，但是它不适用于提供实时计算；</p><p>HBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证期高容错性;</p><p>但是再生产环境中，HBase是如何基于hadoop提供实时性呢？ </p><p>HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；</p><p>但是HDFS并不知道的HBase用于存储什么，它只把存储文件认为是二进制文件，也就是说，HBase的存储数据对于HDFS文件系统是透明的。</p></blockquote><h3 id="1-3-HBase与HDFS"><a href="#1-3-HBase与HDFS" class="headerlink" title="1.3    HBase与HDFS"></a>1.3    HBase与HDFS</h3><blockquote><p>在下面的表格中，我们对HDFS与HBase进行比较：    </p></blockquote><table><thead><tr><th>HDFS</th><th>HBase</th></tr></thead><tbody><tr><td>HDFS适于存储大容量文件的分布式文件系统。</td><td>HBase是建立在HDFS之上的数据库。</td></tr><tr><td>HDFS不支持快速单独记录查找。</td><td>HBase提供在较大的表快速查找</td></tr><tr><td>HDFS提供了高延迟批量处理;没有批处理概念。</td><td>HBase提供了数十亿条记录低延迟访问单个行记录（随机存取）。</td></tr><tr><td>HDFS提供的数据只能顺序访问。</td><td>HBase内部使用哈希表和提供随机接入，并且其存储索引，可将在HDFS文件中的数据进行快速查找。</td></tr></tbody></table><p>Hbase—&gt;HashMap</p><h2 id="二、HBase相关概念"><a href="#二、HBase相关概念" class="headerlink" title="二、HBase相关概念"></a>二、HBase相关概念</h2><h3 id="2-1-分布式数据库"><a href="#2-1-分布式数据库" class="headerlink" title="2.1    分布式数据库"></a>2.1    分布式数据库</h3><p><img src="https://s2.loli.net/2022/06/09/N9gnjo1GSKQ2UY4.png" alt="image-20220609215840812"></p><h3 id="2-2-列式存储"><a href="#2-2-列式存储" class="headerlink" title="2.2    列式存储"></a>2.2    列式存储</h3><p><img src="https://s2.loli.net/2022/06/09/PmgjIZuvkKYE72C.png" alt="image-20220609215924536"></p><h3 id="2-3-稀疏性"><a href="#2-3-稀疏性" class="headerlink" title="2.3    稀疏性"></a>2.3    稀疏性</h3><blockquote><p>理解稀疏（rowkey）</p><p>HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“<strong>四维坐标</strong>”，即**[行键, 列族, 列限定符, 时间戳]**</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/kC42Rz8LeFw67vy.png" alt="稀疏性"></p><h3 id="2-4-数据模型"><a href="#2-4-数据模型" class="headerlink" title="2.4    数据模型"></a>2.4    数据模型</h3><blockquote><p>HBase通过表格的模式存储数据，每个表格由列和行组成，其中，每个列又被划分为若干个列族（colnum family），请参考下面的图：</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/eHQcAD7hfqXNRk4.png" alt="image-20220609220036643"></p><blockquote><p>          <strong>表：</strong>HBase的数据同样是用表来组织的，表由行和列组成，列分为若干个列族，行和列的坐标交叉决定了一个单元格。</p><p>       <strong>行：</strong>每个表由若干行组成，每个行有一个行键作为这一行的唯一标识。访问表中的行只有三种方式：通过单个行键进行查询、通过一个行键的区间来访问、全表扫描。</p><p>       <strong>列族：</strong>一个HBase表被分组成许多“列族”的集合，它是基本的访问控制单元。</p><p>       <strong>列修饰符（列限定符）：</strong>列族里的数据通过列限定符（或列）来定位</p><p>       <strong>单元格：</strong>在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，<strong>总被视为字节数组byte[]</strong></p><p>       <strong>时间戳：</strong>每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引</p></blockquote><h4 id="2-4-1-Hbase数据模型"><a href="#2-4-1-Hbase数据模型" class="headerlink" title="2.4.1    Hbase数据模型"></a>2.4.1    Hbase数据模型</h4><blockquote><p>HBase将数据存放在带有标签的<strong>表</strong>中，表由<strong>行和列</strong>组成，行和列交叉确定一个<strong>单元格</strong>，单元格有<strong>版本号</strong>，版本号自动分配，为数据插入该单元格时的<strong>时间戳</strong>。单元格的内容没有数据类型，<strong>所有数据都被视为未解释的字节数组</strong>。</p><p>  表格中每一行有一个<strong>行键</strong>（也是字节数组，任何形式的数据都可以表示成字符串，比如数据结构进行序列化之后），<strong>整个表根据行键的字节序来排序</strong>，所有对表的访问必须通过行键。</p><p>  表中的列又划分为多个<strong>列族</strong>（column family），同一个列族的所有成员具有相同的前缀，具体的列由列修饰符标识，因此，<strong>列族和列修饰符</strong>合起来才可以表示某一列，比如：info:format、cotents:image</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/JkNlnw1zLYGjP2u.png" alt="image-20220609220054289"></p><blockquote><p>在创建一个表的时候，列族必须作为模式定义的一部分预先给出，而<strong>列族是支持动态扩展的</strong>，也就是列族成员可以随后按需加入。物理上，所有的列族成员一起存放在文件系统上，所以实际上说HBase是面向列的数据库，更准确的应该是<strong>面向列族</strong>，调优和存储都是在列族这个层次上进行的。一般情况下，同一个列族的成员最后具有相同的访问模式和大小特征。</p><p>  总结起来，HBase表和我们熟知的RDBMS的表很像，不同之处在于：<strong>行按行键排序，列划分为列族，单元格有版本号，没有数据类型。</strong></p></blockquote><h4 id="2-4-2-Hbase数据坐标"><a href="#2-4-2-Hbase数据坐标" class="headerlink" title="2.4.2    Hbase数据坐标"></a>2.4.2    Hbase数据坐标</h4><blockquote><p>HBase中需要根据行键、列族、列限定符和时间戳来确定一个<strong>单元格(cell)<strong>，cell中的数据是没有类型的，全部是</strong>字节码</strong>形式存贮。，因此，可以视为一个“<strong>四维坐标</strong>”，即**[行键, 列族, 列限定符, 时间戳]**。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/kz6J29nxcSCYZlV.png" alt="image-20220609220127385"></p><blockquote><p>对于上图这样一个HBase表，其数据坐标举例如下：</p></blockquote><table><thead><tr><th>键</th><th>值</th></tr></thead><tbody><tr><td>[“201505003”, “Info”, “email”, 1174184619081]</td><td>“<a href="mailto:&#x78;&#x69;&#101;&#64;&#113;&#x71;&#46;&#x63;&#111;&#109;">&#x78;&#x69;&#101;&#64;&#113;&#x71;&#46;&#x63;&#111;&#109;</a>”</td></tr><tr><td>[“201505003”, “Info”, “email”, 1174184620720]</td><td>“<a href="mailto:&#x79;&#111;&#x75;&#x40;&#49;&#x36;&#x33;&#46;&#x63;&#x6f;&#109;">&#x79;&#111;&#x75;&#x40;&#49;&#x36;&#x33;&#46;&#x63;&#x6f;&#109;</a>”</td></tr></tbody></table><h4 id="2-4-3-HBase区域"><a href="#2-4-3-HBase区域" class="headerlink" title="2.4.3    HBase区域"></a>2.4.3    HBase区域</h4><blockquote><p>HBase自动把表水平划分为<strong>区域</strong>（Region），每个区域都是有若干连续行构成的，一个区域由<strong>所属的表、起始行、终止行（不包括这行）</strong>三个要素来表示。</p><p>  一开始，一个表只有一个区域，但是随着数据的增加，区域逐渐变大，等到它超出设定的阈值大小，就会在某行的边界上进行拆分，分成两个大小<strong>基本相同</strong>的区域。然后随着数据的再增加，区域就不断的增加，如果超出了单台服务器的容量，就可以把一些区域放到其他节点上去，构成一个集群。也就是说：<strong>集群中的每个节点（Region Server）管理整个表的若干个区域</strong>。所以，我们说：<strong>区域是HBase集群上分布数据的最小单位</strong>。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/4lDPXtMkmfhdz2C.png" alt="image-20220609220146716"></p><h2 id="三、HBase系统架构"><a href="#三、HBase系统架构" class="headerlink" title="三、HBase系统架构"></a>三、HBase系统架构</h2><h3 id="3-1-架构图"><a href="#3-1-架构图" class="headerlink" title="3.1    架构图"></a>3.1    架构图</h3><p><img src="https://s2.loli.net/2022/06/09/Dhl7Z3jRKHa8F2p.png" alt="image-20220609220202453"></p><h3 id="3-2-组件介绍"><a href="#3-2-组件介绍" class="headerlink" title="3.2    组件介绍"></a>3.2    组件介绍</h3><p>HBase由三种类型的服务器以主从模式构成：</p><ul><li>Region Server：负责数据的读写服务，用户通过与Region server交互来实现对数据的访问。</li><li>HBase HMaster：负责Region的分配及数据库的创建和删除等操作。</li><li>ZooKeeper：负责维护集群的状态（某台服务器是否在线，服务器之间数据的同步操作及master的选举等）。</li></ul><p>HDFS的DataNode负责存储所有Region Server所管理的数据，即HBase中的所有数据都是以HDFS文件的形式存储的。出于使Region server所管理的数据更加本地化的考虑，Region server是根据DataNode分布的。HBase的数据在写入的时候都存储在本地。但当某一个region被移除或被重新分配的时候，就可能产生数据不在本地的情况。这种情况只有在所谓的compaction之后才能解决。</p><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><blockquote><p>包含访问HBase的接口并维护cache来加快对HBase的访问</p></blockquote><h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><blockquote><p>保证任何时候，集群中只有一个master</p><p>存贮所有Region的寻址入口。</p><p>实时监控Region server的上线和下线信息。并实时通知Master</p><p>存储HBase的schema和table元数据</p></blockquote><h4 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h4><blockquote><p>为Region server分配region</p><p>负责Region server的负载均衡</p><p>发现失效的Region server并重新分配其上的region</p><p>管理用户对table的增删改操作</p></blockquote><h4 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h4><blockquote><p>Region server维护region，处理对这些region的IO请求</p><p>Region server负责切分在运行过程中变得过大的region　</p></blockquote><h4 id="HLog-WAL-log-："><a href="#HLog-WAL-log-：" class="headerlink" title="HLog(WAL log)："></a>HLog(WAL log)：</h4><blockquote><p>HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是 HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和 region名字外，同时还包括sequence number和timestamp，timestamp是” 写入时间”，sequence number的起始值为0，或者是最近一次存入文件系 统sequence number。</p><p>HLog SequeceFile的Value是HBase的KeyValue对象，即对应HFile中的 KeyValue</p></blockquote><h4 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h4><blockquote><p>HBase自动把表水平划分成多个区域(region)，每个region会保存一个表里面某段连续的数据；每个表一开始只有一个region，随着数据不断插 入表，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region（裂变）；</p><p>当table中的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Regionserver上。</p></blockquote><h4 id="Memstore-与-storefile"><a href="#Memstore-与-storefile" class="headerlink" title="Memstore 与 storefile"></a>Memstore 与 storefile</h4><blockquote><ol><li><p>一个region由多个store组成，一个store对应一个CF（列簇）</p></li><li><p>store包括位于内存中的memstore和位于磁盘的storefile写操作先写入 memstore，当memstore中的数据达到某个阈值，hregionserver会启动 flashcache进程写入storefile，每次写入形成单独的一个storefile</p></li><li><p>当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、 major compaction），在合并过程中会进行版本合并和删除工作 （majar），形成更大的storefile。</p></li><li><p>当一个region所有storefile的大小和超过一定阈值后，会把当前的region 分割为两个，并由hmaster分配到相应的regionserver服务器，实现负载均衡。</p></li><li><p>客户端检索数据，先在memstore找，找不到再找storefile</p></li><li><p>HRegion是HBase中分布式存储和负载均衡的最小单元。最小单元就表 示不同的HRegion可以分布在不同的HRegion server上。</p></li><li><p>HRegion由一个或者多个Store组成，每个store保存一个columns family。</p></li><li><p>每个Strore又由一个memStore和0至多个StoreFile组成。</p></li></ol><p>如图：StoreFile 以HFile格式保存在HDFS上。</p></blockquote><p><img src="https://s2.loli.net/2022/06/09/ckzY96POTFUQwtK.png" alt="image-20220609220217852"></p><p><img src="https://s2.loli.net/2022/06/09/B5yDYaUn7vM3lif.png" alt="image-20220609220227154"></p><h3 id="3-3-理解难点"><a href="#3-3-理解难点" class="headerlink" title="3.3    理解难点"></a>3.3    理解难点</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">　　1、flush刷新在HDFS上呈现究竟是怎么刷新的呢？？</span><br><span class="line">　　　　我们目前刚刚学习的时候，添加数据，都是一条一条的put进去，而我们在put的数据比较少（小于128M）的时候，我们put完去HDFS上并未查看到我们put的文件，这是因为数据还在内存中，也就是还在memStore中，所以要想在HDFS中查看到，我们必须手动刷新到磁盘中，这是将memStore的数据刷新到StoreFile中去，这样我们在HDFS中就可以查看到了。　　</span><br><span class="line"></span><br><span class="line">　　2、为什么Hbase不可以使用像Mysql那样进行查询？？</span><br><span class="line">　　　　首先，我们应该可以感受到，我们在插入的时候，每行数据，有多少列，列名叫什么完全是我们自己定义的，之所以不支持像MySql那样对列进行查询和操作，因为不确定列的个数和名称。</span><br><span class="line"></span><br><span class="line">　　3、数据最后存在HDFS上的，HDFS不支持删改，为什么Hbase就可以呢？？</span><br><span class="line">　　　　这里有个思想误区，的确，数据是以HFile形式存在HDFS上的，而且HDFS的确是不支持删改的，但是为什么Hbase就支持呢？首先，这里的删除并不是真正意义上的对数据进行删除，而是对数据进行打上标记，我们再去查的时，就不会查到这个打过标记的数据，这个数据Hmaster会每隔1小时清理。修改是put两次，Hbase会取最新的数据，过期数据也是这个方式被清理。</span><br></pre></td></tr></table></figure><h2 id="四、HBase1-4-6安装搭建"><a href="#四、HBase1-4-6安装搭建" class="headerlink" title="四、HBase1.4.6安装搭建"></a>四、HBase1.4.6安装搭建</h2><h3 id="4-1-hbase下载"><a href="#4-1-hbase下载" class="headerlink" title="4.1 hbase下载"></a>4.1 hbase下载</h3><p><strong>后期在测试时发现1.7.1不是很兼容，因此回退到1.4.6版本</strong></p><p>官网下载地址：<a href="https://archive.apache.org/dist/hbase/1.4.6/hbase-1.4.6-bin.tar.gz">https://archive.apache.org/dist/hbase/1.4.6/hbase-1.4.6-bin.tar.gz</a></p><p><img src="https://s2.loli.net/2022/06/09/duV1iZ2pMrFfqCO.png" alt="image-20220609220320634"></p><h3 id="4-2-前期准备（Hadoop-zookeeper-jdk）"><a href="#4-2-前期准备（Hadoop-zookeeper-jdk）" class="headerlink" title="4.2 前期准备（Hadoop,zookeeper,jdk）"></a>4.2 前期准备（Hadoop,zookeeper,jdk）</h3><blockquote><p>启动hadoop</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><blockquote><p>验证</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://master:50070</span><br></pre></td></tr></table></figure><blockquote><p>启动zookeeper（三台分别启动）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><blockquote><p>检查状态</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure><h3 id="4-3-搭建Hbase"><a href="#4-3-搭建Hbase" class="headerlink" title="4.3    搭建Hbase"></a>4.3    搭建Hbase</h3><h4 id="1、上传解压"><a href="#1、上传解压" class="headerlink" title="1、上传解压"></a>1、上传解压</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf hbase-1.4.6-bin.tar.gz</span><br></pre></td></tr></table></figure><h4 id="2、配置环境变量"><a href="#2、配置环境变量" class="headerlink" title="2、配置环境变量"></a>2、配置环境变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HBASE_HOME=/usr/local/soft/hbase-1.4.6</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">HBASE_HOME/bin</span></span><br></pre></td></tr></table></figure><blockquote><p>source &#x2F;etc&#x2F;profile</p></blockquote><h4 id="3、修改hbase-env-sh文件"><a href="#3、修改hbase-env-sh文件" class="headerlink" title="3、修改hbase-env.sh文件"></a>3、修改hbase-env.sh文件</h4><blockquote><p>增加java配置</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><blockquote><p>关闭默认zk配置（原本是注释的，放开修改false）</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure><h4 id="4、修改hbase-site-xml文件"><a href="#4、修改hbase-site-xml文件" class="headerlink" title="4、修改hbase-site.xml文件"></a>4、修改hbase-site.xml文件</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>node1,node2,master<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure><h4 id="5、修改regionservers文件"><a href="#5、修改regionservers文件" class="headerlink" title="5、修改regionservers文件"></a>5、修改regionservers文件</h4><blockquote><p>如果是伪分布式版本，增加master即可</p></blockquote><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure><h4 id="6、同步到所有节点（如果是伪分布式不需要同步）"><a href="#6、同步到所有节点（如果是伪分布式不需要同步）" class="headerlink" title="6、同步到所有节点（如果是伪分布式不需要同步）"></a>6、同步到所有节点（如果是伪分布式不需要同步）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r hbase-1.4.6 node1:`pwd`</span><br><span class="line">scp -r hbase-1.4.6 node2:`pwd`</span><br></pre></td></tr></table></figure><h4 id="7、启动hbase集群-，-在master上执行"><a href="#7、启动hbase集群-，-在master上执行" class="headerlink" title="7、启动hbase集群 ， 在master上执行"></a>7、启动hbase集群 ， 在master上执行</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/09/6ybGojvBhIMR2VP.png" alt="image-20220609220348414"></p><h4 id="8、验证hbase"><a href="#8、验证hbase" class="headerlink" title="8、验证hbase"></a>8、验证hbase</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://master:16010</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/09/GetFKMrWAZJDdqC.png" alt="image-20220609220410102"></p><blockquote><p>hbase日志文件所在的目录: &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hbase-1.7.1&#x2F;logs</p></blockquote><h4 id="9、关闭集群的命令"><a href="#9、关闭集群的命令" class="headerlink" title="9、关闭集群的命令"></a>9、关闭集群的命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure><h3 id="4-4-启动顺序"><a href="#4-4-启动顺序" class="headerlink" title="4.4    启动顺序"></a>4.4    启动顺序</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">启动顺序</span><br><span class="line">Hadoop及hbase集群启动顺序 zookeepeer -&gt; hadoop -&gt; hbase</span><br><span class="line"></span><br><span class="line">停止顺序</span><br><span class="line">Hadoop及hbase集群关闭顺序 hbase -&gt; hadoop -&gt; zookeepeer</span><br></pre></td></tr></table></figure><h3 id="4-5-重置hbase"><a href="#4-5-重置hbase" class="headerlink" title="4.5    重置hbase"></a>4.5    重置hbase</h3><h5 id="1、关闭hbase集群"><a href="#1、关闭hbase集群" class="headerlink" title="1、关闭hbase集群"></a>1、关闭hbase集群</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1)杀死进程</span><br><span class="line">   </span><br><span class="line">2)stop-hbase.sh</span><br></pre></td></tr></table></figure><h5 id="2、删除数据-hdfs"><a href="#2、删除数据-hdfs" class="headerlink" title="2、删除数据   hdfs"></a>2、删除数据   hdfs</h5> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs dfs -rmr /hbase</span><br></pre></td></tr></table></figure><h5 id="3、删除元数据-zk"><a href="#3、删除元数据-zk" class="headerlink" title="3、删除元数据 zk"></a>3、删除元数据 zk</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkCli.sh</span><br><span class="line">rmr /hbase</span><br></pre></td></tr></table></figure><h5 id="4、重新启动hbase"><a href="#4、重新启动hbase" class="headerlink" title="4、重新启动hbase"></a>4、重新启动hbase</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><h5 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install ntp -y</span><br><span class="line"></span><br><span class="line">ntpdate -u time.windows.com</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive优化</title>
      <link href="/2022/06/07/Hive%E4%BC%98%E5%8C%96/"/>
      <url>/2022/06/07/Hive%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="Hive优化"><a href="#Hive优化" class="headerlink" title="Hive优化"></a>Hive优化</h2><h2 id="1-1-hive的随机抓取策略"><a href="#1-1-hive的随机抓取策略" class="headerlink" title="1.1    hive的随机抓取策略"></a>1.1    <strong>hive的随机抓取策略</strong></h2><blockquote><p>理论上来说，Hive中的所有sql都需要进行mapreduce，但是hive的抓取策略帮我们<br>省略掉了这个过程，把切片split的过程提前帮我们做了。<br>set hive.fetch.task.conversion&#x3D;none;<br>(一旦进行这么设置，select字段名也是需要进行mapreduce的过程，默认是more)</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Fetch</span>抓取的模式</span><br><span class="line">可以通过 <span class="keyword">set</span> hive.fetch.task.conversion查看，有以下<span class="number">3</span>种模式：</span><br><span class="line"></span><br><span class="line"><span class="keyword">none</span>：所有涉及hdfs的读取查询都走mapreduce任务；</span><br><span class="line">mininal：在进行简单的<span class="keyword">select</span> <span class="operator">*</span>，简单的过滤或涉及分区字段的过滤时走mr；</span><br><span class="line">more:在mininal模式的基础上，增加了针对查询语句字段进行一些别名的计算操作。</span><br><span class="line">以下HQL，mininal模式与more模式下都不会走mr任务:</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">sale_ord_id,</span><br><span class="line">store_id</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">test_table</span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">dt <span class="operator">=</span> <span class="string">&#x27;2021-01-01&#x27;</span></span><br><span class="line"> limit <span class="number">10</span>;</span><br><span class="line"> </span><br><span class="line">以下HQL,mininal模式会走mr任务，more模式不会：</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">sale_ord_id,</span><br><span class="line">store_id,</span><br><span class="line">if(store_id <span class="operator">&gt;</span> <span class="number">20</span>,<span class="number">1</span>,<span class="number">0</span>) <span class="keyword">as</span> store_id_new</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">test_table</span><br><span class="line"><span class="keyword">where</span> </span><br><span class="line">dt <span class="operator">=</span> <span class="string">&#x27;2021-01-01&#x27;</span></span><br><span class="line"> limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure><blockquote><p>查看怎么将一个sql转化成一个MR任务的<br>explain sql语句<br>例如：<br>explain select count(*) from stu_dy1_1;<br>更加详细的查看，例如：<br><strong>explain extended select count(*) from stu_dy1_1;</strong><br>当你输入一个sql语句的时候，hive会将对其关键字进行截串，截完串之后，变成<br>都是一些TOK开头的一些东西，然后经过这样的抽象语法树，再转成具体的查询块，<br>最后变成逻辑查询计划</p></blockquote><h2 id="1-2-本地运行模式"><a href="#1-2-本地运行模式" class="headerlink" title="1.2    本地运行模式"></a>1.2    本地运行模式</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。不过，</span><br><span class="line">有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能</span><br><span class="line">会比实际 job 的执行时间要多的多。对于大多数这种情况， Hive 可以通过本地模式在单台机</span><br><span class="line">器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</span><br><span class="line">用户可以通过设置 hive.exec.mode.local.auto 的值为 true ，来让 Hive 在适当的时候自动</span><br><span class="line">启动这个优化。</span><br><span class="line"></span><br><span class="line">本地模式运行比集群模式块很多，33秒的任务降到2秒</span><br><span class="line">更改为本地模式：</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto=true</span><br><span class="line">注意：</span><br><span class="line">hive&gt; set hive.exec.mode.local.auto.inputbytes.max=134217728     ---&gt; 128M</span><br><span class="line">（默认值就是128）</span><br><span class="line">表示加载文件的最大值，若大于该配置仍然会以集群的方式去运行。</span><br><span class="line">97万行数据，50MB</span><br><span class="line">当我们开发或者测试阶段，可以去使用本地模式进行运行，默认是集群模式</span><br><span class="line">但是，这里有个问题，当我们去更改为本地模式的时候，在8088的页面上就看不到</span><br><span class="line">任务的执行情况了。</span><br><span class="line"></span><br><span class="line">测试：select count(*) from emp group by deptno;</span><br></pre></td></tr></table></figure><h2 id="1-3-并行计算"><a href="#1-3-并行计算" class="headerlink" title="1.3    并行计算"></a>1.3    <strong>并行计算</strong></h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过设置以下参数开启并行模式（默认是false）</span><br><span class="line">set hive.exec.parallel=true;</span><br><span class="line"></span><br><span class="line">注意：hive.exec.parallel.thread.number</span><br><span class="line">(一次SQl计算中允许并行执行的job个数最大值，默认是8个)</span><br><span class="line"></span><br><span class="line">举例：</span><br><span class="line">select t1.n1,t2.n2 from (select count(ename) as n1 from emp) t1,(select count(dname) as n2 from dept) t2;</span><br><span class="line">注意，有时候开启并行计算运行时间并没有不开启的快，那是因为，资源的问题。</span><br><span class="line">需要两套资源，资源申请会浪费点时间，最多可以并行8个，默认是8个。</span><br><span class="line">所以，并行的越多，不一定是越快，因为它涉及到一个资源申请的策略。</span><br></pre></td></tr></table></figure><h2 id="1-4-严格模式-理解为增加一些限制"><a href="#1-4-严格模式-理解为增加一些限制" class="headerlink" title="1.4    严格模式(理解为增加一些限制)"></a>1.4    <strong>严格模式(理解为增加一些限制)</strong></h2><p>​    <strong>1.什么是Hive的严格模式</strong><br>​        hive中的一种模式,在该模式下禁止一些不好SQL的执行。</p><p>​    <strong>2.Hive的严格模式不允许哪些SQL执行</strong><br>​        <strong>2.1 禁止分区表全表扫描</strong><br>               分区表往往数据量大,如果不加分区查询会带来巨大的资源消耗 。例如以下分区表<br>               SELECT DISTINCT(planner_id) FROM fracture_ins WHERE planner_id&#x3D;5;</p><p>​                报错如下:<br>​               FAILED: Error in semantic analysis: No Partition Predicate Found for Alias “fracture_ins” Table “fracture_ins</p><p>​               解决如下:<br>​              SELECT DISTINCT(planner_id) FROM fracture_ins WHERE planner_id&#x3D;5 AND hit_date&#x3D;20120101;</p><p>​      <strong>2.2 禁止排序不加limit</strong><br>​        排序最终是要都进到一个Reduce中操作,防止reducer额外执行很长一段时间<br>​        SELECT * FROM fracture_ins WHERE hit_date&gt;2012 ORDER BY planner_id;<br>​        出现如下错误<br>​               FAILED: Error in semantic analysis: line 1:56 In strict mode,limit must be specified if ORDER BY is present planner_id<br>​        解决方案就是增加一个limit关键字：<br>​               hive&gt; SELECT * FROM fracture_ins WHERE hit_date&gt;2012 ORDER BY planner_id LIMIT 100000;</p><p>​      <strong>2.3 禁止笛卡尔积</strong><br>​          笛卡尔积是什么: A&#x3D;{a,b}, B&#x3D;{0,1,2}，则 A×B&#x3D;{(a, 0), (a, 1), (a, 2), (b, 0), (b, 1), (b, 2)}</p><p>​          SELECT * FROM fracture_act JOIN fracture_ads;<br>​        解决方法<br>​        SELECT * FROM fracture_act JOIN fracture_ads WHERE fracture_act.planner_id &#x3D; fracture_ads.planner_id;</p><p><strong>3.Hive的严格模式怎样开启</strong></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 查看当前严格模式的状态</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 设置为严格模式</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode<span class="operator">=</span>strict;</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 设置为非严格模式</span><br><span class="line"><span class="keyword">set</span> hive.mapred.mode<span class="operator">=</span>nostrict;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意，这里的严格模式和动态分区的那个严格模式半毛钱关系没有）</span><br><span class="line">通过设置以下参数开启严格模式：</span><br><span class="line">set hive.mapred.mode=strict;</span><br><span class="line">(默认为：nonstrict非严格模式)</span><br><span class="line"></span><br><span class="line">查询限制：</span><br><span class="line">1、对于分区表，必须添加where对于分区字段的条件过滤</span><br><span class="line">2、order by 语句必须包含limit输出限制</span><br><span class="line">3、限制执行笛卡尔积的查询</span><br><span class="line">这些限制是帮助我们提高查询效率的。</span><br></pre></td></tr></table></figure><h2 id="1-5-Hive排序"><a href="#1-5-Hive排序" class="headerlink" title="1.5    Hive排序"></a>1.5    <strong>Hive排序</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> 对于查询结果做全排序，只允许有一个reduce处理</span><br><span class="line">（注意：它会把我们所有的字段或者查询结果全部放在一个reduce里进行处理</span><br><span class="line">当数据量较大时候，有可能reduce执行不完，所以，我们以后把这个给弃用掉）</span><br><span class="line"></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span>   sort <span class="keyword">by</span> 对于单个reduce进行排序 但是我们将每个reduce里面进行排序，没有考虑到</span><br><span class="line">每个reduce之间的排序。所以我们引出下一个</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span>   distribute <span class="keyword">by</span> 分区排序，通常结合sort <span class="keyword">by</span>一起使用</span><br><span class="line">（distribute <span class="keyword">by</span> <span class="keyword">column</span> sort <span class="keyword">by</span> <span class="keyword">column</span> <span class="keyword">asc</span><span class="operator">|</span><span class="keyword">desc</span>）</span><br><span class="line"></span><br><span class="line">cluster <span class="keyword">by</span> 相当于distribute <span class="keyword">by</span> <span class="operator">+</span> sort <span class="keyword">by</span>  (注意，虽然是两个结合，但是我们也不去用它</span><br><span class="line">原因很简单，cluster <span class="keyword">by</span>不能通过<span class="keyword">asc</span> <span class="keyword">desc</span>的方式指定排序方式规则)</span><br></pre></td></tr></table></figure><h2 id="1-6-Hive-join数据倾斜"><a href="#1-6-Hive-join数据倾斜" class="headerlink" title="1.6    Hive join数据倾斜"></a>1.6    Hive join数据倾斜</h2><p>1、小表join小表 不管他</p><p>2、小表join大表   map-join</p><p>3、大表join大表  map-side</p><p>考虑会不会发生reduce,并且考虑reduce压力是否大（是否会出现某个reduce数据量庞大的情况）</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">join</span>计算的时候，将小表（驱动表）放在<span class="keyword">join</span>的左边</span><br><span class="line">Map <span class="keyword">join</span>：在Map端完成<span class="keyword">join</span></span><br><span class="line">两种实现方式：</span><br><span class="line"><span class="number">1</span>、<span class="keyword">sql</span>方式，在<span class="keyword">sql</span>语句中添加Mapjoin标记（mapjoin hint）</span><br><span class="line"><span class="operator">&gt;&gt;</span>语法：</span><br><span class="line"><span class="keyword">select</span> <span class="comment">/*+MAPJOIN(smallTable)*/</span> smallTable.key bigTable.value <span class="keyword">from</span> smallTable <span class="keyword">join</span> bigTable <span class="keyword">on</span> smallTable.key<span class="operator">=</span>bigTable.key;</span><br><span class="line"><span class="number">2</span>、自动开启mapjoin</span><br><span class="line">通过修改以下配置启用自动的mapjoin：</span><br><span class="line"><span class="keyword">set</span> hive.auto.convert.join<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line">(注意：该参数为<span class="literal">true</span>的时候，Hive自动对左边的表统计量，如果</span><br><span class="line">是小表，就加入到内存，即对小表使用Mapjoin)</span><br><span class="line"></span><br><span class="line">相关配置参数</span><br><span class="line">　　hive.mapjoin.smalltable.filesize;(默认<span class="number">25</span>M,大表小表判断的阈值，如果表的大小小于该值则会被加载到内存中运行。)</span><br><span class="line">　　hive.ignore,mapjoin.hint;(默认值：<span class="literal">true</span>;是否忽略mapjoin hint的标记)</span><br><span class="line">　　hive.auto.convert.join.noconditionaltask;(默认值：<span class="literal">true</span>；将普通的<span class="keyword">join</span>转换为mapjoin时，是否将多个mapjoin转化为一个mapjoin)</span><br><span class="line">　　hive.auto.convert.join.noconditionaltask.size;(将多个mapjoin转化为一个mapjoin时，这个表的最大值)</span><br><span class="line"><span class="number">3</span>、尽可能使用相同的连接键，如果不同，多一个<span class="keyword">join</span>就会多开启一个mapreduce，执行速度变得慢。</span><br><span class="line"><span class="number">4</span>、大表<span class="keyword">join</span>大表（当两个都是大表的时候，只能发生reduce了，但是这里有两个优化策略）（面试的时候说，加分）</span><br><span class="line">　　a: 空key过滤:</span><br><span class="line">　　　　有时<span class="keyword">join</span>超时是因为某些key对应的数据太多,而相同key对应的数据都会发送到相同的 reducer上,从而导致内存不够。</span><br><span class="line">　　　　此时我们应该仔细分析这些异常的key,很多情况下,这些key对应的数据是异常数据,我们需要在<span class="keyword">SQL</span>语句中进行过滤。</span><br><span class="line">　　　　但是这个的前提条件是异常数据，但是我们一般拿到的数据都是经过ETL数据清洗过后的，一般影响不大，面试的时候可以说。</span><br><span class="line">　　b: 空key转换:</span><br><span class="line">　　　　有时虽然某个key为空对应的数据很多,但是相应的数据不是异常数据,必须要包含在<span class="keyword">join</span>的结果中,</span><br><span class="line">　　　　此时我们可以表a中key为空的字段赋随机的值,使得数据随机均匀地分不到不同的 reducer上。</span><br><span class="line">　　　　但是我们一般拿到的数据都是经过ETL数据清洗过后的，规则数据，一般影响不大，面试的时候可以说。</span><br><span class="line"><span class="number">5</span>、Map<span class="operator">-</span>Side聚合</span><br><span class="line">通过设置以下参数开启在Map端的聚合</span><br><span class="line"><span class="keyword">set</span> hive.map.aggr<span class="operator">=</span><span class="literal">true</span>;（一定要进行开启，虽然进行了两个mapreduce，但是当数据倾斜发生的时候，很多时候会根本跑不出结果，卡死在<span class="number">99</span><span class="operator">%</span>或者<span class="number">100</span><span class="operator">%</span>，慢总比出不来结果要好）！！！！！！！</span><br><span class="line">相关配置参数</span><br><span class="line">　　hive. groupby mapaggr. checkinterval;</span><br><span class="line">　　map端 igroup <span class="keyword">by</span>执行聚合时处理的多少行数据(默认:<span class="number">10000</span></span><br><span class="line">　　hive.map.aggr.hash.min.reduction;比例(若聚合之后的数据<span class="number">100</span>大该<span class="number">0.5</span>,map端聚合使用的内存的最大值</span><br><span class="line">　　hive.mapaggr.hashforce.flush.memory.threshold;map端做聚合操作是has表的最大可用内容,大于该值则会触发fush</span><br><span class="line">　　hive.groupby.skewindata<span class="operator">-</span>是否对 GroupBy产生的数据倾斜做优化,默认为<span class="literal">false</span>(十分重要！！！)</span><br><span class="line"><span class="number">6</span>、数据倾斜，尽可能地让我们的数据散列到不同的reduce里面去,负载均衡</span><br></pre></td></tr></table></figure><h2 id="1-7-合并小文件"><a href="#1-7-合并小文件" class="headerlink" title="1.7    合并小文件"></a>1.7    <strong>合并小文件</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Hive优化</span><br><span class="line">合并小文件</span><br><span class="line">文件数目小,容易在文件存储端造成压力,给hdfs造成压力,影响效率</span><br><span class="line">设置合并属性</span><br><span class="line">　　是否合并map输出文件: hive.merge.mapfiles<span class="operator">=</span><span class="literal">true</span></span><br><span class="line">　　是否合并reduce输出文件: hive.merge.mapredfiles<span class="operator">=</span><span class="literal">true</span></span><br><span class="line">　　合并文件的大小: hive.merge.size.per.task<span class="operator">=</span><span class="number">256</span><span class="operator">*</span><span class="number">1000</span><span class="operator">*</span><span class="number">1000</span></span><br><span class="line">去重统计</span><br><span class="line">数据量小的时候无所谓,数据量大的情况下,由于 COUNT <span class="keyword">DISTINCT</span>操作需要用一个 Reduce Task来完成,</span><br><span class="line">这一个 Reduce需要处理的数据量太大,就会导致整个JOb很难完成,一般 COUNT <span class="keyword">DISTINCT</span>使用先 <span class="keyword">GROUP</span> <span class="keyword">BY</span>再COUNT的方式替换</span><br></pre></td></tr></table></figure><h2 id="1-8-控制map和reduce的数量-一般情况下我们不去动它"><a href="#1-8-控制map和reduce的数量-一般情况下我们不去动它" class="headerlink" title="1.8    控制map和reduce的数量(一般情况下我们不去动它)"></a>1.8    <strong>控制map和reduce的数量(一般情况下我们不去动它)</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">控制Hive中Map以及 Reduce的数量</span><br><span class="line">Map数量相关的参数</span><br><span class="line">mapred.max.split.size;一个split的最大值,即每个map处理文件的最大值</span><br><span class="line">mapred.min.split.size.per.node个节点上split的最小值</span><br><span class="line">mapred.min.split.size.per.rack一个机架上spit的最小值</span><br><span class="line">Reduce数量相关的参数</span><br><span class="line">mapred.reduce.tasks;强制指定reduce任务的数量</span><br><span class="line">hive.exec.reducers.bytes.per.reducer每个reduce任务处理的数据量</span><br><span class="line">hive.exec.reducers.max每个任务最大的reduce数</span><br></pre></td></tr></table></figure><h2 id="1-9-JVM重用"><a href="#1-9-JVM重用" class="headerlink" title="1.9    JVM重用"></a>1.9    <strong>JVM重用</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">当我们的小文件个数过多，task个数过多，需要申请的资源过多的时候，我们可以先申请一部分资源，全部执行完毕后再释放，</span><br><span class="line">比我们申请一个释放一个要快。</span><br><span class="line">通过 <span class="keyword">set</span> mapred.job.reuse.jvm.num.tasks<span class="operator">=</span>n;来设置</span><br><span class="line">（n为task插槽个数）</span><br><span class="line">缺点：</span><br><span class="line">设置开启后，task插槽会一直占用资源，无论是否有task进行，直到所有的task,</span><br><span class="line">即整个job全部执行完毕后，才会释放所有的task插槽，所以我们要合理地设置这个n</span><br><span class="line">(比如，我们设置申请了<span class="number">10</span>个，但是现在来了<span class="number">6</span>个，剩下<span class="number">4</span>个插槽会在job全部执行完毕之前一直占用资源)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>连续登陆问题</title>
      <link href="/2022/06/07/%E8%BF%9E%E7%BB%AD%E7%99%BB%E5%BD%95%E9%97%AE%E9%A2%98/"/>
      <url>/2022/06/07/%E8%BF%9E%E7%BB%AD%E7%99%BB%E5%BD%95%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h4 id="连续登陆问题"><a href="#连续登陆问题" class="headerlink" title="连续登陆问题"></a>连续登陆问题</h4><blockquote><p>在电商、物流和银行可能经常会遇到这样的需求：统计用户连续交易的总额、连续登陆天数、连续登陆开始和结束时间、间隔天数等</p></blockquote><h5 id="数据："><a href="#数据：" class="headerlink" title="数据："></a>数据：</h5><blockquote><p>注意：每个用户每天可能会有多条记录</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">iddatestr  amount</span><br><span class="line">1,2019-02-08,6214.23 </span><br><span class="line">1,2019-02-08,6247.32 </span><br><span class="line">1,2019-02-09,85.63 </span><br><span class="line">1,2019-02-09,967.36 </span><br><span class="line">1,2019-02-10,85.69 </span><br><span class="line">1,2019-02-12,769.85 </span><br><span class="line">1,2019-02-13,943.86 </span><br><span class="line">1,2019-02-14,538.42</span><br><span class="line">1,2019-02-15,369.76</span><br><span class="line">1,2019-02-16,369.76</span><br><span class="line">1,2019-02-18,795.15</span><br><span class="line">1,2019-02-19,715.65</span><br><span class="line">1,2019-02-21,537.71</span><br><span class="line">2,2019-02-08,6214.23 </span><br><span class="line">2,2019-02-08,6247.32 </span><br><span class="line">2,2019-02-09,85.63 </span><br><span class="line">2,2019-02-09,967.36 </span><br><span class="line">2,2019-02-10,85.69 </span><br><span class="line">2,2019-02-12,769.85 </span><br><span class="line">2,2019-02-13,943.86 </span><br><span class="line">2,2019-02-14,943.18</span><br><span class="line">2,2019-02-15,369.76</span><br><span class="line">2,2019-02-18,795.15</span><br><span class="line">2,2019-02-19,715.65</span><br><span class="line">2,2019-02-21,537.71</span><br><span class="line">3,2019-02-08,6214.23 </span><br><span class="line">3,2019-02-08,6247.32 </span><br><span class="line">3,2019-02-09,85.63 </span><br><span class="line">3,2019-02-09,967.36 </span><br><span class="line">3,2019-02-10,85.69 </span><br><span class="line">3,2019-02-12,769.85 </span><br><span class="line">3,2019-02-13,943.86 </span><br><span class="line">3,2019-02-14,276.81</span><br><span class="line">3,2019-02-15,369.76</span><br><span class="line">3,2019-02-16,369.76</span><br><span class="line">3,2019-02-18,795.15</span><br><span class="line">3,2019-02-19,715.65</span><br><span class="line">3,2019-02-21,537.71</span><br></pre></td></tr></table></figure><h5 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> deal_tb(</span><br><span class="line">    id string</span><br><span class="line">    ,datestr string</span><br><span class="line">    ,amount string</span><br><span class="line">)<span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure><h5 id="计算逻辑"><a href="#计算逻辑" class="headerlink" title="计算逻辑"></a>计算逻辑</h5><ul><li>先按用户和日期分组求和，使每个用户每天只有一条数据</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id,datestr,<span class="built_in">sum</span>(amount) <span class="keyword">as</span> sum_amount <span class="keyword">from</span> deal_tb <span class="keyword">group</span> <span class="keyword">by</span> id,datestr;</span><br></pre></td></tr></table></figure><ul><li>根据用户ID分组按日期排序，将日期和分组序号相减得到连续登陆的开始日期，如果开始日期相同说明连续登陆</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> tt1.id,tt1.datestr,tt1.sum_amount,date_sub(tt1.datestr,tt1.rn) <span class="keyword">as</span> grp <span class="keyword">from</span> (<span class="keyword">select</span> t1.id <span class="keyword">as</span> id,t1.datestr <span class="keyword">as</span> datestr,t1.sum_amount <span class="keyword">as</span> sum_amount,<span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> t1.id <span class="keyword">order</span> <span class="keyword">by</span> t1.datestr) <span class="keyword">as</span> rn <span class="keyword">from</span> (<span class="keyword">select</span> id,datestr,<span class="built_in">sum</span>(amount) <span class="keyword">as</span> sum_amount <span class="keyword">from</span> deal_tb <span class="keyword">group</span> <span class="keyword">by</span> id,datestr) t1) tt1;</span><br></pre></td></tr></table></figure><ul><li><em>datediff(string end_date,string start_date);</em> 等于0说明连续登录</li><li>统计用户连续交易的总额、连续登陆天数、连续登陆开始和结束时间、间隔天数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> ttt1.id,ttt1.grp,round(<span class="built_in">sum</span>(ttt1.sum_amount),<span class="number">2</span>) <span class="keyword">as</span> user_sum_amount,<span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> user_days,<span class="built_in">min</span>(ttt1.datestr) <span class="keyword">as</span> user_start_date,<span class="built_in">max</span>(ttt1.datestr) <span class="keyword">as</span> user_end_date,datediff(ttt1.grp,<span class="built_in">lag</span>(ttt1.grp,<span class="number">1</span>) <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> ttt1.id <span class="keyword">order</span> <span class="keyword">by</span> ttt1.grp)) <span class="keyword">as</span> interval_days <span class="keyword">from</span> (<span class="keyword">select</span> tt1.id <span class="keyword">as</span> id,tt1.datestr <span class="keyword">as</span> datestr,tt1.sum_amount <span class="keyword">as</span> sum_amount,date_sub(tt1.datestr,tt1.rn) <span class="keyword">as</span> grp <span class="keyword">from</span> (<span class="keyword">select</span> t1.id <span class="keyword">as</span> id,t1.datestr <span class="keyword">as</span> datestr,t1.sum_amount <span class="keyword">as</span> sum_amount,<span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> t1.id <span class="keyword">order</span> <span class="keyword">by</span> t1.datestr) <span class="keyword">as</span> rn <span class="keyword">from</span> (<span class="keyword">select</span> id,datestr,<span class="built_in">sum</span>(amount) <span class="keyword">as</span> sum_amount <span class="keyword">from</span> deal_tb <span class="keyword">group</span> <span class="keyword">by</span> id,datestr) t1) tt1) ttt1 <span class="keyword">group</span> <span class="keyword">by</span> ttt1.id,ttt1.grp;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ttt1.id, ttt1.grp</span><br><span class="line">, round(<span class="built_in">sum</span>(ttt1.sum_amount), <span class="number">2</span>) <span class="keyword">AS</span> user_sum_amount</span><br><span class="line">, <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">AS</span> user_days, <span class="built_in">min</span>(ttt1.datestr) <span class="keyword">AS</span> user_start_date</span><br><span class="line">, <span class="built_in">max</span>(ttt1.datestr) <span class="keyword">AS</span> user_end_date</span><br><span class="line">, datediff(ttt1.grp, <span class="built_in">lag</span>(ttt1.grp, <span class="number">1</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> ttt1.id <span class="keyword">ORDER</span> <span class="keyword">BY</span> ttt1.grp)) <span class="keyword">AS</span> interval_days</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line"><span class="keyword">SELECT</span> tt1.id <span class="keyword">AS</span> id, tt1.datestr <span class="keyword">AS</span> datestr, tt1.sum_amount <span class="keyword">AS</span> sum_amount</span><br><span class="line">, date_sub(tt1.datestr, tt1.rn) <span class="keyword">AS</span> grp</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line"><span class="keyword">SELECT</span> t1.id <span class="keyword">AS</span> id, t1.datestr <span class="keyword">AS</span> datestr, t1.sum_amount <span class="keyword">AS</span> sum_amount, <span class="built_in">row_number</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> t1.id <span class="keyword">ORDER</span> <span class="keyword">BY</span> t1.datestr) <span class="keyword">AS</span> rn</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line"><span class="keyword">SELECT</span> id, datestr, <span class="built_in">sum</span>(amount) <span class="keyword">AS</span> sum_amount</span><br><span class="line"><span class="keyword">FROM</span> deal_tb</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> id, datestr</span><br><span class="line">) t1</span><br><span class="line">) tt1</span><br><span class="line">) ttt1</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> ttt1.id, ttt1.grp;</span><br></pre></td></tr></table></figure><ul><li>结果</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">12019-02-0713600.2332019-02-082019-02-10 NULL</span><br><span class="line">12019-02-082991.65052019-02-122019-02-161</span><br><span class="line">12019-02-091510.822019-02-182019-02-191</span><br><span class="line">12019-02-10537.7112019-02-212019-02-211</span><br><span class="line">22019-02-0713600.2332019-02-082019-02-10 NULL</span><br><span class="line">22019-02-083026.64942019-02-122019-02-151</span><br><span class="line">22019-02-101510.822019-02-182019-02-192</span><br><span class="line">22019-02-11537.7112019-02-212019-02-211</span><br><span class="line">32019-02-0713600.2332019-02-082019-02-10 NULL</span><br><span class="line">32019-02-082730.0452019-02-122019-02-161</span><br><span class="line">32019-02-091510.822019-02-182019-02-191</span><br><span class="line">32019-02-10537.7112019-02-212019-02-211</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive的基本操作-2</title>
      <link href="/2022/06/02/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-2/"/>
      <url>/2022/06/02/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-2/</url>
      
        <content type="html"><![CDATA[<h2 id="1、Hive分区"><a href="#1、Hive分区" class="headerlink" title="1、Hive分区"></a>1、Hive分区</h2><blockquote><p>在大数据中，最常见的一种思想就是<strong>分治</strong>，我们可以<strong>把大的文件切割划分成一个个的小的文件</strong>，这样每次操作一个个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，就是我们可以把大的数据，按照每天或者每小时切分成一个个小的文件，这样去操作小的文件就会容易很多了。</p><p>假如现在我们公司一天产生3亿的数据量，那么为了方便管理和查询，就做以下的事情。</p><p>​        1）建立分区（可按照日期，部门等等具体业务分区）</p><p>​        2）分门别类的管理</p></blockquote><p><img src="https://s2.loli.net/2022/06/03/QdRsgvWS7yYnN13.png" alt="hive分区的种类.png"></p><h3 id="1-2-静态分区（SP）"><a href="#1-2-静态分区（SP）" class="headerlink" title="1.2    静态分区（SP）"></a>1.2    静态分区（SP）</h3><blockquote><p>静态分区（SP）static partition–partition by (字段 类型)</p><p>​        <strong>借助于物理的文件夹分区，实现快速检索的目的。</strong></p><p>​        <strong>一般对于查询比较频繁的列设置为分区列。</strong></p><p>​        <strong>分区查询的时候直接把对应分区中所有数据放到对应的文件夹中</strong>。</p></blockquote><blockquote><p>创建单分区表语法：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_student (</span><br><span class="line">sno <span class="type">int</span>,</span><br><span class="line">sname string</span><br><span class="line">) partitioned <span class="keyword">by</span>(grade <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"><span class="comment">--  分区的字段不要和表的字段相同。相同会报错error10035</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">1</span>,xiaohu01,<span class="number">1</span></span><br><span class="line"><span class="number">2</span>,xiaohu02,<span class="number">1</span></span><br><span class="line"><span class="number">3</span>,xiaohu03,<span class="number">1</span></span><br><span class="line"><span class="number">4</span>,xiaohu04,<span class="number">1</span></span><br><span class="line"><span class="number">5</span>,xiaohu05,<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">6</span>,xiaohu06,<span class="number">2</span></span><br><span class="line"><span class="number">7</span>,xiaohu07,<span class="number">2</span></span><br><span class="line"><span class="number">8</span>,xiaohu08,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">9</span>,xiaohu09,<span class="number">3</span></span><br><span class="line"><span class="number">10</span>,xiaohu10,<span class="number">3</span></span><br><span class="line"><span class="number">11</span>,xiaohu11,<span class="number">3</span></span><br><span class="line"><span class="number">12</span>,xiaohu12,<span class="number">3</span></span><br><span class="line"><span class="number">13</span>,xiaohu13,<span class="number">3</span></span><br><span class="line"><span class="number">14</span>,xiaohu14,<span class="number">3</span></span><br><span class="line"><span class="number">15</span>,xiaohu15,<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">16</span>,xiaohu16,<span class="number">4</span></span><br><span class="line"><span class="number">17</span>,xiaohu17,<span class="number">4</span></span><br><span class="line"><span class="number">18</span>,xiaohu18,<span class="number">4</span></span><br><span class="line"><span class="number">19</span>,xiaohu19,<span class="number">4</span></span><br><span class="line"><span class="number">20</span>,xiaohu20,<span class="number">4</span></span><br><span class="line"><span class="number">21</span>,xiaohu21,<span class="number">4</span></span><br><span class="line"><span class="comment">-- 载入数据</span></span><br><span class="line"><span class="comment">-- 将相应年级一次导入</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/usr/local/soft/shujia/student1.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> t_student <span class="keyword">partition</span>(grade<span class="operator">=</span><span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 演示多拷贝一行上传，分区的列的值是分区的值，不是原来的值</span></span><br></pre></td></tr></table></figure><blockquote><p>静态多分区表语法：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_teacher (</span><br><span class="line">tno <span class="type">int</span>,</span><br><span class="line">tname string</span><br><span class="line">) partitioned <span class="keyword">by</span>(grade <span class="type">int</span>,clazz <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--注意：前后两个分区的关系为父子关系，也就是grade文件夹下面有多个clazz子文件夹。</span></span><br><span class="line"><span class="number">1</span>,xiaoge01,<span class="number">1</span>,<span class="number">1</span></span><br><span class="line"><span class="number">2</span>,xiaoge02,<span class="number">1</span>,<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">3</span>,xiaoge03,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line"><span class="number">4</span>,xiaoge04,<span class="number">1</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>,xiaoge05,<span class="number">1</span>,<span class="number">3</span></span><br><span class="line"><span class="number">6</span>,xiaoge06,<span class="number">1</span>,<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="number">7</span>,xiaoge07,<span class="number">2</span>,<span class="number">1</span></span><br><span class="line"><span class="number">8</span>,xiaoge08,<span class="number">2</span>,<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="number">9</span>,xiaoge09,<span class="number">2</span>,<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--载入数据</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/usr/local/soft/shujia/teacher11.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> t_teacher <span class="keyword">partition</span>(grade<span class="operator">=</span><span class="number">1</span>,clazz<span class="operator">=</span><span class="number">1</span>);</span><br></pre></td></tr></table></figure><blockquote><p>分区表查询</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_student <span class="keyword">where</span> grade <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 全表扫描，不推荐，效率低</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> students_pt1;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 使用<span class="keyword">where</span>条件进行分区裁剪，避免了全表扫描，效率高</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> students_pt1 <span class="keyword">where</span> grade <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 也可以在<span class="keyword">where</span>条件中使用非等值判断</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> students_pt1 <span class="keyword">where</span> grade<span class="operator">&lt;</span><span class="number">3</span> <span class="number">1</span> <span class="keyword">and</span> grade<span class="operator">&gt;=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><blockquote><p>查看分区</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> partitions t_student;</span><br></pre></td></tr></table></figure><blockquote><p>添加分区</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_student <span class="keyword">add</span> <span class="keyword">partition</span> (grade<span class="operator">=</span><span class="number">5</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_student <span class="keyword">add</span> <span class="keyword">partition</span> (grade<span class="operator">=</span><span class="number">5</span>) location <span class="string">&#x27;指定数据文件的路径&#x27;</span>;</span><br></pre></td></tr></table></figure><blockquote><p>删除分区</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_student <span class="keyword">drop</span> <span class="keyword">partition</span> (grade<span class="operator">=</span><span class="number">5</span>);</span><br></pre></td></tr></table></figure><h3 id="1-3-动态分区（DP）"><a href="#1-3-动态分区（DP）" class="headerlink" title="1.3    动态分区（DP）"></a>1.3    动态分区（DP）</h3><ul><li>动态分区（DP）dynamic partition</li><li>静态分区与动态分区的<strong>主要区别在于静态分区是手动指定，而动态分区是通过数据来进行判断。</strong></li><li>详细来说，静态分区的列是在编译时期通过用户传递来决定的；<strong>动态分区只有在SQL执行时才能决定</strong>。</li></ul><blockquote><p>开启动态分区首先要在hive会话中设置如下的参数</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># 表示开启动态分区</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.dynamic.partition<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"># 表示动态分区模式：strict（需要配合静态分区一起使用）、nostrict</span><br><span class="line"># strict： <span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> students_pt <span class="keyword">partition</span>(dt<span class="operator">=</span><span class="string">&#x27;anhui&#x27;</span>,pt) <span class="keyword">select</span> ......,pt <span class="keyword">from</span> students;</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.dynamic.partition.mode<span class="operator">=</span>nonstrict;</span><br><span class="line"></span><br><span class="line"># 表示支持的最大的分区数量为<span class="number">1000</span>，可以根据业务自己调整</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.max.dynamic.partitions.pernode<span class="operator">=</span><span class="number">1000</span>;</span><br></pre></td></tr></table></figure><blockquote><p>其余的参数详细配置如下</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">设置为<span class="literal">true</span>表示开启动态分区的功能（默认为<span class="literal">false</span>）</span><br><span class="line"><span class="comment">--hive.exec.dynamic.partition=true;</span></span><br><span class="line"></span><br><span class="line">设置为nonstrict，表示允许所有分区都是动态的（默认为strict）</span><br><span class="line"><span class="comment">-- hive.exec.dynamic.partition.mode=nonstrict; </span></span><br><span class="line"></span><br><span class="line">每个mapper或reducer可以创建的最大动态分区个数(默认为<span class="number">100</span>) </span><br><span class="line">比如：源数据中包含了一年的数据，即<span class="keyword">day</span>字段有<span class="number">365</span>个值，那么该参数就需要设置成大于<span class="number">365</span>，如果使用默认值<span class="number">100</span>，则会报错</span><br><span class="line"><span class="comment">--hive.exec.max.dynamic.partition.pernode=100; </span></span><br><span class="line"></span><br><span class="line">一个动态分区创建可以创建的最大动态分区个数（默认值<span class="number">1000</span>）</span><br><span class="line"><span class="comment">--hive.exec.max.dynamic.partitions=1000;</span></span><br><span class="line"></span><br><span class="line">全局可以创建的最大文件个数（默认值<span class="number">100000</span>）</span><br><span class="line"><span class="comment">--hive.exec.max.created.files=100000; </span></span><br><span class="line"></span><br><span class="line">当有空分区产生时，是否抛出异常（默认<span class="literal">false</span>） </span><br><span class="line"><span class="comment">-- hive.error.on.empty.partition=false;  </span></span><br></pre></td></tr></table></figure><ul><li>案例1： 动态插入学生年级班级信息</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--创建分区表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_student_d (</span><br><span class="line">sno <span class="type">int</span>,</span><br><span class="line">sname string</span><br><span class="line">) partitioned <span class="keyword">by</span> (grade <span class="type">int</span>,clazz <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--创建外部表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_student_e (</span><br><span class="line">sno <span class="type">int</span>,</span><br><span class="line">sname string,</span><br><span class="line">grade <span class="type">int</span>,</span><br><span class="line">clazz <span class="type">int</span></span><br><span class="line">) </span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">location &quot;/shujia/student&quot;;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">数据：</span><br><span class="line"></span><br><span class="line">1,xiaohu01,1,1</span><br><span class="line">2,xiaohu02,1,1</span><br><span class="line">3,xiaohu03,1,1</span><br><span class="line">4,xiaohu04,1,2</span><br><span class="line">5,xiaohu05,1,2</span><br><span class="line">6,xiaohu06,2,3</span><br><span class="line">7,xiaohu07,2,3</span><br><span class="line">8,xiaohu08,2,3</span><br><span class="line">9,xiaohu09,3,3</span><br><span class="line">10,xiaohu10,3,3</span><br><span class="line">11,xiaohu11,3,3</span><br><span class="line">12,xiaohu12,3,4</span><br><span class="line">13,xiaohu13,3,4</span><br><span class="line">14,xiaohu14,3,4</span><br><span class="line">15,xiaohu15,3,4</span><br><span class="line">16,xiaohu16,4,4</span><br><span class="line">17,xiaohu17,4,4</span><br><span class="line">18,xiaohu18,4,5</span><br><span class="line">19,xiaohu19,4,5</span><br><span class="line">20,xiaohu20,4,5</span><br><span class="line">21,xiaohu21,4,5</span><br></pre></td></tr></table></figure><blockquote><p>如果静态分区的话，我们插入数据必须指定分区的值。</p><p>如果想要插入多个班级的数据，我要写很多SQL并且执行24次很麻烦。</p><p>而且静态分区有可能会产生数据错误问题</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 会报错 </span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_student_d <span class="keyword">partition</span> (grade<span class="operator">=</span><span class="number">1</span>) <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_student_e <span class="keyword">where</span> grade<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure><blockquote><p>如果使用动态分区，动态分区会根据select的结果自动判断数据应该load到哪儿分区去。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> t_student_d <span class="keyword">partition</span> (grade,clazz) <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_student_e;</span><br></pre></td></tr></table></figure><blockquote><p>优点：不用手动指定了，自动会对数据进行分区</p><p>缺点：可能会出现数据倾斜</p></blockquote><h2 id="2、Hive分桶"><a href="#2、Hive分桶" class="headerlink" title="2、Hive分桶"></a>2、Hive分桶</h2><h3 id="2-1-业务场景"><a href="#2-1-业务场景" class="headerlink" title="2.1    业务场景"></a>2.1    业务场景</h3><blockquote><p>数据分桶的适用场景：<br>        分区提供了一个隔离数据和优化查询的便利方式，不过并非所有的数据都可形成合理的分区，尤其是需要确定合适大小的分区划分方式<br>        不合理的数据分区划分方式可能导致有的分区数据过多，而某些分区没有什么数据的尴尬情况<br>        分桶是将数据集分解为更容易管理的若干部分的另一种技术。<br>        分桶就是将数据按照字段进行划分，可以将数据按照字段划分到多个文件当中去。</p></blockquote><h3 id="2-2-数据分桶原理"><a href="#2-2-数据分桶原理" class="headerlink" title="2.2    数据分桶原理"></a>2.2    数据分桶原理</h3><ul><li>Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。<ul><li>bucket num &#x3D; hash_function(bucketing_column) mod num_buckets</li><li>列的值做哈希取余 决定数据应该存储到哪个桶</li></ul></li></ul><h3 id="2-3-数据分桶优势"><a href="#2-3-数据分桶优势" class="headerlink" title="2.3    数据分桶优势"></a>2.3    数据分桶优势</h3><blockquote><p><strong>方便抽样</strong></p><p>​        使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便</p><p><strong>提高join查询效率</strong></p><p>​        获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。</p></blockquote><h3 id="2-4-分桶实战"><a href="#2-4-分桶实战" class="headerlink" title="2.4    分桶实战"></a>2.4    分桶实战</h3><blockquote><p>​    首先，分区和分桶是两个不同的概念，很多资料上说需要先分区在分桶，其实不然，分区是对数据进行划分，而分桶是对文件进行划分。</p><p>​    当我们的分区之后，最后的文件还是很大怎么办，就引入了分桶的概念。</p><p>将这个比较大的文件再分成若干个小文件进行存储，我们再去查询的时候，在这个小范围的文件中查询就会快很多。</p><p>​        对于hive中的每一张表、分区都可以进一步的进行分桶。</p><p>​        当然，分桶不是说将文件随机进行切分存储，而是有规律的进行存储。在看完下面的例子后进行解释，现在干巴巴的解释也不太好理解。它是由列的哈希值除以桶的个数来决定每条数据划分在哪个桶中。</p><p>创建顺序和分区一样，创建的方式不一样。</p></blockquote><blockquote><p><strong>首先我们需要开启分桶的支持</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">（依然十分重要，不然无法进行分桶操作！！！！）</span><br><span class="line"><span class="keyword">set</span> hive.enforce.bucketing<span class="operator">=</span><span class="literal">true</span>; </span><br></pre></td></tr></table></figure><blockquote><p><strong>数据准备（id,name,age）</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1,tom,11</span><br><span class="line">2,cat,22</span><br><span class="line">3,dog,33</span><br><span class="line">4,hive,44</span><br><span class="line">5,hbase,55</span><br><span class="line">6,mr,66</span><br><span class="line">7,alice,77</span><br><span class="line">8,scala,88</span><br></pre></td></tr></table></figure><blockquote><p><strong>创建一个普通的表</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn31</span><br><span class="line">(</span><br><span class="line">id <span class="type">int</span>,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure><blockquote><p><strong>将数据load到这张表中</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;文件在Linux上的绝对路径&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> psn31;</span><br></pre></td></tr></table></figure><blockquote><p><strong>创建分桶表</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn_bucket</span><br><span class="line">(</span><br><span class="line">id <span class="type">int</span>,</span><br><span class="line">name string,</span><br><span class="line">age <span class="type">int</span></span><br><span class="line">)</span><br><span class="line">clustered <span class="keyword">by</span>(age) <span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure><blockquote><p><strong>将数据insert到表psn_bucket中</strong></p><p><strong>(注意：这里和分区表插入数据有所区别，分区表需要select 和指定分区，而分桶则不需要)</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> psn_bucket <span class="keyword">select</span> id,name,age <span class="keyword">from</span> psn31;</span><br></pre></td></tr></table></figure><blockquote><p><strong>在HDFS上查看数据</strong></p></blockquote><p><img src="https://s2.loli.net/2022/06/08/xOIdzYoEqhRLe4g.png" alt="image-20220601223434297.png"></p><blockquote><p><strong>查询数据</strong></p><p><strong>我们在linux中使用Hadoop的命令查看一下（与我们猜想的顺序一致）</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop fs -cat /user/hive/warehouse/bigdata17.db/psn_bucket/*</span><br></pre></td></tr></table></figure><blockquote><p>这里设置的桶的个数是4 数据按照 年龄%4 进行放桶(文件)<br>11%4 &#x3D;&#x3D; 3 —–&gt; 000003_0<br>22%4 &#x3D;&#x3D; 2 —–&gt; 000002_0<br>33%4 &#x3D;&#x3D; 1 —–&gt; 000001_0<br>44%4 &#x3D;&#x3D; 0 —–&gt; 000000_0<br>…以此类推</p></blockquote><p><img src="https://s2.loli.net/2022/06/08/smJGetELUTlaIuo.png" alt="分桶逻辑发逻辑.png"></p><blockquote><p>在Hive进行查询</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- tablesample是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y)</span></span><br><span class="line"><span class="comment">-- 分桶语句中的分母表示的是数据将会被散列的桶的个数，分子表示将会选择的桶的个数。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- x表示从哪个bucket开始抽取。</span></span><br><span class="line"><span class="comment">-- 例如，table总bucket数为32，tablesample(bucket 2 out of 2)</span></span><br><span class="line"><span class="comment">-- 表示总共抽取（2/2=）1个bucket的数据，分别为第2个bucket和第（2+2=）4个bucket的数据</span></span><br><span class="line"><span class="comment">-- y必须是table总bucket数的倍数或者因子。hive根据y的大小，决定抽样的比例。</span></span><br><span class="line"><span class="comment">-- 例如，table总共分了4份，当y=2时，抽取(4/2=)2个bucket的数据，当y=8时，抽取(4/8=)1/2个bucket的数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> psn_bucket <span class="keyword">tablesample</span>(bucket <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">2</span>);</span><br><span class="line">随机取值（设置因子，桶的个数<span class="operator">/</span>因子）</span><br><span class="line">这里就是取<span class="number">2</span>号桶和<span class="number">4</span>号桶，取<span class="number">2</span>个</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> psn_bucket <span class="keyword">tablesample</span>(bucket <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span>);</span><br><span class="line">随机取值（设置因子，桶的个数<span class="operator">/</span>因子）</span><br><span class="line">这里就是取<span class="number">2</span>号桶，取一个</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> psn_bucket <span class="keyword">tablesample</span>(bucket <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">8</span>);</span><br><span class="line">随机取值（设置倍数，倍数<span class="operator">/</span>桶的个数）</span><br><span class="line">这里就是取<span class="number">2</span>号桶 <span class="number">1</span><span class="operator">/</span><span class="number">2</span>个数据</span><br><span class="line">取出来是一条数据</span><br></pre></td></tr></table></figure><h2 id="3、Hive-JDBC"><a href="#3、Hive-JDBC" class="headerlink" title="3、Hive JDBC"></a>3、Hive JDBC</h2><h5 id="启动hiveserver2"><a href="#启动hiveserver2" class="headerlink" title="启动hiveserver2"></a>启动hiveserver2</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive --service hiveserver2 &amp;</span><br><span class="line">或者</span><br><span class="line">hiveserver2 &amp;</span><br></pre></td></tr></table></figure><h5 id="新建maven项目并添加两个依赖"><a href="#新建maven项目并添加两个依赖" class="headerlink" title="新建maven项目并添加两个依赖"></a>新建maven项目并添加两个依赖</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.7.6&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-jdbc --&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h5 id="编写JDBC代码"><a href="#编写JDBC代码" class="headerlink" title="编写JDBC代码"></a>编写JDBC代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HiveJDBC</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException &#123;</span><br><span class="line">        Class.forName(<span class="string">&quot;org.apache.hive.jdbc.HiveDriver&quot;</span>);</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(<span class="string">&quot;jdbc:hive2://master:10000/bigdata17&quot;</span>);</span><br><span class="line">        <span class="type">Statement</span> <span class="variable">stat</span> <span class="operator">=</span> conn.createStatement();</span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">rs</span> <span class="operator">=</span> stat.executeQuery(<span class="string">&quot;select * from students limit 10&quot;</span>);</span><br><span class="line">        <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">id</span> <span class="operator">=</span> rs.getInt(<span class="number">1</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> rs.getString(<span class="number">2</span>);</span><br><span class="line">            <span class="type">int</span> <span class="variable">age</span> <span class="operator">=</span> rs.getInt(<span class="number">3</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">gender</span> <span class="operator">=</span> rs.getString(<span class="number">4</span>);</span><br><span class="line">            <span class="type">String</span> <span class="variable">clazz</span> <span class="operator">=</span> rs.getString(<span class="number">5</span>);</span><br><span class="line">            System.out.println(id + <span class="string">&quot;,&quot;</span> + name + <span class="string">&quot;,&quot;</span> + age + <span class="string">&quot;,&quot;</span> + gender + <span class="string">&quot;,&quot;</span> + clazz);</span><br><span class="line">        &#125;</span><br><span class="line">        rs.close();</span><br><span class="line">        stat.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4、Hive查询语法-DQL"><a href="#4、Hive查询语法-DQL" class="headerlink" title="4、Hive查询语法(DQL)"></a>4、Hive查询语法(DQL)</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line"><span class="keyword">FROM</span> table_reference</span><br><span class="line">[<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">[CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line"><span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">]</span><br><span class="line">[LIMIT [<span class="keyword">offset</span>,] <span class="keyword">rows</span>]</span><br></pre></td></tr></table></figure><h3 id="4-1-全局排序"><a href="#4-1-全局排序" class="headerlink" title="4.1    全局排序"></a>4.1    全局排序</h3><ul><li><strong>order by 会对输入做全局排序，因此只有一个reducer</strong>，会导致当输入规模较大时，需要较长的计算时间</li><li>使用 order by子句排序 :ASC（ascend）升序（默认）| DESC（descend）降序</li><li><strong>order by放在select语句的结尾</strong></li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 <span class="keyword">order</span> <span class="keyword">by</span> 字段名<span class="number">1</span>[，别名<span class="number">2.</span>..];</span><br></pre></td></tr></table></figure><h3 id="4-2-局部排序"><a href="#4-2-局部排序" class="headerlink" title="4.2    局部排序"></a>4.2    局部排序</h3><ul><li><strong>sort by 不是全局排序,其在数据进入reducer前完成排序</strong>。</li><li>如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1,则sort by 只保证每个reducer的输出有序，<strong>不保证全局有序</strong>。asc,desc</li><li>设置reduce个数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduce<span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"><span class="keyword">set</span> mapred.reduce.tasks<span class="operator">=</span><span class="number">3</span>;</span><br></pre></td></tr></table></figure><ul><li>查看reduce个数</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduce;</span><br></pre></td></tr></table></figure><ul><li>排序</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 sort <span class="keyword">by</span> 字段名[,字段名...];</span><br></pre></td></tr></table></figure><h3 id="4-3-分区排序"><a href="#4-3-分区排序" class="headerlink" title="4.3    分区排序"></a>4.3    分区排序</h3><blockquote><p><strong>distribute by（字段）根据指定的字段将数据</strong>分到不同的reducer，且分发算法是hash散列。</p><p><strong>类似MR中partition,进行分区，结合sort by使用。</strong>（注意：distribute by 要在sort by之前）</p><p>对于distrbute by 进行测试，一定要多分配reduce进行处理，否则无法看到distribute by的效果。</p><p>设置reduce个数</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduce<span class="operator">=</span><span class="number">7</span>;</span><br></pre></td></tr></table></figure><ul><li>排序</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 distribute <span class="keyword">by</span> 字段名[,字段名...];</span><br></pre></td></tr></table></figure><h3 id="4-3-分区并排序"><a href="#4-3-分区并排序" class="headerlink" title="4.3    分区并排序"></a>4.3    分区并排序</h3><ul><li>cluster by（字段）除了具有Distribute by的功能外，还会对该字段进行排序</li><li>cluster by &#x3D; distribute by + sort by 只能默认升序，不能使用倒序</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 sort cluster <span class="keyword">by</span> 字段名[,字段名...];</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> 表名 distribute <span class="keyword">by</span> 字段名[,字段名...] sort <span class="keyword">by</span> 字段名[,字段名...];</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/08/ZVozuJNtE9wXm2a.png" alt="hive几种分区的区别.png"></p><h2 id="5、Hive内置函数"><a href="#5、Hive内置函数" class="headerlink" title="5、Hive内置函数"></a>5、Hive内置函数</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">https:<span class="operator">/</span><span class="operator">/</span>cwiki.apache.org<span class="operator">/</span>confluence<span class="operator">/</span>display<span class="operator">/</span>Hive<span class="operator">/</span>LanguageManual<span class="operator">+</span>UDF</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 1.查看系统自带函数</span></span><br><span class="line"><span class="keyword">show</span> functions;</span><br><span class="line"><span class="comment">-- 2.显示自带的函数的用法</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> upper;</span><br><span class="line"><span class="comment">-- 3.详细显示自带的函数的用法</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> extended upper;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/06/08/gWa3pOnDHT89EtI.png" alt="内置函数的分类.png"></p><h3 id="5-1-内置函数分类"><a href="#5-1-内置函数分类" class="headerlink" title="5.1    内置函数分类"></a>5.1    内置函数分类</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">关系操作符：包括 <span class="operator">=</span> 、 <span class="operator">&lt;&gt;</span> 、 <span class="operator">&lt;=</span> 、<span class="operator">&gt;=</span>等</span><br><span class="line"></span><br><span class="line">算数操作符：包括 <span class="operator">+</span> 、 <span class="operator">-</span> 、 <span class="operator">*</span>、／等</span><br><span class="line"></span><br><span class="line">逻辑操作符：包括<span class="keyword">AND</span> 、 <span class="operator">&amp;&amp;</span> 、 <span class="keyword">OR</span> 、 <span class="operator">||</span> 等</span><br><span class="line"></span><br><span class="line">复杂类型构造函数：包括map、struct、create_union等</span><br><span class="line"></span><br><span class="line">复杂类型操作符：包括A[n]、Map[key]、S.x</span><br><span class="line"></span><br><span class="line">数学操作符：包括<span class="built_in">ln</span>(<span class="keyword">double</span> a)、<span class="built_in">sqrt</span>(<span class="keyword">double</span> a)等</span><br><span class="line"></span><br><span class="line">集合操作符：包括size(<span class="keyword">Array</span>)、sort_array(<span class="keyword">Array</span>)等</span><br><span class="line"></span><br><span class="line">类型转换函数： <span class="type">binary</span>(string<span class="operator">|</span><span class="type">binary</span>)、<span class="built_in">cast</span>(expr <span class="keyword">as</span> )</span><br><span class="line"></span><br><span class="line">日期函数：包括from_unixtime(<span class="type">bigint</span> unixtime[, string format])、unix_timestamp()等</span><br><span class="line"></span><br><span class="line">条件函数：包括if(<span class="type">boolean</span> testCondition, T valueTrue, T valueFalseOrNull)等</span><br><span class="line"></span><br><span class="line">字符串函数：包括acat(string<span class="operator">|</span><span class="type">binary</span> A, string<span class="operator">|</span><span class="type">binary</span> B…)等</span><br><span class="line"></span><br><span class="line">其他：xpath、get_json_objectscii(string str)、con</span><br></pre></td></tr></table></figure><h3 id="5-2-UDTF-hive中特殊的一个功能（进一出多）"><a href="#5-2-UDTF-hive中特殊的一个功能（进一出多）" class="headerlink" title="5.2    UDTF hive中特殊的一个功能（进一出多）"></a>5.2    UDTF hive中特殊的一个功能（进一出多）</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- UDF 进一出一</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">-- UDAF 进多出一</span></span><br><span class="line"><span class="comment">-- collect_set()和collect_list()都是对多列转成一行，区别就是list里面可重复而set里面是去重的</span></span><br><span class="line"><span class="comment">-- concat_ws(&#x27;:&#x27;,collect_set(type))   &#x27;:&#x27; 表示你合并后用什么分隔，collect_set(stage)表示要合并表中的那一列数据</span></span><br><span class="line"><span class="keyword">select</span> 字段名,concat_ws(<span class="string">&#x27;:&#x27;</span>,collect_set(列名)) <span class="keyword">as</span> 别名 <span class="keyword">from</span> 表名 <span class="keyword">group</span> <span class="keyword">by</span> id;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- UDTF 进一出多</span></span><br><span class="line"><span class="comment">-- explode  可以将一组数组的数据变成一列表</span></span><br><span class="line"><span class="keyword">select</span>  explode(split(列名,&quot;数据的分隔符&quot;)) <span class="keyword">from</span> 表名;</span><br><span class="line"><span class="comment">-- lateral view 表生成函数，可以将explode的数据生成一个列表</span></span><br><span class="line"><span class="keyword">select</span> id,name,列名 <span class="keyword">from</span> 表<span class="number">1</span>,<span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(表<span class="number">1.</span>列名,&quot;数据的分隔符&quot;))新列名 <span class="keyword">as</span> 别列名;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_movie1(</span><br><span class="line">id <span class="type">int</span>,</span><br><span class="line">name string,</span><br><span class="line">types string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 电影数据  movie1.txt</span></span><br><span class="line"><span class="comment">-- 加载数据到数据库 load data inpath &#x27;/shujia/movie1.txt&#x27; into table t_movie1;</span></span><br><span class="line"><span class="number">1</span>,这个杀手不太冷,剧情<span class="operator">-</span>动作<span class="operator">-</span>犯罪</span><br><span class="line"><span class="number">2</span>,七武士,动作<span class="operator">-</span>冒险<span class="operator">-</span>剧情</span><br><span class="line"><span class="number">3</span>,勇敢的心,动作<span class="operator">-</span>传记<span class="operator">-</span>剧情<span class="operator">-</span>历史<span class="operator">-</span>战争</span><br><span class="line"><span class="number">4</span>,东邪西毒,剧情<span class="operator">-</span>动作<span class="operator">-</span>爱情<span class="operator">-</span>武侠<span class="operator">-</span>古装</span><br><span class="line"><span class="number">5</span>,霍比特人,动作<span class="operator">-</span>奇幻<span class="operator">-</span>冒险</span><br><span class="line"></span><br><span class="line"><span class="comment">-- explode  可以将一组数组的数据变成一列表</span></span><br><span class="line"><span class="keyword">select</span>  explode(split(types,&quot;-&quot;)) <span class="keyword">from</span> t_movie1;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- lateral view 表生成函数，可以将explode的数据生成一个列表</span></span><br><span class="line"><span class="keyword">select</span> id,name,type <span class="keyword">from</span> t_movie1 <span class="keyword">lateral</span> <span class="keyword">view</span> explode(split(types,&quot;-&quot;)) typetable <span class="keyword">as</span> type;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_movie2(</span><br><span class="line">id <span class="type">int</span>,</span><br><span class="line">name string,</span><br><span class="line">type string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 电影数据 movie2.txt</span></span><br><span class="line"><span class="comment">-- 加载数据到数据库 load data inpath &#x27;/shujia/movie2.txt&#x27; into table t_movie2;</span></span><br><span class="line"><span class="number">1</span>,这个杀手不太冷,剧情</span><br><span class="line"><span class="number">1</span>,这个杀手不太冷,动作</span><br><span class="line"><span class="number">1</span>,这个杀手不太冷,犯罪</span><br><span class="line"><span class="number">2</span>,七武士,动作</span><br><span class="line"><span class="number">2</span>,七武士,冒险</span><br><span class="line"><span class="number">2</span>,七武士,剧情</span><br><span class="line"><span class="number">3</span>,勇敢的心,动作</span><br><span class="line"><span class="number">3</span>,勇敢的心,传记</span><br><span class="line"><span class="number">3</span>,勇敢的心,剧情</span><br><span class="line"><span class="number">3</span>,勇敢的心,历史</span><br><span class="line"><span class="number">3</span>,勇敢的心,战争</span><br><span class="line"><span class="number">4</span>,东邪西毒,剧情</span><br><span class="line"><span class="number">4</span>,东邪西毒,动作</span><br><span class="line"><span class="number">4</span>,东邪西毒,爱情</span><br><span class="line"><span class="number">4</span>,东邪西毒,武侠</span><br><span class="line"><span class="number">4</span>,东邪西毒,古装</span><br><span class="line"><span class="number">5</span>,霍比特人,动作</span><br><span class="line"><span class="number">5</span>,霍比特人,奇幻</span><br><span class="line"><span class="number">5</span>,霍比特人,冒险</span><br><span class="line"></span><br><span class="line"><span class="comment">-- collect_set()和collect_list()都是对列转成行，区别就是list里面可重复而set里面是去重的</span></span><br><span class="line"><span class="comment">-- concat_ws(&#x27;:&#x27;,collect_set(type))   &#x27;:&#x27; 表示你合并后用什么分隔，collect_set(stage)表示要合并表中的那一列数据</span></span><br><span class="line"><span class="keyword">select</span> id,concat_ws(<span class="string">&#x27;:&#x27;</span>,collect_set(type)) <span class="keyword">as</span> types <span class="keyword">from</span> t_movie2 <span class="keyword">group</span> <span class="keyword">by</span> id;</span><br></pre></td></tr></table></figure><h3 id="5-3-WordCount案例"><a href="#5-3-WordCount案例" class="headerlink" title="5.3    WordCount案例"></a>5.3    WordCount案例</h3><blockquote><p>数据准备</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hello,world</span><br><span class="line">hello,bigdata</span><br><span class="line">like,life</span><br><span class="line">bigdata,good</span><br></pre></td></tr></table></figure><blockquote><p>建表</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> wc</span><br><span class="line">(</span><br><span class="line">line string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br></pre></td></tr></table></figure><blockquote><p>导入数据</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/usr/local/soft/data/wc1.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> wc;</span><br></pre></td></tr></table></figure><blockquote><p><strong>步骤1：先对一行数据进行切分</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> split(line,<span class="string">&#x27;,&#x27;</span>) <span class="keyword">from</span> wc;</span><br></pre></td></tr></table></figure><blockquote><p><strong>步骤2：将行转列</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> explode(split(line,<span class="string">&#x27;,&#x27;</span>)) <span class="keyword">from</span> wc; </span><br></pre></td></tr></table></figure><blockquote><p><strong>步骤3：将相同的进行分组统计</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> w.word,<span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> (<span class="keyword">select</span> explode(split(line,<span class="string">&#x27;,&#x27;</span>)) <span class="keyword">as</span> word <span class="keyword">from</span> wc) w <span class="keyword">group</span> <span class="keyword">by</span> w.word;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive概述及安装</title>
      <link href="/2022/05/31/Hive%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%AE%89%E8%A3%85/"/>
      <url>/2022/05/31/Hive%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Hive基本概念"><a href="#一、Hive基本概念" class="headerlink" title="一、Hive基本概念"></a>一、Hive基本概念</h2><h3 id="1-1-Hive简介"><a href="#1-1-Hive简介" class="headerlink" title="1.1    Hive简介"></a>1.1    Hive简介</h3><p>Hive本质是将SQL转换为MapReduce的任务进行运算，底层由HDFS来提供数据存储，说白了hive可以理解为一个将SQL转换为MapReduce的任务的工具，甚至更近一步说hive就是一个MapReduce客户端。</p><p><img src="https://s2.loli.net/2022/06/01/EXbKAUlr4ao5e83.png" alt="image-20220531221835408"></p><h4 id="1-1-1-为什么使用Hive"><a href="#1-1-1-为什么使用Hive" class="headerlink" title="1.1.1    为什么使用Hive?"></a>1.1.1    为什么使用Hive?</h4><blockquote><p>如果直接使用hadoop的话，人员学习成本太高，项目要求周期太短，MapReduce实现复杂查询逻辑开发难度太大。如果使用hive的话，可以操作接口采用类SQL语法，提高开发能力，免去了写MapReduce，减少开发人员学习成本，功能扩展很方便（比如：开窗函数）。</p></blockquote><h4 id="1-1-2-Hive的特点："><a href="#1-1-2-Hive的特点：" class="headerlink" title="1.1.2    Hive的特点："></a>1.1.2    Hive的特点：</h4><blockquote><p>1、可扩展性</p><p>​    Hive可以自由的扩展集群的规模，一般情况下不需要重启服务</p><p>2、延申性</p><p>​    Hive支持自定义函数，用户可以根据自己的需求来实现自己的函数</p><p>3、容错</p><p>​    即使节点出现错误，SQL仍然可以完成执行</p></blockquote><h4 id="1-1-3-Hive的优缺点："><a href="#1-1-3-Hive的优缺点：" class="headerlink" title="1.1.3    Hive的优缺点："></a>1.1.3    Hive的优缺点：</h4><blockquote><p><strong>优点：</strong></p><p>​    1、操作接口采用类sql语法，提供快速开发的能力（简单、容易上手）</p><p>​    2、避免了去写MapReduce,减少开发人员的学习成本</p><p>​    3、Hive的延迟性比较高，因此Hive常用于数据分析，适用于对实时性要求不高的场合</p><p>​    4、Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。（不断地开关JVM虚拟机）</p><p>​    5、Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p><p>​    6、集群可自由扩展并且具有良好的容错性，节点出现问题SQL仍可以完成执行</p><p><strong>缺点：</strong></p><p>​    1、Hive的HQL表达能力有限</p><p>​            （1）迭代式算法无法表达    （反复调用，mr之间独立，只有一个map一个reduce，反复开关）                </p><p>​            （2）数据挖掘方面不擅长</p><p>​    2、Hive 的效率比较低</p><p>​                （1）Hive 自动生成的 MapReduce 作业，通常情况下不够智能化</p><p>​                （2）Hive 调优比较困难，粒度较粗   （hql根据模板转成mapreduce，不能像自己编写mapreduce一样精细，无法控制在map处理数据还是在reduce处理数据）</p></blockquote><h4 id="1-1-4-Hive和传统数据库对比"><a href="#1-1-4-Hive和传统数据库对比" class="headerlink" title="1.1.4    Hive和传统数据库对比"></a>1.1.4    Hive和传统数据库对比</h4><p><img src="https://s2.loli.net/2022/06/01/JlRsONUB1oQMrxy.png" alt="image-20220531213145918"></p><h4 id="1-1-5-Hive应用场景"><a href="#1-1-5-Hive应用场景" class="headerlink" title="1.1.5    Hive应用场景"></a>1.1.5    Hive应用场景</h4><blockquote><p>日志分析：大部分互联网公司使用hive进行日志分析，如百度、淘宝等。</p><p>​    统计一个网站一个时间段内的<strong>pv,uv，SKU,SPU</strong></p><p>​    多维度数据分析</p><p>海量结构化数据离线分析</p><p><strong>构建数据仓库</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PV（Page View）访问量, 即页面浏览量或点击量，衡量网站用户访问的网页数量；在一定统计周期内用户每打开或刷新一个页面就记录1次，多次打开或刷新同一页面则浏览量累计。</span><br><span class="line"></span><br><span class="line">UV（Unique Visitor）独立访客，统计1天内访问某站点的用户数(以cookie为依据);访问网站的一台电脑客户端为一个访客。可以理解成访问某网站的电脑的数量。网站判断来访电脑的身份是通过来访电脑的cookies实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的。如果用户不保存cookies访问、清除了cookies或者更换设备访问，计数会加1。00:00-24:00内相同的客户端多次访问只计为1个访客。</span><br></pre></td></tr></table></figure><h3 id="1-2-Hive架构"><a href="#1-2-Hive架构" class="headerlink" title="1.2    Hive架构"></a>1.2    Hive架构</h3><p><img src="https://s2.loli.net/2022/06/01/vRqfEbaU8TzhVQs.png" alt="image-20220531214038409"></p><h4 id="1-2-1-Client"><a href="#1-2-1-Client" class="headerlink" title="1.2.1    Client"></a>1.2.1    Client</h4><blockquote><p>Hive允许client连接的方式有三个CLI（hive shell）、JDBC&#x2F;ODBC(java访问hive)、WEBUI（浏览器访问 hive）。JDBC访问时中间件Thrift软件框架，跨语言服务开发。DDL DQL DML,整体仿写一套SQL语句。</p><p>​        1）client–需要下载安装包</p><p>​        2）JDBC&#x2F;ODBC 也可以连接到Hive<br>​                现在主流都在倡导第二种 HiveServer2&#x2F;beeline<br>​                做基于用户名和密码安全的一个校验</p><p>​        3）Web Gui<br>​                hive给我们提供了一套简单的web页面<br>​                我们可以通过这套web页面访问hive 做的太简陋了</p></blockquote><h4 id="1-2-2-Metastore"><a href="#1-2-2-Metastore" class="headerlink" title="1.2.2    Metastore"></a>1.2.2    Metastore</h4><blockquote><p><strong>元数据</strong>包括表名、表所属的数据库（默认是default）、表的拥有者、列&#x2F;分区字段、表的类型（是否是 外部表）、表的数据所在目录等。</p><p>​        一般需要借助于其他的数据载体（数据库）</p><p>​        主要用于存放数据库的建表语句等信息</p><p>​        推荐使用Mysql数据库存放数据</p><p>​        连接数据库需要提供：uri username password driver</p></blockquote><h4 id="1-2-3-Driver"><a href="#1-2-3-Driver" class="headerlink" title="1.2.3    Driver"></a>1.2.3    Driver</h4><blockquote><p>元数据存储在数据库中，默认存在自带的derby数据库（单用户局限性）中，推荐使用Mysql进行存储。</p><p>​            1） 解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完 成，比如ANTLR；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p><p>​            2） 编译器（Physical Plan）：将AST编译生成逻辑执行计划。</p><p>​            3） 优化器（Query Optimizer）：对逻辑执行计划进行优化。</p><p>​            4） 执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是 MR&#x2F;Spark。</p></blockquote><p><img src="https://s2.loli.net/2022/06/01/Ubx7kIWChHfcLmv.png" alt="image-20220531000823975.png"></p><h4 id="1-2-4-数据处理"><a href="#1-2-4-数据处理" class="headerlink" title="1.2.4    数据处理"></a>1.2.4    数据处理</h4><blockquote><p>Hive的数据存储在HDFS中，计算由MapReduce完成。HDFS和MapReduce是源码级别上的整合，两者结合最佳。解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。</p></blockquote><h3 id="二、Hive的安装和使用"><a href="#二、Hive的安装和使用" class="headerlink" title="二、Hive的安装和使用"></a>二、Hive的安装和使用</h3><h4 id="2-1-离线安装MySQL（已经安装过MySQL可以跳过此步骤）"><a href="#2-1-离线安装MySQL（已经安装过MySQL可以跳过此步骤）" class="headerlink" title="2.1    离线安装MySQL（已经安装过MySQL可以跳过此步骤）"></a>2.1    离线安装MySQL（已经安装过MySQL可以跳过此步骤）</h4><p>注：</p><p>如果在&#x2F;usr&#x2F;bin&#x2F;mysql_secure_installation 一直是下面报错后</p><p><strong>解决办法：</strong></p><p>ps aux | grep mysql<br> 然后KILLmysql相关全部进程 Pid是进程号<br> kill -9 pid1 pid2 …</p><p>比如 kill -9 8301 8302<br> 然后再从第4步重新操作。</p><h4 id="2-2-修改MySQL编码"><a href="#2-2-修改MySQL编码" class="headerlink" title="2.2    修改MySQL编码"></a>2.2    修改MySQL编码</h4><p>1、修改mysql编码为UTF-8</p><p>1.1 编辑配置文件</p><pre><code>vim /etc/my.cnf</code></pre><p>1.2 加入以下内容：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[client]</span><br><span class="line"></span><br><span class="line">default-character-set = utf8mb4</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line"></span><br><span class="line">character-set-server = utf8mb4</span><br><span class="line"></span><br><span class="line">collation-server = utf8mb4_general_ci</span><br></pre></td></tr></table></figure><p>1.3 重启mysql</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemctl restart mysqld</span><br></pre></td></tr></table></figure><p>1.4 登录mysql</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p123456</span><br></pre></td></tr></table></figure><p>1.5 查看mysql当前字符集</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">show variables like <span class="string">&#x27;%char%&#x27;</span>;</span><br></pre></td></tr></table></figure><p>1.6 修改mysql元数据库hive，让其hive支持utf-8编码以支持中文</p><p>登录mysql：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -u root -p123456</span><br></pre></td></tr></table></figure><p>切换到hive数据库:</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use hive;</span><br></pre></td></tr></table></figure><p>1).修改字段注释字符集</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> COLUMNS_V2 modify <span class="keyword">column</span> COMMENT <span class="type">varchar</span>(<span class="number">256</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure><p>2).修改表注释字符集</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> TABLE_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure><p>3).修改分区表参数，以支持分区键能够用中文表示</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> PARTITION_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> PARTITION_KEYS modify <span class="keyword">column</span> PKEY_COMMENT <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure><p>4).修改索引注解(可选)</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> INDEX_PARAMS modify <span class="keyword">column</span> PARAM_VALUE <span class="type">varchar</span>(<span class="number">4000</span>) <span class="type">character</span> <span class="keyword">set</span> utf8;</span><br></pre></td></tr></table></figure><h4 id="2-3-安装Hive"><a href="#2-3-安装Hive" class="headerlink" title="2.3    安装Hive"></a>2.3    安装Hive</h4><p>前提是：mysql和hadoop必须已经成功启动了</p><h5 id="1、解压hive的安装包："><a href="#1、解压hive的安装包：" class="headerlink" title="1、解压hive的安装包："></a>1、解压hive的安装包：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-hive-1.2.1-bin.tar.gz </span><br><span class="line"></span><br><span class="line">修改目录名称：</span><br><span class="line"><span class="built_in">mv</span> apache-hive-1.2.1-bin hive-1.2.1</span><br></pre></td></tr></table></figure><h5 id="2、进入hive-1-2-1-x2F-conf目录，复制备份文件并重命名"><a href="#2、进入hive-1-2-1-x2F-conf目录，复制备份文件并重命名" class="headerlink" title="2、进入hive-1.2.1&#x2F;conf目录，复制备份文件并重命名"></a>2、进入hive-1.2.1&#x2F;conf目录，复制备份文件并重命名</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> hive-env.sh.template hive-env.sh</span><br><span class="line"><span class="built_in">cp</span> hive-default.xml.template hive-site.xml</span><br></pre></td></tr></table></figure><h5 id="3、配置hive的配置文件"><a href="#3、配置hive的配置文件" class="headerlink" title="3、配置hive的配置文件"></a>3、配置hive的配置文件</h5><p>可以在 vim非编辑模式输入**&#x2F;想要查找的具体配置**，这样可以定位并以高亮形式标出</p><h6 id="3-1、修改hive-env-sh"><a href="#3-1、修改hive-env-sh" class="headerlink" title="3.1、修改hive-env.sh"></a>3.1、修改hive-env.sh</h6><p>加入三行内容（根据自己的目录和实际情况来添加）</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">HADOOP_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line">JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br><span class="line">HIVE_HOME=/usr/local/soft/hive-1.2.1</span><br></pre></td></tr></table></figure><h6 id="3-2、修改hive-site-xml"><a href="#3-2、修改hive-site-xml" class="headerlink" title="3.2、修改hive-site.xml"></a>3.2、修改hive-site.xml</h6><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">&lt;！--数据存储位置就是我们在HDFS上看的目录--&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">(注意：修改自己安装mysql的主机地址）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://192.168.40.110:3306/hive?createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>useUnicode=true<span class="symbol">&amp;amp;</span>characterEncoding=utf8<span class="symbol">&amp;amp;</span>useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">(固定写法，mysql驱动类的位置)</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">（mysql的用户名）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">（mysql的用户密码）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">（你的hive安装目录的tmp目录）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hive-1.2.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">（同上）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hive-1.2.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">（同上）</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hive-1.2.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--指定这个的时候，为了启动metastore服务的时候不用指定端口--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--hive --service metastore -p 9083 &amp; | hive --service metastore--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>thrift://master:9083<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>修改hadoop中<strong>core-site.xml</strong>直接改，改完重启就行，为后面beeline连接做准备</p><p><strong>注意：三个节点上的都要改。</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--该参数表示可以通过httpfs接口hdfs的ip地址限制--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--通过httpfs接口访问的用户获得的群组身份--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="4、拷贝mysql驱动到-HIVE-HOME-x2F-lib目录下"><a href="#4、拷贝mysql驱动到-HIVE-HOME-x2F-lib目录下" class="headerlink" title="4、拷贝mysql驱动到$HIVE_HOME&#x2F;lib目录下"></a>4、拷贝mysql驱动到$HIVE_HOME&#x2F;lib目录下</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> /usr/local/soft/mysql-connector-java-5.1.49.jar ../lib/</span><br></pre></td></tr></table></figure><h5 id="5、将hive的jline-2-12-jar拷贝到hadoop对应目录下，hive的-jline-2-12-jar-位置在-："><a href="#5、将hive的jline-2-12-jar拷贝到hadoop对应目录下，hive的-jline-2-12-jar-位置在-：" class="headerlink" title="5、将hive的jline-2.12.jar拷贝到hadoop对应目录下，hive的 jline-2.12.jar 位置在 ："></a>5、将hive的jline-2.12.jar拷贝到hadoop对应目录下，hive的 jline-2.12.jar 位置在 ：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/local/soft/hive-1.2.1/lib/jline-2.12.jar</span><br></pre></td></tr></table></figure><h5 id="6、将hive的jar拷过去hadoop下："><a href="#6、将hive的jar拷过去hadoop下：" class="headerlink" title="6、将hive的jar拷过去hadoop下："></a>6、将hive的jar拷过去hadoop下：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> /usr/local/soft/hive-1.2.1/lib/jline-2.12.jar /usr/local/soft/hadoop-2.7.6/share/hadoop/yarn/lib/</span><br></pre></td></tr></table></figure><h5 id="7、配置环境变量"><a href="#7、配置环境变量" class="headerlink" title="7、配置环境变量"></a>7、配置环境变量</h5><p> vim &#x2F;etc&#x2F;profile</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">HIVE_HOME=/usr/local/soft/hive-1.2.1</span><br><span class="line"><span class="built_in">export</span> PATH=.:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line"></span><br><span class="line">重新加载环境变量</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h5 id="8、分发Hive"><a href="#8、分发Hive" class="headerlink" title="8、分发Hive"></a>8、分发Hive</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">拷贝到其他两个节点中去，因为可能我们会在其他的节点上当作客户端访问hive，注意，也需要配置环境变量，增加驱动jar包，将hadoop的jline-0.9.94.jar的jar替换成hive的版本</span><br></pre></td></tr></table></figure><h5 id="9、启动hive："><a href="#9、启动hive：" class="headerlink" title="9、启动hive："></a>9、启动hive：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动hadoop</span><br><span class="line"></span><br><span class="line">start-all.sh</span><br><span class="line"></span><br><span class="line">启动hive</span><br><span class="line"></span><br><span class="line">​hive --service metastore</span><br><span class="line"></span><br><span class="line">​<span class="built_in">nohup</span> hive --service metastore &gt;/dev/null &amp;</span><br><span class="line"></span><br><span class="line">​hive</span><br><span class="line"></span><br><span class="line">启动HiveServer2</span><br><span class="line"></span><br><span class="line">​hiveserver2</span><br><span class="line"></span><br><span class="line">​<span class="built_in">nohup</span> hiveserver2 &gt;/dev/null &amp;</span><br><span class="line"></span><br><span class="line">​beeline -u jdbc:hive2://master:10000 -n root</span><br></pre></td></tr></table></figure><h6 id="9-1Hive的三种交互方式"><a href="#9-1Hive的三种交互方式" class="headerlink" title="9.1Hive的三种交互方式"></a>9.1Hive的三种交互方式</h6><h6 id="1）第一种交互方式"><a href="#1）第一种交互方式" class="headerlink" title="1）第一种交互方式"></a><strong>1）第一种交互方式</strong></h6><blockquote><p>shell交互Hive，用命令hive启动一个hive的shell命令行，在命令行中输入sql或者命令来和Hive交互。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">服务端启动metastore服务（后台启动）：nohup hive --service metastore &gt; /usr/local/soft/mylogs 2&gt;&amp;1 &amp;</span><br><span class="line">进入命令:hive</span><br><span class="line">退出命令行：quit;</span><br></pre></td></tr></table></figure><h6 id="2）第二种交互方式"><a href="#2）第二种交互方式" class="headerlink" title="2）第二种交互方式"></a><strong>2）第二种交互方式</strong></h6><blockquote><p><strong>Hive启动为一个服务器，对外提供服务</strong>，其他机器可以通过客户端通过协议连接到服务器，来完成访问操作，这是生产环境用法最多的</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">服务端启动hiveserver2服务：</span><br><span class="line">nohup hive --service metastore &gt;/dev/null &amp;</span><br><span class="line">nohup hiveserver2 &gt;/dev/null &amp;</span><br><span class="line"></span><br><span class="line">需要稍等一下，启动服务需要时间：</span><br><span class="line">进入命令:1)先执行： beeline ，再执行： !connect jdbc:hive2://master:10000 </span><br><span class="line">        2)或者直接执行：  beeline -u jdbc:hive2://master:10000 -n root</span><br><span class="line">退出命令行：！exit</span><br></pre></td></tr></table></figure><h6 id="3）第三种交互方式"><a href="#3）第三种交互方式" class="headerlink" title="3）第三种交互方式"></a><strong>3）第三种交互方式</strong></h6><blockquote><p>使用 –e 参数来直接执行hql的语句</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/hive -e &quot;show databases;&quot;</span><br></pre></td></tr></table></figure><blockquote><p>使用 –f 参数通过指定文本文件来执行hql的语句</p><p>特点：执行完sql后，回到linux命令行。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim hive.sql</span><br><span class="line"></span><br><span class="line">use myhive;</span><br><span class="line">select * from test;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive -f hive.sql</span><br></pre></td></tr></table></figure><h6 id="4）hive-cli和beeline-cli的区别"><a href="#4）hive-cli和beeline-cli的区别" class="headerlink" title="4）hive cli和beeline cli的区别"></a>4）hive cli和beeline cli的区别</h6><p><img src="https://s2.loli.net/2022/06/01/CaqXyTQ47VhWeZ3.png" alt="image-20220531230402802.png"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive的基本操作</title>
      <link href="/2022/05/31/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-1/"/>
      <url>/2022/05/31/Hive%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-1/</url>
      
        <content type="html"><![CDATA[<h3 id="1、Hive元数据"><a href="#1、Hive元数据" class="headerlink" title="1、Hive元数据"></a>1、Hive元数据</h3><p><strong>Hive元数据库中一些重要的表结构及用途</strong>，方便Impala、SparkSQL、Hive等组件访问元数据库的理解。</p><p>1、存储Hive版本的**元数据表(VERSION)**，该表比较简单，但很重要,如果这个表出现问题，根本进不来Hive-Cli。比如该表不存在，当启动Hive-Cli的时候，就会报错“Table ‘hive.version’ doesn’t exist”</p><p>2、Hive数据库相关的元数据表(DBS、DATABASE_PARAMS)</p><p>​        DBS：该表存储Hive中所有数据库的基本信息。</p><p>​        DATABASE_PARAMS：该表存储数据库的相关参数。</p><p>3、Hive表和视图相关的元数据表</p><p>​        主要有TBLS、TABLE_PARAMS、TBL_PRIVS，这三张表通过TBL_ID关联。<br>​        TBLS:该表中存储Hive表，视图，索引表的基本信息。<br>​        TABLE_PARAMS:该表存储表&#x2F;视图的属性信息。<br>​        TBL_PRIVS：该表存储表&#x2F;视图的授权信息。<br>4、Hive文件存储信息相关的元数据表</p><p>​        主要涉及SDS、SD_PARAMS、SERDES、SERDE_PARAMS，由于HDFS支持的文件格式很多，而建Hive表时候也可以指定各种文件格式，Hive在将HQL解析成MapReduce时候，需要知道去哪里，使用哪种格式去读写HDFS文件，而这些信息就保存在这几张表中。<br>​        SDS：该表保存文件存储的基本信息，如INPUT_FORMAT、OUTPUT_FORMAT、是否压缩等。TBLS表中的SD_ID与该表关联，可以获取Hive表的存储信息。<br>​        SD_PARAMS: 该表存储Hive存储的属性信息。<br>​        SERDES:该表存储序列化使用的类信息。<br>​        SERDE_PARAMS:该表存储序列化的一些属性、格式信息，比如:行、列分隔符。<br>5、Hive表字段相关的元数据表</p><p>​        主要涉及COLUMNS_V2：该表存储表对应的字段信息。</p><h3 id="2、Hive的基本操作"><a href="#2、Hive的基本操作" class="headerlink" title="2、Hive的基本操作"></a>2、Hive的基本操作</h3><h4 id="2-1-Hive库操作"><a href="#2-1-Hive库操作" class="headerlink" title="2.1    Hive库操作"></a>2.1    Hive库操作</h4><h5 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h5><blockquote><p>1）创建一个数据库，数据库在<strong>HDFS上的默认存储路径是&#x2F;hive&#x2F;warehouse&#x2F;*.db</strong>。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database testdb;</span><br></pre></td></tr></table></figure><blockquote><p>2）避免要创建的数据库已经存在错误，增加if not exists判断。<strong>（标准写法）</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> testdb; </span><br></pre></td></tr></table></figure><h5 id="创建数据库和位置"><a href="#创建数据库和位置" class="headerlink" title="创建数据库和位置"></a>创建数据库和位置</h5><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> dept location <span class="string">&#x27;/testdb.db&#x27;</span>;</span><br></pre></td></tr></table></figure><h5 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h5><blockquote><p><strong>数据库的其他元数据信息都是不可更改的</strong>，包括数据库名和数据库所在的目录位置。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> database dept <span class="keyword">set</span> dbproperties(<span class="string">&#x27;createtime&#x27;</span><span class="operator">=</span><span class="string">&#x27;20220531&#x27;</span>);</span><br></pre></td></tr></table></figure><h5 id="数据库详细信息"><a href="#数据库详细信息" class="headerlink" title="数据库详细信息"></a>数据库详细信息</h5><blockquote><p>1）显示数据库（show）</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> databases;</span><br></pre></td></tr></table></figure><blockquote><p>2）可以通过like进行过滤</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;t*&#x27;</span>;</span><br></pre></td></tr></table></figure><blockquote><p>3）查看详情（desc）</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">desc</span> database testdb;</span><br></pre></td></tr></table></figure><blockquote><p>4）切换数据库（use）</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">use testdb;</span><br></pre></td></tr></table></figure><h5 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h5><blockquote><p>1）最简写法</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> database testdb;</span><br></pre></td></tr></table></figure><blockquote><p>2）如果删除的数据库不存在，最好使用if exists判断数据库是否存在。否则会报错：FAILED: SemanticException [Error 10072]: Database does not exist: db_hive</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> testdb;</span><br></pre></td></tr></table></figure><blockquote><p>3)如果数据库不为空，使用cascade命令进行强制删除。报错信息如下FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database db_hive is not empty. One or more tables exist.)</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> database if <span class="keyword">exists</span> testdb cascade;</span><br></pre></td></tr></table></figure><h3 id="2-2-Hive数据类型"><a href="#2-2-Hive数据类型" class="headerlink" title="2.2    Hive数据类型"></a>2.2    Hive数据类型</h3><h4 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h4><table><thead><tr><th>类型</th><th>Java数据类型</th><th>描述</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>8位有符号整型。取值范围：-128~127。</td></tr><tr><td>SMALLINT</td><td>short</td><td>16位有符号整型。取值范围：-32768~32767。</td></tr><tr><td>INT</td><td>int</td><td>32位有符号整型。取值范围：-2 31 ~2 31 -1。</td></tr><tr><td><strong>BIGINT</strong></td><td>long</td><td>64位有符号整型。取值范围：-2 63 +1~2 63 -1。</td></tr><tr><td>BINARY</td><td></td><td>二进制数据类型，目前长度限制为8MB。</td></tr><tr><td>FLOAT</td><td>float</td><td>32位二进制浮点型。</td></tr><tr><td>DOUBLE</td><td>double</td><td>64位二进制浮点型。</td></tr><tr><td><strong>DECIMAL(precision,scale)</strong></td><td></td><td>10进制精确数字类型。precision：表示最多可以表示多少位的数字。取值范围：1 &lt;&#x3D; precision &lt;&#x3D; 38。scale：表示小数部分的位数。取值范围： 0 &lt;&#x3D; scale &lt;&#x3D; 38。如果不指定以上两个参数，则默认为decimal(10,0)。</td></tr><tr><td>VARCHAR(n)</td><td></td><td>变长字符类型，n为长度。取值范围：1~65535。</td></tr><tr><td>CHAR(n)</td><td></td><td>固定长度字符类型，n为长度。最大取值255。长度不足则会填充空格，但空格不参与比较。</td></tr><tr><td><strong>STRING</strong></td><td>string</td><td>字符串类型，目前长度限制为8MB。</td></tr><tr><td>DATE</td><td></td><td>日期类型，格式为<code>yyyy-mm-dd</code>。取值范围：0000-01-01~9999-12-31。</td></tr><tr><td>DATETIME</td><td></td><td>日期时间类型。取值范围：0000-01-01 00:00:00.000~9999-12-31 23.59:59.999，精确到毫秒。</td></tr><tr><td><strong>TIMESTAMP</strong></td><td></td><td>与时区无关的时间戳类型。取值范围：0000-01-01 00:00:00.000000000~9999-12-31 23.59:59.999999999，精确到纳秒。说明 对于部分时区相关的函数，例如cast(<a timestamp> as string)，要求TIMESTAMP按照与当前时区相符的方式来展现。</td></tr><tr><td><strong>BOOLEAN</strong></td><td>boolean</td><td>BOOLEAN类型。取值：True、False。</td></tr></tbody></table><h4 id="复杂的数据类型"><a href="#复杂的数据类型" class="headerlink" title="复杂的数据类型"></a>复杂的数据类型</h4><table><thead><tr><th>类型</th><th>定义方法</th><th>构造方法</th></tr></thead><tbody><tr><td>ARRAY</td><td><code>array&lt;int&gt;``array&lt;struct&lt;a:int, b:string&gt;&gt;</code></td><td><code>array(1, 2, 3)``array(array(1, 2), array(3, 4))</code></td></tr><tr><td>MAP</td><td><code>map&lt;string, string&gt;``map&lt;smallint, array&lt;string&gt;&gt;</code></td><td><code>map(“k1”, “v1”, “k2”, “v2”)``map(1S, array(‘a’, ‘b’), 2S, array(‘x’, ‘y’))</code></td></tr><tr><td>STRUCT</td><td></td><td>struct&lt;x:int, y:int&gt;<code>struct&lt;field1:bigint, field2:array&lt;int&gt;, field3:map&lt;int, int&gt;&gt;    named_struct(‘x’, 1, ‘y’, 2)</code>named_struct(‘field1’, 100L, ‘field2’, array(1, 2), ‘field3’, map(1, 100, 2, 200))</td></tr></tbody></table><blockquote><p>Hive有三种复杂数据类型ARRAY、MAP 和 STRUCT。ARRAY和MAP与Java中的Array和Map类似，而STRUCT与C语言中的Struct类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。还有一个uniontype&lt; 所有类型，所有类型… &gt; 。</p><p>​        数组：array&lt; 所有类型 &gt;；<br>​        Map &lt; 基本数据类型，所有数据类型 &gt;；<br>​        struct &lt; 名：所有类型[注释] &gt;;<br>​        uniontype&lt; 所有类型，所有类型… &gt;</p></blockquote><h3 id="2-3-Hive表操作"><a href="#2-3-Hive表操作" class="headerlink" title="2.3    Hive表操作"></a>2.3    Hive表操作</h3><blockquote><p>Hive的存储格式:</p><p>Hive没有专门的数据文件格式,常见的有以下几种:</p><p>​        <strong>TEXTFILE</strong><br>​        SEQUENCEFILE<br>​        AVRO<br>​        <strong>RCFILE</strong><br>​        <strong>ORCFILE</strong><br>​        <strong>PARQUET</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TextFile:</span><br><span class="line">       TEXTFILE 即正常的文本格式，是Hive默认文件存储格式，因为大多数情况下源数据文件都是以text文件格式保存（便于查看验数和防止乱码）。此种格式的表文件在HDFS上是明文，可用hadoop fs -cat命令查看，从HDFS上get下来后也可以直接读取。</span><br><span class="line">        TEXTFILE 存储文件默认每一行就是一条记录，可以指定任意的分隔符进行字段间的分割。但这个格式无压缩，需要的存储空间很大。虽然可结合Gzip、Bzip2、Snappy等使用，使用这种方式，Hive不会对数据进行切分，从而无法对数据进行并行操作。</span><br><span class="line">一般只有与其他系统由数据交互的接口表采用TEXTFILE 格式，其他事实表和维度表都不建议使用。</span><br><span class="line"></span><br><span class="line">RCFile:</span><br><span class="line">Record Columnar的缩写。是Hadoop中第一个列文件格式。能够很好的压缩和快速的查询性能。通常写操作比较慢，比非列形式的文件格式需要更多的内存空间和计算量。 RCFile是一种行列存储相结合的存储方式。首先，其将数据按行分块，保证同一个record在一个块上，避免读一个记录需要读取多个block。其次，块数据`列式存储`，有利于数据压缩和快速的列存取。</span><br><span class="line"></span><br><span class="line">ORCFile:</span><br><span class="line">Hive从0.11版本开始提供了ORC的文件格式，ORC文件不仅仅是一种列式文件存储格式，最重要的是有着很高的压缩比，并且对于MapReduce来说是可切分（Split）的。因此，在Hive中使用ORC作为表的文件存储格式，不仅可以很大程度的节省HDFS存储资源，而且对数据的查询和处理性能有着非常大的提升，因为ORC较其他文件格式压缩比高，查询任务的输入数据量减少，使用的Task也就减少了。ORC能很大程度的节省存储和计算资源，但它在读写时候需要消耗额外的CPU资源来压缩和解压缩，当然这部分的CPU消耗是非常少的。</span><br><span class="line"></span><br><span class="line">Parquet:</span><br><span class="line">通常我们使用关系数据库存储结构化数据，而关系数据库中使用数据模型都是扁平式的，遇到诸如List、Map和自定义Struct的时候就需要用户在应用层解析。但是在大数据环境下，通常数据的来源是服务端的埋点数据，很可能需要把程序中的某些对象内容作为输出的一部分，而每一个对象都可能是嵌套的，所以如果能够原生的支持这种数据，这样在查询的时候就不需要额外的解析便能获得想要的结果。Parquet的灵感来自于2010年Google发表的Dremel论文，文中介绍了一种支持嵌套结构的存储格式，并且使用了列式存储的方式提升查询性能。Parquet仅仅是一种存储格式，它是语言、平台无关的，并且不需要和任何一种数据处理框架绑定。这也是parquet相较于orc的仅有优势：支持嵌套结构。Parquet 没有太多其他可圈可点的地方,比如他不支持update操作(数据写成后不可修改),不支持ACID等.</span><br><span class="line"></span><br><span class="line">SEQUENCEFILE:</span><br><span class="line">SequenceFile是Hadoop API 提供的一种二进制文件，它将数据以&lt;key,value&gt;的形式序列化到文件中。这种二进制文件内部使用Hadoop 的标准的Writable 接口实现序列化和反序列化。它与Hadoop API中的MapFile 是互相兼容的。Hive 中的SequenceFile 继承自Hadoop API 的SequenceFile，不过它的key为空，使用value 存放实际的值， 这样是为了避免MR 在运行map 阶段的排序过程。SequenceFile支持三种压缩选择：NONE, RECORD, BLOCK。 Record压缩率低，一般建议使用BLOCK压缩。 SequenceFile最重要的优点就是Hadoop原生支持较好，有API，但除此之外平平无奇，实际生产中不会使用。</span><br><span class="line"></span><br><span class="line">AVRO:</span><br><span class="line">Avro是一种用于支持数据密集型的二进制文件格式。它的文件格式更为紧凑，若要读取大量数据时，Avro能够提供更好的序列化和反序列化性能。并且Avro数据文件天生是带Schema定义的，所以它不需要开发者在API 级别实现自己的Writable对象。Avro提供的机制使动态语言可以方便地处理Avro数据。最近多个Hadoop 子项目都支持Avro 数据格式，如Pig 、Hive、Flume、Sqoop和Hcatalog。</span><br></pre></td></tr></table></figure><p><strong>Hive的四大常用存储格式存储效率及执行速度对比</strong></p><blockquote><p>结论：ORCFILE存储文件读操作效率最高</p><p>耗时比较：ORC&lt;Parquet&lt;RC&lt;Text</p></blockquote><blockquote><p>结论：ORCFILE存储文件占用空间少，压缩效率高</p><p>占用空间：ORC&lt;Parquet&lt;RC&lt;Text</p></blockquote><h4 id="2-3-1-创建表"><a href="#2-3-1-创建表" class="headerlink" title="2.3.1    创建表"></a>2.3.1    创建表</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">[COMMENT table_comment] </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] </span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">[STORED <span class="keyword">AS</span> file_format] </span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">字段解释说明:</span><br><span class="line"><span class="operator">-</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> </span><br><span class="line">创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> 选项来忽略这个异常。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> <span class="keyword">EXTERNAL</span></span><br><span class="line">关键字可以让用户创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION）</span><br><span class="line">创建内部表时，会将数据移动到数据仓库指向的路径（默认位置）；</span><br><span class="line">创建外部表时，仅记录数据所在的路径，不对数据的位置做任何改变。在</span><br><span class="line">删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> COMMENT：</span><br><span class="line">为表和列添加注释。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> PARTITIONED <span class="keyword">BY</span></span><br><span class="line">创建分区表</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> CLUSTERED <span class="keyword">BY</span></span><br><span class="line">创建分桶表</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> SORTED <span class="keyword">BY</span></span><br><span class="line">不常用</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> <span class="type">ROW</span> FORMAT </span><br><span class="line">  DELIMITED [FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] [LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] <span class="operator">|</span> SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name<span class="operator">=</span>property_value, property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line">用户在建表的时候可以自定义SerDe或者使用自带的SerDe。</span><br><span class="line">如果没有指定<span class="type">ROW</span> FORMAT 或者<span class="type">ROW</span> FORMAT DELIMITED，将会使用自带的SerDe。</span><br><span class="line">在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。</span><br><span class="line">SerDe是Serialize<span class="operator">/</span>Deserilize的简称，目的是用于序列化和反序列化。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> STORED <span class="keyword">AS</span>指定存储文件类型</span><br><span class="line">常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</span><br><span class="line">如果文件数据是纯文本，可以使用STORED <span class="keyword">AS</span> TEXTFILE。</span><br><span class="line">如果数据需要压缩，使用 STORED <span class="keyword">AS</span> SEQUENCEFILE。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> LOCATION ：</span><br><span class="line">指定表在HDFS上的存储位置。</span><br><span class="line"></span><br><span class="line"><span class="operator">-</span> <span class="keyword">LIKE</span></span><br><span class="line">允许用户复制现有的表结构，但是不复制数据。</span><br></pre></td></tr></table></figure><h5 id="建表1：全部使用默认建表方式"><a href="#建表1：全部使用默认建表方式" class="headerlink" title="建表1：全部使用默认建表方式"></a>建表1：全部使用默认建表方式</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table students</span><br><span class="line">(</span><br><span class="line">    id bigint,</span><br><span class="line">    name string,</span><br><span class="line">    age int,</span><br><span class="line">    gender string,</span><br><span class="line">    clazz string</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;,&#x27;; // 必选，指定列分隔符 </span><br></pre></td></tr></table></figure><h5 id="建表2：指定location-（这种方式也比较常用）"><a href="#建表2：指定location-（这种方式也比较常用）" class="headerlink" title="建表2：指定location （这种方式也比较常用）"></a>建表2：指定location （这种方式也比较常用）</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table students2</span><br><span class="line">(</span><br><span class="line">    id bigint,</span><br><span class="line">    name string,</span><br><span class="line">    age int,</span><br><span class="line">    gender string,</span><br><span class="line">    clazz string</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;,&#x27;</span><br><span class="line">LOCATION &#x27;/input1&#x27;; // 指定Hive表的数据的存储位置，一般在数据已经上传到HDFS，想要直接使用，会指定Location，通常Locaion会跟外部表一起使用，内部表一般使用默认的location</span><br></pre></td></tr></table></figure><h5 id="建表3：指定存储格式"><a href="#建表3：指定存储格式" class="headerlink" title="建表3：指定存储格式"></a>建表3：指定存储格式</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table students3</span><br><span class="line">(</span><br><span class="line">    id bigint,</span><br><span class="line">    name string,</span><br><span class="line">    age int,</span><br><span class="line">    gender string,</span><br><span class="line">    clazz string</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;,&#x27;</span><br><span class="line">STORED AS rcfile; // 指定储存格式为rcfile，inputFormat:RCFileInputFormat,outputFormat:RCFileOutputFormat，如果不指定，默认为textfile，注意：除textfile以外，其他的存储格式的数据都不能直接加载，需要使用从表加载的方式。</span><br></pre></td></tr></table></figure><h5 id="建表4：create-table-xxxx-as-select-statement-SQL语句-这种方式比较常用"><a href="#建表4：create-table-xxxx-as-select-statement-SQL语句-这种方式比较常用" class="headerlink" title="建表4：create table xxxx as select_statement(SQL语句) (这种方式比较常用)"></a>建表4：create table xxxx as select_statement(SQL语句) (这种方式比较常用)</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table students4 as select * from students2;</span><br></pre></td></tr></table></figure><h5 id="建表5：create-table-xxxx-like-table-name-只想建表，不需要加载数据"><a href="#建表5：create-table-xxxx-like-table-name-只想建表，不需要加载数据" class="headerlink" title="建表5：create table xxxx like table_name  只想建表，不需要加载数据"></a>建表5：create table xxxx like table_name  只想建表，不需要加载数据</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table students5 like students;</span><br></pre></td></tr></table></figure><blockquote><p><strong>简单用户信息表创建：</strong></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_user(</span><br><span class="line">id <span class="type">int</span>,</span><br><span class="line">uname string,</span><br><span class="line">pwd string,</span><br><span class="line">gender string,</span><br><span class="line">age <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1,admin,123456,男,18</span><br><span class="line">2,zhangsan,abc123,男,23</span><br><span class="line">3,lisi,654321,女,16</span><br></pre></td></tr></table></figure><p>复杂人员信息表创建：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_person(</span><br><span class="line">name string,</span><br><span class="line">friends <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line">children map<span class="operator">&lt;</span>string,<span class="type">int</span><span class="operator">&gt;</span>,</span><br><span class="line">address struct<span class="operator">&lt;</span>street:string ,city:string<span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;_&#x27;</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">songsong,bingbing_lili,xiao song:<span class="number">18</span>_xiaoxiao song:<span class="number">19</span>,beng bu_anhui</span><br><span class="line">yangyang,caicai_susu,xiao yang:<span class="number">18</span>_xiaoxiao yang:<span class="number">19</span>,he fei_anhui</span><br></pre></td></tr></table></figure></blockquote><h4 id="2-3-2-显示表"><a href="#2-3-2-显示表" class="headerlink" title="2.3.2    显示表"></a>2.3.2    显示表</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="keyword">show</span> tables <span class="keyword">like</span> <span class="string">&#x27;u&#x27;</span>;</span><br><span class="line"><span class="keyword">desc</span> t_person;</span><br><span class="line"><span class="keyword">desc</span> formatted t_person;</span><br></pre></td></tr></table></figure><h4 id="2-3-3-加载数据"><a href="#2-3-3-加载数据" class="headerlink" title="2.3.3    加载数据"></a>2.3.3    加载数据</h4><h5 id="1、使用hdfs-dfs-put-39-本地数据-39-39-hive表对应的HDFS目录下-39"><a href="#1、使用hdfs-dfs-put-39-本地数据-39-39-hive表对应的HDFS目录下-39" class="headerlink" title="1、使用hdfs dfs -put &#39;本地数据&#39; &#39;hive表对应的HDFS目录下&#39;"></a>1、使用<code>hdfs dfs -put &#39;本地数据&#39; &#39;hive表对应的HDFS目录下&#39;</code></h5><h5 id="2、使用-load-data-inpath"><a href="#2、使用-load-data-inpath" class="headerlink" title="2、使用 load data inpath"></a>2、使用 load data inpath</h5><blockquote><p>下列命令需要在hive shell里执行</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 将HDFS上的/input1目录下面的数据 移动至 students表对应的HDFS目录下，注意是 移动、移动、移动</span><br><span class="line">load data inpath &#x27;/input1/students.txt&#x27; into table students;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 清空表</span><br><span class="line">truncate table students;</span><br><span class="line">// 加上 local 关键字 可以将Linux本地目录下的文件 上传到 hive表对应HDFS 目录下 原文件不会被删除</span><br><span class="line">load data local inpath &#x27;/usr/local/soft/data/students.txt&#x27; into table students;</span><br><span class="line">// overwrite 覆盖加载</span><br><span class="line">load data local inpath &#x27;/usr/local/soft/data/students.txt&#x27; overwrite into table students;</span><br></pre></td></tr></table></figure><h5 id="3、create-table-xxx-as-SQL语句"><a href="#3、create-table-xxx-as-SQL语句" class="headerlink" title="3、create table xxx as SQL语句"></a>3、create table xxx as SQL语句</h5><h5 id="4、insert-into-table-xxxx-SQL语句-（没有as）"><a href="#4、insert-into-table-xxxx-SQL语句-（没有as）" class="headerlink" title="4、insert into table xxxx SQL语句 （没有as）"></a>4、insert into table xxxx SQL语句 （没有as）</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 将 students表的数据插入到students2 这是复制 不是移动 students表中的表中的数据不会丢失</span><br><span class="line">insert into table students2 select * from students;</span><br><span class="line"></span><br><span class="line">// 覆盖插入 把into 换成 overwrite</span><br><span class="line">insert overwrite table students2 select * from students;</span><br></pre></td></tr></table></figure><h4 id="2-3-4-修改列"><a href="#2-3-4-修改列" class="headerlink" title="2.3.4    修改列"></a>2.3.4    修改列</h4><blockquote><p>查询表结构</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">desc</span> students2;</span><br></pre></td></tr></table></figure><blockquote><p>添加列</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> students2 <span class="keyword">add</span> columns (education string);</span><br></pre></td></tr></table></figure><blockquote><p>查询表结构</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">desc</span> students2;</span><br></pre></td></tr></table></figure><blockquote><p>更新列</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> stduents2 change education educationnew string;</span><br></pre></td></tr></table></figure><h4 id="2-3-5-删除表"><a href="#2-3-5-删除表" class="headerlink" title="2.3.5    删除表"></a>2.3.5    删除表</h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> students2;</span><br></pre></td></tr></table></figure><h3 id="2-4-Hive内外部表"><a href="#2-4-Hive内外部表" class="headerlink" title="2.4    Hive内外部表"></a>2.4    Hive内外部表</h3><blockquote><p><strong>面试题：内部表和外部表的区别？如何创建外部表？工作中使用外部表</strong></p></blockquote><h4 id="2-4-1-hive内部表"><a href="#2-4-1-hive内部表" class="headerlink" title="2.4.1    hive内部表"></a>2.4.1    hive内部表</h4><blockquote><p>当<strong>创建好表的时候，HDFS会在当前表所属的库中创建一个文件夹</strong></p><p>当设置表路径的时候，如果直接指向一个已有的路径,可以直接去使用文件夹中的数据</p><p><strong>当load数据的时候，就会将数据文件存放到表对应的文件夹中</strong></p><p>而且<strong>数据一旦被load，就不能被修改</strong></p><p>我们查询数据也是查询文件中的文件,这些数据最终都会存放到HDFS</p><p>当我们<strong>删除表的时候，表对应的文件夹会被删除，同时数据也会被删除</strong></p><p><strong>默认建表的类型就是内部表</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 内部表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> students_internal</span><br><span class="line">(</span><br><span class="line">    id <span class="type">bigint</span>,</span><br><span class="line">    name string,</span><br><span class="line">    age <span class="type">int</span>,</span><br><span class="line">    gender string,</span><br><span class="line">    clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">LOCATION <span class="string">&#x27;/input2&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hive<span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>soft<span class="operator">/</span>data<span class="operator">/</span>students.txt <span class="operator">/</span>input2<span class="operator">/</span>;</span><br></pre></td></tr></table></figure><h4 id="2-4-1-Hive外部表"><a href="#2-4-1-Hive外部表" class="headerlink" title="2.4.1    Hive外部表"></a>2.4.1    Hive外部表</h4><blockquote><p>外部表说明</p><p>​    <strong>外部表因为是指定其他的hdfs路径的数据加载到表中来，所以hive会认为自己不完全独占这份数据</strong></p><p>​    <strong>删除hive表的时候，数据仍然保存在hdfs中，不会删除。</strong></p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 外部表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> students_external</span><br><span class="line">(</span><br><span class="line">    id <span class="type">bigint</span>,</span><br><span class="line">    name string,</span><br><span class="line">    age <span class="type">int</span>,</span><br><span class="line">    gender string,</span><br><span class="line">    clazz string</span><br><span class="line">)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">LOCATION <span class="string">&#x27;/input3&#x27;</span>;</span><br><span class="line"></span><br><span class="line">hive<span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>soft<span class="operator">/</span>data<span class="operator">/</span>students.txt <span class="operator">/</span>input3<span class="operator">/</span>;</span><br></pre></td></tr></table></figure><blockquote><p>删除表测试一下：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">table</span> students_internal;</span><br><span class="line">Moved: <span class="string">&#x27;hdfs://master:9000/input2&#x27;</span> <span class="keyword">to</span> trash <span class="keyword">at</span>: hdfs:<span class="operator">/</span><span class="operator">/</span>master:<span class="number">9000</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>root<span class="operator">/</span>.Trash<span class="operator">/</span><span class="keyword">Current</span></span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.474</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">table</span> students_external;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.09</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> </span><br></pre></td></tr></table></figure><blockquote><p>一般在公司中，使用外部表多一点，因为数据可以需要被多个程序使用，避免误删，通常外部表会结合location一起使用</p><p>外部表还可以将其他数据源中的数据 映射到 hive中，比如说：hbase，ElasticSearch……</p><p>设计外部表的初衷就是 让 表的元数据 与 数据 解耦</p></blockquote><ul><li>操作案例:  分别创建dept，emp，salgrade。并加载数据。</li></ul><blockquote><p>创建数据文件存放的目录</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hdfs dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span>shujia<span class="operator">/</span>bigdata17<span class="operator">/</span>dept</span><br><span class="line">hdfs dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span>shujia<span class="operator">/</span>bigdata17<span class="operator">/</span>emp</span><br><span class="line">hdfs dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span>shujia<span class="operator">/</span>bigdata17<span class="operator">/</span>salgrade</span><br></pre></td></tr></table></figure><ul><li>创建dept表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dept (</span><br><span class="line">  DEPTNO <span class="type">int</span>,</span><br><span class="line">  DNAME <span class="type">varchar</span>(<span class="number">255</span>),</span><br><span class="line">  LOC <span class="type">varchar</span>(<span class="number">255</span>)</span><br><span class="line">) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/shujia/bigdata17/dept&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="number">10</span>,ACCOUNTING,<span class="keyword">NEW</span> YORK</span><br><span class="line"><span class="number">20</span>,RESEARCH,DALLAS</span><br><span class="line"><span class="number">30</span>,SALES,CHICAGO</span><br><span class="line"><span class="number">40</span>,OPERATIONS,BOSTON</span><br></pre></td></tr></table></figure><ul><li>创建emp表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> emp (</span><br><span class="line">   EMPNO <span class="type">int</span>,</span><br><span class="line">   ENAME <span class="type">varchar</span>(<span class="number">255</span>),</span><br><span class="line">   JOB <span class="type">varchar</span>(<span class="number">255</span>),</span><br><span class="line">   MGR <span class="type">int</span>,</span><br><span class="line">   HIREDATE <span class="type">date</span>,</span><br><span class="line">   SAL <span class="type">decimal</span>(<span class="number">10</span>,<span class="number">0</span>),</span><br><span class="line">   COMM <span class="type">decimal</span>(<span class="number">10</span>,<span class="number">0</span>),</span><br><span class="line">   DEPTNO <span class="type">int</span></span><br><span class="line"> ) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"> location <span class="string">&#x27;/shujia/bigdata17/emp&#x27;</span>;</span><br><span class="line"> </span><br><span class="line"><span class="number">7369</span>,SMITH,CLERK,<span class="number">7902</span>,<span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>,<span class="number">800</span>,<span class="keyword">null</span>,<span class="number">20</span></span><br><span class="line"><span class="number">7499</span>,ALLEN,SALESMAN,<span class="number">7698</span>,<span class="number">1981</span><span class="number">-02</span><span class="number">-20</span>,<span class="number">1600</span>,<span class="number">300</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7521</span>,WARD,SALESMAN,<span class="number">7698</span>,<span class="number">1981</span><span class="number">-02</span><span class="number">-22</span>,<span class="number">1250</span>,<span class="number">500</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7566</span>,JONES,MANAGER,<span class="number">7839</span>,<span class="number">1981</span><span class="number">-04</span><span class="number">-02</span>,<span class="number">2975</span>,<span class="keyword">null</span>,<span class="number">20</span></span><br><span class="line"><span class="number">7654</span>,MARTIN,SALESMAN,<span class="number">7698</span>,<span class="number">1981</span><span class="number">-09</span><span class="number">-28</span>,<span class="number">1250</span>,<span class="number">1400</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7698</span>,BLAKE,MANAGER,<span class="number">7839</span>,<span class="number">1981</span><span class="number">-05</span><span class="number">-01</span>,<span class="number">2850</span>,<span class="keyword">null</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7782</span>,CLARK,MANAGER,<span class="number">7839</span>,<span class="number">1981</span><span class="number">-06</span><span class="number">-09</span>,<span class="number">2450</span>,<span class="keyword">null</span>,<span class="number">10</span></span><br><span class="line"><span class="number">7788</span>,SCOTT,ANALYST,<span class="number">7566</span>,<span class="number">1987</span><span class="number">-07</span><span class="number">-13</span>,<span class="number">3000</span>,<span class="keyword">null</span>,<span class="number">20</span></span><br><span class="line"><span class="number">7839</span>,KING,PRESIDENT,<span class="keyword">null</span>,<span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>,<span class="number">5000</span>,<span class="keyword">null</span>,<span class="number">10</span></span><br><span class="line"><span class="number">7844</span>,TURNER,SALESMAN,<span class="number">7698</span>,<span class="number">1981</span><span class="number">-09</span><span class="number">-08</span>,<span class="number">1500</span>,<span class="number">0</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7876</span>,ADAMS,CLERK,<span class="number">7788</span>,<span class="number">1987</span><span class="number">-07</span><span class="number">-13</span>,<span class="number">1100</span>,<span class="keyword">null</span>,<span class="number">20</span></span><br><span class="line"><span class="number">7900</span>,JAMES,CLERK,<span class="number">7698</span>,<span class="number">1981</span><span class="number">-12</span><span class="number">-03</span>,<span class="number">950</span>,<span class="keyword">null</span>,<span class="number">30</span></span><br><span class="line"><span class="number">7902</span>,FORD,ANALYST,<span class="number">7566</span>,<span class="number">1981</span><span class="number">-12</span><span class="number">-03</span>,<span class="number">3000</span>,<span class="keyword">null</span>,<span class="number">20</span></span><br><span class="line"><span class="number">7934</span>,MILLER,CLERK,<span class="number">7782</span>,<span class="number">1982</span><span class="number">-01</span><span class="number">-23</span>,<span class="number">1300</span>,<span class="keyword">null</span>,<span class="number">10</span></span><br></pre></td></tr></table></figure><ul><li>创建salgrade表</li></ul><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> salgrade (</span><br><span class="line">  GRADE <span class="type">int</span>,</span><br><span class="line">  LOSAL <span class="type">int</span>,</span><br><span class="line">  HISAL <span class="type">int</span></span><br><span class="line">) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/shujia/bigdata17/salgrade&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>,<span class="number">700</span>,<span class="number">1200</span></span><br><span class="line"><span class="number">2</span>,<span class="number">1201</span>,<span class="number">1400</span></span><br><span class="line"><span class="number">3</span>,<span class="number">1401</span>,<span class="number">2000</span></span><br><span class="line"><span class="number">4</span>,<span class="number">2001</span>,<span class="number">3000</span></span><br><span class="line"><span class="number">5</span>,<span class="number">3001</span>,<span class="number">9999</span></span><br></pre></td></tr></table></figure><h3 id="2-5-Hive导出数据"><a href="#2-5-Hive导出数据" class="headerlink" title="2.5    Hive导出数据"></a>2.5    Hive导出数据</h3><blockquote><p>将表中的数据备份</p></blockquote><p>将查询结果存放到本地</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建存放数据的目录</span><br><span class="line">mkdir <span class="operator">-</span>p <span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>soft<span class="operator">/</span>shujia</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>导出查询结果的数据(导出到Node01上)</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/usr/local/soft/shujia/person_data&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_person;</span><br></pre></td></tr></table></figure><p>按照指定的方式将数据输出到本地</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建存放数据的目录</span></span><br><span class="line">mkdir <span class="operator">-</span>p <span class="operator">/</span>usr<span class="operator">/</span><span class="keyword">local</span><span class="operator">/</span>soft<span class="operator">/</span>shujia</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导出查询结果的数据</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/usr/local/soft/shujia/person&#x27;</span> </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;-&#x27;</span> </span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span> </span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span> </span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_person;</span><br></pre></td></tr></table></figure><p>将查询结果输出到HDFS</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建存放数据的目录</span></span><br><span class="line">hdfs dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span>shujia<span class="operator">/</span>bigdata17<span class="operator">/</span><span class="keyword">copy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导出查询结果的数据</span></span><br><span class="line"><span class="keyword">insert</span> overwrite directory <span class="string">&#x27;/shujia/bigdata17/user&#x27;</span> </span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> </span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user;</span><br></pre></td></tr></table></figure><p>直接使用HDFS命令保存表对应的文件夹</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// 创建存放数据的目录</span><br><span class="line">hdfs dfs -mkdir -p /shujia/bigdata17/person</span><br><span class="line"></span><br><span class="line">// 使用HDFS命令拷贝文件到其他目录</span><br><span class="line">hdfs dfs -cp /hive/warehouse/t_person/*  /shujia/bigdata17/person</span><br></pre></td></tr></table></figure><p>将表结构和数据同时备份将数据导出到HDFS</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建存放数据的目录</span><br><span class="line">hdfs dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span>shujia<span class="operator">/</span>bigdata17<span class="operator">/</span><span class="keyword">copy</span></span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>导出查询结果的数据</span><br><span class="line">export <span class="keyword">table</span> t_person <span class="keyword">to</span> <span class="string">&#x27;/shujia/bigdata17/copy&#x27;</span>;</span><br></pre></td></tr></table></figure><p>删除表结构</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> t_person;</span><br></pre></td></tr></table></figure><p>恢复表结构和数据</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">import <span class="keyword">from</span> <span class="string">&#x27;/shujia/bigdata17&#x27;</span>;</span><br></pre></td></tr></table></figure><blockquote><p>注意：时间不同步，会导致导入导出失败</p></blockquote><p>hive表查询时使用中文别名</p><p>在hive查询时 使用英文别名是没有任何问题的，</p><p>SELECT st.source_task_order A, st.creation_date B FROM tr_source_task st;</p><p>但是有某些特殊需求，需要使用中文别名时</p><p><strong>解决方法：</strong></p><p>将中文别名用<strong>反单引号</strong>（ tab键上面的那个键可以敲出来）引起来即可。</p><p>SELECT unit_name as <code>单位名称</code> FROM table_company_task;</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop的一些优化</title>
      <link href="/2022/05/27/Hadoop%E6%A1%88%E4%BE%8B%E5%92%8C%E4%BC%98%E5%8C%96/"/>
      <url>/2022/05/27/Hadoop%E6%A1%88%E4%BE%8B%E5%92%8C%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop优化"><a href="#Hadoop优化" class="headerlink" title="Hadoop优化"></a>Hadoop优化</h1><h2 id="优化1：Combiner"><a href="#优化1：Combiner" class="headerlink" title="优化1：Combiner"></a>优化1：Combiner</h2><blockquote><p>减少了reduce 从map拉取数据的过程，提高计算效率。</p><p>hadoop 的计算特点：<strong>将计算任务向数据靠拢，而不是将数据向计算靠拢。</strong></p><p>特点：数据本地化，减少网络io。</p><p>首先需要知道，hadoop数据本地化是指的map任务，reduce任务并不具备数据本地化特征。<br>   通常输入的数据首先在<strong>逻辑上</strong>（<strong>注意这里不是真正物理上划分</strong>）将会分片split，每个分片上构建一个map任务，由该任务执行执行用户自定义的map函数，从而处理分片中的每条记录。<br>   那么切片的大小一般是趋向一个HDFS的block块的大小。为什么最佳的分片大小是趋向block块的大小呢？是因为这样能够确保单节点上最大输入块的大小，如果分片跨越两个数据块，没有一个block能够同时存储这两块数据，因此需要通过网络传输将部分数据传输到map任务节点上。这样明显比使用本地数据的map效率更低。<br>    注意，map任务执行后的结果并没有写到HDFS中，而是作为中间结果存储到本地硬盘，那为什么没有存储到HDFS呢？因为，该中间结果会被reduce处理后产生最终结果后，该中间数据会被删除，如果存储到HDFS中，他会进行备份，这样明显没有意义。如果map将中间结果传输到reduce过程中出现了错误，Hadoop会在另一个节点上重新执行map产生中间结果。<br>    那么为什么reduce没有数据本地化的特点呢？对于单个reduce任务来说，他的输入通常是所有mapper经过排序输出，这些输出通过网络传输到reduce节点，数据在reduce节点合并然后由reduce函数进行处理。最终结果输出到HDFS上。当多个有reduce任务的时候，map会针对输出进行分区partition，也就是为每个reduce构建一个分区，分区是由用户指定的partition函数，效率很高。<br>   同时为了高效传输可以指定combiner函数，他的作用就是，<strong>减少网络传输和本地传输</strong></p><p>假设文件是500mb</p><p>long bytesRemaining &#x3D; length; 500mb</p><p>​     while (((double) bytesRemaining)&#x2F;splitSize &gt; SPLIT_SLOP) {</p><p>​      int blkIndex &#x3D; getBlockIndex(blkLocations, length-bytesRemaining  );</p><p>​      splits.add(makeSplit(path, length-bytesRemaining 256 , splitSize 128,</p><p>​            blkLocations[blkIndex].getHosts(),</p><p>​            blkLocations[blkIndex].getCachedHosts()));</p><p>​      bytesRemaining &#x3D; bytesRemaining-splitSize;116</p><p>​     }</p><p><strong>注意：将reduce端的聚合操作，放到map 进行执行。适合求和，计数，等一些等幂操作。不适合求平均值，次幂等类似操作</strong></p></blockquote><h2 id="优化2：Join（数据倾斜）"><a href="#优化2：Join（数据倾斜）" class="headerlink" title="优化2：Join（数据倾斜）"></a>优化2：Join（数据倾斜）</h2><blockquote><p>MapReduce中的join</p><p>　　其实就是类似于关系型数据库中的连接查询一样。需要计算的数据可能存储在不同的文件中或不同表中，两个文件又有一些相同的字段可以相互关联，这时候我们就可以通过这些关联字段将两个文件中的数据组合到一起进行计算了。</p><p>　　我知道的mr有三种join方式。Map join、SemiJoin、reduce join。</p><p>Reduce Join（我们之前做的代码连接就是这个方式）</p><p>思路：</p><p>　　分为两个阶段</p><p>　　 （1）map函数主要是对不同文件中的数据打标签。</p><p>　　（2）reduce函数获取key相同的value list，进行笛卡尔积。</p><p>Map Join思路：</p><p>　　比如有两个表，有一个表非常大，而另一个表非常小，以至于小表可以直接存放到内存中。这样，我们可以将小表复制多份，让每个map task内存中保存一个hash map，将小表数据放入这个hash map中，key是小表与大表的内个连接字段，value是小表一条记录，然后只扫描大表：对于大表中的每一条记录key&#x2F;value，在hash map中查找是否有相同的key的记录，如果有，则连接输出即可。</p><p><strong>Semi Join 这个SemiJoin其实就是对reduce join的一种优化。</strong></p><p>　　就是在map端过滤掉不参加join操作的数据，则可以大大减少数据量，提高网络传输速度。</p><p>这三种join方式适用于不同的场景：</p><p>　　Reduce join要考虑数据量过大时的网络传输问题。</p><p>　　Map join和SemiJoin则要考虑数据量过大时的内存问题。 如果只考虑网络传输，忽略内存问题则。</p><p>　　Map join效率最高，其次是SemiJoin，最低的是reduce join。</p><p>DistributedCache DistributedCache是Hadoop提供的文件缓存工具，它能够自动将指定的文件分发到各个节点上，缓存到本地，供用户程序读取使用。一般用户数据字典的分发，和map join使用。一般缓存的文件都是只读。</p></blockquote><h2 id="优化3：根据实际情况调整切片大小"><a href="#优化3：根据实际情况调整切片大小" class="headerlink" title="优化3：根据实际情况调整切片大小"></a>优化3：根据实际情况调整切片大小</h2><blockquote><p><strong>为什么默认切片是128MB和blk大小一致？（优化）</strong></p><p>1 切片大小默认一致，是为了数据本地化，减少数据拉取消耗网络io</p><p>2 并不是越大越好，也不是越小越好。根据集群的资源情况而定。</p><p> 当集群计算资源充足的情况下：将切片的大小调小，增加map数量，提高读取效率。</p><p> 当集群计算资源紧张的情况下：将切片的大小调大，减少资源占用，让任务正常运转。</p><p> mapred.min.split.size、mapred.max.split.size、blockSize</p></blockquote><h2 id="优化4：可以设置yarn资源和队列。"><a href="#优化4：可以设置yarn资源和队列。" class="headerlink" title="优化4：可以设置yarn资源和队列。"></a>优化4：可以设置yarn资源和队列。</h2><blockquote><p>调整计算资源：<a href="https://blog.csdn.net/qq_36753550/article/details/83065546">https://blog.csdn.net/qq_36753550/article/details/83065546</a></p><p> 设置队列：<a href="https://blog.csdn.net/weixin_30607029/article/details/96507281">https://blog.csdn.net/weixin_30607029/article/details/96507281</a></p><p>mr运行日志信息：百分比是按照完成的m或r的任务的个数&#x2F;m或r的总个数。</p><p>MRv1&#x2F;MRv2&#x2F;YARN MRv1:</p><p>　　对于经典的MRv1它由三部分组成 :</p><p>　　　　编程模型、 数据处理引擎和运行时环境。</p><p>　　　　编程模型由新旧 API 两部分组成，新旧api只是代码封装上略有变化，性能没变化。</p><p>　　　　数据处理引擎由 MapTask 和 ReduceTask 组成。 运行时环境由 JobTracker 和 TaskTracker 两类服务组成。</p><p>　　MRv2:</p><p>　　　　由于MRv1对JobTracker的功能过多造成负载过重在扩展性、 资源利用率和多框架支持等方面存在不足，因此MRv2框架 的基本设计思想是将MRv1中的JobTracker包含的资源管理和应用管理两部分功能进行拆分，分别交给两个进程实现。 资源管理进程与具体应用程序无关，它负责整个集群的资源管理（内存、 CPU、 磁盘）。 应用管理进程负责管理应用程序，并且每个应用管理进程只管理一个作业。 由于资源管理可以共享给其他框架使用，因此MRv2将其做成了一个通用的系统YARN,YARN系统使得MRv2计算框架在可扩展性，资源利用率，多框架支持方面得到了很大改进。</p><p>　　YARN：yarn由4部分组成。</p><p>　　　　1. ResourceManager主要功能是：</p><p>　　　　　　（1）接收用户请求</p><p>　　　　　　（2）管理调度资源</p><p>　　　　　　（3）启动管理am　　　　</p><p>　　　　　　（4）管理所有nm,处理nm的状态汇报，向nm下达命令。</p><p>　2.Container：yarn的应用都是运行在容器上的，容器包含cpu，内存等信息。</p><p>　3.NodeManager：NM是每个节点上的资源和任务管理器，它会定时地向RM汇报本节点上的资源使用情况和各个容器的运行状态；同时负责对容器的启动和停止。</p><p>　　　　4. ApplicationMaster：管理应用程序。向RM获取资源、为应用程序分配任务、 监控所有任务运行状态。</p><ol><li>作业提交</li></ol><p>　　首先我们将任务提交给JobClient,JobClient会向RM获取一个appId。 然后我们的JobClient会对作业进行处理, 切分InputSplit, 将作业的Jar包, 配置文件和拷贝InputSplit信息拷贝到HDFS。 最后, 通过调用RM的submitApplication()来提交作业。</p><ol start="2"><li>作业初始化</li></ol><p>　　当RM收到submitApplciation()的请求时, 就将该请求发给调度器, 调度器分配第一个容器, 然后RM在该容器内启动ApplicationMaster进程。该进程上运行着一个MRAppMaster的Java应用。其通过创造一些bookkeeping对象来监控作业的进度。 然后通过hdfs得到由JobClient已经处理好的作业信息。为每个Inputsplit创建一个map任务, 并创建相应的reduce任务。然后ApplicationMaster会对整个作业量进行判断，<strong>如果作业量很小, ApplicationMaster会选择在其自己的JVM中运行任务</strong>, <strong>这种作业称作是uber task的方式</strong>。在任务运行之前, 作业的<strong>setup</strong>方法被调用来创建输出路径。</p><ol start="3"><li>任务分配</li></ol><p>　　如果不是小作业, 那么ApplicationMaster向RM请求更多的容器来运行所有的map和reduce任务，<strong>每个容器只能对应一个任务</strong>。这些请求是通过心跳来传输的, 包括每个map任务的数据位置, 比如Inputsplit的主机名和机架。调度器利用这些信息来调度任务, 尽量将任务分配给有存储数据的节点, 或者分配给和存放Inputsplit的节点相同机架的节点。</p><ol start="4"><li>任务运行</li></ol><p>　　当一个任务由RM的调度器分配了一个容器后, ApplicationMaster与NM通信来启动容器。任务由一个为YarnChild的Java应用执行。在运行任务之前首先本地化任务需要的资源, 比如作业配置, JAR文件, 以及hdfs中保存的任务所需的所有文件。最后, map任务或者reduce运行在一个叫YarnChild的进程当中。</p><ol start="5"><li>进度和状态更新</li></ol><p>　　每个NM会向applicationmaster汇报自己的工作状态，JobClient会每秒轮询检测applicationmaster，这样就能随时收到更新信息。</p><ol start="6"><li>作业完成</li></ol><p>　　除了向applicationmaster请求作业进度外, JobClient每5分钟都会通过调用waitForCompletion()来检查作业是否完成。作业完成之后,applicationmaster和NM会清理工作状态, OutputCommiter的作业清理方法也会被调用. 作业的信息会被作业历史服务器存储以备之后用户核查.</p><p><strong>yarn对异常task的处理（推测执行）？(重要！！！)</strong></p><p>　　推测执行是在分布式环境下，因为某种原因造成同一个job的多个task运行速度不一致，有的task运行速度明显慢于其他task，则这些task拖慢了整个job的执行进度，为了避免这种情况发生，Hadoop会为该task启动备份任务，让该speculative task与原始task同时处理一份数据，哪个先运行完，则将谁的结果作为最终结果。推测执行优化机制采用了<strong>典型的以空间换时间的优化策略</strong>，它同时启动多个相同task（备份任务）处理相同的数据块，哪个完成的早，则采用哪个task的结果，这样可防止拖后腿Task任务出现，进而提高作业计算速度，但是，这样却会占用更多的资源。</p><p><strong>yarn调度器的策略？(重要！！！)</strong></p><p>　　yarn默认是计算能力调度 FifoScheduler:根据先进先出排队，最简单的调度器。  FIFO</p><p>​        CapacityScheduler(计算能力调度)、FairScheduler(公平调度)：</p><p>　　相同点：</p><p>　　　　(1)都是多队列。</p><p>　　　　(2)都有资源最大最小上线限制。</p><p>　　　　(3)都是资源共享，每个队列剩余的资源可以给其他队列使用。</p><p>　　不同点：</p><p>　　　　(1)队列排序算法不同：计算能力调度资源使用量小的优先。公平调度根据公平排序算法排序。</p><p>　　　　(2)应该用选择算法不同：计算能力调度是先进先出。公平调度先进先出或者公平排序算法。</p><p>　　　　(3)资源抢占：公平调度如果当前队列有新应用提交后，会把共享出去的资源抢夺回来。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-MapReduce</title>
      <link href="/2022/05/26/Hadoop-MapReduce/"/>
      <url>/2022/05/26/Hadoop-MapReduce/</url>
      
        <content type="html"><![CDATA[<h3 id="一、MapReduce设计理念"><a href="#一、MapReduce设计理念" class="headerlink" title="一、MapReduce设计理念"></a>一、MapReduce设计理念</h3><blockquote><p>map—&gt;映射</p><p>reduce—&gt;归纳</p><p>mapreduce必须构建在hdfs之上的一种大数据离线计算框架</p><p>​        在线：实时数据处理</p><p>​        离线：数据处理时效性没有在线那么强，但是相对也需要很快得到结果</p><p>mapreduce不会马上得到结果，他会有一定的延时（磁盘IO）</p><p>​        如果数据量小，使用mapreduce反而不合适</p><p>​        杀鸡焉用宰牛刀</p><p>原始数据–&gt;map(Key,Value)–&gt;Reduce</p><p>分布式i计算</p><p>​        将大的数据切分成多个小数据，交给更多的节点参与运算</p><p>计算向数据靠拢</p><p>​        将计算传递给有数据的节点上进行工作</p></blockquote><h3 id="二、MapReduce架构特点"><a href="#二、MapReduce架构特点" class="headerlink" title="二、MapReduce架构特点"></a>二、MapReduce架构特点</h3><h4 id="MapReduce1-x"><a href="#MapReduce1-x" class="headerlink" title="MapReduce1.x"></a>MapReduce1.x</h4><blockquote><p><strong>JobTracker</strong></p><p>　　　主节点，单点，负责调度所有的作用和监控整个集群的资源负载。</p><p><strong>TaskTracker</strong></p><p>　　　从节点，自身节点资源管理和JobTracker进行心跳联系，汇报资源和获取task。</p><p><strong>Client</strong></p><p>　　　以作业为单位，规划作业计算分布，提交作业资源到HDFS，最终提交作业到JobTracker。</p><h5 id="MapReduce1-x的弊端"><a href="#MapReduce1-x的弊端" class="headerlink" title="MapReduce1.x的弊端"></a>MapReduce1.x的弊端</h5><p>　　1.JobTracker负载过重，存在单点故障。</p><p>　　2.资源管理和计算调度强耦合，其它计算框架难以复用其资源管理。</p><p>　　3.不同框架对资源不能全局管理。</p></blockquote><h4 id="MapReduce2-x"><a href="#MapReduce2-x" class="headerlink" title="MapReduce2.x"></a>MapReduce2.x</h4><blockquote><p>ResourceManager</p><p>　　　主节点，负责整个集群的资源管理。</p><p>NodeManager</p><p>　　　与ResourceManager汇报资源，管理Container生命周期，计算框架中的角色都以Container表示。</p><p>Container</p><p>　　　默认NodeManager启动线程监控Container大小，超出申请资源额度会kill掉。支持Linux内核的Cgroup。</p><p>Client</p><p>　　　ResourceManager-client：请求资源创建ApplicationMaster-client。</p><p>　　　ApplicationMaster-client：与ApplicationMaster交互。</p><p><strong>YARN【Yet Another Resource Negotiator】：Hadoop 2.0新引入的资源管理系统，直接从MRv1演化而来的。</strong></p><p><strong>核心思想：将MRv1中JobTracker的资源管理和任务调度两个功能分开，分别由ResourceManager和ApplicationMaster进程实现：</strong></p><p>　　　ResourceManager：负责整个集群的资源管理和调度。</p><p>　　　ApplicationMaster：负责应用程序相关的事务，比如任务调度、任务监控和容错等。</p><p>YARN的引入，使得多个计算框架可运行在一个集群中 每个应用程序对应一个ApplicationMaster 目前多个计算框架可以运行在YARN上，比如MapReduce、Spark、Storm等。</p></blockquote><h3 id="三、扑克牌的问题"><a href="#三、扑克牌的问题" class="headerlink" title="三、扑克牌的问题"></a>三、扑克牌的问题</h3><p><strong>你想数出一摞牌中有多少张黑桃，红桃，方块，梅花。直观方式是一张一张检查并且数出分别有多少张。</strong><br><strong>MapReduce方法则是：</strong><br>        1.给在座的所有玩家中分配这摞牌<br>        2.让每个玩家数自己手中的牌有几张是黑桃，然后把这个数目汇报给你<br>        3.你把所有玩家告诉你的数字加起来，得到最后的结论</p><h3 id="四、MR的计算流程"><a href="#四、MR的计算流程" class="headerlink" title="四、MR的计算流程"></a>四、MR的计算流程</h3><h4 id="4-1-原始数据File-可以从网上找一篇英文的文章"><a href="#4-1-原始数据File-可以从网上找一篇英文的文章" class="headerlink" title="4.1    原始数据File(可以从网上找一篇英文的文章)"></a>4.1    原始数据File(可以从网上找一篇英文的文章)</h4><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">The books chronicle the adventures of the adolescent wizard Harry Potter and his best friends Ron Weasley and Hermione Granger, all of whom are students at Hogwarts School of Witchcraft and Wizardry. </span><br></pre></td></tr></table></figure><blockquote><p>1T数据被切分成块存放在HDFS上，每一个块有128M大小</p></blockquote><h4 id="4-2-数据块Block"><a href="#4-2-数据块Block" class="headerlink" title="4.2    数据块Block"></a>4.2    数据块Block</h4><blockquote><p>block块是hdfs上存储的一个单元，同一个文件块的大小都是相同</p><p>因为数据存储到HDFS上不可变，所以有可能快的数量和集群的计算能力不匹配</p><p>我们需要一个动态调整本次参与计算节点数量的单位</p><p>我们可以动态的改变这个单位—&gt;参与的节点</p></blockquote><h4 id="5-3-切片Split"><a href="#5-3-切片Split" class="headerlink" title="5.3    切片Split"></a>5.3    切片Split</h4><blockquote><p>目的：动态地控制计算单元的数量 </p></blockquote><blockquote><p>切片是个逻辑概念</p><p>在不改变现有数据存储的情况下，可以控制参与计算的节点数目</p><p>通过切片大小可以达到控制计算节点数量的目的</p></blockquote><p><strong>有多少切片就会有多少个Map任务</strong></p><blockquote><p>一般切片大小为Block的整数倍（2    1&#x2F;2）</p><p>防止多余创建和很多的数据连接</p><p>如果Split大小 &gt; Block大小，计算节点少了  </p><p>如果Split大小 &lt; Block大小，计算节点多了</p><p>默认情况下，Split切片的大小等于Block的大小，默认128M，如果读取到最后一个block块的时候，与前一个block块组合起来大小小于128*1.1M的话，它们会结合生成一个Split切片，生成一个map任务</p><p>一个切片对应一个MapTask</p></blockquote><h4 id="4-4-MapTask"><a href="#4-4-MapTask" class="headerlink" title="4.4    MapTask"></a>4.4    MapTask</h4><blockquote><p>map默认从所属切片读取数据，每次读取一行（默认读取器）到内存中（map中的逻辑作用在每一行上）我们可以根据自己书写的分词逻辑（空格，逗号等分隔符），计算每个单词出现的次数 （wordcount），这时会产生（map &lt;String，Integer&gt;）临时数据，存放带内存中</p></blockquote><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">the books chronicle the adventures of the adolescent wizard Harry Potter and his best friends Ron Weasley and Hermione Granger, all of whom are students at Hogwarts School of Witchcraft and Wizardry</span><br><span class="line"></span><br><span class="line">the 1</span><br><span class="line">books 1</span><br><span class="line">chronicle 1</span><br><span class="line">the 1</span><br><span class="line">adventures 1</span><br><span class="line">of 1</span><br><span class="line">...</span><br><span class="line">Wizardry 1</span><br></pre></td></tr></table></figure><blockquote><p>但是内存的大小是有限的，如果每个任务随机的去占用内存，会导致内存不可控。多个任务同时执行有可能内存溢出（OOM）</p><p>如果把数据都直接放到硬盘上，效率低</p><p>考虑到把内存和硬盘结合，可以先往内存中写入一部分数据，然后写到硬盘上</p></blockquote><h4 id="4-5-环形缓冲区（KV-Buffer）"><a href="#4-5-环形缓冲区（KV-Buffer）" class="headerlink" title="4.5    环形缓冲区（KV-Buffer）"></a>4.5    环形缓冲区（KV-Buffer）</h4><blockquote><p>可以循环利用这块内存区域，减少数据溢写时map的停止时间</p><p>每一个Map可以独享的一个内存区域</p><p>在内存中构建一个环形缓冲区（kv-Buffer），默认大小为100M</p><p>设置缓冲区的阈值为80%（设置阈值的目的是为了同时写入和写出），当缓冲区的数据达到80M开始溢写到硬盘</p><p>溢写的时候有20M的空间可以被使用并且使用效率不会被减缓，不用担心出现OOM问题</p></blockquote><h4 id="4-6-分区Partition（环形缓冲区做的）"><a href="#4-6-分区Partition（环形缓冲区做的）" class="headerlink" title="4.6    分区Partition（环形缓冲区做的）"></a>4.6    分区Partition（环形缓冲区做的）</h4><blockquote><p>根据Key直接计算出对应的Reduce</p><p>分区的数量和reduce的数量是相等的</p><p>hash(key) % partition(reduce的数量) &#x3D; num</p><p>默认分区的算法是Hash然后取余</p><p>Object的hashCode()—equals()</p><p>如果两个对象equals，那么两个对象的hashcode一定相等</p><p>如果两个对象的hashcode相等，但是对象不一定equals</p></blockquote><h4 id="4-7-排序Sort（环形缓冲区做的，快速排序，对前面分区后的编号进行排序，目的是使得相同编号在一起）"><a href="#4-7-排序Sort（环形缓冲区做的，快速排序，对前面分区后的编号进行排序，目的是使得相同编号在一起）" class="headerlink" title="4.7    排序Sort（环形缓冲区做的，快速排序，对前面分区后的编号进行排序，目的是使得相同编号在一起）"></a>4.7    排序Sort（环形缓冲区做的，快速排序，对前面分区后的编号进行排序，目的是使得相同编号在一起）</h4><blockquote><p>对要溢写的数据进行排序（QuickSort）</p><p>按照先Partition后Key的顺序排序–&gt;相同分区在一起，相同Key的在一起</p><p>将来溢写出来的小文件也是有序的</p></blockquote><h4 id="4-8-溢写Spill"><a href="#4-8-溢写Spill" class="headerlink" title="4.8    溢写Spill"></a>4.8    溢写Spill</h4><blockquote><p>将内存中的数据循环写到硬盘上，无需担心OOM问题</p><p>每次会产生一个80M的文件</p><p>如果本次Map产生的数据较多，可能会溢写多个文件</p></blockquote><h4 id="4-9-合并Merge"><a href="#4-9-合并Merge" class="headerlink" title="4.9    合并Merge"></a>4.9    合并Merge</h4><blockquote><p>因为溢写会产生很多有序（分区 key）的小文件，而且小文件的数目也不确定</p><p>后面向reduce传递数据带来很大问题</p><p>所以将小文件合并成一个大文件，将来来取得数据直接从大文件拉去即可 </p><p>合并小文件的时候同样进行排序（<strong>归并排序</strong>），最终产生一个有序的大文件</p></blockquote><h4 id="4-10-组合器Combiner"><a href="#4-10-组合器Combiner" class="headerlink" title="4.10 组合器Combiner"></a>4.10 组合器Combiner</h4><blockquote><p>a.    集群的带宽限制了mapreduce作业的数量 ，因此应该尽量避免map和reduce任务之间的数据传输，hadoop允许用户对map的输出数据进行处理，用户可自定义combiner函数（如同map函数和reduce函数一般），其逻辑一般和reduce函数一样，combiner的输入是map的输出，combiner的输出作为reduce的输入，很多情况下可以直接将reduce函数作为combiner函数来试用</p><p>（job.setCombinerClass(FlowCountReducer.class)）</p><p>b.    combiner属于优化方案，所以无法确定combiner函数会调用多少次，可以在环形缓冲区溢出文件时调用combiner函数，也可以在溢出的小文件合并成大文件时调用combiner，但是要保证不管调用多少次，combiner函数都不影响最终结果，所以不是所有处理逻辑都可以使用combiner组件，有些逻辑如果使用了combiner函数会影响最后reduce的输出结果（如求几个数的平均值，就不能先用combiner求一次各个map输出结果的平均值，再求这些平均值的平均值，那样会导致结果错误）</p><p>c.  combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量：</p><p>​        原先传给reduce的数据时a1 a1 a1 a1 a1</p><p>​        第一次combiner组合后变成a(1,1,1,1,1)</p><p>​        第二次combiner后传给reduce的数据变为a(5,5,6,7,23,…)</p></blockquote><h4 id="4-11-拉取Fetch"><a href="#4-11-拉取Fetch" class="headerlink" title="4.11    拉取Fetch"></a>4.11    拉取Fetch</h4><blockquote><p>我们需要将Map的临时结果拉取到Reduce节点</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;第一种方式：两两合并</span><br><span class="line">&gt;第二种方式：相同的进一个reduce</span><br><span class="line">&gt;第三种对第二种优化，排序</span><br><span class="line">&gt;第四种对第三种优化：如果一个reduce处理两种key，而key分布一个首一个尾，解决不连续的问题，给个编号，这个编号怎么算呢，`回到分区，排序`</span><br></pre></td></tr></table></figure><p>第一种方式：两两合并<br>第二种方式：相同的进一个reduce<br>第三种对第二种优化，排序<br>第四种对第三种优化：如果一个reduce处理两种key，而key分布一个首一个尾，解决不连续的问题，给个编号，这个编号怎么算呢，<code>回到分区，排序</code></p></blockquote><h4 id="4-12-合并Merge"><a href="#4-12-合并Merge" class="headerlink" title="4.12    合并Merge"></a>4.12    合并Merge</h4><blockquote><p>因为reduce拉取的时候，会从多个map拉取数据</p><p>那么每个map都会产生一个小文件,这些小文件（文件与文件之间无序，文件内部有序）</p><p>为了方便计算（没必要读取N个小文件）,需要合并文件</p><p>归并算法合并成2个(qishishilia)</p><p>相同的key都在一起</p></blockquote><h4 id="4-13-归并Reduce"><a href="#4-13-归并Reduce" class="headerlink" title="4.13    归并Reduce"></a>4.13    归并Reduce</h4><blockquote><p>将文件中的数据读取到内存中</p><p>一次性将相同的key全部读取到内存中</p><p>直接将相同的key得到结果-&gt;最终结果 </p></blockquote><h4 id="4-14-写出Output"><a href="#4-14-写出Output" class="headerlink" title="4.14    写出Output"></a>4.14    写出Output</h4><blockquote><p>每个reduce将自己计算的最终结果都会存放到HDFS上</p></blockquote><p><img src="https://s2.loli.net/2022/05/26/QXb2lUNZsR7PB8g.png" alt="image-20220526222212188"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop高可用集群搭建（HA）</title>
      <link href="/2022/05/25/Hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88HA%EF%BC%89/"/>
      <url>/2022/05/25/Hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88HA%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="1、zookeeper搭建"><a href="#1、zookeeper搭建" class="headerlink" title="1、zookeeper搭建"></a>1、zookeeper搭建</h3><p>1、上传安装包到master并解压<br>    tar -xvf zookeeper-3.4.6.tar.gz</p><p>2、配置环境变量<br>    vim &#x2F;etc&#x2F;profile</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/usr/local/soft/zookeeper-3.4.6</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br><span class="line"></span><br><span class="line">别忘记source /etc/profile</span><br></pre></td></tr></table></figure><p>3、修改配置文件<br>    cd conf<br>    cp  zoo_sample.cfg zoo.cfg</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">修改</span><br><span class="line">dataDir=/usr/local/soft/zookeeper-3.4.6/data</span><br><span class="line"></span><br><span class="line">增加</span><br><span class="line">server.0=master:2888:3888</span><br><span class="line">server.1=node1:2888:3888</span><br><span class="line">server.2=node2:2888:3888</span><br></pre></td></tr></table></figure><p>4、同步到其它节点</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r zookeeper-3.4.6 node1:`pwd`</span><br><span class="line">scp -r zookeeper-3.4.6 node2:`pwd`</span><br><span class="line"></span><br><span class="line">配置node1和node2的环境变量</span><br><span class="line">scp /etc/profile node1:/etc/</span><br><span class="line">scp /etc/profile node2:/etc/</span><br><span class="line"></span><br><span class="line">在所有节点执行</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>5、创建&#x2F;usr&#x2F;local&#x2F;soft&#x2F;zookeeper-3.4.6&#x2F;data目录,所有节点都要创建</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /usr/local/soft/zookeeper-3.4.6/data</span><br><span class="line"></span><br><span class="line">在data目录下创建myid文件</span><br><span class="line">vim myid </span><br><span class="line">master,node1,node2分别加上0，1，2</span><br></pre></td></tr></table></figure><p>6、启动zk，</p><pre><code>zkServer.sh start  三台都需要执行zkServer.sh status 查看状态当有一个leader的时候启动成功</code></pre><p>连接zk</p><pre><code>zkCli.shzk  是一个目录结构 ，每个节点可以存数据，同时可以有子节点</code></pre><p>zk shell</p><pre><code>创建目录create /test testcreate /test/a 1获取数据get /test ls /testdelete 只能删除没有子节点的节点rmr /test  删除节点</code></pre><p><strong>关闭命令</strong></p><p>zkServer.sh stop</p><p><strong>拍摄快照</strong></p><p><strong>重置zk</strong><br>1、杀掉所有zk进程<br>kiil -9 pid</p><p>2、删除data目录下的version文件, 所有节点都要删除<br>rm -rf &#x2F;usr&#x2F;local&#x2F;soft&#x2F;zookeeper-3.4.6&#x2F;data&#x2F;version-2</p><p>2、启动zk<br>zkServer.sh start</p><h3 id="2、Hadoop-HA"><a href="#2、Hadoop-HA" class="headerlink" title="2、Hadoop-HA"></a>2、Hadoop-HA</h3><table><thead><tr><th></th><th>ZK</th><th>NN</th><th>DN</th><th>RN</th><th>NM</th><th>JN</th><th>ZKFC</th></tr></thead><tbody><tr><td>master</td><td>1</td><td>1</td><td></td><td>1</td><td></td><td>1</td><td>1</td></tr><tr><td>node1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td>node2</td><td>1</td><td></td><td>1</td><td></td><td>1</td><td></td><td></td></tr></tbody></table><h4 id="防火墙、时间同步、免密配置操作不再赘述"><a href="#防火墙、时间同步、免密配置操作不再赘述" class="headerlink" title="防火墙、时间同步、免密配置操作不再赘述"></a>防火墙、时间同步、免密配置操作不再赘述</h4><p>1、修改hadoop配置文件</p><p><strong>core-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hadoop-2.7.6/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,node1:2181,node2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>hdfs-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs元数据存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hadoop-2.7.6/data/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs数据存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hadoop-2.7.6/data/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 数据备份的个数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 关闭权限验证 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启WebHDFS功能（基于REST的接口服务） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- //////////////以下为HDFS HA的配置////////////// --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hdfs的nameservices名称为mycluster --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定cluster的两个namenode的名称分别为nn1,nn2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.cluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置nn1,nn2的rpc通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.cluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.cluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置nn1,nn2的http通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.cluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.cluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定namenode元数据存储在journalnode中的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://master:8485;node1:8485;node2:8485/cluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定journalnode日志文件存储的路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/soft/hadoop-2.7.6/data/journal<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定HDFS客户端连接active namenode的java类 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.cluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置隔离机制为ssh --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定秘钥的位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>yarn-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- NodeManager上运行的附属服务，需配置成mapreduce_shuffle才可运行MapReduce程序 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置Web Application Proxy安全代理（防止yarn被攻击） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.web-proxy.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置日志删除时间为7天，-1为禁用，单位为秒 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 修改日志目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置nodemanager可用的资源内存 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置nodemanager可用的资源CPU --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- //////////////以下为YARN HA的配置////////////// --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启YARN HA --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 启用自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN HA的名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarncluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定两个resourcemanager的名称 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置rm1，rm2的主机 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置YARN的http端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置zookeeper的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>master:2181,node1:2181,node2:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置zookeeper的存储位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-state-store.parent-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/rmstore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启yarn resourcemanager restart --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置resourcemanager的状态存储到zookeeper中 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启yarn nodemanager restart --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置nodemanager IPC的通信端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.0.0.0:45454<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>mapred-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定MapReduce计算框架使用YARN --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定jobhistory server的rpc地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定jobhistory server的http地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启uber模式（针对小作业的优化） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置启动uber模式的最大map数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>9<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置启动uber模式的最大reduce数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxreduces<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、删除hadoop数据存储目录下的文件  每个节点都需要删除</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /usr/local/soft/hadoop-2.7.6/tmp</span><br></pre></td></tr></table></figure><p>3、启动zookeeper<strong>三台都需要启动</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">zkServer.sh start启动</span><br><span class="line">zkServer.sh status查看状态</span><br></pre></td></tr></table></figure><p>4、启动 JN 存储hdfs元数据</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start journalnode每个节点都要执行</span><br></pre></td></tr></table></figure><p> 5、格式化 在一台NN上执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format在master上执行</span><br></pre></td></tr></table></figure><p>6、启动当前的NN</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode在master上执行</span><br></pre></td></tr></table></figure><p>7、执行同步 没有格式化的NN上执行  在另外一个namenode上面执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs namenode -bootstrapStandby在node1上执行</span><br></pre></td></tr></table></figure><p>8、格式化ZK   在已经启动的namenode上面执行<br>    <strong>！！一定要先 把zk集群正常 启动起来！！</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs zkfc -formatZKmaster上执行</span><br></pre></td></tr></table></figure><p>9、启动hdfs集群,在启动了namenode的节点上执行</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">start-dfs.shmaster上执行</span><br></pre></td></tr></table></figure><h3 id="3、Hadoop-HA遇到的问题"><a href="#3、Hadoop-HA遇到的问题" class="headerlink" title="3、Hadoop-HA遇到的问题"></a>3、Hadoop-HA遇到的问题</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dfs.ha.fencing.methods</span><br><span class="line">表示：a list of scripts or Java classes which will be used to fence the Active NameNode during a failover</span><br><span class="line"></span><br><span class="line">而配置为shell(true)就是直接返回隔离成功，即表示没进行任何操作，为什么不会导致脑裂现象的发生，这是因为Quorun Journal方式内置了fencing功能，不需要实现单独的fencing机制（epoch number解决互斥问题）。</span><br><span class="line">而如果使用共享存储NAS+NFS那种方式的话，就需要配置具体的真正有fencing功能的，比如：sshfence，下面是sshfence的说明：</span><br><span class="line"></span><br><span class="line">sshfence - SSH to the Active NameNode and kill the process</span><br><span class="line">The sshfence option SSHes to the target node and uses fuser to kill the process listening on the service’s TCP port. In order for this fencing option to work, it must be able to SSH to the target node without providing a passphrase. Thus, one must also configure the dfs.ha.fencing.ssh.private-key-files option, which is a comma-separated list of SSH private key files. 即配置sshfence需要两个namenode之间配置无密码认证，如下:(hdfs-site.xml)</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;sshfence&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">但如果只配置sshfence，如果在机器宕机后不可达，则sshfence会返回false，即fence失败，所以得要配置成：</span><br><span class="line"></span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;</span><br><span class="line">            sshfence</span><br><span class="line">            shell(/bin/true)</span><br><span class="line">        &lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">这样子配置，顺序执行时，如果可达就执行sshfence执行杀死namenode后返回true，不可达就直接shell(true)返回true。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop进程相关</title>
      <link href="/2022/05/24/Hadoop%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/"/>
      <url>/2022/05/24/Hadoop%E8%BF%9B%E7%A8%8B%E7%9B%B8%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<h3 id="1、进程理解"><a href="#1、进程理解" class="headerlink" title="1、进程理解"></a>1、进程理解</h3><h4 id="HDFS相关（NN、DN、SNN）"><a href="#HDFS相关（NN、DN、SNN）" class="headerlink" title="HDFS相关（NN、DN、SNN）"></a>HDFS相关（NN、DN、SNN）</h4><h5 id="NameNode（NN）"><a href="#NameNode（NN）" class="headerlink" title="NameNode（NN）"></a>NameNode（NN）</h5><p><img src="https://s2.loli.net/2022/05/24/OAdzRlIwaLnFTB7.png" alt="image-20220524205656034"></p><blockquote><p>功能：</p><p>​    1、接收客户端的读&#x2F;写服务    因为NN知道数据文件与DN的对应（映射）关系</p><p>​    2、保存文件的时候会保存文件的元数据信息</p><p>​            a、文件的归属</p><p>​            b、文件的权限</p><p>​            c、文件的大小 、时间</p><p>​            d、Block块的信息，但是Block块的位置信息不会持久化，需要每次开启集群的时候DN向NN汇报。</p><p>​    3、收集Block块的位置信息</p><p>​        3.1    系统启动</p><p>​            a、NN关机的时候不会存储任何的Block块与DN的映射信息</p><p>​            b、DN启动的时候会自动将自己节点上存储的Block块信息汇报给NN</p><p>​            c、NN接收请求之后会重新生成映射关系</p><p>​                        File –&gt;Block</p><p>​                        Block–&gt;DN</p><p>​            d、如果数据块的副本数小于设置数，NN会将整个副本拷贝到其他节点</p><p>​        3.2    集群运行中</p><p>​            a、NN与DN保持心跳机制，三秒钟发送一次</p><p>​            b、如果客户端需要读取或者上传数据的时候，NN可以知道DN的健康情况</p><p>​            c、可以让客户端读取存活的DN节点</p><p>​            d、如果NN与DN三秒没有心跳反馈，就会认为DN出现异常（掉线），此时不会让新的数据写到这个异常的DN中，客户端访问的时候不提供异常的DN节点地址</p><p>​            e、如果超过十分钟没有心跳，那么NN会认为它宕机，会将当前DN节点存储的数据转移到其他节点</p><p>​    4、NameNode为了效率，将所有操作都在内存中进行</p><p>​        a、执行速度快</p><p>​        b、NameNode不会和磁盘进行任何的数据交换</p><p>​        但是会存在两个问题：</p><p>​        1、数据的持久化</p><p>​        2、数据保存在内存中，断电会丢失</p></blockquote><h5 id="DataNode（DN）"><a href="#DataNode（DN）" class="headerlink" title="DataNode（DN）"></a>DataNode（DN）</h5><blockquote><p>1、存放的是文件的数据信息，以及验证文件完整性的校验信息 </p><p>2、数据会存放在硬盘上</p><p>​        a、1m&#x3D;1条数据</p><p>​        b、1G&#x3D;1条数据</p><p>​        c、NN非常排斥存储小文件（能存，但是不推荐）</p><p>​            一般小文件在存储之前需要进行压缩</p><p>3、汇报</p><p>​        1、启动时</p><p>​                汇报之前会先验证Block文件是否损坏</p><p>​                向NN汇报当前DN上Block的信息</p><p>​        2、运行时</p><p>​                向NN保持心跳机制</p><p>4、当客户端读写数据的时候，首先会先去查询file与block与DN的映射，然后客户端直接与DN建立连接，然后读写数据</p></blockquote><h5 id="SecondaryNameNode（SNN）"><a href="#SecondaryNameNode（SNN）" class="headerlink" title="SecondaryNameNode（SNN）"></a>SecondaryNameNode（SNN）</h5><blockquote><h5 id="1、传统的内存持久化方案"><a href="#1、传统的内存持久化方案" class="headerlink" title="1、传统的内存持久化方案"></a>1、传统的内存持久化方案</h5><p>​    1）日志机制</p><p>​            a、做任何操作之前先记录日志</p><p>​            b、在数据改变之前先记录对应的日志，当NN停止的时候</p><p>​            c、当我下次启动的时候，只需要重新按照以前的日志”重做一遍”即可</p><p>​            <strong>缺点：</strong></p><p>​                a、log日志文件的大小不可控，随着时间的变化，集群启动的时间也会越来越长</p><p>​                b、日志中会存在大量无效日志</p><p>​            <strong>优点：</strong></p><p>​                a、不会丢失数据</p><h5 id="2）拍摄快照"><a href="#2）拍摄快照" class="headerlink" title="2）拍摄快照"></a>2）拍摄快照</h5><p>​            a、将内存中的数据写到硬盘上（序列化）</p><p>​            b、启动时还可以将硬盘上的数据写回到内存中（反序列化）</p><p>​            <strong>缺点</strong></p><p>​                a、关机时间长</p><p>​                b、如果时异常关机，数据还在内存中，没法写入到硬盘</p><p>​                c、如果写出的频率过高，导致内存使用效率低</p><p>​            <strong>优点</strong></p><p>​                启动时间较短</p><h5 id="2、SNN的解决方案"><a href="#2、SNN的解决方案" class="headerlink" title="2、SNN的解决方案"></a>2、SNN的解决方案</h5><p>​    1）解决思路</p><p>​            a、让日志大小可控（每64M）</p><p>​            b、快照需要定时保存（每隔1h）</p><p>​            c、日志+快照</p><p>​    2）解决方案 </p><p>​            a、当我们启动一个集群的时候，会产生4个文件 …&#x2F;name&#x2F;current&#x2F;</p><p><img src="https://s2.loli.net/2022/05/24/Us7rSuhcvWiNzdJ.png" alt="image-20220524222400282"></p><p>​            b、我们每次操作都会记录日志–&gt;edits-inprogress- edits_00000001，随着时间的推移，日志文件会越来越大-当达到阈值的时候（64M或3600秒），会生成新的日志文件，edits_inprogress-000000001 –&gt;edits_0000001，创建新的日志文件 edits_inprogress-0000000016。</p><p><img src="https://s2.loli.net/2022/05/24/N5eijCIE2SUzJ7v.png" alt="image-20220524222453522"></p></blockquote><h3 id="2、安全模式"><a href="#2、安全模式" class="headerlink" title="2、安全模式"></a>2、安全模式</h3><blockquote><p>安全模式是 HDFS 的一种工作状态，处于安全模式的状态下，只向客户端提供文件的只读视图，不接受对命名空间的修改；同时 NameNode 节点也不会进行数据块的复制或者删除，<br><strong>NameNode 启动时，</strong><br>        1）首先将镜像文件（ fsimage ）载入内存，并执行编辑日志（ edits ）中的各项操作。<br>        2）一旦在内存中成功建立文件系统元数据的映射，则创建一个新的 fsimage 文件和一个空的编辑日志。<br>        3）NameNode 开始监听 RPC 和 Http 请求。<br>        4）此时 NameNode 处于<strong>安全模式</strong>，只接受客户端的读请求。</p><p>​        5）处于这个状态是为了保护数据的安全所以只能被客户端访问读取数据</p></blockquote><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 对安全模式的理解</span></span><br><span class="line"><span class="section"># 1.工作流程</span></span><br><span class="line"><span class="code">a.启动 NameNode，NameNode 加载 fsimage 到内存，对内存数据执行 edits log 日 志中的事务操作。</span></span><br><span class="line"><span class="code">b.文件系统元数据内存镜像加载完毕，进行 fsimage 和 edits log 日志的合并，并创 建新的 fsimage 文件和一个空的 edits log 日志文件。</span></span><br><span class="line"><span class="code">c.NameNode 等待 DataNode 上传 block 列表信息，直到副本数满足最小副本条件。</span></span><br><span class="line"><span class="code">d.当满足了最小副本条件，再过 30 秒，NameNode 就会退出安全模式。最小副本条件指 整个文件系统中有 99.9%的 block 达到了最小副本数（默认值是 1，可设置）</span></span><br><span class="line"><span class="code"># 在 NameNode 安全模式（safemode）</span></span><br><span class="line"><span class="code">对文件系统元数据进行只读操作</span></span><br><span class="line"><span class="code">当文件的所有 block 信息具备的情况下，对文件进行只读操作</span></span><br><span class="line"><span class="code">不允许进行文件修改（写，删除或重命名文件）</span></span><br><span class="line"><span class="code"># 2.注意事项</span></span><br><span class="line"><span class="code">a.NameNode 不会持久化 block 位置信息；DataNode 保有各自存储的 block 列表信息。 正常操作时，NameNode 在内存中有一个 blocks 位置的映射信息（所有文件的所有文 件块的位置映射信息）。</span></span><br><span class="line"><span class="code">b.NameNode 在安全模式，NameNode 需要给 DataNode 时间来上传 block 列表信息到 NameNode。如果 NameNode 不等待 DataNode 上传这些信息的话，则会在 DataNode 之间进行 block 的复制，而这在大多数情况下都是非必须的（因为只需要等待 DataNode 上传就行了），还会造成资源浪费。</span></span><br><span class="line"><span class="code">c.在安全模式 NameNode 不会要求 DataNode 复制或删除 block。</span></span><br><span class="line"><span class="code">d.新格式化的 HDFS 不进入安全模式，因为 DataNode 压根就没有 block。</span></span><br><span class="line"><span class="code"># 4.命令操作</span></span><br><span class="line"><span class="code"># 通过命令查看 namenode 是否处于安全模式：</span></span><br><span class="line"><span class="code">hdfs dfsadmin -safemode get</span></span><br><span class="line"><span class="code">Safe mode is ON HDFS 的前端 webUI 页面也可以查看 NameNode 是否处于安全模式。 有时候我们希望等待安全模式退出，之后进行文件的读写操作，尤其是在脚本中，此时：</span></span><br><span class="line"><span class="code">`hdfs dfsadmin -safemode wait`</span></span><br><span class="line"><span class="code"># your read or write command goes here 管理员有权在任何时间让 namenode 进入或退出安全模式。进入安全模式：</span></span><br><span class="line"><span class="code">`hdfs dfsadmin -safemode enter`</span></span><br><span class="line"><span class="code">Safe mode is ON 这 样 做 可 以 让 namenode 一 直 处 于 安 全 模 式 ， 也 可 以 设 置 `dfs.namenode.safemode.threshold-pct` 为 1 做到这一点。 离开安全模式：</span></span><br><span class="line"><span class="code">`hdfs dfsadmin -safemode leave`</span></span><br><span class="line"><span class="code">Safe mode is OFF</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>系统中的数据块的位置并不是由 NameNode 维护的，而是以块列表的形式存储在 DataNode 中。</strong><br>[root@node01 ~]# rm -rf &#x2F;var&#x2F;yjx&#x2F;hadoop&#x2F;full&#x2F;dfs&#x2F;name&#x2F;current&#x2F;*<br>[root@node01 ~]# scp -r<br>root@node02:&#x2F;var&#x2F;yjx&#x2F;hadoop&#x2F;full&#x2F;dfs&#x2F;namesecondary&#x2F;current&#x2F;*<br>&#x2F;var&#x2F;yjx&#x2F;hadoop&#x2F;full&#x2F;dfs&#x2F;name&#x2F;current </p><p><strong>安全模式下</strong><br>        a. 安全模式下，各个 DataNode 会向 NameNode 发送自身的数据块列表<br>        b. 当 NameNode 有足够的数据块信息后，便在 30 秒后退出安全模式<br>        c. NameNode 发现数据节点过少会启动数据块复制过程<br><strong>如果 NN 收集的 Block 信息没有达到最少副本数，就会将缺失的副本 , 从有的 DN 上拷贝到其他 DN</strong><br>        a. dfs.replication.min&#x3D;2<br>        b. 但是默认最低副本数为 1<br>        c. 在拷贝的过程中系统还是处于安全模式<br><strong>安全模式相关命令</strong><br>hadoop dfsadmin -safemode leave 强制 NameNode 退出安全模式<br>hadoop dfsadmin -safemode enter 进入安全模式<br>hadoop dfsadmin -safemode get 查看安全模式状态<br>hadoop dfsadmin -safemode wait 等待一直到安全模式结束</p></blockquote><h3 id="3、HDFS的权限"><a href="#3、HDFS的权限" class="headerlink" title="3、HDFS的权限"></a>3、HDFS的权限</h3><blockquote><p>HDFS对权限的控制</p><p>​        a. 只能防止好人做错事</p><p>​        b. 不能防止坏人做坏事</p><p><strong>但是告诉你是谁，他就认为你是谁！！</strong></p></blockquote><h3 id="4、机架感知"><a href="#4、机架感知" class="headerlink" title="4、机架感知"></a>4、机架感知</h3><blockquote><p>机架感知是为了保证副本在集群中的安全性<br>我们需要将节点放在不同的DN节点上，节点也需要一定的考量<br>     可靠性，可用性，带宽消耗<br>第一个节点：<br>     集群内部（优先考虑和客户端相同的节点作为第一个节点）<br>     集群外部（选择资源丰富且不繁忙的节点作为第一个节点）<br>第二个节点：<br>     第二个节点选择与第一个节点不同机架的其他节点<br>第三个节点：<br>     与第二个相同机架相同的其他节点<br>第N个节点：<br>     与前面节点不重复的其他节点</p></blockquote><h3 id="5、HDFS的读写流程（重点）"><a href="#5、HDFS的读写流程（重点）" class="headerlink" title="5、HDFS的读写流程（重点）"></a>5、HDFS的读写流程（重点）</h3><h4 id="写数据"><a href="#写数据" class="headerlink" title="写数据"></a>写数据</h4><blockquote><p> <strong>写数据就是将客户端上的数据上传到HDFS</strong></p><h4 id="宏观过程"><a href="#宏观过程" class="headerlink" title="宏观过程"></a>宏观过程</h4><p> <img src="https://s2.loli.net/2022/05/24/wTPqf3aR9eGsKv7.png" alt="image-20220524222751307"></p><p> <strong>1.客户端向HDFS发送写数据请求</strong></p><p>   hdfs dfs -put students.txt &#x2F;shujia&#x2F;</p><p> <strong>2. Filesystem通过rpc调用namenode的put方法</strong></p><p> a. nn首先检查是否有足够的空间权限等条件创建这个文件,或者这个路径是否已经存在，权限</p><p> b. 有：NN会针对这个文件创建一个空的Entry对象,并返回成功状态给DFS        </p><p> c. 没有：直接抛出对应的异常，给予客户端错误提示信息</p><p> <strong>3.如果DFS接收到成功的状态，会创建一个FSDataOutputStream的对象给客户端使用</strong></p><p> <strong>4.客户端要向nn询问第一个Block存放的位置</strong></p><p> ​    NN通过机架感知策略 (node1 node 2 node3)</p><p> <strong>5.需要将客户端和DN节点创建连接</strong></p><pre><code>pipeline(管道)客户端 和 node1 创建连接 socketnode1 和 node2 创建连接 socketnode2 和 Node3 创建连接 socket</code></pre><p> <strong>6.客户端按照文件块切分数据，但是按照packet发送数据</strong><br>    默认一个packet大小为64K,Block128M为2048个packet</p><p> <strong>7.客户端通过pipeline管道开始使用FDSOutputStream对象将数据输出</strong></p><pre><code>    1. 客户端首先将一个 packet 发送给 node1, 同时给予 node1 一个 ack 状态    2. node1接受数据后会将数据继续传递给 node2, 同时给予 node2 一个 ack 状态    3. node2接受数据后会将数据继续传递给 node3, 同时给予 node3 一个 ack 状态    4. node3将这个 packet 接受完成后，会响应这个 ack 给 node2 为 true    5. node2会响应给 node1 , 同理 node1 响应给客户端</code></pre><p> <strong>8.客户端接收到成功的状态 , 就认为某个 packet 发送成功了，直到当前块所有的 packet 都发送完成</strong></p><p> ​    1. 如果客户端接收到最后一个 pakcet 的成功状态 , 说明当前 block 传输完成，管道就会被撤销</p><p> ​    2. 客户端会将这个消息传递给 NN ， NN 确认传输完成</p><p> ​        1. NN会将 block 的信息记录到 Entry, 客户端会继续向 NN 询问第二个块的存储位置 , 依次类推</p><p> ​                block1 (node1 node2 node3)</p><p> ​                block2 (node1 node3 node6)</p><p> ​                ….</p><p> ​                blockn(node1 node4 node6)</p><pre><code> 3. 当所有的 block 传输完成后， NN 在 Entry 中存储所有的 File 与 Block 与 DN 的映射关系关闭FsDataOutPutStream</code></pre><h4 id="微观过程（如何保证package发送的时候不出错呢？）"><a href="#微观过程（如何保证package发送的时候不出错呢？）" class="headerlink" title="微观过程（如何保证package发送的时候不出错呢？）"></a>微观过程（如何保证package发送的时候不出错呢？）</h4><p> <strong>1.客户端首先从自己的硬盘中以流的形式将自己的数据读取到缓存中</strong><br> <strong>2.然后将缓存中的数据以chunk(512B)和checksum(4B)的方式放入到packet（64k)</strong></p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. chunk:checksum=128:1</span><br><span class="line">2. checksum:在数据处理和数据通信领域中，用于校验目的的一组数据项的和</span><br><span class="line">3. Packet中的数据分为两类，一类是实际数据包，另一类是 header 包。</span><br><span class="line">4. 一个 Packet 数据包的组成结构（分两类，一类是实际的数据包，另一类是header包。）</span><br></pre></td></tr></table></figure><p> <strong>一个数据包的组成结构：</strong></p><p> <img src="https://s2.loli.net/2022/05/24/jfzr86gaTiWdvlD.png" alt="image-20220524225301985"></p><p> <strong>参数理解：</strong></p><p> <img src="https://s2.loli.net/2022/05/24/yp9kOTUjeMYHxEZ.png" alt="image-20220524225333906"></p><p> <strong>3.（默认生成的快，发送的慢）当packet满的时候添加到dataqueue</strong><br> <strong>4.datastreamer开始从dataqueue队列上读取一个packet,通过FDSDataOPS发送到Poepleline</strong><br>     在取出的时候，也会将 packet 加入到 ackQueue, 典型的生产者消费者模式</p><p> ​    客户端发送一个 Packet 数据包以后开始接收 ack ，会有一个用来接收 ack 的 ResponseProcessor 进<br> 程，如果收到成功的 ack </p> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 如果某一个 packet 的 ack 为 true, 那么就从 ackqueue 删除掉这个 packet</span><br><span class="line">2. 如果某一个 packet 的 ack 为 false, 将 ackqueue 中所有的 packet 重新挂载到 发送队列 , 重新发送</span><br></pre></td></tr></table></figure><p> <img src="https://s2.loli.net/2022/05/24/1W63lkyhUTdDBGg.png" alt="image-20220524225407656"></p><p> <strong>最终DFS保存的数据格式：</strong></p><p> <img src="https://s2.loli.net/2022/05/24/9lJKUgNxXzPv16Q.png" alt="image-20220524225430756"></p><p> <strong>读数据</strong></p><p> <img src="https://s2.loli.net/2022/05/24/C9qYBsOL6RjZyM4.png" alt="image-20220524225514935"></p><p> <strong>1.首先客户端发送请求到 DFS ，申请读取某一个文件</strong><br> <strong>2.DFS 去 NN 查找这个文件的信息 ( 权限 , 文件是否存在 )</strong><br>     如果文件不存在，抛出指定的错误<br>     如果文件存在，返回成功状态<br> <strong>3.DFS 创建 FSDataInputStream 对象，客户端通过这个对象读取数据</strong><br> <strong>4.客户端获取文件第一个 Block 信息 , 返回 DN1 DN2 DN8</strong><br> <strong>5.客户端直接就近原则选择 DN1 对应的数据即可</strong><br> <strong>6.依次类推读取其他块的信息，直到最后一个块 , 将 Block 合并成一个文件</strong><br> <strong>7.关闭 FSDataInputStream</strong></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-2.7.6-基础</title>
      <link href="/2022/05/23/Hadoop-2.7.6-%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/05/23/Hadoop-2.7.6-%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<p>hadoop的<strong>特点</strong>：</p><p><strong>扩容能力</strong></p><p>扩容能力(Scalable)：能可靠(reliably)地存储和处理PB级别的数据。如果数据量更大，存储不下了,再增加节点就可以了。</p><p><strong>成本低</strong></p><p>成本低(Economical):可以通过普通机器组成的服务器集群来分发以及处理数据.这些服务器集群可达数千个节点。</p><p><strong>高效率</strong></p><p>高效率(Efficient):通过分发计算程序,hadoop可以在数据所在节点上(本地)并行地(parallel)处理他们,这使得处理非常的迅速</p><p><strong>可靠性</strong></p><p>可靠性(Reliable):hadoop能够自动地维护数据的多份副本,并且在任务失败后能够自动地重新部署(redeploy)计算任务</p><p>作者Doug Cutting 受Google三篇论文的启发，开发了hadoop</p><blockquote><p><strong>Google FS</strong></p><p><strong>MapReduce</strong></p><p><strong>BigTable</strong></p></blockquote><p>hadoop是一个统称，目前hadoop主要包含<strong>三大组件</strong></p><blockquote><p><strong>hdfs</strong>：是一个分布式存储框架，适合海量数据存储</p><p><strong>mapreduce</strong>：是一个分布式计算框架，适合海量数据计算</p><p><strong>yarn</strong>：是一个资源调度平台，负责给计算框架分配计算资源</p></blockquote><p>HDFS具有<strong>主从架构</strong>。HDFS集群由单个名称节点组成，主服务器管理文件系统名称空间并控制客户机对文件的访问。此外，还有许多数据节点，通常是集群中每个节点一个，它们管理连接到运行它们的节点的存储。</p><p><img src="https://s2.loli.net/2022/05/17/SODawkZY6AnX4RL.png" alt="image-20220517200532901"></p><p>hadoop的三种启动（停止）方式</p><p>第一种：全部启动集群所有进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动：sbin/start-all.sh</span><br><span class="line">停止：sbin/stop-all.sh</span><br></pre></td></tr></table></figure><p>第二种：单独启动hdfs【web端口50070】和【web端口8088】的相关进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动：sbin/start-dfs.sh sbin/start-yarn.sh</span><br><span class="line">停止：sbin/stop-dfs.sh  sbin/stop-yarn.sh</span><br><span class="line">**每次重新启动集群的时候使用**</span><br></pre></td></tr></table></figure><p>第三种：单独启动某一个进程</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">启动hdfs：sbin/hadoop-daemon.sh start (namenode | datanode)</span><br><span class="line">停止hdfs：sbin/hadoop-daemon.sh stop (namenode | datanode)</span><br><span class="line">启动yarn：sbin/hadoop-daemon.sh start (resourcemanager | nodemanager)</span><br><span class="line">停止yarn：sbin/hadoop-daemon.sh stop (resourcemanager | nodemanager)</span><br><span class="line">**用于当某个进程启动失败或者down掉的时候，重启进程**</span><br></pre></td></tr></table></figure><p><strong>hdfs shell</strong></p><p>调用文件系统(FS)Shell命令应使用 bin&#x2F;hdfs dfs -xxx 的形式。</p><p>所有的FS shell命令使用URI路径作为参数。</p><p>URI格式是scheme:&#x2F;&#x2F;authority&#x2F;path。HDFS的scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。</p><p>例如：&#x2F;parent&#x2F;child可以表示成hdfs:&#x2F;&#x2F;namenode:namenodePort&#x2F;parent&#x2F;child，或者更简单的&#x2F;parent&#x2F;child（假设配置文件是namenode:namenodePort）</p><p>大多数FS Shell命令的行为和对应的Linux Shell命令类似。</p><p>常用操作</p><p>-ls            查看hdfs上目录，如hdfs dfs -ls &#x2F;</p><p>-put         将本地文件上传到hdfs，如hdfs dfs -put 本地文件路径 hdfs路径</p><p>-get         将hdfs文件下载到本地，如hdfs dfs -get hdfs的文件路径 本地文件路径</p><p>-mkdir    在hdfs上创建文件夹，如hdfs dfs -mkdir &#x2F;test</p><p>-cp          将hdfs文件或目录复制，如hdfs dfs -cp &#x2F;test.txt &#x2F;a&#x2F;</p><p>-cat         查看hdfs上文件内容，如hdfs dfs -cat &#x2F;test.txt</p><p><strong>运行word count实例</strong></p><p>hadoop jar  &#x2F;usr&#x2F;local&#x2F;soft&#x2F;hadoop-2.7.6&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-2.7.6.jar wordcount  inputpath outputpath</p><p>运行结果：</p><p><img src="https://s2.loli.net/2022/05/17/ix2tcnZwKjelkMo.png" alt="image-20220517211619031"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群搭建（完全分布式）</title>
      <link href="/2022/05/22/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%89/"/>
      <url>/2022/05/22/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><ul><li><p>三台虚拟机：master、node1、node2</p></li><li><p>时间同步</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ntpdate ntp.aliyun.com</span><br></pre></td></tr></table></figure></li><li><p>调整时区</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp  /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime</span><br></pre></td></tr></table></figure></li><li><p>jdk1.8</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure></li><li><p>修改主机名</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">三台分别执行 vim /etc/hostname 并将内容指定为对应的主机名</span><br></pre></td></tr></table></figure></li><li><p>关闭防火墙：systemctl stop firewalld   </p><ul><li>查看防火墙状态：systemctl status firewalld </li><li>取消防火墙自启：systemctl disable firewalld</li></ul></li><li><p>静态IP配置（两种方式）</p><ul><li><p>1、直接使用图形化界面配置</p></li><li><p>2、手动编辑配置文件进行配置</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、编辑网络配置文件</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"></span><br><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">HWADDR=00:0C:29:E2:B8:F2</span><br><span class="line">NAME=ens33</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.190.100</span><br><span class="line">GATEWAY=192.168.190.2</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">DNS1=192.168.190.2</span><br><span class="line">DNS2=223.6.6.6</span><br><span class="line"></span><br><span class="line">需要修改：HWADDR（mac地址,centos7不需要手动指定mac地址）</span><br><span class="line">IPADDR（根据自己的网段，自定义IP地址）</span><br><span class="line">GATEWAY（根据自己的网段填写对应的网关地址）</span><br><span class="line"></span><br><span class="line">2、关闭NetworkManager，并取消开机自启</span><br><span class="line">systemctl stop NetworkManager</span><br><span class="line">systemctl disable NetworkManager</span><br><span class="line"></span><br><span class="line">3、重启网络服务</span><br><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure></li></ul></li><li><p>免密登录</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1、生成密钥</span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"># 2、配置免密登录</span><br><span class="line">ssh-copy-id master</span><br><span class="line">ssh-copy-id node1</span><br><span class="line">ssh-copy-id node2</span><br><span class="line"># 3、测试免密登录</span><br><span class="line">ssh node1</span><br></pre></td></tr></table></figure></li><li><p>配置好映射文件：&#x2F;etc&#x2F;hosts</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.151.81 master</span><br><span class="line">192.168.151.82 node1</span><br><span class="line">192.168.151.83 node2</span><br></pre></td></tr></table></figure></li></ul><h3 id="二、搭建Hadoop集群"><a href="#二、搭建Hadoop集群" class="headerlink" title="二、搭建Hadoop集群"></a>二、搭建Hadoop集群</h3><blockquote><p>NameNode：接受客户端的读&#x2F;写服务,收集 DataNode 汇报的 Block 列表信息</p><p>DataNode：真实数据存储的地方（block）</p><p>SecondaryNameNode：做持久化的时候用到</p></blockquote><table><thead><tr><th>进程</th><th>master（主）</th><th>node1（从）</th><th>node2（从）</th></tr></thead><tbody><tr><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td>SecondaryNameNode</td><td>√</td><td></td><td></td></tr><tr><td>ResourceManager</td><td>√</td><td></td><td></td></tr><tr><td>DataNode</td><td></td><td>√</td><td>√</td></tr><tr><td>NodeManager</td><td></td><td>√</td><td>√</td></tr></tbody></table><h3 id="2-1-完全分布式搭建"><a href="#2-1-完全分布式搭建" class="headerlink" title="2.1    完全分布式搭建"></a>2.1    完全分布式搭建</h3><h4 id="1、上传安装包并解压"><a href="#1、上传安装包并解压" class="headerlink" title="1、上传安装包并解压"></a>1、上传安装包并解压</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用xftp上传压缩包至master的/usr/local/soft/packages/</span><br><span class="line">cd /urs/local/soft/packages/</span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf hadoop-2.7.6.tar.gz -C /usr/local/soft/</span><br></pre></td></tr></table></figure><h4 id="2、配置环境变量"><a href="#2、配置环境变量" class="headerlink" title="2、配置环境变量"></a>2、配置环境变量</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br><span class="line">HADOOP_HOME=/usr/local/soft/hadoop-2.7.6</span><br><span class="line">export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span><br><span class="line"></span><br><span class="line"># 重新加载环境变量</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="3、修改Hadoop配置文件"><a href="#3、修改Hadoop配置文件" class="headerlink" title="3、修改Hadoop配置文件"></a>3、修改Hadoop配置文件</h4><ul><li><p><code>cd /usr/local/soft/hadoop-2.7.6/etc/hadoop/</code></p></li><li><p>core-site.xml</p><blockquote><p>fs.defaultFS： 默认文件系统的名称。其方案和权限决定文件系统实现的URI。uri的方案确定命名文件系统实现类的配置属性（fs.scheme.impl）。uri的权限用于确定文件系统的主机、端口等。</p><p>hadoop.tmp.dir：是 hadoop文件系统依赖的基本配置，很多配置路径都依赖它，它的默认位置是在 &#x2F;tmp&#x2F;{$user}下面，注意这是个临时目录！！！</p><p>因此，它的持久化配置很重要的！ 如果选择默认，一旦因为断电等外在因素影响，&#x2F;tmp&#x2F;{$user}下的所有东西都会丢失。</p><p>fs.trash.interval：启用垃圾箱配置，dfs命令删除的文件不会立即从HDFS中删除。相反，HDFS将其移动到垃圾目录（每个用户在<code>/user/&lt;username&gt;/.Trash</code>下都有自己的垃圾目录）。只要文件保留在垃圾箱中，文件可以快速恢复。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/usr/local/soft/hadoop-2.7.6/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.trash.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1440&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>hadoop-env.sh</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/24/ABd2KfenPMkySoT.png" alt="image.png"></p></li><li><p>hdfs-site.xml</p></li><li><blockquote><p>dfs.replication：每个datanode上只能存放一个副本。我这里就2个datanode</p><p>dfs.permissions：如果为“true”，则在HDFS中启用权限检查。如果为“false”，则关闭权限检查，但所有其他行为保持不变。从一个参数值切换到另一个参数值不会更改文件或目录的模式、所有者或组。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>mapred-site.xml.template</p></li><li><blockquote><p>mapreduce.framework.name：用于执行MapReduce作业的运行时框架。</p><p>mapreduce.jobhistory.address：Hadoop自带了一个历史服务器，可以通过历史服务器查看已经运行完的Mapreduce作业记录，比如用了多少个Map、用了多少个Reduce、作业提交时间、作业启动时间、作业完成时间等信息。默认情况下，Hadoop历史服务器是没有启动的，我们可以通过*mr-<strong>jobhistory-daemon.sh start historyserver</strong>命令来启动Hadoop历史服务器。我们可以通过Hadoop jar的命令来实现我们的程序jar包的运行，关于运行的日志，我们一般都需要通过启动一个服务来进行查看，就是我们的JobHistoryServer，我们可以启动一个进程，专门用于查看我们的任务提交的日志。mapreduce.jobhistory.address和mapreduce.jobhistory.webapp.address默认的值分别是0.0.0.0:10020和0.0.0.0:19888</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1、重命名文件</span><br><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line"># 2、修改</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;  </span><br><span class="line">        &lt;value&gt;master:10020&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt;  </span><br><span class="line"></span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;  </span><br><span class="line">        &lt;value&gt;master:19888&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt; </span><br></pre></td></tr></table></figure></li><li><p>slaves</p></li><li><blockquote><p>从节点的信息</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure></li><li><p>yarn-site.xml</p></li><li><blockquote><p>yarn.resourcemanager.hostname：指定yarn主节点</p></blockquote></li></ul><blockquote><p>yarn.nodemanager.aux-services：NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序。默认值：“”</p><p>yarn.log-aggregation-enable：yarn日志聚合功能开关</p><p>yarn.log-aggregation.retain-seconds：日志保留时限，默认7天</p></blockquote>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h4 id="4、分发Hadoop到node1、node2"><a href="#4、分发Hadoop到node1、node2" class="headerlink" title="4、分发Hadoop到node1、node2"></a>4、分发Hadoop到node1、node2</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/soft/</span><br><span class="line">scp -r hadoop-2.7.6/ node1:`pwd`</span><br><span class="line">scp -r hadoop-2.7.6/ node2:`pwd`</span><br></pre></td></tr></table></figure><h4 id="5、格式化namenode（第一次启动的时候需要执行，以及每次修改核心配置文件后都需要）"><a href="#5、格式化namenode（第一次启动的时候需要执行，以及每次修改核心配置文件后都需要）" class="headerlink" title="5、格式化namenode（第一次启动的时候需要执行，以及每次修改核心配置文件后都需要）"></a>5、格式化namenode（第一次启动的时候需要执行，以及每次修改核心配置文件后都需要）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/24/tQ9ZOuvozXcPIB2.png" alt="image.png"></p><h4 id="6、启动Hadoop集群"><a href="#6、启动Hadoop集群" class="headerlink" title="6、启动Hadoop集群"></a>6、启动Hadoop集群</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start-all.sh</span><br></pre></td></tr></table></figure><h4 id="7、检查master、node1、node2上的进程"><a href="#7、检查master、node1、node2上的进程" class="headerlink" title="7、检查master、node1、node2上的进程"></a>7、检查master、node1、node2上的进程</h4><ul><li><p>master：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@master soft]# jps</span><br><span class="line">2597 NameNode</span><br><span class="line">2793 SecondaryNameNode</span><br><span class="line">2953 ResourceManager</span><br><span class="line">3215 Jps</span><br></pre></td></tr></table></figure></li><li><p>node1：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node1 jdk1.8.0_171]# jps</span><br><span class="line">11361 DataNode</span><br><span class="line">11459 NodeManager</span><br><span class="line">11559 Jps</span><br></pre></td></tr></table></figure></li><li><p>node2：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@node2 ~]# jps</span><br><span class="line">11384 DataNode</span><br><span class="line">11482 NodeManager</span><br><span class="line">11582 Jps</span><br></pre></td></tr></table></figure></li></ul><h4 id="8、访问HDFS的WEB界面"><a href="#8、访问HDFS的WEB界面" class="headerlink" title="8、访问HDFS的WEB界面"></a>8、访问HDFS的WEB界面</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://master:50070</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/24/7MHt8o3gIjN2rBn.png" alt="image.png"></p><h4 id="9、访问YARN的WEB界面"><a href="#9、访问YARN的WEB界面" class="headerlink" title="9、访问YARN的WEB界面"></a>9、访问YARN的WEB界面</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://master:8088</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/24/6bOFBZ7GKSyxYEU.png" alt="image.png"></p><h3 id="强制格式化集群（遇到问题的简单暴力的方法）"><a href="#强制格式化集群（遇到问题的简单暴力的方法）" class="headerlink" title="强制格式化集群（遇到问题的简单暴力的方法）"></a>强制格式化集群（遇到问题的简单暴力的方法）</h3><blockquote><p>1、停止正在运行的集群</p><p>​    <strong>stop-all.sh</strong></p><p>2、删除所有节点hadoop根目录中的tmp文件夹</p><p>3、在主节点（master）中hadoop的根目录中的bin目录下，重新格式化HDFS</p><p>​    <strong>.&#x2F;hdfs namenode -format</strong></p><p>4、启动集群</p><p>​    <strong>start-all.sh</strong></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis数据库</title>
      <link href="/2022/05/22/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
      <url>/2022/05/22/Redis%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h3 id="1-NoSQL的引言"><a href="#1-NoSQL的引言" class="headerlink" title="1.  NoSQL的引言"></a>1.  NoSQL的引言</h3><p><strong>NoSQL</strong>(<code> Not Only SQL</code> )，意即<strong>不仅仅是SQL</strong>, 泛指非关系型的数据库。Nosql这个技术门类,早期就有人提出,发展至2009年趋势越发高涨。</p><h3 id="2-为什么是NoSQL"><a href="#2-为什么是NoSQL" class="headerlink" title="2. 为什么是NoSQL"></a>2. 为什么是NoSQL</h3><p>随着互联网网站的兴起，传统的关系数据库在应付动态网站，特别是超大规模和高并发的纯动态网站已经显得力不从心，暴露了很多难以克服的问题。如<code>商城网站中对商品数据频繁查询</code>、<code>对热搜商品的排行统计</code>、<code>订单超时问题</code>、以及微信朋友圈（音频，视频）存储等相关使用传统的关系型数据库实现就显得非常复杂，虽然能实现相应功能但是在性能上却不是那么乐观。nosql这个技术门类的出现，更好的解决了这些问题，它告诉了世界不仅仅是sql。</p><h3 id="3-NoSQL的四大分类"><a href="#3-NoSQL的四大分类" class="headerlink" title="3. NoSQL的四大分类"></a>3. NoSQL的四大分类</h3><h4 id="3-1键值-Key-Value-存储数据库"><a href="#3-1键值-Key-Value-存储数据库" class="headerlink" title="3.1键值(Key-Value)存储数据库"></a>3.1键值(Key-Value)存储数据库</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.说明: </span><br><span class="line">- 这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。</span><br><span class="line"></span><br><span class="line"># 2.特点</span><br><span class="line">- Key/value模型对于IT系统来说的优势在于简单、易部署。  </span><br><span class="line">- 但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。</span><br><span class="line"></span><br><span class="line"># 3.相关产品</span><br><span class="line">- Tokyo Cabinet/Tyrant,</span><br><span class="line">- Redis  基于内存的    运行软件---&gt;磁盘---&gt;内存中</span><br><span class="line">- SSDB   基于磁盘的    直接与磁盘做交互--&gt; IO</span><br><span class="line">- Voldemort </span><br><span class="line">- Oracle BDB</span><br></pre></td></tr></table></figure><h4 id="3-2列存储数据库-gt-Hbase"><a href="#3-2列存储数据库-gt-Hbase" class="headerlink" title="3.2列存储数据库-&gt;Hbase"></a>3.2列存储数据库-&gt;Hbase</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.说明- 这部分数据库通常是用来应对分布式存储的海量数据。</span><br><span class="line">2.特点- 键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。列簇- rowkey</span><br><span class="line">3.相关产品- Cassandra、`HBase`、Riak.</span><br></pre></td></tr></table></figure><h4 id="3-3文档型数据库"><a href="#3-3文档型数据库" class="headerlink" title="3.3文档型数据库"></a>3.3文档型数据库</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.说明</span><br><span class="line">- 文档型数据库的灵感是来自于Lotus Notes办公软件的，而且它同第一种键值存储相类似该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高</span><br><span class="line">&#123;&#x27;id&#x27;:1001,&#x27;name&#x27;:xiaohu&#125;</span><br><span class="line">&#123;&#x27;id&#x27;:1001,&#x27;name&#x27;:&#x27;xiaohu2,&#x27;address&#x27;:&#x27;anhuihefei&#x27;,&#x27;likes&#x27;:[&#x27;play&#x27;,&#x27;eat&#x27;],&#x27;study&#x27;:&#123;&#x27;yuyan&#x27;:java,&#x27;ruanjian&#x27;:&#x27;mysql&#x27;&#125;&#125;</span><br><span class="line">文档数据库对于单条数据来说，他的事务支持并没有那么强大</span><br><span class="line">目前的mongodb5，支持了单条数据的事务，但是多条不行</span><br><span class="line"></span><br><span class="line"># 2.特点</span><br><span class="line">- 以文档形式存储</span><br><span class="line"></span><br><span class="line"># 3.相关产品</span><br><span class="line">- MongoDB、CouchDB、 MongoDb(4.x). 国内也有文档型数据库SequoiaDB，已经开源。</span><br></pre></td></tr></table></figure><h4 id="3-4图形-Graph-数据库"><a href="#3-4图形-Graph-数据库" class="headerlink" title="3.4图形(Graph)数据库"></a>3.4图形(Graph)数据库</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.说明</span><br><span class="line">- 图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。</span><br><span class="line"></span><br><span class="line"># 2.特点</span><br><span class="line">- NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API。</span><br><span class="line"></span><br><span class="line"># 3.相关产品</span><br><span class="line">- Neo4J、InfoGrid、 Infinite Graph</span><br></pre></td></tr></table></figure><h3 id="4-NoSQL应用场景"><a href="#4-NoSQL应用场景" class="headerlink" title="4.NoSQL应用场景"></a>4.NoSQL应用场景</h3><p>数据模型比较简单 </p><p>需要灵活性更强的IT系统 </p><p>对数据库性能要求较高</p><p>不需要高度的数据一致性（NoSQL数据库对事物的支持不是很好）</p><h3 id="5-什么是Redis"><a href="#5-什么是Redis" class="headerlink" title="5.什么是Redis"></a>5.什么是Redis</h3><p>redis是一个内存型的数据库，开源遵循BSD基于内存数据存储被用于作为数据库缓存消息中间件 </p><h3 id="6-Redis特点"><a href="#6-Redis特点" class="headerlink" title="6.Redis特点"></a>6.Redis特点</h3><p>Redis是一个高性能Key-Value内存型数据库在redis中，所有的数据形式都是以键值对的方式来存储的</p><p>redis支持丰富的数据类型string，list，set，sorted set 其中指的是键值对中的值的类型</p><p>redis支持持久化（将数据落盘）</p><p>redis单线程，单进程    由于是单进程和单进程的，所以它是线程安全的，在java中的多线程安全在分布式中不起作用，当时只针对一个JVM有效。</p><h3 id="7-Redis数据库相关指令"><a href="#7-Redis数据库相关指令" class="headerlink" title="7.Redis数据库相关指令"></a>7.Redis数据库相关指令</h3><h4 id="7-1数据库操作指令"><a href="#7-1数据库操作指令" class="headerlink" title="7.1数据库操作指令"></a>7.1数据库操作指令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.Redis中库说明</span><br><span class="line">- 使用redis的默认配置器动redis服务后,默认会存在16个库,编号从0-15 配置问价中有个database相关的</span><br><span class="line">- 可以使用select 库的编号 来选择一个redis的库</span><br><span class="line"></span><br><span class="line"># 2.Redis中操作库的指令</span><br><span class="line">- 清空当前的库  FLUSHDB</span><br><span class="line">- 清空全部的库  FLUSHALL</span><br><span class="line"></span><br><span class="line"># 3.redis客户端显示中文</span><br><span class="line">-./redis-cli  -p 7000 --raw</span><br></pre></td></tr></table></figure><h4 id="7-2操作key相关指令"><a href="#7-2操作key相关指令" class="headerlink" title="7.2操作key相关指令"></a>7.2操作key相关指令</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.DEL指令</span><br><span class="line">- 语法 :  DEL key [key ...] </span><br><span class="line">- 作用 :  删除给定的一个或多个key 。不存在的key 会被忽略。多个key之间使用空格隔开</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值： 被删除key 的数量。 </span><br><span class="line"></span><br><span class="line"># 2.EXISTS指令</span><br><span class="line">- 语法:  EXISTS key</span><br><span class="line">- 作用:  检查给定key 是否存在。多个key之间使用空格隔开，只要有一个key存在，返回值就是1</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值： 若key 存在，返回1 ，否则返回0。 </span><br><span class="line"></span><br><span class="line"># 3.EXPIRE</span><br><span class="line">- 语法:  EXPIRE key seconds</span><br><span class="line">- 作用:  为给定key 设置生存时间，当key 过期时(生存时间为0 )，它会被自动删除。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 时间复杂度： O(1)</span><br><span class="line">- 返回值：设置成功返回1 。</span><br><span class="line"></span><br><span class="line"># 4.KEYS</span><br><span class="line">- 语法 :  KEYS pattern</span><br><span class="line">- 作用 :  查找所有符合给定模式pattern 的key 。</span><br><span class="line">- 语法:</span><br><span class="line">KEYS * 匹配数据库中所有key 。</span><br><span class="line">KEYS h?llo 匹配hello ，hallo 和hxllo 等。</span><br><span class="line">KEYS h*llo 匹配hllo 和heeeeello 等。</span><br><span class="line">KEYS h[ae]llo 匹配hello 和hallo ，但不匹配hillo 。特殊符号用 &quot;\&quot; 隔开</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值： 符合给定模式的key 列表。</span><br><span class="line"></span><br><span class="line"># 5.MOVE</span><br><span class="line">- 语法 :  MOVE key db  （move name 1----将name键移动到1号库）</span><br><span class="line">- 作用 :  将当前数据库的key 移动到给定的数据库db 当中。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值： 移动成功返回1 ，失败则返回0 。</span><br><span class="line"></span><br><span class="line"># 6.PEXPIRE</span><br><span class="line">- 语法 :  PEXPIRE key milliseconds</span><br><span class="line">- 作用 :  这个命令和EXPIRE 命令的作用类似，但是它以毫秒为单位设置key 的生存时间，而不像EXPIRE 命令那样，以秒为单位。</span><br><span class="line">- 可用版本： &gt;= 2.6.0</span><br><span class="line">- 时间复杂度： O(1)</span><br><span class="line">- 返回值：设置成功，返回1  key 不存在或设置失败，返回0</span><br><span class="line"></span><br><span class="line"># 7.PEXPIREAT</span><br><span class="line">- 语法 :  PEXPIREAT key milliseconds-timestamp</span><br><span class="line">- 作用 :  这个命令和EXPIREAT 命令类似，但它以毫秒为单位设置key 的过期unix 时间戳，而不是像EXPIREAT那样，以秒为单位。</span><br><span class="line">- 可用版本： &gt;= 2.6.0</span><br><span class="line">- 返回值：如果生存时间设置成功，返回1 。当key 不存在或没办法设置生存时间时，返回0 。(查看EXPIRE 命令获取更多信息)</span><br><span class="line"></span><br><span class="line"># 8.TTL</span><br><span class="line">- 语法 :   TTL key</span><br><span class="line">- 作用 :   以秒为单位，返回给定key 的剩余生存时间(TTL, time to live)。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值：</span><br><span class="line">当key 不存在时，返回-2 。</span><br><span class="line">当key 存在但没有设置剩余生存时间时，返回-1 。</span><br><span class="line">否则，以秒为单位，返回key 的剩余生存时间。</span><br><span class="line">- Note : 在Redis 2.8 以前，当key 不存在，或者key 没有设置剩余生存时间时，命令都返回-1 。</span><br><span class="line"></span><br><span class="line"># 9.PTTL</span><br><span class="line">- 语法 :  PTTL key</span><br><span class="line">- 作用 :  这个命令类似于TTL 命令，但它以毫秒为单位返回key 的剩余生存时间，而不是像TTL 命令那样，以秒为单位。</span><br><span class="line">- 可用版本： &gt;= 2.6.0</span><br><span class="line">- 返回值： 当key 不存在时，返回-2 。当key 存在但没有设置剩余生存时间时，返回-1 。</span><br><span class="line">- 否则，以毫秒为单位，返回key 的剩余生存时间。</span><br><span class="line">- 注意 : 在Redis 2.8 以前，当key 不存在，或者key 没有设置剩余生存时间时，命令都返回-1 。</span><br><span class="line"></span><br><span class="line"># 10.RANDOMKEY</span><br><span class="line">- 语法 :  RANDOMKEY</span><br><span class="line">- 作用 :  从当前数据库中随机返回(不删除) 一个key 。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值：当数据库不为空时，返回一个key 。当数据库为空时，返回nil 。</span><br><span class="line"></span><br><span class="line"># 11.RENAME</span><br><span class="line">- 语法 :  RENAME key newkey</span><br><span class="line">- 作用 :  将key 改名为newkey 。当key 和newkey 相同，或者key 不存在时，返回一个错误。当newkey 已经存在时，RENAME 命令将覆盖旧值。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值： 改名成功时提示OK ，失败时候返回一个错误。</span><br><span class="line"></span><br><span class="line"># 12.TYPE</span><br><span class="line">- 语法 :  TYPE key</span><br><span class="line">- 作用 :  返回key 所储存的值的类型。</span><br><span class="line">- 可用版本： &gt;= 1.0.0</span><br><span class="line">- 返回值：</span><br><span class="line">none (key 不存在)</span><br><span class="line">string (字符串)</span><br><span class="line">list (列表)</span><br><span class="line">set (集合)</span><br><span class="line">zset (有序集)</span><br><span class="line">hash (哈希表)</span><br></pre></td></tr></table></figure><h4 id="7-3-String类型"><a href="#7-3-String类型" class="headerlink" title="7.3 String类型"></a>7.3 String类型</h4><p><img src="https://s2.loli.net/2022/05/18/q9nKXHYv7iJgRDT.png"></p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>set</td><td>设置一个key&#x2F;value</td></tr><tr><td>get</td><td>根据key获得对应的value</td></tr><tr><td>mset</td><td>一次设置多个key value</td></tr><tr><td>mget</td><td>一次获得多个key的value</td></tr><tr><td>getset</td><td>获得原始key的值，同时设置新值</td></tr><tr><td>strlen</td><td>获得对应key存储value的长度</td></tr><tr><td>append</td><td>为对应key的value追加内容</td></tr><tr><td>getrange 索引0开始</td><td>截取value的内容    到末尾-1</td></tr><tr><td>setex</td><td>设置一个key存活的有效期（秒）</td></tr><tr><td>psetex</td><td>设置一个key存活的有效期（毫秒）</td></tr><tr><td>setnx</td><td>存在不做任何操作,不存在添加</td></tr><tr><td>msetnx原子操作(只要有一个存在不做任何操作)</td><td>可以同时设置多个key,只有有一个存在都不保存</td></tr><tr><td>decr</td><td>进行数值类型的-1操作</td></tr><tr><td>decrby</td><td>根据提供的数据进行减法操作</td></tr><tr><td>Incr</td><td>进行数值类型的+1操作</td></tr><tr><td>incrby</td><td>根据提供的数据进行加法操作</td></tr><tr><td>Incrbyfloat</td><td>根据提供的数据加入浮点数（不是四舍五入）</td></tr></tbody></table><h4 id="7-4-List类型"><a href="#7-4-List类型" class="headerlink" title="7.4 List类型"></a>7.4 List类型</h4><blockquote><p>list 列表 相当于java中list 集合  特点  元素有序  且 可以重复，key还是一个字符串，值是一个list</p></blockquote><p><img src="https://s2.loli.net/2022/05/18/g3awqjvZztbsJpr.png" alt="image-20200623161114380"></p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>lpush</td><td>将某个值加入到一个key列表头部  lpush list xiaohu xiaohei xiaoming    当列表不存在的时候会进行创建</td></tr><tr><td>lpushx</td><td>同lpush,但是必须要保证这个key存在  必须在列表进行存在的情况下从左插入</td></tr><tr><td>rpush</td><td>将某个值加入到一个key列表末尾</td></tr><tr><td>rpushx</td><td>同rpush,但是必须要保证这个key存在</td></tr><tr><td>lpop</td><td>返回和移除列表左边的第一个元素</td></tr><tr><td>rpop</td><td>返回和移除列表右边的第一个元素</td></tr><tr><td>lrange</td><td>获取某一个下标区间内的元素   lrange list 0 -1</td></tr><tr><td>llen</td><td>获取列表元素个数</td></tr><tr><td>lset</td><td>设置某一个指定索引的值(索引必须存在)</td></tr><tr><td>lindex</td><td>获取某一个指定索引位置的元素</td></tr><tr><td>lrem</td><td>删除重复元素</td></tr><tr><td>ltrim</td><td>保留列表中特定区间内的元素</td></tr><tr><td>linsert</td><td>在某一个元素之前，之后插入新元素</td></tr></tbody></table><h4 id="7-5-Set类型"><a href="#7-5-Set类型" class="headerlink" title="7.5 Set类型"></a>7.5 Set类型</h4><blockquote><p>特点: Set类型 Set集合 元素无序  不可以重复</p></blockquote><p><img src="https://s2.loli.net/2022/05/18/bIPlvO4NeKDwndE.png" alt="image-20200623193634316"></p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>sadd</td><td>为集合添加元素</td></tr><tr><td>smembers</td><td>显示集合中所有元素 无序</td></tr><tr><td>scard</td><td>返回集合中元素的个数</td></tr><tr><td>spop</td><td>随机返回一个元素 并将元素在集合中删除</td></tr><tr><td>smove</td><td>从一个集合中向另一个集合移动元素  必须是同一种类型</td></tr><tr><td>srem</td><td>从集合中删除一个元素</td></tr><tr><td>sismember</td><td>判断一个集合中是否含有这个元素</td></tr><tr><td>srandmember</td><td>随机返回元素   后面可以加数字 表示每次返回的个数</td></tr><tr><td>sdiff</td><td>去掉第一个集合中其它集合含有的相同元素</td></tr><tr><td>sinter</td><td>求交集</td></tr><tr><td>sunion</td><td>求和集</td></tr></tbody></table><h4 id="7-6-ZSet类型"><a href="#7-6-ZSet类型" class="headerlink" title="7.6 ZSet类型"></a>7.6 ZSet类型</h4><p><img src="https://s2.loli.net/2022/05/18/MyIESsQJzqaoh2K.png" alt="image-20200623194903967"></p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>zadd</td><td>添加一个有序集合元素     zadd zset 2 xiaohu 3 xiaohu2</td></tr><tr><td>zcard</td><td>返回集合的元素个数</td></tr><tr><td>zrange 升序 zrevrange 降序</td><td>返回一个范围内的元素       如果想看看分数 withscores</td></tr><tr><td>zrangebyscore</td><td>按照分数查找一个范围内的元素  zrangebyscore zset 0 20 withscores limit 0 2</td></tr><tr><td>zrank</td><td>返回排名</td></tr><tr><td>zrevrank</td><td>倒序排名</td></tr><tr><td>zscore</td><td>显示某一个元素的分数</td></tr><tr><td>zrem</td><td>移除某一个元素</td></tr><tr><td>zincrby</td><td>给某个特定元素加分</td></tr></tbody></table><h4 id="7-7-hash类型"><a href="#7-7-hash类型" class="headerlink" title="7.7 hash类型"></a>7.7 hash类型</h4><p><img src="https://s2.loli.net/2022/05/18/7Ga5zsBAPJCfSqh.png" alt="image-20220511234124908"></p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>hset</td><td>设置一个key&#x2F;value对</td></tr><tr><td>hget</td><td>获得一个key对应的value</td></tr><tr><td>hgetall</td><td>获得所有的key&#x2F;value对</td></tr><tr><td>hdel</td><td>删除某一个key&#x2F;value对</td></tr><tr><td>hexists</td><td>判断一个key是否存在</td></tr><tr><td>hkeys</td><td>获得所有的key</td></tr><tr><td>hvals</td><td>获得所有的value</td></tr><tr><td>hmset</td><td>设置多个key&#x2F;value</td></tr><tr><td>hmget</td><td>获得多个key的value</td></tr><tr><td>hsetnx</td><td>设置一个不存在的key的值</td></tr><tr><td>hincrby</td><td>为value进行加法运算</td></tr><tr><td>hincrbyfloat</td><td>为value加入浮点值</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shell编程</title>
      <link href="/2022/05/21/Shell%E7%BC%96%E7%A8%8B/"/>
      <url>/2022/05/21/Shell%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Shell编程"><a href="#Shell编程" class="headerlink" title="Shell编程"></a>Shell编程</h1><h3 id="1-1-Shell名词解释"><a href="#1-1-Shell名词解释" class="headerlink" title="1.1 Shell名词解释"></a>1.1 Shell名词解释</h3><p>• Kernel</p><p>​        Linux内核主要是为了和硬件打交道</p><p>• Shell</p><p>​        命令器(command interpreter)</p><p>​        Shell是一个用C语言编写的程序，它是用户使用Linux的桥梁。Shell既是一种命令语言， 又是一种程序设计语言.</p><p>​        Shell是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作集作系统内核的服务。</p><p>• shell两大主流：</p><p>​        sh:</p><p>​            ■ Bourne shell（sh） ,Solaris,hpux默认shell</p><p>​            ■ Bourne again shell（bash） ,Linux系统默认shell</p><p>​        bash:</p><p>​            ■ C shell(csh)</p><p>​            ■ tc shell(tcsh)</p><p>• #!声明</p><p>告诉系统其后路径所指定的程序即是解释此脚本文件的Shell程序</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello world!&quot;</span></span><br></pre></td></tr></table></figure><h3 id="1-2-Shell本的执行"><a href="#1-2-Shell本的执行" class="headerlink" title="1.2 Shell本的执行"></a>1.2 Shell本的执行</h3><p>• 输入脚本的绝对路径或相对路径</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/root/helloworld.sh</span><br><span class="line"></span><br><span class="line">./helloworld.sh</span><br><span class="line"></span><br><span class="line">注意：执行的必须是一个可执行文件</span><br></pre></td></tr></table></figure><p>• bash或sh +脚本</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sh helloworld.sh</span><br><span class="line"></span><br><span class="line">注意：当脚本没有X权限时，root和文件所有者通过该方式可以正常执行</span><br></pre></td></tr></table></figure><p>•在脚本的路径前再加”或source</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source helloworld.sh</span><br></pre></td></tr></table></figure><p>查看当前正在执行的进程：ps -ef</p><p>•区别</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">第一种和第二种会新开一个bash,不同bash中的变量无法共享。</span><br><span class="line"></span><br><span class="line">第三种是在同一个shell里面执行的</span><br></pre></td></tr></table></figure><p>•export :可以将当前进程的变量传递给子进程去使用</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">将来配置profile的时候所有的变量前必须加export</span><br></pre></td></tr></table></figure><h1 id="2-Shell基础入门"><a href="#2-Shell基础入门" class="headerlink" title="2. Shell基础入门"></a>2. Shell基础入门</h1><h3 id="2-1-shell变量"><a href="#2-1-shell变量" class="headerlink" title="2.1. shell变量"></a>2.1. shell变量</h3><p>定义变量时，变量名不加美元符号</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</span><br><span class="line"></span><br><span class="line">​中间不能有空格，可以使用下划线（_）。</span><br><span class="line"></span><br><span class="line">​不能使用标点符号。</span><br><span class="line"></span><br><span class="line">​不能使用bash里的关键字（可用help命令查看保留关键字）</span><br></pre></td></tr></table></figure><p>变量的类型</p><p>​    局部变量</p><p>​        局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。</p><p>​    环境变量</p><p>​        所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。</p><p>​    Shell变量</p><p>​        shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量</p><p>(时间同步 ntpdate cn.ntp.org.cn)</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#变量的声明</span></span><br><span class="line">name=<span class="string">&quot;zhangsan&quot;</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `<span class="built_in">ls</span> /etc` </span><br><span class="line">或</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> $(<span class="built_in">ls</span> /etc)</span><br><span class="line"></span><br><span class="line"><span class="comment">#变量的调用 (推荐不省略大括号)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$name</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;name&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> skill <span class="keyword">in</span> Ada Coffe Action Java; <span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;I am good at <span class="variable">$&#123;skill&#125;</span>Script&quot;</span> </span><br><span class="line"><span class="keyword">done</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># x /bin/sh: NAME: This variable is read only. </span></span><br><span class="line">url=<span class="string">&quot;https://www.google.com&quot;</span> </span><br><span class="line"><span class="built_in">readonly</span> url </span><br><span class="line">url=<span class="string">&quot;https://www.runoob.com&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除变量 </span></span><br><span class="line"><span class="built_in">unset</span> name</span><br></pre></td></tr></table></figure><h3 id="2-2-Shell的字符串"><a href="#2-2-Shell的字符串" class="headerlink" title="2.2. Shell的字符串"></a>2.2. Shell的字符串</h3><p>字符串是shell编程中最常用最有用的数据类型，字符串可以用单引号，也可以用双引号，也可以不用引号。</p><p>单引号</p><p>​    单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；</p><p>​    单引号字串中不能出现单独一个的单引号，但可成对出现，作为字符串拼接使用。</p><p>双引号</p><p>​    双引号里可以有变量</p><p>​    双引号里可以出现转义字符</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 声明字符串 </span></span><br><span class="line">str1=<span class="string">&quot;hello world 1&quot;</span> </span><br><span class="line">str2=<span class="string">&#x27;hello world 2&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串拼接--双引号 </span></span><br><span class="line">name=<span class="string">&#x27;sunwukong&#x27;</span> </span><br><span class="line">name1=<span class="string">&quot;hello, &quot;</span><span class="variable">$name</span><span class="string">&quot; !&quot;</span> </span><br><span class="line">name2=<span class="string">&quot;hello, <span class="variable">$&#123;name&#125;</span> !&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串拼接--单引号 </span></span><br><span class="line">passwd=<span class="string">&#x27;123456&#x27;</span> </span><br><span class="line">passwd1=<span class="string">&#x27;hello, &#x27;</span><span class="variable">$passwd</span><span class="string">&#x27; !&#x27;</span></span><br><span class="line">passwd2=<span class="string">&#x27;hello, $&#123;passwd&#125; !&#x27;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$passwd2</span> <span class="comment"># hello, $&#123;passwd&#125; ! </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串的长度 </span></span><br><span class="line">email=<span class="string">&quot;123456@qq.com&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;#email&#125;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;email:1:4&#125;</span></span><br></pre></td></tr></table></figure><h3 id="2-3-Shell数组（尾对象）伪数组"><a href="#2-3-Shell数组（尾对象）伪数组" class="headerlink" title="2.3  Shell数组（尾对象）伪数组"></a>2.3  Shell数组（尾对象）伪数组</h3><p>bash支持一维数组（不支持多维数组），并且没有限定数组的大小。</p><p>数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义数组 括号来表示数组，数组元素用&quot;空格&quot;符号分割开 </span></span><br><span class="line">数组名=(值1 值2 ... 值n) </span><br><span class="line">favs=(<span class="string">&quot;足球&quot;</span> <span class="string">&quot;蓝球&quot;</span> <span class="string">&quot;乒乓球&quot;</span> <span class="string">&quot;保龄球&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数组 $&#123;数组名[下标]&#125; </span></span><br><span class="line">fav=<span class="variable">$&#123;favs[1]&#125;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 @ 符号可以获取数组中的所有元素 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;favs[@]&#125;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数组的长度 </span></span><br><span class="line">length1=<span class="variable">$&#123;#favs[@]&#125;</span> </span><br><span class="line">length2=<span class="variable">$&#123;#favs[*]&#125;</span></span><br></pre></td></tr></table></figure><h3 id="2-4-Shell的注释"><a href="#2-4-Shell的注释" class="headerlink" title="2.4  Shell的注释"></a>2.4  Shell的注释</h3><p>以 <strong>#</strong> 开头的行就是注释，会被解释器忽略。</p><p>通过每一行加一个 <strong>#</strong> 号设置多行注释</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#-------------------------------------------- </span></span><br><span class="line"><span class="comment"># 这是一个注释 </span></span><br><span class="line"><span class="comment"># author： </span></span><br><span class="line"><span class="comment"># site： </span></span><br><span class="line"><span class="comment">#-------------------------------------------- </span></span><br><span class="line"><span class="comment">##### 服务器配置-start #####</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">##### 服务器配置-end ##### </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特殊的多行注释 </span></span><br><span class="line"><span class="comment"># end of file</span></span><br><span class="line">:&lt;&lt;<span class="string">EOF  </span></span><br><span class="line"><span class="string">注释内容... </span></span><br><span class="line"><span class="string">注释内容... </span></span><br><span class="line"><span class="string">注释内容... </span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">:&lt;&lt;! </span><br><span class="line">注释内容... </span><br><span class="line">注释内容... </span><br><span class="line">注释内容... </span><br><span class="line">!</span><br></pre></td></tr></table></figure><h3 id="2-5-Shell参数传递"><a href="#2-5-Shell参数传递" class="headerlink" title="2.5  Shell参数传递"></a>2.5  Shell参数传递</h3><p>执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：**$n<strong>。</strong>n** 代表一个数字</p><table><thead><tr><th><strong>参数处理</strong></th><th><strong>参数说明</strong></th></tr></thead><tbody><tr><td>$#</td><td>传递到脚本的参数个数</td></tr><tr><td>$*</td><td>以一个单字符串显示所有向脚本传递的参数。</td></tr><tr><td>$$</td><td>脚本运行的当前进程ID号</td></tr><tr><td>$!</td><td>后台运行的最后一个进程的ID号</td></tr><tr><td>$?</td><td>显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。</td></tr><tr><td>$0</td><td>执行的文件名</td></tr></tbody></table> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Shell 传递参数实例！&quot;</span>; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;执行的文件名：<span class="variable">$0</span>&quot;</span>; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第一个参数为：<span class="variable">$1</span>&quot;</span>; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第二个参数为：<span class="variable">$2</span>&quot;</span>; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第三个参数为：<span class="variable">$3</span>&quot;</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment"># ./hello.sh 11 22 33 44</span></span><br></pre></td></tr></table></figure><h1 id="3-Shell高级进阶"><a href="#3-Shell高级进阶" class="headerlink" title="3  Shell高级进阶"></a>3  Shell高级进阶</h1><h3 id="3-1-Shell运算符"><a href="#3-1-Shell运算符" class="headerlink" title="3.1 Shell运算符"></a>3.1 Shell运算符</h3><p>运算符的分类</p><p>​    算数运算符</p><table><thead><tr><th>运算符</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>+</td><td>加法</td><td>‘expr $a + $b’ 为 30。</td></tr><tr><td>-</td><td>减法</td><td>‘expr $a-$b’结果为-10。</td></tr><tr><td>*</td><td>乘法</td><td>‘expr $a * $b’ 结果为 200。</td></tr><tr><td>&#x2F;</td><td>除法</td><td>‘expr$b&#x2F;$a’结果为2。</td></tr><tr><td>%</td><td>取余</td><td>‘expr $b % $a’ 结果为0。</td></tr><tr><td>&#x3D;</td><td>赋值</td><td>a&#x3D;$b将把变量b的值赋给a</td></tr><tr><td>&#x3D;&#x3D;</td><td>相等，用于比较两个数字，相同返回true</td><td>[$a &#x3D;&#x3D; $b]返回false。</td></tr><tr><td>!&#x3D;</td><td>不相等,用于比较两个数字，不相同返回true</td><td>[$a !&#x3D; $b]返回true。</td></tr></tbody></table><p>​    关系运算符</p><table><thead><tr><th>运算符</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>-eq</td><td>检测两个数是否相等，相等返回true</td><td>[$a -eq $b ]返回 false。</td></tr><tr><td>-ne</td><td>检测两个数是否不相等，不相等返回true</td><td>[$a -ne $b ]返回 true。</td></tr><tr><td>-gt</td><td>检测左边的数是否大于右边的，如果是，返回true</td><td>[$a -gt $b ]返回 false.</td></tr><tr><td>-lt</td><td>检测左边的数是否小于右边的，如果是，返回true</td><td>[$a -It $b ]返回 true。</td></tr><tr><td>-ge</td><td>检测左边的数是否大于等于右边的，如果是，返回true</td><td>[$a -ge $b ]返回 false。</td></tr><tr><td>-le</td><td>检测左边的数是否小于等于右边的，如果是，返回true</td><td>[$a -le $b ]返回 true.</td></tr></tbody></table><p>​    布尔运算符</p><table><thead><tr><th>运算符</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>！</td><td>非运算，表达式为true则返回false,否则退回true。</td><td>[! false ]返回 true。</td></tr><tr><td>-o</td><td>或运算，有一个表达式为true则返回true。</td><td>[$a -It 20 -o $b -gt100 ]返回 true。</td></tr><tr><td>-a</td><td>与运算，两个表达式都为true才返回true.</td><td>[$a -It 20 -a $b -gt100 J 返回 false。</td></tr></tbody></table><p>​    字符串运算符</p><table><thead><tr><th>运算符</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>&amp;&amp;</td><td>逻辑的AND</td><td>[[$a -It 100 &amp;&amp; $b-gt 100 ]]返回 false</td></tr><tr><td>||</td><td>逻辑的OR</td><td>[[$a -It 100 || $b -gt 100 ]]返回 true</td></tr></tbody></table><p>​    文件测试运算符</p><table><thead><tr><th>运算符</th><th>说明</th><th>举例</th></tr></thead><tbody><tr><td>&#x3D;</td><td>检测两个字符串是否相等，相等返回true。</td><td>[$a &#x3D; $b ]返回 false。</td></tr><tr><td>!&#x3D;</td><td>检测两个字符串是否相等，不相等返回true。</td><td>[$a !&#x3D; $b ]返回 true。</td></tr><tr><td>-z</td><td>检测字符串长度是否为0,为0返回true。</td><td>[-z $a ]返回 false。</td></tr><tr><td>-n</td><td>检测字符串长度是否不为不为0返回true。</td><td>[n “$a”]返回 true.</td></tr><tr><td>$</td><td>检测字符串是否为空，不为空返回trueo</td><td>[$a]返回 true.</td></tr></tbody></table><h4 id="3-1-1-算数运算符"><a href="#3-1-1-算数运算符" class="headerlink" title="3.1.1 算数运算符"></a>3.1.1 算数运算符</h4><p> expr 是一款表达式计算工具，使用它能完成表达式的求值操作。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line">a=10 </span><br><span class="line">b=20 </span><br><span class="line"></span><br><span class="line">val=`<span class="built_in">expr</span> <span class="variable">$a</span> + <span class="variable">$b</span>` </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a + b : <span class="variable">$val</span>&quot;</span> </span><br><span class="line"></span><br><span class="line">val=`<span class="built_in">expr</span> <span class="variable">$a</span> - <span class="variable">$b</span>` </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a - b : <span class="variable">$val</span>&quot;</span> </span><br><span class="line"></span><br><span class="line">val=`<span class="built_in">expr</span> <span class="variable">$a</span> \* <span class="variable">$b</span>` </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a * b : <span class="variable">$val</span>&quot;</span> </span><br><span class="line"></span><br><span class="line">val=`<span class="built_in">expr</span> <span class="variable">$b</span> / <span class="variable">$a</span>` </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;b / a : <span class="variable">$val</span>&quot;</span> </span><br><span class="line"></span><br><span class="line">val=`<span class="built_in">expr</span> <span class="variable">$b</span> % <span class="variable">$a</span>` </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;b % a : <span class="variable">$val</span>&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> == <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> != <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-1-2-关系运算符"><a href="#3-1-2-关系运算符" class="headerlink" title="3.1.2 关系运算符"></a>3.1.2 关系运算符</h4><p>关系运算符只支持数字，不支持字符串，除非字符串的值是数字。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line">a=10 </span><br><span class="line">b=20 </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -eq <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -eq <span class="variable">$b</span> : a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -eq <span class="variable">$b</span>: a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -ne <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -ne <span class="variable">$b</span>: a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -ne <span class="variable">$b</span> : a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -gt <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -gt <span class="variable">$b</span>: a 大于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -gt <span class="variable">$b</span>: a 不大于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -lt <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -lt <span class="variable">$b</span>: a 小于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -lt <span class="variable">$b</span>: a 不小于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -ge <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -ge <span class="variable">$b</span>: a 大于或等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -ge <span class="variable">$b</span>: a 小于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -le <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -le <span class="variable">$b</span>: a 小于或等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> -le <span class="variable">$b</span>: a 大于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-1-3布尔运算符"><a href="#3-1-3布尔运算符" class="headerlink" title="3.1.3布尔运算符"></a>3.1.3布尔运算符</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line">a=10 </span><br><span class="line">b=20 </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> != <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> != <span class="variable">$b</span> : a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> == <span class="variable">$b</span>: a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -lt 100 -a <span class="variable">$b</span> -gt 15 ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 100 且 <span class="variable">$b</span> 大于 15 : 返回 true&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 100 且 <span class="variable">$b</span> 大于 15 : 返回 false&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -lt 100 -o <span class="variable">$b</span> -gt 100 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 100 或 <span class="variable">$b</span> 大于 100 : 返回 true&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 100 或 <span class="variable">$b</span> 大于 100 : 返回 false&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> -lt 5 -o <span class="variable">$b</span> -gt 100 ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 5 或 <span class="variable">$b</span> 大于 100 : 返回 true&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> 小于 5 或 <span class="variable">$b</span> 大于 100 : 返回 false&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-1-4-逻辑运算符"><a href="#3-1-4-逻辑运算符" class="headerlink" title="3.1.4 逻辑运算符"></a>3.1.4 逻辑运算符</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line">a=10 </span><br><span class="line">b=20 </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$a</span> -lt 100 &amp;&amp; <span class="variable">$b</span> -gt 100 ]] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;返回 true&quot;</span> elseecho <span class="string">&quot;返回 false&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$a</span> -lt 100 || <span class="variable">$b</span> -gt 100 ]] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;返回 true&quot;</span> elseecho <span class="string">&quot;返回 false&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-1-5-字符串运算符"><a href="#3-1-5-字符串运算符" class="headerlink" title="3.1.5 字符串运算符"></a>3.1.5 字符串运算符</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line">a=<span class="string">&quot;abc&quot;</span> </span><br><span class="line">b=<span class="string">&quot;efg&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> = <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> = <span class="variable">$b</span> : a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> = <span class="variable">$b</span>: a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> != <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> != <span class="variable">$b</span> : a 不等于 b&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> != <span class="variable">$b</span>: a 等于 b&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="variable">$a</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-z <span class="variable">$a</span> : 字符串长度为 0&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-z <span class="variable">$a</span> : 字符串长度不为 0&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$a</span>&quot;</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-n <span class="variable">$a</span> : 字符串长度不为 0&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-n <span class="variable">$a</span> : 字符串长度为 0&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> : 字符串不为空&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$a</span> : 字符串为空&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-1-6-文件测试运算符"><a href="#3-1-6-文件测试运算符" class="headerlink" title="3.1.6 文件测试运算符"></a>3.1.6 文件测试运算符</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line">file=<span class="string">&quot;/var/node/test.sh&quot;</span> </span><br><span class="line"><span class="keyword">if</span> [ -r <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件可读&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件不可读&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -w <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件可写&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件不可写&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -x <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件可执行&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件不可执行&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件为普通文件&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件为特殊文件&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -d <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件是个目录&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件不是个目录&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -s <span class="variable">$file</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件不为空&quot;</span> </span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;文件为空&quot;</span> </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="3-2-echo打印数据"><a href="#3-2-echo打印数据" class="headerlink" title="3.2 echo打印数据"></a>3.2 echo打印数据</h4><p> Shell的echo指令用于字符串的输出。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 显示普通字符串 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello World&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示转义字符 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;\&quot;Hello World\&quot;&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示变量 </span></span><br><span class="line">name=<span class="string">&quot;zhangsan&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$name</span> Hello World&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示换行 </span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;OK! \n&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello World&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示不换行 </span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;OK! \c&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello World&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示结果定向至文件 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Hello World&quot;</span> &gt; myfile </span><br><span class="line"><span class="comment">## &gt; 代表覆盖</span></span><br><span class="line"><span class="comment"># &gt;&gt; 追加写入</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 原样输出字符串 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;$name\&quot;&#x27;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示命令执行结果 </span></span><br><span class="line"><span class="built_in">echo</span> `<span class="built_in">date</span>`</span><br></pre></td></tr></table></figure><h3 id="3-4-Shell流程控制"><a href="#3-4-Shell流程控制" class="headerlink" title="3.4 Shell流程控制"></a>3.4 Shell流程控制</h3><h4 id="3-4-1-if"><a href="#3-4-1-if" class="headerlink" title="3.4.1  if"></a>3.4.1  if</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> conditionl</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">commandl</span><br><span class="line"><span class="keyword">elif</span> condition2</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">command2</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">commandN</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">a=10</span><br><span class="line">b=20</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$a</span> == <span class="variable">$b</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a 等于 b&quot;</span></span><br><span class="line"><span class="keyword">elif</span> [ <span class="variable">$a</span> -gt <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a 大于 b&quot;</span></span><br><span class="line"><span class="keyword">elif</span> [ <span class="variable">$a</span> -lt <span class="variable">$b</span> ] </span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;a 小于 bn&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;没有符合的条件&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="Shell-case语句为多选择语句。"><a href="#Shell-case语句为多选择语句。" class="headerlink" title="Shell case语句为多选择语句。"></a>Shell case语句为多选择语句。</h4><h4 id="可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。"><a href="#可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。" class="headerlink" title="可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。"></a>可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> 值 <span class="keyword">in</span> </span><br><span class="line">模式1)</span><br><span class="line">command1 </span><br><span class="line">command2 </span><br><span class="line">... </span><br><span class="line">commandN ;; </span><br><span class="line"></span><br><span class="line">模式2）</span><br><span class="line">command1 </span><br><span class="line">command2 </span><br><span class="line">... </span><br><span class="line">commandN </span><br><span class="line">;; </span><br><span class="line"><span class="keyword">esac</span> </span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;输入 1 到 4 之间的数字:&#x27;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;你输入的数字为:&#x27;</span> </span><br><span class="line"><span class="built_in">read</span> num </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$num</span> <span class="keyword">in</span> </span><br><span class="line">1) <span class="built_in">echo</span> <span class="string">&#x27;你选择了 1&#x27;</span> </span><br><span class="line">;;</span><br><span class="line">2) <span class="built_in">echo</span> <span class="string">&#x27;你选择了 2&#x27;</span> </span><br><span class="line">;;</span><br><span class="line">3) <span class="built_in">echo</span> <span class="string">&#x27;你选择了 3&#x27;</span> </span><br><span class="line">;;</span><br><span class="line">4) <span class="built_in">echo</span> <span class="string">&#x27;你选择了 4&#x27;</span> </span><br><span class="line">;;</span><br><span class="line">*) <span class="built_in">echo</span> <span class="string">&#x27;你没有输入 1 到 4 之间的数字&#x27;</span> </span><br><span class="line">;; </span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><h4 id="3-4-2-for"><a href="#3-4-2-for" class="headerlink" title="3.4.2 for"></a>3.4.2 for</h4><p>当变量值在列表里，for循环即执行一次所有命令，使用变量名获取列表中的当前取值。</p><p>命令可为田可有效的shell命令和语句。in列表可以包含替换、字符串和文件名。</p><p>in列表是可选的，如果不用它，for循环使用命令行的位置参数。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> item1 item2 ... itemN </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">command1 </span><br><span class="line">command2 </span><br><span class="line">... </span><br><span class="line">commandN </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> loop <span class="keyword">in</span> 1 2 3 4 5 </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;The value is: <span class="variable">$loop</span>&quot;</span> </span><br><span class="line"><span class="keyword">done</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> str <span class="keyword">in</span> <span class="string">&#x27;This is a string&#x27;</span> <span class="string">&#x27;hello moto&#x27;</span> </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$str</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="3-4-3-while循环"><a href="#3-4-3-while循环" class="headerlink" title="3.4.3 while循环"></a>3.4.3 while循环</h4><p>while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> condition </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">command</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Bash let 命令，它用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash </span></span><br><span class="line">int=1 </span><br><span class="line"><span class="keyword">while</span>(( <span class="variable">$int</span>&lt;=5 )) </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$int</span> </span><br><span class="line"><span class="built_in">let</span> <span class="string">&quot;int++&quot;</span> </span><br><span class="line"><span class="keyword">done</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 无限循环 </span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span> </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">command</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="3-4-4-break"><a href="#3-4-4-break" class="headerlink" title="3.4.4 break"></a>3.4.4 break</h4><p>break命令允许跳出所有循环（终止执行后面的所有循环）。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"><span class="keyword">while</span> : </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">&quot;输入 1 到 5 之间的数字:&quot;</span> </span><br><span class="line"><span class="built_in">read</span> aNum </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span> </span><br><span class="line">1|2|3|4|5) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字为 <span class="variable">$aNum</span>!&quot;</span> </span><br><span class="line">;;</span><br><span class="line">*) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字不是 1 到 5 之间的! 游戏结束&quot;</span> </span><br><span class="line"><span class="built_in">break</span> </span><br><span class="line">;; </span><br><span class="line"><span class="keyword">esac</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="3-4-5-continue"><a href="#3-4-5-continue" class="headerlink" title="3.4.5 continue"></a>3.4.5 continue</h4><p>continue命令不会跳出所有循环，仅仅跳出当前循环。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"><span class="keyword">while</span> : </span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">&quot;输入 1 到 5 之间的数字: &quot;</span> </span><br><span class="line"><span class="built_in">read</span> aNum </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$aNum</span> <span class="keyword">in</span> </span><br><span class="line">1|2|3|4|5) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字为 <span class="variable">$aNum</span>!&quot;</span> </span><br><span class="line">;;</span><br><span class="line">*) <span class="built_in">echo</span> <span class="string">&quot;你输入的数字不是 1 到 5 之间的!&quot;</span></span><br><span class="line">        <span class="built_in">continue</span> </span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;游戏结束&quot;</span> </span><br><span class="line">        ;; </span><br><span class="line">    <span class="keyword">esac</span> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="3-5-Shell函数"><a href="#3-5-Shell函数" class="headerlink" title="3.5 Shell函数"></a>3.5 Shell函数</h2><p>linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。</p><p>可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。</p><p>参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。return后跟数值n(0-255</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 第一个函数------------------------------ </span></span><br><span class="line"><span class="function"><span class="title">demoFun</span></span>()&#123; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;这是我的第一个 shell 函数!&quot;</span> </span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-----函数开始执行-----&quot;</span> </span><br><span class="line">demoFun </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-----函数执行完毕-----&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">## 函数返回值------------------------------ </span></span><br><span class="line"><span class="function"><span class="title">funWithReturn</span></span>()&#123; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;这个函数会对输入的两个数字进行相加运算...&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;输入第一个数字: &quot;</span> </span><br><span class="line"><span class="built_in">read</span> aNum </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;输入第二个数字: &quot;</span> </span><br><span class="line"><span class="built_in">read</span> anotherNum  </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;两个数字分别为 <span class="variable">$aNum</span> 和 <span class="variable">$anotherNum</span> !&quot;</span> </span><br><span class="line"><span class="built_in">return</span> $((<span class="variable">$aNum</span>+<span class="variable">$anotherNum</span>)) </span><br><span class="line">&#125;</span><br><span class="line">funWithReturn </span><br><span class="line"><span class="comment"># 函数返回值在调用该函数后通过 $? 来获得。 </span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;输入的两个数字之和为 $? !&quot;</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 函数参数------------------------------ </span></span><br><span class="line"><span class="function"><span class="title">funWithParam</span></span>()&#123; </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第一个参数为 <span class="variable">$1</span> !&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第二个参数为 <span class="variable">$2</span> !&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第十个参数为 <span class="variable">$10</span> !&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第十个参数为 <span class="variable">$&#123;10&#125;</span> !&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;第十一个参数为 <span class="variable">$&#123;11&#125;</span> !&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;参数总数有 <span class="variable">$#</span> 个!&quot;</span> </span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;作为一个字符串输出所有参数 $* !&quot;</span> </span><br><span class="line">&#125;</span><br><span class="line">funWithParam 1 2 3 4 5 6 7 8 9</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Shell编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>shell中系统任务设置</title>
      <link href="/2022/05/21/shell%E4%BB%BB%E5%8A%A1%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"/>
      <url>/2022/05/21/shell%E4%BB%BB%E5%8A%A1%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="shell中系统任务设置"><a href="#shell中系统任务设置" class="headerlink" title="shell中系统任务设置"></a>shell中系统任务设置</h1><h3 id="1、系统启动流程"><a href="#1、系统启动流程" class="headerlink" title="1、系统启动流程"></a>1、系统启动流程</h3><p>启动计算机的硬件(BIOS)</p><p>​        读取时间</p><p>​        选择对应的启动模式(USB HDD EFI）</p><p>如果是Linux系统，回去找&#x2F;boot目录.引导这个系统启动</p><p>计算机系统开始启动,读取初始化配置文件</p><p>​        vim &#x2F;etc&#x2F;inittab</p><p>​        启动时控制着计算机的运行级别 runlevel</p><table><thead><tr><th>0</th><th>halt(关机)</th></tr></thead><tbody><tr><td>1</td><td>Single user mode(单用户模式)</td></tr><tr><td>2</td><td>Multiuser, without NFS(多用户模式，但是无网络状态) FS–&gt;FileSystem</td></tr><tr><td>3</td><td>Full multiuser mode(多用户完整版模式)</td></tr><tr><td>4</td><td>unused (保留模式)</td></tr><tr><td>5</td><td>X11(用户界面模式)</td></tr><tr><td>6</td><td>reboot(重启模式)</td></tr></tbody></table><p>​        id:3:initdefault: 默认runlevel为3 </p><p>​        以runlevel&#x3D;3开始启动对应的服务和组件</p><p>开始默认引导公共的组件或者服务</p><p>​        vim &#x2F;etc&#x2F;rc.d&#x2F;rc.sysinit</p><p>开始加载对应runlevel的服务</p><p>​        vi &#x2F;etc&#x2F;rc3.d&#x2F;</p><p>​            K:关机时需要关闭的服务</p><p>​            S:启动时需要开启的服务</p><p>​            数字代表了开启或者关闭的顺序</p><p>​            所有的文件都是软链接，链接的地址为 &#x2F;etc&#x2F;init.d</p><p>当启动完毕，所有的服务也被加载完成</p><h3 id="2、系统服务"><a href="#2、系统服务" class="headerlink" title="2、系统服务"></a>2、系统服务</h3><p>​    我们可以使用chkconfig命令查看当前虚拟机的服务</p><p>​    通过查看可以得知不同的级别对应到每一个服务确定本次开机自动启动</p><p>​    开机结束后，我们需要使用service（Centos6）Systemctl(Centos7)命令控制服务的开启或者关闭</p><h3 id="3、-开机自启动服务"><a href="#3、-开机自启动服务" class="headerlink" title="3、 开机自启动服务"></a>3、 开机自启动服务</h3><h5 id="rc-local"><a href="#rc-local" class="headerlink" title="rc.local"></a>rc.local</h5><p>​        首先创建脚本存放的文件夹</p><p>​                mkdir -p &#x2F;usr&#x2F;local&#x2F;scripts</p><p>​        在文件夹中创建脚本文件</p><p>​                vim hello.sh</p><p>​                给予执行权限</p><p>​        去&#x2F;etc&#x2F;rc.d&#x2F;rc.local文件中添加脚本的绝对路径</p><p>​                给予rc.local执行权限</p><p>​        创建一个文件夹</p><p>​                mkdir &#x2F;usr&#x2F;local&#x2F;soft&#x2F;ceshitest</p><p>​        重启虚拟机</p><p>​                reboot</p><h5 id="chkconfig"><a href="#chkconfig" class="headerlink" title="chkconfig"></a>chkconfig</h5><p>​        创建开机自启动脚本文件</p><p>​        vim schoolntpdate.sh</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash </span></span><br><span class="line"><span class="comment">#chkconfig: 2345 88 99 </span></span><br><span class="line"><span class="comment">#description:auto_run </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开机创建文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> /usr/local/soft/ceshitest2</span><br></pre></td></tr></table></figure><p>​        给其设置执行权限</p><p>​                chmod u+x schoolntpdate.sh</p><p>​        将脚本拷贝到 &#x2F;etc&#x2F;init.d    下</p><p>​                cp schoolntpdate.sh &#x2F;etc&#x2F;init.d&#x2F;</p><p>​        添加到服务</p><p>​                chkconfig –add &#x2F;etc&#x2F;init.d&#x2F;schoolntpdate.sh</p><p>​        重启服务器</p><p>​                reboot</p><h3 id="4、定时任务"><a href="#4、定时任务" class="headerlink" title="4、定时任务"></a>4、定时任务</h3><blockquote><p>在linux中最小时间是到分钟的</p></blockquote><p>在系统服务中心，crond负责周期任务</p><p>​        systemctl status crond.service</p><p>添加任务，编辑当前用户的任务列表</p><p>​        crontab -e</p><p>编辑任务</p><p>​        星 星 星 星 星 command</p><p>​        分 时 日 月 周 命令</p><p>​        第1列表示分钟1～59 每分钟用*或者 *&#x2F;2表示</p><p>​        第2列表示小时1～23（0表示0点）</p><p>​        第3列表示日期1～31</p><p>​        第4列表示月份1～12</p><p>​        第5列标识号星期0～6（0表示星期天）</p><p>​        第6列要运行的命令</p><p>​        *：表示任意时间都，实际上就是“每”的意思。可以代表00-23小时或者00-12每月或者00-59分</p><p>​        -：表示区间，是一个范围，00 17-19 * * * cmd，就是每天17,18,19点的整点执行命令</p><p>​        ,：是分割时段，30 3,19,21 * * * cmd，就是每天凌晨3和晚上19,21点的半点时刻执行命令</p><p>​        &#x2F;n：表示分割，可以看成除法，*&#x2F;5 * * * * cmd，每隔五分钟执行一次</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">30 21 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每晚的21:30重启apache。 </span><br><span class="line"></span><br><span class="line">45 4 1,10,22 * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每月1、10、22日的4 : 45重启apache。 </span><br><span class="line"></span><br><span class="line">10 1 * * 6,0 /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每周六、周日的1 : 10重启apache。 </span><br><span class="line"></span><br><span class="line">0,30 18-23 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。 </span><br><span class="line"></span><br><span class="line">0 23 * * 6 /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">上面的例子表示每星期六的11 : 00 pm重启apache。 </span><br><span class="line"></span><br><span class="line">* */2 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">每两小时重启apache </span><br><span class="line"></span><br><span class="line">* 23-7/1 * * * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">晚上11点到早上7点之间，每隔一小时重启apache </span><br><span class="line"></span><br><span class="line">0 11 4 * mon-wed /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">每月的4号与每周一到周三的11点重启apache </span><br><span class="line"></span><br><span class="line">0 4 1 jan * /usr/local/etc/rc.d/lighttpd restart </span><br><span class="line">一月一号的4点重启apache</span><br><span class="line"></span><br><span class="line">需求：每分钟要干一些事情</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--（功能描述：显示年月日时分秒） </span><br><span class="line"><span class="built_in">date</span> <span class="string">&quot;+%Y%m%d%H%M%S&quot;</span></span><br></pre></td></tr></table></figure><p>重启crontab，使配置生效</p><p>​        systemctl restart crond.service</p><p>通过crontab -l</p><p>​        查看当前的定时任务</p><p>查看任务的历史</p><p>​        vim &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root</p><p>清除任务</p><p>​        crontab -r</p>]]></content>
      
      
      <categories>
          
          <category> Shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell中系统任务设置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化</title>
      <link href="/2022/05/20/Redis%E6%8C%81%E4%B9%85%E5%8C%96/"/>
      <url>/2022/05/20/Redis%E6%8C%81%E4%B9%85%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h3 id="1-持久化机制"><a href="#1-持久化机制" class="headerlink" title="1.持久化机制"></a>1.持久化机制</h3><p>Redis官方提供了两种不同的持久化方法来将内存的数据存储到硬盘里</p><p><strong>快照（Snapshot）</strong></p><p><strong>AOF（Append Only File）</strong>只追加日志文件</p><h4 id="1-1-快照（Snapshot）"><a href="#1-1-快照（Snapshot）" class="headerlink" title="1.1 快照（Snapshot）"></a>1.1 快照（Snapshot）</h4><h5 id="1-特点"><a href="#1-特点" class="headerlink" title="1.特点"></a>1.特点</h5><blockquote><p>这种方式可以将某一时刻的所有数据都写入硬盘中，这是Redis的默认开启持久化的方式，保存的文件时以**.rdb**后缀的文件，所以这种方式也成为RDB方式。</p></blockquote><blockquote><p>官方说法叫快照持久化</p></blockquote><p><img src="https://s2.loli.net/2022/05/18/F62H8pT9SQ5XAcy.png" alt="image-20220512214029142"></p><h5 id="2-快照生成方式"><a href="#2-快照生成方式" class="headerlink" title="2.快照生成方式"></a>2.快照生成方式</h5><blockquote><p>客户端方式：BGSAVE和SAVE指令</p></blockquote><blockquote><p>服务器配置自动触发</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、客户端方式-BGSAVE</span><br><span class="line">-客户端可以使用BGSAVE命令来创建一个快照，当接收到客户端的BGSAVE命令时，redis会调用fork来创建一个子进程，然后子进程负责将快照写入磁盘中，而父进程则继续处理命令请求</span><br><span class="line"></span><br><span class="line">名词解释：*fork*。当一个进程创建子进程的时候，底层的操作系统会创建该进程的一个副本，在类似于unix系统中创建子进程的操作会进行优化：在刚开始的时候，父子进程共享相同内存，知道父进程或子进程对内存进行了写之后，对被写入的内存才会结束服务。</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/18/QLUB12mTMPFrE45.png" alt="image-20220512214729500"></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2、客户端方式-SAVE</span><br><span class="line">-客户端还可以使用SAVE命令来创建一个快照，接收到SAVE命令的redis服务器在快照创建完毕之前将不再响应任何其他的命令</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/18/671QPakdDzq8Hfg.png" alt="image-20220512214914633"></p><p>注意：SAVE命令并不常用，使用SAVE命令在快照创建完毕之前，redis处于阻塞状态，无法对外服务</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3、服务器配置-满足自动触发</span><br><span class="line">-如果用户在redis.conf中设置了save配置选项，redis会在save选项条件满足之后自动触发一次BGSAVE命令，如果设置多个save配置选项，当任意一个save配置选项条件满足，redis也会触发一次BGSAVE命令</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">4、服务器接收客户端shutdown指令</span><br><span class="line">-当redis通过shutdown指令接收到关闭服务器的请求时，会执行一个save命令，阻塞所有的客户端，不再执行客户端执行发送的任何命令，并且在save命令执行完毕之后关闭服务器</span><br></pre></td></tr></table></figure><h5 id="3-配置生成快照名称和位置"><a href="#3-配置生成快照名称和位置" class="headerlink" title="3.配置生成快照名称和位置"></a>3.配置生成快照名称和位置</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、修改生成快照名称</span><br><span class="line">-dbfilename dump.rbd</span><br><span class="line">2、修改生成位置</span><br><span class="line">-dir ./</span><br><span class="line"></span><br><span class="line">经过断电操作测试后，发现这个持久化并不是太好，可能会造成数据丢失问题（刚刚做完一次快照，又来一次写数据请求断电）</span><br></pre></td></tr></table></figure><h4 id="1-2-AOF只追加日志文件"><a href="#1-2-AOF只追加日志文件" class="headerlink" title="1.2 AOF只追加日志文件"></a>1.2 AOF只追加日志文件</h4><h5 id="1-特点-1"><a href="#1-特点-1" class="headerlink" title="1.特点"></a>1.特点</h5><p>这种方式可以将所有客户端执行的<strong>写命令</strong>记录到日志文件中，AOF持久化会被执行的写命令写到AOF的文件末尾，以此来记录数据发生的变化，因此只要redis从头到尾执行一次AOF文件所包含的所有写命令，就可以恢复AOF文件的记录的数据集</p><p><img src="https://s2.loli.net/2022/05/18/yJIqWEfzsv3Kajp.png"></p><h5 id="2-开启AOF持久化"><a href="#2-开启AOF持久化" class="headerlink" title="2.开启AOF持久化"></a>2.开启AOF持久化</h5><p>在开启redis的默认配置中AOF持久化机制是没有开启的，需要在配置中开启</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、开启AOF持久化</span><br><span class="line">-修改 appendonly yes 开启持久化</span><br><span class="line">-修改 appendfilename &quot;appendonly.aof&quot; 指定生成文件名称</span><br></pre></td></tr></table></figure><h5 id="3-日志追加频率"><a href="#3-日志追加频率" class="headerlink" title="3.日志追加频率"></a>3.日志追加频率</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.always 【谨慎使用】</span><br><span class="line">- 说明: 每个redis写命令都要同步写入硬盘,严重降低redis速度</span><br><span class="line">- 解释: 如果用户使用了always选项,那么每个redis写命令都会被写入硬盘,从而将发生系统崩溃时出现的数据丢失减到最少;遗憾的是,因为这种同步策略需要对硬盘进行大量的写入操作,所以redis处理命令的速度会受到硬盘性能的限制;</span><br><span class="line">- 注意: 转盘式硬盘在这种频率下200左右个命令/s ; 固态硬盘(SSD) 几百万个命令/s;</span><br><span class="line">- 警告: 使用SSD用户请谨慎使用always选项,这种模式不断写入少量数据的做法有可能会引发严重的`写入放大`问题,导致将固态硬盘的寿命从原来的几年降低为几个月。</span><br><span class="line"></span><br><span class="line"># 2.everysec 【推荐默认】</span><br><span class="line">- 说明: 每秒执行一次同步显式的将多个写命令同步到磁盘</span><br><span class="line">- 解释： 为了兼顾数据安全和写入性能,用户可以考虑使用everysec选项,让redis每秒一次的频率对AOF文件进行同步;redis每秒同步一次AOF文件时性能和不使用任何持久化特性时的性能相差无几,而通过每秒同步一次AOF文件,redis可以保证,即使系统崩溃,用户最多丢失一秒之内产生的数据。 </span><br><span class="line"></span><br><span class="line"># 3.no【不推荐】</span><br><span class="line">- 说明: 由操作系统决定何时同步 </span><br><span class="line">- 解释：最后使用no选项,将完全有操作系统决定什么时候同步AOF日志文件,这个选项不会对redis性能带来影响但是系统崩溃时,会丢失不定数量的数据,甚至丢失全部数据，另外如果用户硬盘处理写入操作不够快的话,当缓冲区被等待写入硬盘数据填满时,redis会处于阻塞状态,并导致redis的处理命令请求的速度变慢。</span><br></pre></td></tr></table></figure><h4 id="1-3-AOF文件的重写"><a href="#1-3-AOF文件的重写" class="headerlink" title="1.3 AOF文件的重写"></a>1.3 AOF文件的重写</h4><h5 id="1-AOF带来的问题"><a href="#1-AOF带来的问题" class="headerlink" title="1. AOF带来的问题"></a>1. AOF带来的问题</h5><p>AOF的方式也同时带来了另一个问题。持久化文件会变得越来越大。例如我们调用incr test命令100次，文件中必须保存全部的100条命令，其实有99条都是多余的。因为要恢复数据库的状态其实文件中保存一条set test 100就够了。为了压缩AOF的持久化文件，Redis提供了AOF重写（ReWrite）机制。</p><h5 id="2-AOF重写"><a href="#2-AOF重写" class="headerlink" title="2. AOF重写"></a>2. AOF重写</h5><p>用来在一定程度上减小AOF文件的体积,并且还能保证数据不丢失</p><h5 id="3-触发重写方式"><a href="#3-触发重写方式" class="headerlink" title="3. 触发重写方式"></a>3. 触发重写方式</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.客户端方式触发重写</span><br><span class="line">-执行BGREWRIEAOF命令  不会阻塞redis的服务</span><br><span class="line">2.服务器配置方式自动触发</span><br><span class="line">-配置redis.conf中的auto-aof-rewrite-percentage选项</span><br><span class="line">-如果设置auto-aof-rewrite-percentage值为100和auto-aof-rewrite-min-size 64mb,并且启用的AOF持久化时,那么当AOF文件体积大于64MB,并且AOF文件的体积比上一次重写之后体积大了至少一倍(100%)时,会自动触发,如果重写过于频繁,用户可以考虑将auto-aof-rewrite-percentage设置为更大</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/05/18/YiLCvp4arWw6eBE.png" alt="image-20220512225431013"></p><h5 id="4-重写原理"><a href="#4-重写原理" class="headerlink" title="4. 重写原理"></a>4. 重写原理</h5><p>从Redis 7.0.0开始,Redis使用了多部分AOF机制.也就是将原来的单个AOF文件拆分为基础文件(最多一个)和增量文件(可能不止一个).</p><p>基本文件表示重写AOF时存在的数据的初始(RDB或AOF格式)快照.</p><p>增量文件包含自创建最后一个基本AOF文件以来的增量更改.所有这些文件都放在一个单独的目录中,并由清单文件跟踪</p><p>从 Redis 7.0.0 开始，在调度 AOF 重写时，Redis 父进程会打开一个新的增量 AOF 文件继续写入。子进程执行重写逻辑并生成新的基础 AOF。Redis 将使用一个临时清单文件来跟踪新生成的基础文件和增量文件。当它们准备好后，Redis 会执行原子替换操作，使这个临时清单文件生效。为了避免在 AOF 重写重复失败和重试的情况下创建大量增量文件的问题，Redis 引入了 AOF 重写限制机制，以确保失败的 AOF 重写以越来越慢的速度重试。</p><h4 id="日志重写"><a href="#日志重写" class="headerlink" title="日志重写"></a>日志重写</h4><p>注意AOF文件的操作,并没有读取旧的AO文件,而是将整个内存中的数据库内容用命令的方式写了一个新的aof文件替换原有的文件这点和快照有点类似</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">重写流程</span><br><span class="line">-1 redis调用fork,现在又父子两个进程,子进程根据内存中的数据库快照,往临时文件中写入重建数据库状态的命令</span><br><span class="line">-2 父进程继续处理client请求,除了把写命令写入到原来的aof文件中.同时把接收到的写命令缓存起来.这样就能保证如果子进程重写失败的话,不会丢失数据</span><br><span class="line">-3 当子进程把快照内容写入己命令写到临时文件中后,子进程发信号通知父进程,然后父进程把缓存的命令也写到临时文件中</span><br><span class="line">-4 现在父进程可以使用临时文件替换旧的aof文件,并重命名,后面收到的写命令也开始往新的aof文件中追加.</span><br></pre></td></tr></table></figure><p><strong>Redis7.0.0之前：</strong></p><p><img src="https://s2.loli.net/2022/05/18/5dzkXMxvcObFf6A.png" alt="image-20220512225149515"></p><p><strong>Redis7.0.0之后：</strong></p><p><img src="https://s2.loli.net/2022/05/18/bovIWStHZL1hFaO.png" alt="image-20220513120013948"></p><h4 id="1-4-持久化总结"><a href="#1-4-持久化总结" class="headerlink" title="1.4 持久化总结"></a>1.4 持久化总结</h4><p>两种持久化方案既可以同时使用(aof),又可以单独使用,在某种情况下也可以都不使用,具体使用哪种持久化方案取决于用户的数据和用用决定.</p><p>无论使用AOF还是快照机制持久化,将数据持久化到硬盘都是有必要的,除了持久化之外,用户还应该对持久化的文件进行备份(异地备份)以最大安全保障数据的完整性.</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL5.7概述以及下载安装（centOS7）</title>
      <link href="/2022/04/27/MySQL%E6%A6%82%E8%BF%B0%E4%BB%A5%E5%8F%8A%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/"/>
      <url>/2022/04/27/MySQL%E6%A6%82%E8%BF%B0%E4%BB%A5%E5%8F%8A%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL5-7概述以及下载安装（centOS7）"><a href="#MySQL5-7概述以及下载安装（centOS7）" class="headerlink" title="MySQL5.7概述以及下载安装（centOS7）"></a>MySQL5.7概述以及下载安装（centOS7）</h1><h2 id="一、MySQL简介"><a href="#一、MySQL简介" class="headerlink" title="一、MySQL简介"></a>一、MySQL简介</h2><blockquote><p>MySQL是一个典型的关系数据库，目前是Oracle公司产品之一，也是目前主流使用的关系型数据库之一。使用MySQL可以进行最基本的数据存储、管理、查询等操作，也可以方便的组建数据库集群，配置读写分离。</p><p>MySQL数据库同样使用SQL（结构化查询语言）来进行操作，同时MySQL数据库自身也有很多可以直接使用的内置函数，在部分操作的语法上和其他数据库会存在区别。</p></blockquote><h2 id="二、版本选择"><a href="#二、版本选择" class="headerlink" title="二、版本选择"></a>二、版本选择</h2><h3 id="1-应用场景"><a href="#1-应用场景" class="headerlink" title="1.    应用场景"></a>1.    应用场景</h3><h5 id="社区版"><a href="#社区版" class="headerlink" title="社区版"></a>社区版</h5><blockquote><p>在学习阶段，可以使用免费的社区版，这也是中小型企业会选用的一个版本，可以在官方网站直接进行下载。在社区版中，除了提供数据库服务端以外，同样提供了社区版相关组件，如官方的可视化工具、MySQL集群、各开发语言数据库驱动等，可以根据需要直接下载。</p></blockquote><p><img src="D:/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E6%96%87%E4%BB%B6/MySQL%E6%A6%82%E8%BF%B0%E4%BB%A5%E5%8F%8A%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85.assets/1.png" alt="1"></p><h5 id="企业版"><a href="#企业版" class="headerlink" title="企业版"></a>企业版</h5><blockquote><p>MySQL企业版是提供了商用的解决方案，相关的产品除了数据库服务外，还包括：MySQL云服务、企业级数据备份、企业级防火墙、企业级数据加密等。</p></blockquote><h3 id="2-MySQL版本"><a href="#2-MySQL版本" class="headerlink" title="2.    MySQL版本"></a>2.    MySQL版本</h3><blockquote><p>目前MySQL官网提供了三个大版本的支持，5.6.x、5.7.x、8.0.x。8.x版本相较于5.7版本，在性能方面做出了较大的改进和优化：2x Faster than MySQL5.7!</p><p>在8.0的MySQL数据库中，对某些常用语法的细节部分也做了调整，<strong>如果准备进行升级，一定要注意兼容性的问题</strong>。<br>而5.7版本相较于5.6版本而言，主要是进行了性能上的优化，并提供了更丰富的设置。如：新增了优化器、原生JSON支持、GIS扩展等。</p></blockquote><h2 id="三、下载地址"><a href="#三、下载地址" class="headerlink" title="三、下载地址"></a>三、下载地址</h2><h3 id="1-官网地址"><a href="#1-官网地址" class="headerlink" title="1.    官网地址"></a>1.    官网地址</h3><blockquote><p>首先来到MySQL数据库官网，直接在百度搜索MySQL就可以找到：<a href="https://www.mysql.com/%EF%BC%8C%E6%89%93%E5%BC%80%E4%B9%8B%E5%90%8E%E7%9B%B4%E6%8E%A5%E7%82%B9%E5%87%BB**DOWNLOADS**%E6%8C%89%E9%92%AE%E3%80%82">https://www.mysql.com/，打开之后直接点击**DOWNLOADS**按钮。</a></p></blockquote><h3 id="2-社区版下载"><a href="#2-社区版下载" class="headerlink" title="2.    社区版下载"></a>2.    社区版下载</h3><blockquote><p>进入下载界面后，点击<strong>MySQL Community（GPL）Downloads</strong>按钮进入下载界面：</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/YdSUjexPNmyIiWa.png" alt="image-20220429195827454"></p><blockquote><p>选择<strong>MySQL Community Server</strong>：</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/7Jgtn3lzX6OeTcF.png" alt="image-20220429195858199"></p><blockquote><p>直击链接：<a href="https://dev.mysql.com/downloads/mysql/">https://dev.mysql.com/downloads/mysql/</a></p></blockquote><h3 id="3-选择版本"><a href="#3-选择版本" class="headerlink" title="3.    选择版本"></a>3.    选择版本</h3><blockquote><p>对于Linux平台而言而言，如果是解压安装基本没有任何差别。如果是软件包安装，在下载时一定要选择相应的版本。目前官网提供两个大的稳定版，一个是<strong>5.7</strong>，一个是<strong>8.0</strong>，将演示如何在CentOS 7系统下安装MySQL 5.7。</p></blockquote><p>进入界面后点击<strong>Looking for previous GA versions</strong>链接：</p><p><img src="https://s2.loli.net/2022/04/29/Xe6UCnRI4Z1NdSf.png" alt="image-20220429195935377"></p><blockquote><p>依次选择<strong>操作系统</strong> -&gt; <strong>系统版本</strong> -&gt; <strong>需要下载的软件包</strong>：</p><p>下载的软件包需要：common、client、libs、server。</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/HRfwc8uvV17gsKT.png" alt="image-20220429195958113"></p><h3 id="4-下载安装包"><a href="#4-下载安装包" class="headerlink" title="4.    下载安装包"></a>4.    下载安装包</h3><blockquote><p>进入下载界面后，直接点击 No thanks,just start my download. 链接即可直接下载。</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/V1yAObzluIWtN72.png" alt="image-20220429200026929"></p><blockquote><p>windows下载后的截图</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/PpeOLoHWMQJN1gS.png" alt="image-20220429200037001"></p><h2 id="四、安装步骤"><a href="#四、安装步骤" class="headerlink" title="四、安装步骤"></a>四、安装步骤</h2><blockquote><p>RPM软件包格式适用于所有基于RedHat内核的Linux发行版，包括CentOS等，在安装之前都要解决好依赖和冲突的问题。由于在安装系统时所选的组件不同，可能预安装的系统环境有所不同。</p></blockquote><h3 id="1-解决依赖冲突"><a href="#1-解决依赖冲突" class="headerlink" title="1.    解决依赖冲突"></a>1.    解决依赖冲突</h3><blockquote><p>在安装之前先检查一下是否有历史版本，包括可能产生冲突的mariadb软件包。</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">rpm -qa|grep mysql</span><br><span class="line">rpm -qa|grep MySQL</span><br><span class="line">rpm -qa|grep mariadb</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/29/sXkPU9On2zQoLZi.png" alt="image-20220429200048782"></p><blockquote><p>查询出软件信息后进行卸载</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -e --nodeps mariadb-libs-5.5.65-1.el7.x86_64</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/29/sXkPU9On2zQoLZi.png"></p><h3 id="2-解决依赖缺失"><a href="#2-解决依赖缺失" class="headerlink" title="2.    解决依赖缺失"></a>2.    解决依赖缺失</h3><blockquote><p>在CentOS系统中安装MySQL时通常会缺少Data::Dumper，需要先进行安装。</p><p><strong>注意：(后续需要什么我们按照同样方式安装即可)</strong></p><p>在有网的环境下，可以直接使用yum安装。</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">yum -y install autoconf</span><br></pre></td></tr></table></figure><h3 id="3-MySQL服务端安装"><a href="#3-MySQL服务端安装" class="headerlink" title="3.    MySQL服务端安装"></a>3.    MySQL服务端安装</h3><blockquote><p>将下载的rpm包上传至Linux服务器中</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/Sd7ulYDOUPVcgwm.png" alt="image-20220429200113190"></p><blockquote><p>MySQL服务端的安装包为server，安装的顺序为：<strong>common -&gt; libs -&gt; client -&gt; server</strong>。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><blockquote><p>rpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/Qw5DSM23lu1zky8.png" alt="image-20220429200122777"></p><blockquote><p>rpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/lCEse3qhYFNz2JQ.png" alt="image-20220429200141913"></p><blockquote><p>rpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/lCEse3qhYFNz2JQ.png"></p><blockquote><p>rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm(<strong>到这里可能会报错，如下图所示</strong>：)</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/97E13YhFpGVJOSP.png"></p><blockquote><p>只需要把对应的包安装一下即可</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install net-tools</span><br></pre></td></tr></table></figure><blockquote><p>再执行就可以了</p><p>rpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/PAThaFMHZKR23V6.png" alt="image-20220429200225159"></p><blockquote><p>安装完成后创建的配置文件存放在**&#x2F;etc&#x2F;my.cnf**，如果需要进行一些自定义配置，可以修改该文件。</p></blockquote><h2 id="五、使用测试"><a href="#五、使用测试" class="headerlink" title="五、使用测试"></a>五、使用测试</h2><h3 id="1-启动数据库服务"><a href="#1-启动数据库服务" class="headerlink" title="1.    启动数据库服务"></a>1.    启动数据库服务</h3><blockquote><p>使用root用户来启动服务：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start mysqld.service</span><br></pre></td></tr></table></figure><blockquote><p>检查服务状态：</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl status mysqld.service</span><br></pre></td></tr></table></figure><blockquote><p>查看到下图状态证明启动成功。</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/PAThaFMHZKR23V6.png"></p><h3 id="2-首次连接修改密码"><a href="#2-首次连接修改密码" class="headerlink" title="2.    首次连接修改密码"></a>2.    首次连接修改密码</h3><blockquote><p>MySQL在启动后会产生一个日志文件，存放在 <strong>&#x2F;var&#x2F;log&#x2F;mysqld.log</strong> ，其中包含了初始密码的信息，可以通过以下命令快速找到：</p></blockquote><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">grep <span class="string">&#x27;temporary password&#x27;</span> /var/log/mysqld.log</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/29/vxqckftduipNZSR.png" alt="image-20220429200247691"></p><blockquote><p><strong>复制时注意前后都不要有空格。</strong></p></blockquote><p>使用客户端命令连接</p><blockquote><p>mysql -uroot -pfqomD#lTo5lH</p></blockquote><p><img src="https://s2.loli.net/2022/04/29/2jYR1fn6AP5ogXm.png" alt="image-20220429200256023"></p><blockquote><p>修改安全策略</p><p>MySQL 5.7版本会安装一个密码校验插件，要求设置的密码必须在一定的位数并且要符合密码安全策略（有一定的复杂性），在学习阶段可以先调低策略，设置为一个比较简单的密码。<br>验证策略修改为low（只校验密码长度）：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_policy<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure><blockquote><p>修改最小密码长度为4：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_length<span class="operator">=</span><span class="number">4</span>;</span><br></pre></td></tr></table></figure><blockquote><p>设置新密码：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> password <span class="operator">=</span> password(<span class="string">&#x27;123456&#x27;</span>);</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/29/8BuKyF7wbpzClne.png" alt="image-20220429200422898"></p><blockquote><p>使用新密码连接<br>修改密码后使用 exit; 退出，重新使用新密码登录测试。</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql <span class="operator">-</span>uroot <span class="operator">-</span>p</span><br></pre></td></tr></table></figure><p><img src="C:\Users\xiaohu\AppData\Roaming\Typora\typora-user-images\image-20220428201943496.png" alt="image-20220428201943496"></p><blockquote><p>添加主机名连接规则<br>对于MySQL数据库，会将用户的登录密码及权限等信息存放在mysql.user表中，可以先通过以下命令查看一下：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">user</span>,host,authentication_string <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/29/SkI1CVrlNm7qiFX.png" alt="image-20220429200440293"></p><blockquote><p>为方便以后使用,添加任意主机的连接规则，命令如下：</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h3 id="3-数据库远程连接-课程使用Navicat"><a href="#3-数据库远程连接-课程使用Navicat" class="headerlink" title="3.    数据库远程连接(课程使用Navicat)"></a>3.    数据库远程连接(课程使用Navicat)</h3><p>在Linux系统中安装好数据库以后，通常我们都会使用界面工具来进行远程连接。这个时候可以通过两种方式实现，如果只是需要通过界面工具远程查看数据库情况，可以通过SSH通道的方式连接，这样更安全。<br>如果需要在代码中直接连接远程数据进行调试，此时就需要在MySQL数据库中开启远程连接，也就是需要添加一个连接规则。</p><p><img src="https://s2.loli.net/2022/04/29/Uwtluy85QH4nmxo.png" alt="image-20220429200457727"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql5.7 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux用户管理</title>
      <link href="/2022/04/24/linux%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/"/>
      <url>/2022/04/24/linux%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="1、用户组管理"><a href="#1、用户组管理" class="headerlink" title="1、用户组管理"></a>1、用户组管理</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">用户组的管理包括用户组的添加、删除和修改。</span><br><span class="line"></span><br><span class="line">为什么要建立用户组</span><br><span class="line"></span><br><span class="line">人事部有20名员工，我们要建立一个组，叫 hr，这样就不用分别给20个员工设置权限了。</span><br></pre></td></tr></table></figure><h3 id="①-用户组添加"><a href="#①-用户组添加" class="headerlink" title="① 用户组添加"></a>① 用户组添加</h3><p>命令：groupadd</p><p>作用：添加组</p><p>语法：# groupadd  [参数选项  选项值]  用户组名</p><p>选项：-g：设置用户组ID 数字，如果不指定，则默认从1000 之后递增（1-999系统组）</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">用法一：groupadd 组名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="comment">#groupadd bigdata</span></span><br><span class="line">含义：新建一个组叫做bigdata</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/25/npRaHjm9SbX6M1k.png" alt="image-20220425210757721"></p><p>提示：linux下我们执行完命令，有时候会没有任何提示，直接回到#提示符，这种状态表明，命令执行成功，没有报错。&#x3D;&#x3D;“没有消息就是最好的消息”&#x3D;&#x3D;</p><p>存储用户组信息的文件：&#x2F;etc&#x2F;group<br> 使用cat命令，查看&#x2F;etc&#x2F;group文件</p><p>&#x2F;etc&#x2F;group文件结构：</p><p>特别说明：</p><p>1） 密码位<code>x</code>代表<code>占位符</code>，用户组可以设置密码，但是大部分情况下不需要设置</p><p>2）组内用户名：表示附加组是该组的用户名称。</p><p><img src="https://s2.loli.net/2022/04/25/YDOHwAhScxNpVGe.png" alt="image-20220425211850494"></p><h3 id="②-用户组修改"><a href="#②-用户组修改" class="headerlink" title="② 用户组修改"></a>② 用户组修改</h3><p>命令：groupmod</p><p>语法：# groupmod   [选项   选项值]   用户组名</p><p>选项：-g  ：gid缩写，设置一个自定义的用户组ID 数字</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-n  ：name缩写，设置新的用户组的名称</span><br></pre></td></tr></table></figure><p>示例代码：修改bigdata用户组，将组ID改成1100，将名称改为bigdata1</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">用法一：groupmod -g 新的组ID -n 新的组ID 原有组ID</span><br><span class="line">示例代码：</span><br><span class="line">#groupmod -g 1100 -n bigdata1 bigdata</span><br><span class="line">含义：将bigdata组的组ID改成1100，组名改成bigdata1</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/25/59HpA2iK1Cvdxb6.png" alt="image-20220425220023602"></p><h3 id="③-用户组删除"><a href="#③-用户组删除" class="headerlink" title="③ 用户组删除"></a>③ 用户组删除</h3><p>命令：groupdel</p><p>语法：# groupdel  用户组名</p><p>案例：删除bigdata1组</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">用法一：groupdel 组名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="comment">#groupdel bigdata1</span></span><br><span class="line">含义：将bigdata1组删除</span><br></pre></td></tr></table></figure><p><img src="https://s2.loli.net/2022/04/25/EtZWhnz6brfRJxg.png" alt="image-20220425221937616"></p><h2 id="2、用户管理"><a href="#2、用户管理" class="headerlink" title="2、用户管理"></a>2、用户管理</h2><p>用户的管理涉及用户的添加、删除和修改。</p><p>与用户相关的文件：&#x2F;etc&#x2F;passwd</p><h3 id="①useradd添加用户"><a href="#①useradd添加用户" class="headerlink" title="①useradd添加用户"></a>①useradd添加用户</h3><p>命令：useradd</p><p>作用：添加用户</p><p>语法：# useradd   [选项  选项的值]   …   用户名</p><p>选项：-g：表示指定用户的用户主（主要）组，选项值可以是用户组ID，也可以是组名</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-G：表示指定用户的用户附加（额外）组，选项值可以是用户组ID，也可以是组名</span><br><span class="line"></span><br><span class="line">-u ：uid，用户的id（用户的标识符），系统默认会从500 /或1000之后按顺序分配uid，如果不想使用系统分配的，可以通过该选项自定义【类似于腾讯QQ 的自选靓号情况】</span><br><span class="line"></span><br><span class="line">-c：comment，添加注释（选择是否添加）</span><br><span class="line"></span><br><span class="line">-s：指定用户登入后所使用的shell 解释器，默认/bin/bash【专门的接待员】，如果不想让其登录，则可以设置为/sbin/nologin   （重要）</span><br><span class="line"></span><br><span class="line">-d：指定用户登入时的启始目录（家目录位置）</span><br><span class="line"></span><br><span class="line">    -n：取消建立以用户名称为名的群组（了解）</span><br><span class="line"></span><br><span class="line"> 当我新建一个账户叫user01, 同时，系统会自动建立一个组也叫user01</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">用法一：useradd 用户名</span><br><span class="line">示例代码：</span><br><span class="line">#useradd hzh</span><br><span class="line">含义：创建用户hzh，不带任何选项。</span><br></pre></td></tr></table></figure><p>注意：不用任何参数，创建用户，系统会默认执行以下操作：</p><p>1）在 &#x2F;etc&#x2F;passwd 文件中创建一行关于hzh用户的数据</p><p><img src="https://s2.loli.net/2022/04/25/l149argXGmFtVoK.png" alt="image-20220425222337183"></p><p> 2）在 &#x2F;etc&#x2F;shadow 文件中新增了一行关于wyh密码的数据</p><p><img src="https://s2.loli.net/2022/04/25/oqDQihSmxaUlYCJ.png" alt="image-20220425224109139"></p><p> 3）在 &#x2F;etc&#x2F;group 文件中创建一行与用户名相同的组，例如wyh</p><p><img src="https://s2.loli.net/2022/04/25/V1fFiYKbUw5eumD.png" alt="image-20220425224156762"></p><p> 4）在 &#x2F;etc&#x2F;gshadow 文件中新增一行与新增群组相关的密码信息，例如wyh</p><p><img src="https://s2.loli.net/2022/04/25/mgCprBDyfAshOKx.png" alt="image-20220425224224338"></p><p> 5）自动创建用户的家目录，默认在&#x2F;home下，与用户名同名</p><p><img src="https://s2.loli.net/2022/04/25/k4gRO2fNYBuovF9.png" alt="image-20220425224328709"></p><p>验证是否成功：</p><p>1）使用tail文件查看&#x2F;etc&#x2F;passwd文件</p><p>2）使用tail文件查看&#x2F;etc&#x2F;group文件</p><p>3）验证是否存在家目录（在Centos 下创建好用户之后随之产生一个同名家目录）</p><h3 id="②etc-x2F-passwd存储用户信息的文件"><a href="#②etc-x2F-passwd存储用户信息的文件" class="headerlink" title="②etc&#x2F;passwd存储用户信息的文件"></a>②etc&#x2F;passwd存储用户信息的文件</h3><p>使用vim命令打开&#x2F;etc&#x2F;passwd文件</p><figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">root : x : <span class="number">0</span> : <span class="number">0</span> : root : <span class="regexp">/root : /</span>bin/bash</span><br><span class="line">用户名 : 密码 : 用户<span class="variable constant_">ID</span> : 用户组<span class="variable constant_">ID</span> : 注释 : 家目录 : 解释器shell</span><br></pre></td></tr></table></figure><p><strong>用户名</strong>：登录linux时使用的用户名<br> <strong>密码</strong>：此密码位置一般情况都是”x”，表示密码的占位，真实密码存储在&#x2F;etc&#x2F;shadow<br> <strong>用户ID</strong>：用户的识别符，每个用户都有唯一的UID【-u】<br> <strong>用户组ID</strong>：该用户所属的主组ID；【-g】</p><p><strong>注释</strong>：解释该用户是做什么用的；【-c】<br> <strong>家目录</strong>：用户登录进入系统之后默认的位置；【-d】<br> <strong>解释器shell</strong>：等待用户进入系统之后，用户输入指令之后，该解释器会收集用户输入的指令，转换成机器语言，传递给内核处理；如果解释器是&#x3D;&#x3D;&#x2F;bin&#x2F;bash 表示用户可以登录到系统&#x3D;&#x3D;，&#x3D;&#x3D;&#x2F;sbin&#x2F;nologin表示该用户不能登录到系统&#x3D;&#x3D;【-s】</p><p>下面我们来看一下对于useradd参数的使用</p><p><strong>企业场景1：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">     公司新员工lisi，属于bigdata部门，用户ID1200，不允许登录系统</span><br><span class="line">思路：</span><br><span class="line">    创建用户lisi，默认lisi属于自己同名的主组，让lisi 属于附加组bigdata1，用户ID 1200，注释为<span class="string">&quot;数据工程师lisi&quot;</span>，解释器为/sbin/nologin</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">用法二：useradd <span class="literal">-G</span> 附加组名 <span class="literal">-u</span> 用户ID <span class="literal">-s</span> /sbin/nologin <span class="literal">-c</span> <span class="string">&quot;shuser lisi&quot;</span> 用户名</span><br><span class="line">示例代码：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">hzh</span>]<span class="comment"># useradd -G bigdata -u 1200 -s /sbin/nologin -c &quot;数据工程师lisi&quot; lisi</span></span><br><span class="line">useradd：“bigdata”组不存在</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">hzh</span>]<span class="comment"># groupadd bigdata</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">hzh</span>]<span class="comment"># useradd -G bigdata -u 1200 -s /sbin/nologin -c &quot;数据工程师lisi&quot; lisi</span></span><br><span class="line"></span><br><span class="line">含义：创建用户lisi，不带任何选项。</span><br></pre></td></tr></table></figure><figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line">bigdata行的含义：在bigdata的组里（组<span class="type">id</span> 是<span class="number">1002</span>）有一个组内用户lisi（lisi 的附加组就是<span class="number">1002</span>，附加组的名字是bigdata1）。</span><br><span class="line">如果需要为一个用户指定多个附加组，只需要将多个附加组的<span class="type">id</span> 通过英文逗号“,”分割即可。</span><br><span class="line">例如-G <span class="number">500</span>,<span class="number">501</span>,<span class="number">502</span></span><br><span class="line"></span><br><span class="line">① 主组只能有<span class="number">1</span> 个（类似于亲生父母只有一对），附加组可以多个，也可以没有附加组（类似于认干爹干妈，可以有也可以没有，也可以有多个）</span><br><span class="line">② 主组必须有</span><br><span class="line">③ 后期将权限管理的时候，关于文档的属组指的是主组（了解）</span><br></pre></td></tr></table></figure><h3 id="③id查看用户信息"><a href="#③id查看用户信息" class="headerlink" title="③id查看用户信息"></a>③id查看用户信息</h3><p>命令：id</p><p>作用：查看一个用户的一些基本信息（包含用户id，用户组id，附加组id…），该指令如果不指定用户则默认当前用户。</p><p>语法1：# id  <code>默认显示当前执行该命令的用户的基本信息</code></p><p><img src="https://s2.loli.net/2022/04/25/vXxAD93nSeRUKhf.png" alt="image-20220425224939961"></p><p> 语法2：# id <code>用户名</code>， 显示指定用户的基本信息</p><p> 如何验证以上信息是否正确？</p><p>&#x3D;&#x3D;答：验证用户信息：通过文件&#x2F;etc&#x2F;passwd，验证用户组信息：通过文件&#x2F;etc&#x2F;group&#x3D;&#x3D;</p><h3 id="④usermod修改用户"><a href="#④usermod修改用户" class="headerlink" title="④usermod修改用户"></a>④usermod修改用户</h3><p>命令：usermod(user modify)</p><p>语法：# usermod   [选项  选项的值]   …  用户名</p><p>作用：修改用户的各种属性</p><p>选项：-g：表示指定用户的用户主组，选项的值可以是用户组的ID，也可以是组名</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">-G：表示指定用户的用户附加组，选项的值可以是用户组的ID，也可以是组名</span><br><span class="line"></span><br><span class="line">-u：uid，用户的id（用户的标识符），系统默认会从500 之后按顺序分配uid，如果不想使用系统分配的，可以通过该选项自定义【类似于腾讯QQ 的自选靓号情况】</span><br><span class="line"></span><br><span class="line"> -L：锁定用户，锁定后用户无法登陆系统lock</span><br><span class="line"></span><br><span class="line">     -U：解锁用户unlock</span><br><span class="line"></span><br><span class="line"> -c&lt;备注&gt;：修改用户帐号的备注文字</span><br><span class="line"></span><br><span class="line"> -d&lt;登入目录&gt;：修改用户登入时的目录</span><br><span class="line"></span><br><span class="line"> -s<span class="tag">&lt;<span class="name">shell</span>&gt;</span>：修改用户登入后所使用的shell</span><br></pre></td></tr></table></figure><p><strong>企业场景2：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">公司员工wangwu，属于bigdata部门，现在要休产假，产假期间，暂时停止她登陆电脑的权限，同时原来属于wyhshujia部门的员工lisi，负责wangwu的工作，所以，需要把lisi加入到bigdata的组，同时，修改lisi的账户注释为“wyhshujia bigdata user”</span><br><span class="line"></span><br><span class="line">对于wangwu用户，我们要执行锁定和解锁操作</span><br><span class="line"></span><br><span class="line">对于lisi用户，我们要将lisi加入到bigdata的附加组，同时修改lisi账户的注释</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master hzh]<span class="comment"># usermod -L wangwu</span></span><br><span class="line">usermod：用户“wangwu”不存在</span><br><span class="line">[root@master hzh]<span class="comment"># useradd -G bigdata -u 1300 -c &quot;大数据开发&quot; wangwuuseradd：“bigdata”组不存在</span></span><br><span class="line">[root@master hzh]<span class="comment"># groupadd bigdata</span></span><br><span class="line">[root@master hzh]<span class="comment"># useradd -G bigdata -u 1300 -c &quot;大数据开发&quot; wangwu</span></span><br><span class="line">[root@master hzh]<span class="comment"># usermod -L wangwu</span></span><br><span class="line"></span><br><span class="line">用法一：usermod -L 王五账户名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="comment">#usermod -L wangwu</span></span><br><span class="line">含义：将王五账户暂时锁定</span><br><span class="line"></span><br><span class="line">用法二：usermod -U 王五账户名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="comment">#usermod -U wangwu</span></span><br><span class="line">含义：将王五账户解锁</span><br></pre></td></tr></table></figure><figure class="highlight swift"><table><tr><td class="code"><pre><span class="line">用法三：usermod <span class="operator">-</span><span class="type">G</span> 组名 <span class="operator">-</span>c “注释内容” 李四用户账号</span><br><span class="line">示例代码：</span><br><span class="line">#usermod <span class="operator">-</span><span class="type">G</span> bigdata <span class="operator">-</span>c <span class="string">&quot;bigdata user&quot;</span> lisi</span><br><span class="line">含义：将李四的账户加入bigdata组，并修改注释内容为shhr user</span><br></pre></td></tr></table></figure><h3 id="⑤passwd修改用户密码"><a href="#⑤passwd修改用户密码" class="headerlink" title="⑤passwd修改用户密码"></a>⑤passwd修改用户密码</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Linux ==不允许没有密码的用户登录到系统==，因此前面创建的用户目前都处于锁定状态，需要设置密码之后才能登录计算机。</span><br></pre></td></tr></table></figure><p>命令：passwd</p><p>语法：# passwd  用户名 【如果不指定用户名则修改自己的密码】</p><p>作用：修改用户密码<br> <strong>企业场景3：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">王五产假休完回到公司上班，需要将王五的账户解锁，在使用usermod -U解锁时，我们看到一个错误信息如下：</span><br></pre></td></tr></table></figure><p>usermod: unlocking the user’s password would result in a passwordless account.</p><p>解锁这个账户，将导致一个没有密码的账户，因为之前王五的账户没有密码。这时候，我们就需要使用passwd命令，给王五的账户设置一个密码</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">用法一：passwd 账户名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="comment">#passwd wangwu</span></span><br><span class="line">含义：为wangwu账户设置密码</span><br><span class="line">注意：</span><br><span class="line">    当密码过于简单时，系统会提示这是一个不好的密码，因为它太简单了，但是我们仍然可以坚持使用这个密码。</span><br><span class="line">    在我们输入密码时，屏幕不会有任何显示。</span><br><span class="line">    密码需要输入两次，请确保两次输入的密码是一样的。</span><br></pre></td></tr></table></figure><h3 id="⑥认识-x2F-etc-x2F-shadow文件"><a href="#⑥认识-x2F-etc-x2F-shadow文件" class="headerlink" title="⑥认识&#x2F;etc&#x2F;shadow文件"></a>⑥认识&#x2F;etc&#x2F;shadow文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">由于 /etc/passwd文件允许所有用户读取，易导致用户密码泄露，因此 Linux 系统将用户的密码信息从 /etc/passwd 文件中分离出来，并单独放到了shadow文件中。</span><br><span class="line"></span><br><span class="line">/etc/shadow 文件只有 root 用户拥有读权限，其他用户没有任何权限，这样就保证了用户密码的安全性。  </span><br></pre></td></tr></table></figure><p>与用户密码相关的文件：&#x2F;etc&#x2F;shadow</p><p>为用户设置密码之后，会自动在&#x2F;etc&#x2F;shadow文件中进行体现，使用vim编辑器打开</p><p>第一列为用户名，例如zhangsan</p><p>后面是加密后的密码，就是$开头的字符串</p><p>如果显示为!!,则表示这个用户&#x3D;&#x3D;没有&#x3D;&#x3D;设置密码。</p><p>由以上截图所知，wyh,lisi是没有设置密码的。wangwu我们刚刚设置了密码，所以显示为一个加密的字符创</p><p>任务：新建一个账户叫shujiaxiaoli</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">新建第二个账户叫shujiaxiaoli</span><br><span class="line"></span><br><span class="line">给shujiaxiaoli账户设置一个密码</span><br><span class="line"></span><br><span class="line">进入shadow文件，观察两个账户的区别</span><br></pre></td></tr></table></figure><h3 id="⑦su切换用户"><a href="#⑦su切换用户" class="headerlink" title="⑦su切换用户"></a>⑦su切换用户</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在设置用户密码之后就可以使用此账号进行登录系统了，如果系统处于已登录状态，则可以使用su命令进行切换用户。</span><br><span class="line"></span><br><span class="line">为了系统安全，企业中通常不会允许root用户直接登录计算机，但是工作需要，我们又需要使用root权限，这时候，我们就可以先使用一个普通用户登录计算机，再通过su命令切换到root权限。</span><br></pre></td></tr></table></figure><p>命令：su</p><p>语法：# su  [-]   账号</p><p>作用：切换用户</p><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">用法一：su 用户名</span><br><span class="line">示例代码：</span><br><span class="line"><span class="selector-id">#su</span> root</span><br><span class="line">含义：切换到root权限</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line"><span class="selector-tag">a</span>. 从root 往普通用户切换不需要密码，但是反之则需要root 密码；</span><br><span class="line"><span class="selector-tag">b</span>. 切换用户之后前后的工作路径是不变的，添加了选项<span class="selector-attr">[-]</span>会自动切换到用户的家；</span><br><span class="line">c. 普通用户没有办法访问root 用户家目录，但是反之则可以；</span><br></pre></td></tr></table></figure><p>启用wheel组设置（了解）</p><p>步骤1：使用vim编辑器 打开&#x2F;etc&#x2F;pam.d&#x2F;su文件</p><p>步骤2：编辑文件，去掉auth required pam_wheel.so use_uid这一行前面的#，使这一行配置生效</p><p>步骤3：下面是去掉#后的状态</p><p>步骤4：保存退出 ：wq<br>这时，只有在wheel组内的用户才可以su到root</p><p><img src="https://s2.loli.net/2022/04/25/9CUH3kfQtROpW5K.png" alt="image-20220425225804162"></p><p> ⑧userdel删除用户<br> 命令：userdel</p><p>语法：# userdel   选项   用户名</p><p>作用：删除账户及其对应家目录</p><p>选项：-r：表示删除用户的同时，删除其家目录&#x2F;home下的对应文件夹</p><p>权限:<br>    通过ll查看详细信息时:-rw-r–r–. 1 root root     11 4月  24 21:22 xiao.txt<br>    -:表示类型<br>    rw-:当前用户权限<br>    r–:当前用户组权限<br>    r–:其他用户权限</p><pre><code>r:读     4w:写     2x:执行   1u:当前用户g:当前组o:其他a:所有</code></pre><p>权限分配<br>    chmod:修改权限<br>        格式1:(使用相加减表达权限)<br>            chmod [选项] [权限修改] [文件]<br>        格式2:(使用数字表达权限)<br>            chmod [选项] [权限修改] [文件]<br>            4:读<br>            2:写<br>            1:执行<br>            7:全部<br>        注意:如果只给一个数字表示修改o,两个表示修改go<br>        选项:<br>            -R:迭代修改</p><pre><code>chgrp:修改用户组    格式:        chgrp [选项] [组名] [文件或目录]    选项:        -R:表达迭代修改    注意:文件或目录的所有用户或所有组,都是以编号来查询所有用户或所有组        如果不存在就显示编号,存在显示名称chown:修改所属用户    格式:        chown [选项] [组名] [文件或目录]    选项:        -R:表达迭代修改sudo:越权执行    格式:        sudo 命令    注意:sudo实际上去借root权限执行命令(root对普通用户分配了权限)sudo -l:查看当前权限visudo:修改配置文件进行权限分配(文件所在位置/etc/sudoers)    例如:普通用户拥有root所有权限        用户名 ALL=(ALL) ALL        用户名 ALL=(root) ALL    例如:普通用户只能执行一个命令        用户名 ALL=(root)/bin/rm可以同过vim /etc/sudoers修改权限分配</code></pre><p>查找<br>    find<br>        格式:<br>            find 开始查找路径 [选项] [条件]<br>        选项:<br>            -name<br>                <em>表示匹配所有<br>                ?表示匹配一个<br>                例如:从&#x2F;开始查找后缀为.txt<br>                    find &#x2F; -name “</em>.txt”<br>            -type<br>                d:表示目录<br>                f:表示文件<br>                例如:从&#x2F;开始查找文件<br>                    find &#x2F; -type f<br>            -size<br>                ll –block-size&#x3D;单位<br>                    例如:大小以k为单位进行显示<br>                        ll –block-size&#x3D;k<br>                注意:条件需要给上单位<br>                    +表示大于<br>                    -表示小于<br>                    不给就是等于<br>                例如:从&#x2F;开始查找文件大小大于2k<br>                    find &#x2F; -size +2k<br>            -user<br>            -group<br>Linux常见符号<br>    |:管道,把前面一部分的内容交给后面去处理<br>    例如:<br>        cat &#x2F;etc&#x2F;profile | more</p><pre><code>grep:筛选    格式:        grep 筛选条件&gt;&gt;:追加,把命令1的结果写入到命令2    格式:        命令1 &gt;&gt; 命令2     例如:cat profile &gt;&gt; test.txt&gt;:覆盖    格式:        命令1 &gt; 命令2     例如:cat profile &gt; test.txt</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础</title>
      <link href="/2022/04/23/linux%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/04/23/linux%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><h5 id="linux基础命令："><a href="#linux基础命令：" class="headerlink" title="linux基础命令："></a>linux基础命令：</h5><blockquote><p>1、ll 和 ls    查看当前目录下所有的文件和文件夹<br>2、cd    切换目录<br>3、pwd    查看当前目录的一个完整路径<br>4、ls -a    列出当前目录下的所有文件（包括隐藏文件）<br>5、stat 文件名    查看文件信息<br>6、ls –help    查看ls用法（–help查看命令使用手册）<br>7、mkdir    文件夹的名称<br>8、mkdir-p ….    创建多级文件夹<br>9、touch 文件名    创建文件<br>10、mv    移动一个文件，可以在移动的同时修改文件名<br>11、cp    复制文件<br>12、.    当前目录    ..    上一级目录<br>13、rm 文件的名称    删除一个文件，会进行提示，输入y则表示删除，输入n表示不删除<br>14、rm -f 文件的名称    不进行提示强制删除一个文件<br>15、rm -r    删除一个文件或文件夹，会进行提示，输入y则表示删除，输入n表示不删除<br>16、rm -rf    强制删除文件或文件夹，不进行提示   使用时一定要注意路径！！！<br>17、cat 文件名    不打开文件查看文件内容<br>18、tac 文件名    不打开文件倒序查看内容<br>19、cat file1 file2 &gt; file3    文件合并   ，注意的是file3目标文件可以不存在，会自动创建，如果存在则会覆盖原本内容<br>20、cat -b    显示行号输出<br>21、分屏显示 more    用一次显示一屏，没有显示完时最后一行显示进度。回车显示下一行，按b显示上一页，空格显示下一页，q退出。</p></blockquote><h5 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h5><blockquote><p>touch 文件名    创建一个文件<br>vi 文件名    创建打开并编辑</p></blockquote><h5 id="vi-打开文件"><a href="#vi-打开文件" class="headerlink" title="vi 打开文件"></a>vi 打开文件</h5><blockquote><p>按下i进入编辑模式</p><p>按下esc 退出编辑模式</p><p>英文输入状态下 输入：</p><p>输入wq    表示保存并退出</p><p>输入q!    表示不保存退出</p><p>进入编辑模式后退格一个一个字符删除</p><p>不进入编辑模式 连续两次 d表示删除一行</p><p>另外一种编辑模式 vim</p><p>centOS7并不自带这种编辑命令，需要额外下载安装</p><p>通过yum进行下载并安装 （类比python中的pip）</p><p>yum install vim</p><p>yum -y install vim   使用这个命令在安装过程中不需要手动输入y进行继续，默认都是y</p></blockquote><h5 id="linux安装jdk1-8"><a href="#linux安装jdk1-8" class="headerlink" title="linux安装jdk1.8"></a>linux安装jdk1.8</h5><blockquote><p>1、上传jdk压缩包到&#x2F;usr&#x2F;local&#x2F;soft&#x2F;目录下<br>2、使用解压命令进行解压  tar -zxvf jdk-8u171-linux-x64.tar.gz<br>3、配置环境变量<br>        在linux中环境的变量的文件是&#x2F;etc&#x2F;profile<br>4、打开并编辑环境变量文件<br>        vim &#x2F;etc&#x2F;profile<br>5、按下i进入编辑模式（注意：不要修改文件原本的内容，我们增加环境变量只需要额外增加即可，不要动原本的内容！！！！！！）<br>        export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;soft&#x2F;jdk1.8.0_171<br>        export PATH&#x3D;.:$PATH:$JAVA_HOME&#x2F;bin<br>6、保存退出<br>7、在linux中环境变量修改完后需要使用命令让其生效<br>        source &#x2F;etc&#x2F;profile<br><strong>可能会出现的错误：</strong><br>1、发现交换文件 “&#x2F;etc&#x2F;.profile.swp”<br>            所有者: root    日期: Sat Apr 23 15:35:57 2022<br>            文件名: &#x2F;etc&#x2F;profile<br>            修改过: 是<br>            用户名: root      主机名: master<br>           进程 ID: 61454<br>正在打开文件 “&#x2F;etc&#x2F;profile”<br>              日期: Sat Apr 23 15:2<br>这是由于上一次打开的文件没有正确关闭导致的，需要删除交换文件： rm -rf &#x2F;etc&#x2F;.profile.swp</p></blockquote><h5 id="修改主机名（centOS7）"><a href="#修改主机名（centOS7）" class="headerlink" title="修改主机名（centOS7）"></a>修改主机名（centOS7）</h5><blockquote><p>vim &#x2F;etc&#x2F;hostname<br>修改后需要重启虚拟机<br>使用命令重启：reboot</p></blockquote><h5 id="centOS7关闭防火墙"><a href="#centOS7关闭防火墙" class="headerlink" title="centOS7关闭防火墙"></a>centOS7关闭防火墙</h5><blockquote><p>systemctl stop firewalld.service #停止firewall<br>systemctl disable firewalld.service #禁止firewall开机启动</p></blockquote><h5 id="查看防火墙状态"><a href="#查看防火墙状态" class="headerlink" title="查看防火墙状态"></a>查看防火墙状态</h5><blockquote><p>firewall-cmd –state<br>systemctl status firewalld.service</p></blockquote><h5 id="启动防火墙"><a href="#启动防火墙" class="headerlink" title="启动防火墙"></a>启动防火墙</h5><blockquote><p>systemctl start firewalld.service</p></blockquote><h5 id="关闭networkmanage服务（centOS7内置一个网络服务）"><a href="#关闭networkmanage服务（centOS7内置一个网络服务）" class="headerlink" title="关闭networkmanage服务（centOS7内置一个网络服务）"></a>关闭networkmanage服务（centOS7内置一个网络服务）</h5><blockquote><p>systemctl status NetworkManager    #查看NetworkManager状态<br>systemctl stop NetworkManager    #停止NetworkManager<br>systemctl disable NetworkManager    #禁止NetworkManager开机启动</p></blockquote><h3 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h3><blockquote><p>1、克隆之前不要开启被克隆的虚拟机<br>2、注意：克隆过程中需要选择完整克隆！！！<br>3、克隆完后不要立即启动，因为mac地址和被克隆的虚拟机一模一样，需要修改克隆后虚拟机的mac地址<br>4、需要修改克隆后虚拟机的主机名和ip地址，先不要启动被克隆的虚拟机<br>5、修改主机名：<br>        cd &#x2F;etc<br>        vim hostname<br>        修改后重启生效<br>6、修改ip地址<br>        cd &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts<br>        vim ifcfg-ens33<br>7、重启 reboot</p></blockquote><h5 id="基础命令进阶："><a href="#基础命令进阶：" class="headerlink" title="基础命令进阶："></a>基础命令进阶：</h5><h6 id="1、远程复制命令："><a href="#1、远程复制命令：" class="headerlink" title="1、远程复制命令："></a>1、远程复制命令：</h6><p>​        远程复制文件：scp test.txt 192.168.40.130:&#x2F;usr&#x2F;local&#x2F;soft&#x2F;<br>​        远程复制文件夹：scp -r aaaa 192.168.40.120:&#x2F;usr&#x2F;local&#x2F;soft&#x2F;</p><h6 id="2、配置ip映射"><a href="#2、配置ip映射" class="headerlink" title="2、配置ip映射"></a>2、配置ip映射</h6><p>​    2.1、vim &#x2F;etc&#x2F;hosts</p><p>​        添加如下内容：</p><p>​            192.168.40.110  master<br>​            192.168.40.120  node1<br>​            192.168.40.130  node2</p><p>​    2.2、远程复制到其他节点上，覆盖原来的hosts文件，每台虚拟机都要进行覆盖<br>​        scp &#x2F;etc&#x2F;hosts node1:&#x2F;etc&#x2F;hosts<br>​        scp &#x2F;etc&#x2F;hosts node2:&#x2F;etc&#x2F;hosts</p><p>​    2.3、覆盖完后，尝试ping其他虚拟机</p><h6 id="3、配置免密操作（每个虚拟机都要进行操作）"><a href="#3、配置免密操作（每个虚拟机都要进行操作）" class="headerlink" title="3、配置免密操作（每个虚拟机都要进行操作）"></a>3、配置免密操作（每个虚拟机都要进行操作）</h6><p>​     <strong>在任意目录都可以执行</strong><br>​        3.1 ssh-keygen -t rsa 然后三次回车<br>​        3.2  ssh-copy-id -i 主机名<br>​            注意：生成密钥的虚拟机复制密钥的时候，自己也要复制一份<br>​            举例：ssh-copy-id -i master<br>​                        ssh-copy-id -i node1<br>​                        ssh-copy-id -i node2</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maven</title>
      <link href="/2022/04/15/maven/"/>
      <url>/2022/04/15/maven/</url>
      
        <content type="html"><![CDATA[<h4 id="1、更换阿里云镜像"><a href="#1、更换阿里云镜像" class="headerlink" title="1、更换阿里云镜像"></a>1、更换阿里云镜像</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 阿里镜像 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/repositories/central/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>Maven Repository Switchboard<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo1.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>repo2<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo2.maven.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>ibiblio<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>Human Readable Name for this Mirror.<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://mirrors.ibiblio.org/pub/mirrors/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>jboss-public-repository-group<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>JBoss Public Repository Group<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repository.jboss.org/nexus/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>google-maven-central<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>Google Maven Central<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven-central.storage.googleapis.com</span><br><span class="line"><span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 中央仓库在中国的镜像 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>maven.net.cn<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>oneof the central mirrors in china<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.net.cn/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> maven </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正则表达式</title>
      <link href="/2022/04/01/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/2022/04/01/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><blockquote><p>需求：编写一个java程序检验qq号是否符合规范</p><p>​    1、必须全部都是数字</p><p>​    2、必须是5-10</p><p>​    3、不能以0开头</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">需求：编写一个java程序检验qq号是否符合规范</span></span><br><span class="line"><span class="comment">    1、必须是5-10</span></span><br><span class="line"><span class="comment">    2、不能以0开头</span></span><br><span class="line"><span class="comment">3、必须全部都是数字</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="string">&quot;1165872335&quot;</span>;</span><br><span class="line">        System.out.println(checkQQ(s));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//感受一下使用正则表达式来解决这个需求</span></span><br><span class="line">        System.out.println(checkQQ2(s));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">checkQQ2</span><span class="params">(String s)</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//正则表达式可以很容易地完成字符串地查找匹配替换等工作</span></span><br><span class="line">        <span class="comment">//正则表达式实现</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;[1-9][0-9]&#123;4,9&#125;&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> s.matches(regex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">checkQQ</span><span class="params">(String s)</span>&#123;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//必须是5-10位</span></span><br><span class="line">        <span class="keyword">if</span>(s.length()&gt;=<span class="number">5</span> &amp;&amp; s.length()&lt;=<span class="number">10</span>)&#123;</span><br><span class="line">            <span class="comment">//不能以0开头</span></span><br><span class="line">            <span class="keyword">if</span>(!s.startsWith(<span class="string">&quot;0&quot;</span>))&#123;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//将字符串转成字符数组</span></span><br><span class="line">                <span class="type">char</span>[] chars = s.toCharArray();</span><br><span class="line">                <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;chars.length;i++)&#123;</span><br><span class="line">                    <span class="comment">//包装类Character类中有一个方法可以进行判断该字符是否是数字</span></span><br><span class="line">                    <span class="comment">//public static boolean isDigit(char ch)确定指定的字符是否是数字。</span></span><br><span class="line">                    <span class="keyword">if</span>(!Character.isDigit(chars[i]))&#123;</span><br><span class="line">                        flag = <span class="literal">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;长度不符合规范，不是qq号&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">长度不符合规范，不是qq号</span><br><span class="line"><span class="literal">false</span></span><br><span class="line"><span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="学习正则表达式-正则表达式本身是一个字符串"><a href="#学习正则表达式-正则表达式本身是一个字符串" class="headerlink" title="学习正则表达式(正则表达式本身是一个字符串)"></a>学习正则表达式(正则表达式本身是一个字符串)</h4><blockquote><p>学习正则表达式的目的：通过正则表达式进行处理字符串的复杂的查找&#x2F;替换&#x2F;匹配&#x2F;分割等工作。</p><p>正则表达式是一个独立于任何一门语言的技术，不依附于java,但是它可以在java中进行使用，也可以在python&#x2F;Js等语言中进行使用</p></blockquote><h3 id="正则表达式的概述"><a href="#正则表达式的概述" class="headerlink" title="正则表达式的概述"></a>正则表达式的概述</h3><blockquote><p>概念：使用单个字符串来描述或者匹配一系列符合某种语法规则的字符串</p><p>正则表达式的使用步骤：</p><p>​    1、使用大量的字符串来寻找规律使用正则语法来定义规则<br>​    2、使用这种规则区匹配新的字符串</p><p>​    3、匹配成功后的相应的操作</p></blockquote><p><a href="mailto:&#x31;&#49;&#54;&#53;&#56;&#x37;&#x32;&#x33;&#x33;&#53;&#64;&#x71;&#113;&#46;&#x63;&#111;&#109;">&#x31;&#49;&#54;&#53;&#56;&#x37;&#x32;&#x33;&#x33;&#53;&#64;&#x71;&#113;&#46;&#x63;&#111;&#109;</a></p><h3 id="正则表达式语法规则"><a href="#正则表达式语法规则" class="headerlink" title="正则表达式语法规则"></a>正则表达式语法规则</h3><h4 id="1、原义字符（字符本身就可以当作一个正则表达式）"><a href="#1、原义字符（字符本身就可以当作一个正则表达式）" class="headerlink" title="1、原义字符（字符本身就可以当作一个正则表达式）"></a>1、原义字符（字符本身就可以当作一个正则表达式）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a\b\c\...\z \t \r \n</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        原义字符（字符本身就可以当作一个正则表达式）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;a&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abc12342121sadsa&amp;.;123!&quot;</span>;</span><br><span class="line">        <span class="comment">//String replaceAll(String regex, String replacement)</span></span><br><span class="line">        <span class="comment">//用给定的替换替换与给定的 regular expression匹配的此字符串的每个子字符串。</span></span><br><span class="line">        System.out.println(str.replaceAll(regex,<span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">_bc12342121s_ds_&amp;.;<span class="number">123</span>!</span><br></pre></td></tr></table></figure><h4 id="正则表达是元字符高级用法"><a href="#正则表达是元字符高级用法" class="headerlink" title="正则表达是元字符高级用法"></a>正则表达是元字符高级用法</h4><table><thead><tr><th align="left">字符</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">\</td><td align="left">将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，’n’ 匹配字符 “n”。’\n’ 匹配一个换行符。序列 ‘\‘ 匹配 “&quot; 而 “(“ 则匹配 “(“。</td></tr><tr><td align="left">^</td><td align="left">匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置。</td></tr><tr><td align="left">$</td><td align="left">匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置。</td></tr><tr><td align="left">*</td><td align="left">匹配前面的子表达式零次或多次。例如，zo* 能匹配 “z” 以及 “zoo”。* 等价于{0,}。</td></tr><tr><td align="left">+</td><td align="left">匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。</td></tr><tr><td align="left">?</td><td align="left">匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 。? 等价于 {0,1}。</td></tr><tr><td align="left">{n}</td><td align="left">n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。</td></tr><tr><td align="left">{n,}</td><td align="left">n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。</td></tr><tr><td align="left">{n,m}</td><td align="left">m 和 n 均为非负整数，其中n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。</td></tr><tr><td align="left">?</td><td align="left">当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。</td></tr><tr><td align="left">.</td><td align="left">匹配除换行符（\n、\r）之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用像”<strong>(.|\n)</strong>“的模式。</td></tr><tr><td align="left">(pattern)</td><td align="left">匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ‘(‘ 或 ‘)‘。</td></tr><tr><td align="left">(?:pattern)</td><td align="left">匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (|) 来组合一个模式的各个部分是很有用。例如， ‘industr(?:y|ies) 就是一个比 ‘industry|industries’ 更简略的表达式。</td></tr><tr><td align="left">(?&#x3D;pattern)</td><td align="left">正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，”Windows(?&#x3D;95|98|NT|2000)”能匹配”Windows2000”中的”Windows”，但不能匹配”Windows3.1”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。</td></tr><tr><td align="left">(?!pattern)</td><td align="left">正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如”Windows(?!95|98|NT|2000)”能匹配”Windows3.1”中的”Windows”，但不能匹配”Windows2000”中的”Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。</td></tr><tr><td align="left">(?&lt;&#x3D;pattern)</td><td align="left">反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反。例如，”&#96;(?&lt;&#x3D;95</td></tr><tr><td align="left">(?&lt;!pattern)</td><td align="left">反向否定预查，与正向否定预查类似，只是方向相反。例如”&#96;(?&lt;!95</td></tr><tr><td align="left">x|y</td><td align="left">匹配 x 或 y。例如，’z|food’ 能匹配 “z” 或 “food”。’(z|f)ood’ 则匹配 “zood” 或 “food”。</td></tr><tr><td align="left">[xyz]</td><td align="left">字符集合。匹配所包含的任意一个字符。例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’。</td></tr><tr><td align="left">[^xyz]</td><td align="left">负值字符集合。匹配未包含的任意字符。例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’、’l’、’i’、’n’。</td></tr><tr><td align="left">[a-z]</td><td align="left">字符范围。匹配指定范围内的任意字符。例如，’[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。</td></tr><tr><td align="left">[^a-z]</td><td align="left">负值字符范围。匹配任何不在指定范围内的任意字符。例如，’[^a-z]’ 可以匹配任何不在 ‘a’ 到 ‘z’ 范围内的任意字符。</td></tr><tr><td align="left">\b</td><td align="left">匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td></tr><tr><td align="left">\B</td><td align="left">匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。</td></tr><tr><td align="left">\cx</td><td align="left">匹配由 x 指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。</td></tr><tr><td align="left">\d</td><td align="left">匹配一个数字字符。等价于 [0-9]。</td></tr><tr><td align="left">\D</td><td align="left">匹配一个非数字字符。等价于 [^0-9]。</td></tr><tr><td align="left">\f</td><td align="left">匹配一个换页符。等价于 \x0c 和 \cL。</td></tr><tr><td align="left">\n</td><td align="left">匹配一个换行符。等价于 \x0a 和 \cJ。</td></tr><tr><td align="left">\r</td><td align="left">匹配一个回车符。等价于 \x0d 和 \cM。</td></tr><tr><td align="left">\s</td><td align="left">匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。</td></tr><tr><td align="left">\S</td><td align="left">匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。</td></tr><tr><td align="left">\t</td><td align="left">匹配一个制表符。等价于 \x09 和 \cI。</td></tr><tr><td align="left">\v</td><td align="left">匹配一个垂直制表符。等价于 \x0b 和 \cK。</td></tr><tr><td align="left">\w</td><td align="left">匹配字母、数字、下划线。等价于’[A-Za-z0-9_]’。</td></tr><tr><td align="left">\W</td><td align="left">匹配非字母、数字、下划线。等价于 ‘[^A-Za-z0-9_]’。</td></tr><tr><td align="left">\xn</td><td align="left">匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，’\x41’ 匹配 “A”。’\x041’ 则等价于 ‘\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。</td></tr><tr><td align="left">\num</td><td align="left">匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，’(.)\1’ 匹配两个连续的相同字符。</td></tr><tr><td align="left">\n</td><td align="left">标识一个八进制转义值或一个向后引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。</td></tr><tr><td align="left">\nm</td><td align="left">标识一个八进制转义值或一个向后引用。如果 \nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。</td></tr><tr><td align="left">\nml</td><td align="left">如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。</td></tr><tr><td align="left">\un</td><td align="left">匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。</td></tr></tbody></table><h5 id="字符类："><a href="#字符类：" class="headerlink" title="字符类："></a>字符类：</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        正则表达式的语法规则：</span></span><br><span class="line"><span class="comment">        字符类：</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo3</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//[]作用是将字符进行分类，可以匹配到中括号中的任意一个字符</span></span><br><span class="line">        <span class="comment">//[abc]将来会匹配到abc中任意一个字符</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;[abc]&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abc1234cc21c21sadcsa&amp;.;123!&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex,<span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>运行结果</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">___1234__21_21s_d_s_&amp;.;<span class="number">123</span>!</span><br></pre></td></tr></table></figure><h5 id="范围类："><a href="#范围类：" class="headerlink" title="范围类："></a>范围类：</h5><blockquote><p>其实就是在字符类的基础之上增加了一个范围</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        范围类：</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo4</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//需求1：我想要匹配所有的小写字母</span></span><br><span class="line"><span class="comment">//        String regex = &quot;[abcdefghijklmnopqrstuvwxyz]&quot;;</span></span><br><span class="line">        <span class="comment">//[a-z]表示匹配a到z中的所有小写字母</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;[a-z]&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abcABC1234ERQcc21c21sDASadcsABCCa&amp;.;123!&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;要匹配的字符串为：\n&quot;</span> + str);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========================================&quot;</span>);</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求2：我想要匹配所有的大写字母</span></span><br><span class="line">        regex = <span class="string">&quot;[A-Z]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求3：我即想要匹配小写字母，也想要匹配大写字母</span></span><br><span class="line"><span class="comment">//        regex = &quot;[a-zA-Z]&quot;;</span></span><br><span class="line">        regex = <span class="string">&quot;[A-z]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求4：我想要匹配所有的数字</span></span><br><span class="line">        regex = <span class="string">&quot;[0-9]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求5：我想匹配不仅大小写数字还有感叹号，分号咋办？</span></span><br><span class="line">        regex = <span class="string">&quot;[0-9a-zA-Z!;&amp;.]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//需求6：我想匹配除了大小写字母和数字以外的符号</span></span><br><span class="line">        regex = <span class="string">&quot;[^0-9a-zA-Z]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">要匹配的字符串为：</span><br><span class="line">abcABC1234ERQcc21c21sDASadcsABCCa&amp;.;<span class="number">123</span>!</span><br><span class="line">==========================================</span><br><span class="line">___ABC1234ERQ__21_21_DAS____ABCC_&amp;.;<span class="number">123</span>!</span><br><span class="line">abc___1234___cc21c21s___adcs____a&amp;.;<span class="number">123</span>!</span><br><span class="line">______1234_____21_21_____________&amp;.;<span class="number">123</span>!</span><br><span class="line">abcABC____ERQcc__c__sDASadcsABCCa&amp;.;___!</span><br><span class="line">________________________________________</span><br><span class="line">abcABC1234ERQcc21c21sDASadcsABCCa___123_</span><br></pre></td></tr></table></figure><h5 id="预定义类："><a href="#预定义类：" class="headerlink" title="预定义类："></a>预定义类：</h5><blockquote><p>我们在上面的范围类的情况下，在实际开发中我们可能会遇见一些常见的需求：判断是否是数字，是否是小写字母，是否是大写字母等等这些情况，用上面范围类的写法的话正则会比较长，所以在正则表达式中会给出一些含有特殊含义的表达式，这些表达式更加简化了我们使用范围类的用法，统称为预定义类，具体我们来探讨一下有哪些：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\d == [0-9] 代表的是数字</span><br><span class="line">\D == [^0-9]代表的是非数字</span><br><span class="line">\s == 空白字符</span><br><span class="line">\w == [a-zA-Z0-9]</span><br><span class="line">\W == [^a-zA-Z0-9]</span><br><span class="line">.  == 任意字符</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        预定义类</span></span><br><span class="line"><span class="comment">        \d == [0-9] 代表的是数字</span></span><br><span class="line"><span class="comment">        \D == [^0-9]代表的是非数字</span></span><br><span class="line"><span class="comment">        \s == 空白字符</span></span><br><span class="line"><span class="comment">        \w == [a-zA-Z0-9]</span></span><br><span class="line"><span class="comment">        \W == [^a-zA-Z0-9]</span></span><br><span class="line"><span class="comment">        .  == 任意字符</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo5</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;\\d&quot;</span>;  <span class="comment">// \\d代表转义，使用它原本的意思</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abcABC 1234  ERQcc2 1c21sDA Sadcs ABC Ca&amp;.;12  3!&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;要匹配的字符串为：\n&quot;</span> + str);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========================================&quot;</span>);</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;\\D&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;\\s&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;\\w&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;\\W&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;.&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//仅仅单纯要匹配一个字符.</span></span><br><span class="line">        regex = <span class="string">&quot;[.]&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">        regex = <span class="string">&quot;\\.&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">要匹配的字符串为：</span><br><span class="line">abcABC <span class="number">1234</span>  ERQcc2 1c21sDA Sadcs ABC Ca&amp;.;<span class="number">12</span>  <span class="number">3</span>!</span><br><span class="line">==========================================</span><br><span class="line">abcABC ____  ERQcc_ _c__sDA Sadcs ABC Ca&amp;.;__  _!</span><br><span class="line">_______1234_______2_1_21___________________12__3_</span><br><span class="line">abcABC_1234__ERQcc2_1c21sDA_Sadcs_ABC_Ca&amp;.;<span class="number">12__3</span>!</span><br><span class="line">______ ____  ______ _______ _____ ___ __&amp;.;__  _!</span><br><span class="line">abcABC_1234__ERQcc2_1c21sDA_Sadcs_ABC_Ca___12__3_</span><br><span class="line">_________________________________________________</span><br><span class="line">abcABC <span class="number">1234</span>  ERQcc2 1c21sDA Sadcs ABC Ca&amp;_;<span class="number">12</span>  <span class="number">3</span>!</span><br><span class="line">abcABC <span class="number">1234</span>  ERQcc2 1c21sDA Sadcs ABC Ca&amp;_;<span class="number">12</span>  <span class="number">3</span>!</span><br></pre></td></tr></table></figure><h5 id="边界类字符"><a href="#边界类字符" class="headerlink" title="边界类字符"></a>边界类字符</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">^:以xxx开头</span><br><span class="line">$:以xxx结尾</span><br><span class="line">\b:单词边界</span><br><span class="line">\B:非单词边界</span><br></pre></td></tr></table></figure><h5 id="量词分类"><a href="#量词分类" class="headerlink" title="量词分类"></a>量词分类</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">?:出现了<span class="number">0</span>次或者<span class="number">1</span>次</span><br><span class="line">+:代表出现了<span class="number">1</span>次或者多次</span><br><span class="line">*:代表出现了任意次</span><br><span class="line">&#123;n&#125;:代表出现了n次</span><br><span class="line">&#123;n,m&#125;:出现了n-m次</span><br><span class="line">&#123;n,&#125;:代表出现了至少n次</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        量词分类：</span></span><br><span class="line"><span class="comment">        ?:出现了0次或者1次</span></span><br><span class="line"><span class="comment">        +:代表出现了1次或者多次</span></span><br><span class="line"><span class="comment">        *:代表出现了任意次</span></span><br><span class="line"><span class="comment">        &#123;n&#125;:代表出现了n次</span></span><br><span class="line"><span class="comment">        &#123;n,m&#125;:出现了n-m次</span></span><br><span class="line"><span class="comment">        &#123;n,&#125;:代表出现了至少n次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo7</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;^b?&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;aaaaaabaaacdeaaaafg&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;要匹配的字符串为：\n&quot;</span> + str);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========================================&quot;</span>);</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;^b+&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;^a+&quot;</span>; <span class="comment">//匹配连续出现1次以上并且是开头的a</span></span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;a+&quot;</span>; <span class="comment">//匹配连续出现1次以上的a</span></span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;^a&#123;2&#125;&quot;</span>; <span class="comment">//匹配连续出现2次的a</span></span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;^a&#123;2,5&#125;&quot;</span>; <span class="comment">//匹配连续出现2次到5次的a开头</span></span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;a&#123;4,&#125;&quot;</span>; <span class="comment">//匹配连续出现4次以上</span></span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>运行结果</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">要匹配的字符串为：</span><br><span class="line">aaaaaabaaacdeaaaafg</span><br><span class="line">==========================================</span><br><span class="line">_aaaaaabaaacdeaaaafg</span><br><span class="line">aaaaaabaaacdeaaaafg</span><br><span class="line">_baaacdeaaaafg</span><br><span class="line">_b_cde_fg</span><br><span class="line">_aaaabaaacdeaaaafg</span><br><span class="line">_abaaacdeaaaafg</span><br><span class="line">_baaacde_fg</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">分组的符号：()</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        正则表达式语法：</span></span><br><span class="line"><span class="comment">        分组：()</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo8</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//将连续出现了3次以上的abc替换成_</span></span><br><span class="line"><span class="comment">//        String regex = &quot;abc&#123;3,&#125;&quot;; //ab后面接着3次以上的c</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;(abc)&#123;3,&#125;&quot;</span>; <span class="comment">//使用小括号将abc看作是一组，然后匹配这组出现了3次以上</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abccccccccABC123ABC123abcABCabcabcabc123ABC123123&quot;</span>;</span><br><span class="line">        System.out.println(<span class="string">&quot;要匹配的字符串为：\n&quot;</span> + str);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========================================&quot;</span>);</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求2：ABC后面跟上出现1次以上的123为一个整体进行匹配</span></span><br><span class="line">        <span class="comment">//ABC123123123</span></span><br><span class="line">        regex = <span class="string">&quot;ABC(123)&#123;1,&#125;&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求3：ABC后面跟上出现1次以上的123或者abc为一个整体进行匹配</span></span><br><span class="line">        <span class="comment">//ABC123123</span></span><br><span class="line">        <span class="comment">//ABCabcabc</span></span><br><span class="line">        regex = <span class="string">&quot;ABC(123|abc)&#123;1,&#125;&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">要匹配的字符串为：</span><br><span class="line">abccccccccABC123ABC123abcABCabcabcabc123ABC123123</span><br><span class="line">==========================================</span><br><span class="line">abccccccccABC123ABC123abcABC_123ABC123123</span><br><span class="line">abcccccccc__abcABCabcabcabc123_</span><br><span class="line">abcccccccc____</span><br></pre></td></tr></table></figure><h5 id="反向引用"><a href="#反向引用" class="headerlink" title="反向引用"></a>反向引用</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        反向引用</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo9</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//日期案例</span></span><br><span class="line">        <span class="comment">// 2022-03-28  ---&gt; 03/28/2022</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;2022-03-28 dasdas 2022-04-05&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex,<span class="string">&quot;$2/$3/$1&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//需求2：我不想你取出月份</span></span><br><span class="line">        regex = <span class="string">&quot;(\\d&#123;4&#125;)-(?:\\d&#123;2&#125;)-(\\d&#123;2&#125;)&quot;</span>;</span><br><span class="line">        System.out.println(str.replaceAll(regex,<span class="string">&quot;$2/$1&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">03</span>/<span class="number">28</span>/<span class="number">2022</span> dasdas <span class="number">04</span>/<span class="number">05</span>/<span class="number">2022</span></span><br><span class="line"><span class="number">28</span>/<span class="number">2022</span> dasdas <span class="number">05</span>/<span class="number">2022</span></span><br></pre></td></tr></table></figure><h4 id="正则表达式在java中的应用"><a href="#正则表达式在java中的应用" class="headerlink" title="正则表达式在java中的应用"></a>正则表达式在java中的应用</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、字符串的查找操作：Pattern和Matcher</span><br><span class="line">2、字符串的匹配操作：可以使用字符串String类中matches()方法</span><br><span class="line">3、字符串的分割操作：可以使用字符串String类中的split()方法</span><br><span class="line">4、字符串的替换工作：字符串中的replaceAll()方法和replaceFirst()方法</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.shujia.wyh.day17;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.regex.Matcher;</span><br><span class="line"><span class="keyword">import</span> java.util.regex.Pattern;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        正则表达式在Java中的应用：</span></span><br><span class="line"><span class="comment">        1、字符串的查找操作：Pattern和Matcher</span></span><br><span class="line"><span class="comment">        2、字符串的匹配操作：可以使用字符串String类中matches()方法</span></span><br><span class="line"><span class="comment">        3、字符串的分割操作：可以使用字符串String类中的split()方法</span></span><br><span class="line"><span class="comment">        4、字符串的替换工作：字符串中的replaceAll()方法和replaceFirst()方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RegularDemo10</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">regex</span> <span class="operator">=</span> <span class="string">&quot;\\w&#123;3,&#125;&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">str</span> <span class="operator">=</span> <span class="string">&quot;abcdef123;!&quot;</span>;</span><br><span class="line">        <span class="comment">//public boolean matches(String regex)告诉这个字符串是否匹配给定的regular expression 。</span></span><br><span class="line">        System.out.println(str.matches(regex));</span><br><span class="line">        System.out.println(<span class="string">&quot;======================================&quot;</span>);</span><br><span class="line"></span><br><span class="line">        regex = <span class="string">&quot;[a-z]&#123;2,&#125;&quot;</span>;</span><br><span class="line">        str = <span class="string">&quot;abc def hello 123dsa&quot;</span>;</span><br><span class="line">        System.out.println(str.matches(regex));</span><br><span class="line">        System.out.println(str.replaceAll(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line">        System.out.println(str.replaceFirst(regex, <span class="string">&quot;_&quot;</span>));</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;=======================================&quot;</span>);</span><br><span class="line">        str = <span class="string">&quot;hllo wdw worel spark&quot;</span>;</span><br><span class="line">        <span class="comment">//public String[] split(String regex)将此字符串拆分为给定的regular expression的匹配。</span></span><br><span class="line">        String[] strings = str.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; strings.length; i++) &#123;</span><br><span class="line">            System.out.println(strings[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;=======================================&quot;</span>);</span><br><span class="line">        String[] ws = str.split(<span class="string">&quot;w&quot;</span>);</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> Arrays.toString(ws);</span><br><span class="line">        System.out.println(s);</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;=======================================&quot;</span>);</span><br><span class="line">        <span class="comment">//字符串的查找操作：Pattern和Matcher</span></span><br><span class="line">        regex = <span class="string">&quot;\\w&#123;3,7&#125;&quot;</span>;</span><br><span class="line">        str = <span class="string">&quot;abcd123qqqq122321dddd44&quot;</span>;</span><br><span class="line">        <span class="comment">//创建一个java对应的正则表达式对象</span></span><br><span class="line">        <span class="comment">//public static Pattern compile(String regex)将给定的正则表达式编译为模式</span></span><br><span class="line">        <span class="type">Pattern</span> <span class="variable">compile</span> <span class="operator">=</span> Pattern.compile(regex);</span><br><span class="line">        <span class="comment">//public Matcher matcher(CharSequence input)创建一个匹配器，匹配给定的输入与此模式。</span></span><br><span class="line">        <span class="type">Matcher</span> <span class="variable">matcher</span> <span class="operator">=</span> compile.matcher(str);</span><br><span class="line">        <span class="comment">//boolean matches()</span></span><br><span class="line">        <span class="comment">//尝试将整个区域与模式进行匹配。</span></span><br><span class="line"><span class="comment">//        System.out.println(matcher.matches());</span></span><br><span class="line">        System.out.println(matcher.find());</span><br><span class="line">        <span class="comment">//int end()</span></span><br><span class="line">        <span class="comment">//返回最后一个字符匹配后的偏移量。</span></span><br><span class="line">        <span class="comment">//public int start()返回上一个匹配的起始索引。</span></span><br><span class="line"><span class="comment">//        System.out.println(matcher.start());</span></span><br><span class="line">        System.out.println(matcher.end());</span><br><span class="line">        <span class="comment">//String group()</span></span><br><span class="line">        <span class="comment">//返回与上一个匹配匹配的输入子序列。</span></span><br><span class="line">        System.out.println(matcher.group());</span><br><span class="line">        System.out.println(<span class="string">&quot;====================================&quot;</span>);</span><br><span class="line">        <span class="comment">//boolean find()</span></span><br><span class="line">        <span class="comment">//尝试找到匹配模式的输入序列的下一个子序列。</span></span><br><span class="line">        System.out.println(matcher.find());</span><br><span class="line">        <span class="comment">//int end()</span></span><br><span class="line">        <span class="comment">//返回最后一个字符匹配后的偏移量。</span></span><br><span class="line">        <span class="comment">//public int start()返回上一个匹配的起始索引。</span></span><br><span class="line"><span class="comment">//        System.out.println(matcher.start());</span></span><br><span class="line">        System.out.println(matcher.end());</span><br><span class="line">        <span class="comment">//String group()</span></span><br><span class="line">        <span class="comment">//返回与上一个匹配匹配的输入子序列。</span></span><br><span class="line">        System.out.println(matcher.group());</span><br><span class="line"><span class="comment">//        System.out.println(matcher.group());</span></span><br><span class="line">        System.out.println(<span class="string">&quot;================================&quot;</span>);</span><br><span class="line">        System.out.println(matcher.find());</span><br><span class="line">        <span class="comment">//int end()</span></span><br><span class="line">        <span class="comment">//返回最后一个字符匹配后的偏移量。</span></span><br><span class="line">        <span class="comment">//public int start()返回上一个匹配的起始索引。</span></span><br><span class="line"><span class="comment">//        System.out.println(matcher.start());</span></span><br><span class="line">        System.out.println(matcher.end());</span><br><span class="line">        <span class="comment">//String group()</span></span><br><span class="line">        <span class="comment">//返回与上一个匹配匹配的输入子序列。</span></span><br><span class="line">        System.out.println(matcher.group());</span><br><span class="line">        System.out.println(<span class="string">&quot;==================================&quot;</span>);</span><br><span class="line">        System.out.println(matcher.find());</span><br><span class="line">        <span class="comment">//int end()</span></span><br><span class="line">        <span class="comment">//返回最后一个字符匹配后的偏移量。</span></span><br><span class="line">        <span class="comment">//public int start()返回上一个匹配的起始索引。</span></span><br><span class="line"><span class="comment">//        System.out.println(matcher.start());</span></span><br><span class="line">        System.out.println(matcher.end());</span><br><span class="line">        <span class="comment">//String group()</span></span><br><span class="line">        <span class="comment">//返回与上一个匹配匹配的输入子序列。</span></span><br><span class="line">        System.out.println(matcher.group());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>运行结果</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="literal">false</span></span><br><span class="line">======================================</span><br><span class="line"><span class="literal">false</span></span><br><span class="line">_ _ _ 123_</span><br><span class="line">_ def hello 123dsa</span><br><span class="line">=======================================</span><br><span class="line">hllo</span><br><span class="line">wdw</span><br><span class="line"><span class="type">worel</span></span><br><span class="line"><span class="variable">spark</span></span><br><span class="line"><span class="operator">=</span>======================================</span><br><span class="line">[hllo , d,  , orel spark]</span><br><span class="line">=======================================</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="number">7</span></span><br><span class="line">abcd123</span><br><span class="line">====================================</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line">qqqq122</span><br><span class="line">================================</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="number">21</span></span><br><span class="line">321dddd</span><br><span class="line">==================================</span><br><span class="line"><span class="literal">false</span></span><br><span class="line">Exception in thread <span class="string">&quot;main&quot;</span> java.lang.IllegalStateException: No match available</span><br><span class="line">at java.util.regex.Matcher.end(Matcher.java:<span class="number">415</span>)</span><br><span class="line">at com.shujia.wyh.day17.RegularDemo10.main(RegularDemo10.java:<span class="number">90</span>)</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="正则表达式练习："><a href="#正则表达式练习：" class="headerlink" title="正则表达式练习："></a>正则表达式练习：</h5><p>题目：治疗口吃</p><p>将字符串“我我我我我我我……….我……..要要要要要………….要要要要….学习习习……习习习习习习习习习编程程程程程程程程程程程…..程程程程程程程程” —-&gt; “我要学习编程”</p><p>分析：1、先将.去掉      2、再将叠词变成一个</p><p>帮助理解正则表达式的网址：<a href="https://regexper.com/">https://regexper.com/</a></p>]]></content>
      
      
      <categories>
          
          <category> 正则表达式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 正则表达式 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
